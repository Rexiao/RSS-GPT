<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>微信公众号 - 量子位</title>
<link>https://posts.careerengine.us/author/599d7c52f2145121d1aa4698/posts</link>

<item>
<title>Llama 3低比特量化性能下降显著！全面评估结果来了 | 港大&amp;北航&amp;ETH</title>
<link>https://posts.careerengine.us/p/662c9107c3bb9708569a0622</link>
<guid>https://posts.careerengine.us/p/662c9107c3bb9708569a0622</guid>
<content:encoded><![CDATA[
<div> 量子位，QbitAI，LLaMA3，低比特量化，LoRA微调<br>
<br>
总结：<br>
本文介绍了LLaMA3在超大规模预训练下的低比特量化性能研究结果。研究人员评估了10种量化方法在1-8比特下的表现，发现尽管LLaMA3在量化后仍展现出较好性能，但在低比特量化下仍受到显著影响。LoRA微调量化在MMLU数据集上表现不佳，甚至使性能下降更加严重，与LLaMA1和LLaMA2的情况形成对比。研究指出，需寻求新的量化范式来弥补量化引起的性能下降，以使LLaMA3在资源受限环境中实现更强的能力。该研究强调了在低比特量化背景下的改进空间，以推动生成式人工智能的发展。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">QHT 投稿</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">大模型力大砖飞，让LLaMA3演绎出了新高度：</div><div class=" pTag">超15T Token数据上的超大规模预训练，既实现了令人印象深刻的性能提升，也因远超Chinchilla推荐量再次引爆开源社区讨论。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnEPaXL2k8d2WibH89pPqezIlmjTEQCfH1LRibeRVqe1Kd3iaEl3PzOBs6g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">与此同时，在实际应用层面上，另一个热点话题也浮出水面：</div><div class=" pTag">资源有限场景下，LLaMA3的量化表现又会如何？</div><div class=" pTag">香港大学、北京航空航天大学、苏黎世联邦理工学院联合推出了一项实证研究，全面揭示了LLaMA3的低比特量化性能。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yn6ortJEBTRgZjBfCRcTdQUTRw2jPVrUhoVtKdicnjpT5zEsDAIqQkBqw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">研究人员使用现有的10种训练后量化和LoRA微调方法，评估了LLaMA3在1-8比特和各种评估数据集上的结果。他们发现：</div><div class=" pTag">尽管性能令人印象深刻，<strong style="font-weight: 600;">LLaMA3在低比特量化下仍然遭受了不可忽视的退化，特别是在超低位宽上</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Ynac2V6ib4Jk8UJX4jbKtWmuN0kzz91eOe0wGnf2BDWT8IwKD6ib7XicnUg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">项目已在GitHub上开源，量化模型也已登陆HuggingFace。</div><div class=" pTag">具体来看实证结果。</div><h2>轨道1：训练后量化</h2><div class=" pTag">表1和表2中分别提供了LLaMA3-8B和LLaMA3-70B在8种不同的PTQ方法下的低比特性能表现，覆盖了从1比特到8比特的广泛比特宽度。</div><div class=" pTag"><span><strong style="font-weight: 600;">1.低比特权重</strong></span></div><div class=" pTag">其中，Round-To-Nearest (RTN) 是一种基本的舍入量化方法。</div><div class=" pTag">GPTQ是当前最有效率和有效的仅限权重的量化方法之一，它利用量化中的误差补偿。但在2-3比特下，当量化LLaMA3时，GPTQ会导致严重的准确性崩溃。</div><div class=" pTag">AWQ采用异常通道抑制方法来降低权重量化的难度，而QuIP通过优化矩阵计算来确保权重和Hessian之间的不一致性。它们都能保持LLaMA3在3比特时的能力，甚至将2比特量化推向有希望的水平。</div><div class=" pTag"><span><strong style="font-weight: 600;">2.超低比特权重</strong></span></div><div class=" pTag">最近出现的二值化LLM量化方法实现了超低比特宽度LLM权重压缩。</div><div class=" pTag">PB-LLM采用混合精度量化策略，保留一小部分重要权重的全精度，同时将大部分权重量化为1比特。</div><div class=" pTag">DB-LLM通过双重二值化权重分割实现高效的LLM压缩，并提出偏差感知蒸馏策略以进一步增强2比特LLM性能。</div><div class=" pTag">BiLLM通过显著权重的残差逼近和非显著权重的分组量化，进一步将LLM量化边界推低至1.1比特。这些为超低比特宽度专门设计的LLM量化方法可以实现更高精度的量化LLaMA3-8B，在⩽2比特时远远超过如GPTQ、AWQ和QuIP等方法，在2比特（甚至在某些情况下3比特）下的表现。</div><div class=" pTag"><span><strong style="font-weight: 600;">3.低比特量化激活</strong></span></div><div class=" pTag">还通过SmoothQuant对量化激活进行了LLaMA3评估，SmoothQuant将量化难度从激活转移到权重，以平滑激活异常值。评估显示，SmoothQuant可以在8比特和6比特的权重和激活下保留LLaMA3的准确性，但在4比特时面临崩溃。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnsTy0oOH2350lib4QibR07UdERnJrLxwszNdHIfrdiaCuzxaicMu4aTib0Fw/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnBhuGbItMvBnib9bXl1oQ8XicHs6OZhm6nUqwYjoaSE74xibD30icrFE5Ug/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>轨道2：LoRA微调量化</h2><div class=" pTag">在MMLU数据集上，对于LoRA-FT量化下的LLaMA3-8B，最显著的观察是，在Alpaca数据集上低秩微调不仅不能补偿量化引入的错误，甚至使性能下降更加严重。</div><div class=" pTag">具体来说，各种LoRA-FT量化方法在4比特下获得的量化LLaMA3性能，比没有使用LoRA-FT的4比特对应版本要差。这与LLaMA1和LLaMA2上的类似现象形成鲜明对比，在LLAMA1和LLAMA2中，4比特低秩微调量化版本甚至能轻松超过MMLU上的原始FP16对应版本。</div><div class=" pTag">根据直观分析，这一现象的主要原因是由于LLaMA3强大的性能得益于其大规模的预训练，这意味着原始模型量化后的性能损失不能通过在一小部分低秩参数数据上进行微调来补偿（这可以被视为原始模型的一个子集）。</div><div class=" pTag">尽管量化导致的显著下降不能通过微调来补偿，但4比特LoRA-FT量化的LLaMA3-8B在各种量化方法下显著优于LLaMA1-7B和LLaMA2-7B。例如，使用QLoRA方法，4比特LLaMA3-8B的平均准确率为57.0（FP16: 64.8），超过4比特LLaMA1-7B的38.4（FP16: 34.6）18.6，超过4比特LLaMA2-7B的43.9（FP16: 45.5）13.1。这表明在LLaMA3时代需要一种新的LoRA-FT量化范式。</div><div class=" pTag">在CommonSenseQA基准测试中也出现了类似的现象。与没有使用LoRA-FT的4比特对应版本相比，使用QLoRA和IR-QLoRA微调的模型性能也有所下降（例如，QLoRA平均下降2.8% vs IR-QLoRA平均下降2.4%）。这进一步展示了在LLaMA3中使用高质量数据集的优势，而且通用数据集Alpaca并没有对模型在其他任务中的性能作出贡献。</div><h2>结论</h2><div class=" pTag">这篇论文全面评估了LLaMA3在各种低比特量化技术（包括训练后量化和LoRA微调量化）中的性能。</div><div class=" pTag">此研究发现表明，尽管LLaMA3在量化后仍然展现出优越的性能，但与量化相关的性能下降是显著的，甚至在许多情况下可以导致更大的下降。</div><div class=" pTag">这一发现突显了在资源受限环境中部署LLaMA3可能面临的潜在挑战，并强调了在低比特量化背景下增长和改进的充足空间。通过解决低比特量化引起的性能下降，预期后续的量化范式将使LLMs在较低的计算成本下实现更强的能力，最终推动代表性的生成式人工智能达到新的高度。</div><div class=" pTag"><span style="font-size: 17px;"><span>论文链接：</span><br /><span>https://arxiv.org/abs/2404.14047</span></span></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">项目链接：</div><br /><div class=" pTag">https://github.com/Macaronlin/LLaMA3-Quantization</div><br /><div class=" pTag">https://huggingface.co/LLMQ</div></span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fou-mX9AoQTX7tWL6CWXiaQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 05:45:43 GMT</pubDate>
<pubDate>Sat, 27 Apr 2024 05:45:43 GMT</pubDate>
</item>
<item>
<title>阿里智能体“组装工厂”开源！0经验搞定上万Agent并发</title>
<link>https://posts.careerengine.us/p/662c90f9e9d9800822d255d0</link>
<guid>https://posts.careerengine.us/p/662c90f9e9d9800822d255d0</guid>
<content:encoded><![CDATA[
<div> 多智能体编程框架、AgentScope、拖拽式编程、应用监控、多模态支持
<br>
AgentScope是阿里巴巴通义实验室开源的多智能体编程框架，提供拖拽式编程和多模态支持。AgentScope Workstation提供可视化拖拽式开发界面，帮助开发者搭建多智能体应用。AgentScope Copilot是开发助手，提供交互式帮助解决问题。应用监控模块实时监控成本及多智能体状态。AgentScope支持多种工具函数、智能体和应用样例，提供丰富的开发资源。容错机制确保应用稳定可靠。总体来说，AgentScope提供了便捷的多智能体开发平台，适用于不同领域的开发者。 
<br> 
总结: 
多智能体编程框架AgentScope提供了拖拽式编程、应用监控和多模态支持，为开发者提供了丰富的开发资源和稳定可靠的运行时保障。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">阿里巴巴通义实验室 投稿</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">让多智能体开发就像搭积木，阿里巴巴通义实验室开源多智能体编程框架与开发平台<span><strong style="font-weight: 600;">AgentScope</strong></span>。</div><div class=" pTag">该平台专门为多智能体应用开发者打造，旨在提供高易用的编程体验、稳定可靠的运行时保障，并且为开发者提供了分布式和多模态的技术支持。</div><div class=" pTag">内置了OpenAI、DashScope、Gemini、Ollama等多种不同平台的模型API，深度兼容当下的大模型开源生态。</div><div class=" pTag">AgentScope提供了多种开箱即用的功能，通过简单拖拽就能搭建多智能体应用。</div><div class=" pTag">即使没有分布式开发经验的开发者，在AgentScope平台上也能轻松实现上万级别的多智能体并发。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnLGEkRC0R57fULMGON55D0jibCmpvcyueVicuhEDsKVrdD6VOKJ8iap3VQ/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /></div><div class=" pTag">为了让更多用户能够快速、轻松地开发属于自己的多智能体应用。AgentScope提供了以下功能：</div><ul class="list-paddingleft-1"><li><div class=" pTag"><span><strong style="font-weight: 600;">拖拽式的编程范式——AgentScope Workstation</strong></span>：为用户提供了可视化的拖拽式开发界面</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">交互式编程助手——AgentScope Copilot</strong></span>：解答开发者关于AgentScope的疑问</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">透明可控的开发过程——应用实时监控</strong></span>：实时监控应用运行成本、多智能体状态，实现透明且可控的开发</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">丰富的开发资源</strong></span>：助力快捷且方便的二次开发，搭建应用无需“从零开始”</div></li></ul><h2>AgentScope Workstation</h2><div class=" pTag">AgentScope Workstation提供了便捷的“拖拽式”多智能体应用编排范式。</div><div class=" pTag">在这里，编程经验不再是限制你想象力的因素。每个开发者都可以在丰富的工具栏中，零代码地挑选和拖拽出他们喜欢的大模型、智能体和 Pipeline，就像搭积木一样自由组合，创造出独特创新的多智能体应用。</div><div class=" pTag">为了确保这些通过拖拽搭建的多智能体应用真正可用，AgentScope Workstation引入了静态规则检查，以确保应用的正确性。</div><div class=" pTag">对于那些寻求进一步自定义和深度开发的高级开发者，AgentScope Workstation也提供了强大的支持。</div><div class=" pTag"><div class=" pTag">开发者既可以将应用导出为配置信息，借助AgentScope Workstation引擎进行运行，也可以使用AgentScope Workstation Compiler将配置信息一键转换成Python代码。这样，开发者便可以进一步编辑和优化代码，实现更为精细和个性化的应用调整。</div><br /></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnMTvU0n4dCvz0RFpeO422ehsDumUUiaMvtcmg7mLc5a9HTeet8fAxgLg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><h2>AgentScope Copilot</h2><div class=" pTag"><span><strong style="font-weight: 600;">AgentScope Copilot</strong></span>是基于AgentScope框架自身构建的开发助手，旨在帮助开发者解决在多智能体应用开发过程中所遇到的问题，其技术实现结合了多智能体群聊<span>（Multi-agent Conversation）</span>、数据检索生成<span>（Retrieval-Augmented Generation，RAG）</span>、智能体呼叫<span>（Mention）</span>等诸多特性。</div><div class=" pTag">在与AgentScope Copilot的交互中，开发者既可以与引导助手<span>（Guide Assistant）</span>进行交互，直接获取帮助；也可以呼叫专用的智能体助手，例如问答助手<span>（Tutoring Assistant）</span>或者代码编程助手<span>（Coding Assistant）</span>，从而获得更加专业、更加具体的回答。更具体而言，代码编程助手可以帮助开发者快速理清框架内各个模块的定义及使用方法，提供更优的编程建议。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnFajj5Rg8ITWUFa2kK0RrfZ4SNFibXQU4dlNOTkt1LapMKianOlMR1O3Q/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="text-align: left;"><span style="font-size: 17px; text-align: left;">值得一提的是，AgentScope Copilot本身基于AgentScope框架中的RAG模块进行搭建，支持LlamaIndex等流行的数据检索框架、以及多种向量数据库类型，同时支持接入各种大语言模型。开发者可以进行快速的二次开发，轻松的搭建起自己项目的Copilot助手。</span></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnOCeZTGAzibQyr7beFg7AlgfcOSl9RvcMqp7B8Owh5WQSmnjJjJpf05w/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><h2>透明可控的开发过程</h2><div class=" pTag">一个友好的应用开发过程，对开发者来说应该是可控的、透明的。</div><div class=" pTag">但是在多智能体场景下，模型API种类繁多，调用接口各异，如何有效管理和监控模型API的使用成本，避免资源浪费与意外开支，对资源监控能力提出了更高的挑战。</div><div class=" pTag">例如，在使用搜索引擎时将一个复杂网页作为大模型的输入将引起高额的开销，而开发者的感知往往滞后。为了解决这个问题，AgentScope设计了Monitor模块，实现了：</div><div class=" pTag"><strong style="font-weight: 600;">API开销自动统计</strong>：准确记录不同模型API的token用量，并自动计算当前开销，确保开发者对模型API成本的每一份支出都了如指掌。</div><div class=" pTag"><strong style="font-weight: 600;">预算设置及超额报警</strong>：支持开发者设定各模型API的预算上限。当总开销超过预算时，系统自动触发报警，及时通知开发者进行检查和调整，避免超支的发生。</div><div class=" pTag"><strong style="font-weight: 600;">支持自定义监控指标</strong>：除了预设的模型API相关指标外，Monitor还允许开发者自定义其他监控指标，例如搜索工具的开销，数据存储服务的开销，网络流量等等，从而让开发者能够对应用的状态进行全面且自动化的监控。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yn8E2oFDZGiaLvXZjcmhu0as6TMcNsD3GUoYH2pneZGHvnjofDqlV85sQ/640?wx_fmt=png&amp;from=appmsg" /></div></div><strong style="font-size: 17px; text-align: right; font-weight: 600;">△</strong><span style="font-size: 17px; text-align: right;">&nbsp;Monitor模块</span></div><h2>即拿即用的开发资源</h2><div class=" pTag">AgentScope内置了丰富的工具函数、智能体和应用样例，开发者可以通过轻量化的修改，轻松的开发属于自己的多智能体应用。</div><div class=" pTag"><strong style="font-weight: 600;">工具函数</strong>：AgentScope支持包含网络搜索、数据库查询、文件操作、文本处理等多种类型的工具函数，每种类目下又包含不同实现形式。例如网络搜索层面，AgentScope已经支持Bing、arXiv和DBLP等多种搜索引擎。</div><div class=" pTag"><strong style="font-weight: 600;">智能体</strong>：AgentScope内置了功能各异的智能体，包含基础对话、格式化对话、Reasoning、RAG、分布式等多种不同类型的智能体。开发者只需要使用不同的参数初始化智能体实例，就可以将智能体特化成自己需要的智能体实例。</div><div class=" pTag"><strong style="font-weight: 600;">应用样例</strong>：AgentScope预置了包含对话<span>（Conversation）</span>、游戏<span>（Game）</span>、和分布式<span>（Distribution）</span>等多种不同类型的应用。一方面这些样例可以帮助开发者降低开发代价，另一方面也为应用的开发提供了模版和参照。</div><div class=" pTag">为了让开发者能够更好、更快地了解AgentScope中的内置资源，AgentScope提供了丰富且详细的文档，包含教程<span>（Tutorial）</span>、接口文档<span>（API Document）</span>和设计论文，帮助开发者更好的了解和使用AgentScope。</div><h2>稳定可靠</h2><div class=" pTag">基于大模型的多智能体应用会面临模型幻觉、模型指令跟随能力不足等诸多新的挑战。为了保证多智能体应用能够稳定可靠地运行，AgentScope首先将应用中出现的错误进行分类，然后相应地提供了一套完整的容错机制和自定义的容错处理。</div><div class=" pTag"><strong style="font-weight: 600;">面向随机性的容错</strong>：随机性错误常常由网络状况不稳定，或者模型生成内容的不确定性引起，是基于大模型构建应用时最常见的一类错误。这类错误往往十分琐碎且难以穷举，因此AgentScope通过的内置重试机制，将此类随机性的错误进行过滤和屏蔽，方便开发者将精力投入到应用的编排中。</div><div class=" pTag"><strong style="font-weight: 600;">基于规则的容错</strong>：应用中遇到的部分错误可以通过规则进行修复。例如，要求大模型产生指定格式的回复时，大模型有时会产生额外的内容，因此可以通过预置的规则进行截断，确保应用的正常运行。</div><div class=" pTag"><strong style="font-weight: 600;">基于模型的容错</strong>：借助大模型自身能力进行纠错是多智能体应用的特点之一，AgentScope会尝试将输入和错误信息提供给大模型，利用大模型的理解能力和知识来纠正错误。</div><div class=" pTag"><strong style="font-weight: 600;">面向智能体/开发者的容错</strong>：当预置规则和大模型都无法解决错误时，往往需要开发者或者是智能体的介入才能解决问题，因此AgentScope在遇到此类错误的情况下，会将错误的格式化归因、错误信息、输入输出信息完整的提交给开发者或智能体，从而帮助解决遇到的问题。</div><h2>提示优化</h2><div class=" pTag">多智能体应用性能的提升很大程度依赖大模型的提示（Prompt）质量，一个好的提示可以大幅提高应用运行成功的概率。AgentScope编程框架提供了提示调优模块，助力开发者持续优化应用。</div><div class=" pTag"><strong style="font-weight: 600;">提示自动生成</strong>：对于开发者来说，产生一个好的提示往往是一件耗时耗力的事情。AgentScope预置了一个智能体，其内部通过上下文学习的方式<span>（In-context learning，ICL）</span>，综合开发者的应用场景，直接生成所需的提示，帮助开发者快速开始开发。</div><div class=" pTag"><strong style="font-weight: 600;">支持样例输入</strong>：在AgentScope中，开发者同时可以输入若干样例作为模板，AgentScope可以根据这些样例，为特定的下游任务生成具体的提示词。</div><div class=" pTag"><strong style="font-weight: 600;">提示动态调优</strong>：在应用运行过程中，大模型的提示词还需根据运行情况做进一步的调整，例如添加新的规则以避免错误的产生。AgentScope将此过程自动化，在智能体与开发者、环境进行交互的过程中，其历史数据将成为调整提示的依据；AgentScope根据当时的场景，修改智能体的系统提示<span>（System prompt）</span>从而在运行过程中提高智能体的表现。</div><h2>分布式并行</h2><div class=" pTag">作为一个多智能体编程框架，AgentScope在设计之初就将提升智能体之间的协作效率作为主要目标之一，并为此设计了分布式模式。在该模式中，多智能体可以运行在不同的进程和机器当中，从而充分利用计算资源，提高运行效率。AgentScope中的分布式主要具有以下特点：</div><div class=" pTag"><strong style="font-weight: 600;">自动并行优化</strong>：AgentScope中分布式的设计遵循Actor编程范式，可以自动识别应用流程编排中不同智能体之间潜在的并行可能性，并且进行自动并行优化，提升运行效率。同时各个智能体可以独立运行在本地或者远程机器上，能够充分利用计算资源，支持大规模部署。</div><div class=" pTag"><strong style="font-weight: 600;">上手门槛极低</strong>：AgentScope向开发者完全屏蔽了分布式的技术实现细节，开发者可以零代价开发分布式多智能体应用，或者将已有的多智能体应用转化成分布式模式运行。在转化成分布式应用时，AgentScope中分布式应用编排与本地化的编排方式完全兼容，即使没有分布式背景知识，开发者也能轻松编排分布式多智能体应用。</div><div class=" pTag"><strong style="font-weight: 600;">支持大规模部署</strong>：AgentScope目前支持在单台机器<span>（64核8卡A100）</span>上一次性运行16000多个智能体实例，并且该规模能够随着机器数量的增加实现规模的线性增长。举例来说，AgentScope在4台机器的集群上可以在30秒内完成64000多次智能体的调用。这一特点使得智能体的大规模并行和仿真成为可能。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnPMZMDiaTjB0UKpv5g1Rica8UY0qQkiaxqYI0YQEfe58jE1TGykCiaO7zMg/640?wx_fmt=png&amp;from=appmsg" /></div></div><strong style="font-size: 17px; text-align: right; font-weight: 600;">△</strong><span style="font-size: 17px; text-align: right;">本地模式向分布式模式转换</span></div><h2>多模态支持</h2><div class=" pTag">AgentScope支持开发者使用多模态数据和多模态模型来构建强大的多智能体应用。为了让开发者可以更加直观、便捷地与自己编排的多智能体应用交互，AgentScope提供了一款开发者友好、简便易用的可交互式界面AgentScope Studio，让文本、声音、图像等不同模态的数据得以生动呈现，确保了开发者能以最直观的方式感受并调整自己创造的智能体应用。</div><div class=" pTag" style="text-align: right;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnBILVIW8LLic7x2ahiaeicOVtUdOwsjaaQib3MCGSZonSEqBuhDcI8Cw4pA/640?wx_fmt=gif&amp;from=appmsg" /></div></div><strong style="font-size: 17px; text-align: right; font-weight: 600;">△</strong><span style="font-size: 17px; text-align: right;">AgentScope Studio</span></div><div class=" pTag">接下来，AgentScope还将持续为开发者带来更多的开发便利，也期待更多开发者加入AgentScope开源社区的建设，探索更多更有趣的多智能体应用。<span style="display: none;">‍</span></div><div class=" pTag"><span style="font-size: 17px;">AgentScope开源仓库地址：</span></div><div class=" pTag"><span style="font-size: 17px;">https://github.com/modelscope/agentscope</span></div><div class=" pTag"><span><span style="font-size: 17px;">欢迎试用：</span></span></div><div class=" pTag"><span style="font-size: 17px;">https://agentscope.aliyun.com</span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FNPUZKE1G16zhFDs4bUHAkg">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 05:45:29 GMT</pubDate>
<pubDate>Sat, 27 Apr 2024 05:45:29 GMT</pubDate>
</item>
<item>
<title>清华团队国产“Sora”火了！画面效果对标OpenAI，长度可达16秒，还能读懂物理规律</title>
<link>https://posts.careerengine.us/p/662c90f9e9d9800822d255d8</link>
<guid>https://posts.careerengine.us/p/662c90f9e9d9800822d255d8</guid>
<content:encoded><![CDATA[
<div> 生成视频、技术路线、时空一致性、模拟真实物理世界、团队背景
<br><br>总结:
国内生数科技联合清华大学发布的视频大模型「Vidu」引起关注，支持高清视频生成，画面效果接近Sora，具有镜头语言、时间和空间一致性、物理规律模拟等特点，能虚构超现实主义画面。实现长视频生成突破10秒大关，保持时间和空间一致性，模拟真实物理世界。团队选对技术路线，基于自研U-ViT架构并具备扎实工程化基础。团队由清华背景的精干团队组成，早在多模态模型领域积累经验。团队迅速突破的秘籍在于技术路线选择和工程化基础。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">允中 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag"><div class=" pTag">Sora席卷世界，也掀起了全球竞逐AI视频生成的热潮。</div><br /></div><div class=" pTag"><div class=" pTag">就在今天，国内又有一支短片引发关注。</div><br /></div><div class=" pTag"><div class=" pTag">视频来自生数科技联合清华大学最新发布的视频大模型</div><span style="font-size: 17px; text-align: left;">「</span><span style="font-size: 17px; text-align: left;">Vidu」。</span><br /></div><div class=" pTag">从官宣消息看，「Vidu」支持一键生成<span><strong style="font-weight: 600;">长达16秒、分辨率达1080p</strong></span>的高清视频内容。</div><div class=" pTag">更令人惊喜的是，「Vidu」画面效果非常接近Sora，在多镜头语言、时间和空间一致性、遵循物理规律等方面表现都十分出色，而且还能虚构出真实世界不存在的超现实主义画面，这是当前的视频生成模型难以实现的。</div><div class=" pTag">并且实现这般效果，背后团队只用了两个月的时间。</div><h2>全面对标Sora</h2><div class=" pTag"><div class=" pTag">3月中旬，生数科技联合创始人兼CEO唐家渝就曾公开表示：“今年内一定能达到Sora目前版本的效果。”</div><br /></div><div class=" pTag"><span style="font-size: 17px; text-align: left;">现在，在生成时长、时空一致性、镜头语言、物理模拟等方面，确实能看到<span style="font-size: 17px; text-align: left;">「Vidu」在短时间内已经逼近Sora水平。</span></span></div><h3>长度突破10秒大关</h3><div class=" pTag">「Vidu」生成的视频不再是持续几秒的「GIF」，而是达到了16秒，并且<strong style="font-weight: 600;">做到了画面连续流畅，且有细节、逻辑连贯</strong>。</div><div class=" pTag">尽管都是运动画面，但几乎不会出现穿模、鬼影、运动不符合现实规律的问题。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzvc7t1zPgyoZ4NBOUnVQe6nVVtBZxCCEg2oKV6fzvNKdXjUkac5Wd6w/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;">△</strong>提示：一艘木头玩具船在地毯上航行</h6><h3>给视频注入「镜头语言」</h3><div class=" pTag">在视频制作中有个非常重要的概念——镜头语言。通过不同的镜头选择、角度、运动和组合，来表达故事情节、揭示角色心理、营造氛围以及引导观众情感。</div><div class=" pTag">现有AI生成的视频，能够明显地感觉到镜头语言的单调，镜头的运动局限于轻微幅度的推、拉、移等简单镜头。深究背后的原因看，因为现有的视频内容生成大多是先通过生成单帧画面，再做连续的前后帧预测，但主流的技术路径，很难做到长时序的连贯预测，只能做到小幅的动态预测。</div><div class=" pTag">「Vidu」则突破了这些局限。在一个「海边小屋」为主题的片段中，我们可以看到，「Vidu」一次生成的一段片段中涉及多个镜头，画面既有小屋的近景特写，也有望向海面的远眺，整体看下来有种从屋内到走廊再到栏杆边赏景的叙事感。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzxHnc71ticU8Q9Jia1b85AlrL9VicIibhZr89oeHUaIMFibAN0TwsHBVlmMw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">包括从短片中的多个片段能看到，「Vidu」能直接生成转场、追焦、长镜头等效果，包括能够生成影视级的镜头画面，给视频注入镜头语言，提升画面的整体叙事感。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzP2oytNbF5uQibJ0JdHkqvDhK9YrRmbyw2I3KjUZeV2zHpuWn08FGntQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><h3>保持时间和空间的一致性</h3><div class=" pTag">视频画面的连贯和流畅性至关重要，这背后其实是人物和场景的时空一致性，比如人物在空间中的运动始终保持一致，场景也不能在没有任何转场的情况下突变。而这一点 AI 很难实现，尤其时长一长，AI生成的视频将出现叙事断裂、视觉不连贯、逻辑错误等问题， 这些问题会严重影响视频的真实感和观赏性。</div><div class=" pTag">「Vidu」在一定程度上克服了这些问题。从它生成的一段“带珍珠耳环的猫”的视频中可以看到，随着镜头的移动，作为画面主体的猫在3D空间下一直保持着表情、服饰的一致，视频整体上连贯、流畅，保持了很好的时间、空间一致性。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-iframe-holder offset offset-old-168"></div><strong style="font-size: 17px; text-align: right; font-weight: 600;">△</strong><span style="font-size: 17px; text-align: right;">提示：</span><span style="font-size: 17px; text-align: right;">这是一只蓝眼睛的橙色猫的肖像，慢慢地旋转，灵感来自维米尔的《戴珍珠耳环的少女》，画面上戴着珍珠耳环，棕色头发像荷兰帽一样，黑色背景，工作室灯光。</span></div><h3>模拟真实物理世界</h3><div class=" pTag">Sora令人惊艳的一大特点，就是能够模拟真实物理世界的运动，例如物体的移动和相互作用。其中Sora有发布的一个经典案例，“一辆老式SUV行驶在山坡上”的画面，非常好地模拟了轮胎扬起的灰尘、树林中的光影以及车行驶过程中的阴影变化：</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-169"></div></div><div class=" pTag">在同样的提示词下，「Vidu」与Sora生成效果高度接近，灰尘、光影等细节与人类在真实物理世界中的体验非常接近。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCz3OM6f3WCrAibGaGPibsOSlzn816g7Sg1pj1zSia2y2mZDUeh6zRjwvhnQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;">△</strong>提示：镜头跟随一辆带有黑色车顶行李架的白色老式SUV，它在陡峭的山坡上一条被松树环绕的陡峭土路上加速行驶，轮胎扬起灰尘，阳光照射在SUV上，给整个场景投射出温暖的光芒。土路缓缓地蜿蜒延伸至远方，看不到其他汽车或车辆。道路两旁都是红杉树，零星散落着一片片绿意。从后面看，这辆车轻松地沿着曲线行驶，看起来就像是在崎岖的地形上行驶。土路周围是陡峭的丘陵和山脉，上面是清澈的蓝天和缕缕云彩。</h6><div class=" pTag">当然在“带有黑色车顶行李架”的局部细节上，「Vidu」没能生成出来，但也瑕不掩瑜，整体效果已高度接近真实世界。</div><h3>丰富的想象力</h3><div class=" pTag">与实景拍摄相比，用AI生成视频有一个很大的优势——它可以生成现实世界中不存在的画面。以往，这些画面往往要花费很大的人力、物力去搭建或做成特效，但是AI短时间就可以自动生成了。</div><div class=" pTag">比如在下面这个场景中，「帆船」、「海浪」罕见地出现在了画室里，而且海浪与帆船的交互动态非常自然。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-iframe-holder offset offset-old-174"></div></div><div class=" pTag">包括短片中的“鱼缸女孩”的片段，奇幻但又具有一定的合理感，这种能够虚构真实世界不存在的画面，对于创作超现实主义内容非常有帮助，不仅可以激发创作者的灵感，提供新颖的视觉体验，还能拓宽艺术表达的边界，带来更加丰富和多元化的内容形式。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzLbGKfiaNZNo9etOiaMHNLvcmGVwoEDfEA1Ue8FxsB28oXicZic0RF8Z3VA/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /></div><h3>理解中国元素</h3><div class=" pTag">除了以上四方面的特点外，我们从「Vidu」放出的短片中还看到了一些不一样的惊喜，「Vidu」能够生成特有中国元素的画面，比如熊猫、龙、宫殿场景等。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzZ0sqMiaqhnEgw9uy4HjqUoEtbY9p9HsuxpEsxeA9WVHciaWFrZGxks9A/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;">△</strong><div class=" pTag">提示：在宁静的湖边，一只熊猫热切地弹着吉他，让整个环境变得活跃起来。晴朗天空下平静的水面倒映着这一场景，以生动的全景镜头捕捉到，将现实主义与大熊猫活泼的精神融为一体，创造出活力与平静的和谐融合。</div><br /></h6><h2>两个月快速突破的“秘籍”</h2><div class=" pTag">此前，唐家渝给出的赶上Sora的时间，是“很难说是三个月还是半年”。</div><div class=" pTag">但如今仅仅过去一个多月时间，团队就实现了突破，而且据透露，3月份公司内部就实现了8秒的视频生成，紧接着4月份突破了16秒生成。短短两个月时间，背后是如何做到的？</div><h3>一是选对了技术路线</h3><div class=" pTag">「Vidu」底层基于完全自研的U-ViT架构，该架构由团队在2022年9月提出，早于Sora采用的DiT架构，是全球首个Diffusion和Transformer融合的架构。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCz6JvchthUkaONASUicX1vOcrdqbVRfbK8rPNEkcxNZJEWoNibquhHTh5A/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><div class=" pTag">Transformer架构被广泛应用于大语言模型，该架构的优势在于scale特性，参数量越大，效果越好，而Diffusion被常用于传统视觉任务（图像和视频生成）中。</div><div class=" pTag">融合架构就是在Diffusion Model（扩散模型）中，用Transformer替换常用的U-Net卷积网络，将Transformer的可扩展性与Diffusion模型处理视觉数据的天然优势进行融合，能在视觉任务下展现出卓越的涌现能力。</div><div class=" pTag">不同于市面上之前的一些“类Sora”模型，长视频的实现其实是通过插帧的方式，在视频的每两帧画面中增加一帧或多帧来提升视频的长度。这种方法就需要对视频进行逐帧处理，通过插入额外的帧来改善视频长度和质量。整体画面就会显得僵硬而又缓慢。</div><div class=" pTag">另外，还有一些视频工具看似实现了长视频，实际打了“擦边球”。底层集合了许多其他模型工作，比如先基于Stable Diffusion、Midjourney生成单张画面，再图生4s短视频，再做拼接。表面看时长是长了，但本质还是“短视频生成”的内核。</div><div class=" pTag">但「Vidu」基于纯自研的融合架构，底层是“一步到位”，不涉及中间的插帧和拼接等多步骤的处理，文本到视频的转换是直接且连续的。直观上，我们可以看到“一镜到底”的丝滑感，视频从头到尾连续生成，没有插帧痕迹。</div><h3>二是扎实的工程化基础</h3><div class=" pTag">早在2023年3月，基于U-ViT架构，团队在开源的大规模图文数据集LAION-5B上就训练了10亿参数量的多模态模型——UniDiffuser，并将其开源。</div><div class=" pTag">UniDiffuser主要擅长图文任务，能支持图文模态间的任意生成和转换。UniDiffuser的实现有一项重要的价值——首次验证了融合架构在大规模训练任务中的可扩展性（Scaling Law），相当于将U-ViT 架构在大规模训练任务中的所有环节流程都跑通。值得一提的，同样是图文模型，UniDiffuser比最近才切换到DiT架构的Stable Diffusion 3领先了一年。</div><div class=" pTag">这些在图文任务中积累工程经验为视频模型的研发打下了基础。因为视频本质上是图像的流，相当于是图像在时间轴上做了一个扩增。因此，在图文任务上取得的成果往往能够在视频任务中得到复用。Sora就是这么做的：它采用了DALL·E 3的重标注技术，通过为视觉训练数据生成详细的描述，使模型能够更加准确地遵循用户的文本指令生成视频。</div><div class=" pTag">据悉，「Vidu」也复用了生数科技在图文任务的很多经验，包括训练加速、并行化训练、低显存训练等等，从而快速跑通了训练流程。据悉，他们通过视频数据压缩技术降低输入数据的序列维度，同时采用自研的分布式训练框架，在保证计算精度的同时，通信效率提升1倍，显存开销降低80%，训练速度累计提升40倍。</div><div class=" pTag">从图任务的统一到融合视频能力，「Vidu」可被视为一款通用视觉模型，能够支持生成更加多样化、更长时长的视频内容，官方也透露，「Vidu」目前并在加速迭代提升，面向未来，「Vidu」灵活的模型架构也将能够兼容更广泛的多模态能力。</div><h2>One More Thing</h2><div class=" pTag">最后，再聊下「Vidu」背后的团队——生数科技，这是一支清华背景的精干团队，致力于专注于图像、3D、视频等多模态大模型领域。</div><div class=" pTag">生数科技的核心团队来自清华大学人工智能研究院。首席科学家由清华人工智能研究院副院长朱军担任；CEO唐家渝本硕就读于清华大学计算机系，是THUNLP组成员；CTO鲍凡则是清华大学计算机系博士生、朱军教授的课题组成员，长期关注扩散模型领域研究，U-ViT和UniDiffuser两项工作均是由他主导完成的。</div><div class=" pTag">团队从事生成式人工智能和贝叶斯机器学习的研究已有20余年，在深度生成模型突破的早期就开展了深入研究。在扩散模型方面，团队于国内率先开启了该方向的研究，成果涉及骨干网络、高速推理算法、大规模训练等全栈技术方向。</div><div class=" pTag">团队于ICML、NeurIPS、ICLR等人工智能顶会发表多模态领域相关论文近30篇，其中提出的免训练推理算法Analytic-DPM、DPM-Solver等突破性成果，获得ICLR杰出论文奖，并被OpenAI、苹果、Stability.ai等国外前沿机构采用，应用于DALL·E 2、Stable Diffusion等明星项目中。</div><div class=" pTag">自2023年成立以来，团队已获得蚂蚁集团、启明创投、BV百度风投、字节系锦秋基金等多家知名产业机构的认可，完成数亿元融资。据悉，生数科技是目前国内在多模态大模型赛道估值最高的创业团队。</div><div class=" pTag sectionReplaced"><div style="text-align: center;"><div class=" pTag" style="text-align: right;"><span style="font-size: 17px;"><span style="font-size: 17px; text-align: left;"><span style="font-size: 17px; text-align: right;">*本文系量子位获授权刊载，观点仅为作者所有。</span></span></span></div><div class=" pTag"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div></div></div><div class=" pTag sectionReplaced"><div><div><div style="display: inline-block;"><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCMTiaQvFTH1BuicE6KgJEARU6aCY4PfZHwOUZ0icduoLL4pFsRC23KyvGAhjp4fIYWfVCaicicyVRAxHA/640?wx_fmt=jpeg" /></div></div></div></div><div style="display: inline-block;"><div><div><div class=" pTag"><span style="font-size: 17px;"><strong style="font-weight: 600;">量子位&nbsp;</strong></span><span style="font-size: 17px;">QbitAI</span></div></div><div><div><div style="text-align: left; font-size: 17px;"><div class=" pTag">վ'ᴗ' ի 追踪AI技术和产品新动态</div></div></div></div></div></div></div></div><div><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9e5IWnFrCxFxtON-AY6Jcw">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 05:45:29 GMT</pubDate>
<pubDate>Sat, 27 Apr 2024 05:45:29 GMT</pubDate>
</item>

<item>
<title>激进式押注AI手机的厂商一大堆，为什么登顶的是它家</title>
<link>https://posts.careerengine.us/p/662c90f8e9d9800822d255c8</link>
<guid>https://posts.careerengine.us/p/662c90f8e9d9800822d255c8</guid>
<content:encoded><![CDATA[
<div> 华为 荣耀 AI 手机 市场份额<br />
<br />
总结:<br />
今年中国手机市场迎来大变局，华为全面回归，荣耀以AI成为关键增长引擎登顶市场，展现新的市场格局。荣耀以平台级AI和大模型为核心，提供智慧服务和个性化体验，成为AI手机的先驱。荣耀布局早投入大，在AI研发方面领先。未来手机发展趋势是智能体派，以人为中心满足消费者需求，苹果也有类似动向。2024年终端市场将与AI和大模型密切相关，AI已成为长期竞争焦点，实现人手一个贾维斯的愿景变得更具期待。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">鱼羊 衡宇 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">今年的中国手机市场，正在迎来大变局。</div><div class=" pTag">两大变量交融交汇，已经开始展现作用力，让市场重新火热：</div><div class=" pTag">一是<strong style="font-weight: 600;">华为全面回归，盛况空前</strong>。</div><div class=" pTag">二是<strong style="font-weight: 600;">AI搅动风云，成为兵家必争之地</strong>。</div><div class=" pTag">就在这种交融之下，第一季度王座现已呈现归属——</div><div class=" pTag"><strong style="font-weight: 600;">荣耀</strong>。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yOTzSLZhhT0kwwaDz5Ctesf3GHMGeFib23iblacRfNqXys4Mp04lAp0Pg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>AI成手机厂商关键增长引擎</h2><div class=" pTag">华为的全面回归，采取的是一种最低调的姿态，收获了史上最高的关注度。</div><div class=" pTag">市场一度热议，华为回归后，“荣耀受到的影响最大”。</div><div class=" pTag">但最新数据出炉，事实却并非如此。</div><div class=" pTag">IDC<span>（国际数据公司）</span>发布的最新手机季度跟踪报告显示，今年第一季度，中国智能手机整体出货量约6926万台，具体到厂商方面，<strong style="font-weight: 600;">荣耀以17.1%的市场份额拿下第一</strong>，“成为了拉动市场持续向好的重要力量”。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yWCdVW6ibPSKnTyT6iaKh6xszTFXB0DiaRj1l2vOZOzJ9ufMT5YOhicatKA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">IDC中国区副总裁王吉平认为，此次荣耀登顶，<strong style="font-weight: 600;">AI成为关键增长引擎</strong>：</div><div class=" pTag">今年年初，荣耀发布了AI使能的全场景操作系统MagicOS 8.0，以魔法大模型加持，以平台级AI为内核、为底座，带来了“越用越好用，越用越懂你”的智慧服务。而首发搭载MagicOS 8.0的Magic6系列大受市场欢迎。</div><div class=" pTag">据王吉平介绍，得益于AI功能的增加，以及影像、屏幕等全方位的升级，全新旗舰Magic6系列首销第一季度出货量超过上一代首销前二季度出货量之和；</div><div class=" pTag">另一方面，在搭载平台级AI的荣耀Magic V2以及其他折叠屏家族产品的推动下，去年以来，荣耀折叠屏手机份额同比涨幅最高达到 675.4%。</div><div class=" pTag">而依靠荣耀Magic6系列及折叠屏家族的表现，今年第一季度，荣耀在600美元以上的高端市场份额提升明显，出货量同比增幅高达123.3%，高端市场份额仅次于苹果和华为。</div><h2>手机AI≠AI手机</h2><div class=" pTag">那么问题来了——</div><div class=" pTag">AI手机是大模型应用风暴开刮之后，每家终端厂商必cue的话题。第一季度，激进押注的国内外各大安卓厂商，都纷纷发布自家首款产品。</div><div class=" pTag">大家都野心勃勃，底线当然是不能再这场竞争中落后。</div><div class=" pTag">为什么脱颖而出的是荣耀？</div><div class=" pTag">荣耀CEO赵明认为，关键是“<strong style="font-weight: 600;">手机AI不等于AI手机</strong>”：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">手机上使用AI的技术能力和体验，手机提供的是平台和算法。</div><div class=" pTag">但只有AI成为根基，在手机上无处不在，才能叫AI手机。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yG0lpGNvYc4t4jyVhUz4Z7Juvibwp8HDGfFfibmxvmeB9JBNGR1ZvsqlA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">纵览第一季度市场上出现的AI手机们，不难看出，尽管宣传词都与“大模型”“AIGC”紧紧绑定，但在具体的落地路线上，其实已经出现流派的不同。</div><div class=" pTag">大多数厂商选择的路线，是率先围绕应用发力。基于已在云端锤炼得较为成熟的文本生成、图像生成等AIGC技术，在手机上推出端侧以及端云协同的AIGC应用。比如更为智能的人像抠图、翻译、会议总结等。</div><div class=" pTag">而以荣耀为代表的厂商，则有些反其道而行之的意思。</div><div class=" pTag">赵明就多次公开表示，手机厂商要避免掉入应用爆发呈现的陷阱，在AI领域，<strong style="font-weight: 600;">终端厂商能够给消费者带来的核心价值在操作系统层面</strong>。</div><div class=" pTag">具体来说，后者的路线其实是从第一性原理出发，考虑到消费者真正关心的核心议题是：</div><div class=" pTag"><strong style="font-weight: 600;">轰轰烈烈的大模型、AIGC能否真的给终端设备带来更好、更难替代的实际体验</strong>。</div><div class=" pTag">所以，什么是大模型进入手机后，能切实加强的体验？</div><div class=" pTag">最直观的，就是从“人找服务”，到“服务找人”。</div><div class=" pTag">在技术探索的层面上，高通展示过智能助手结合用户习惯主动决策的能力：在规划出行路线时，会主动询问是否要在路过的咖啡店里买杯咖啡。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yU8EibgE1TR8Wfc2mhTN4XAPwCsdtqlZiaknv2khicRque5kr32dbobeLQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">而实践层面，则可以拿荣耀为例：</div><div class=" pTag">首先，以平台级AI为新内核的MagicOS 8.0，带来行业首个基于意图识别的人机交互。</div><div class=" pTag">它能识别人机交互意图，是系统级的主动服务。</div><div class=" pTag">可以是出行时，到地铁站，手机会自动弹出乘车码；到机场，会自动弹出登机牌；到电影院，会弹出取票码。</div><div class=" pTag sectionReplaced">还可以是领导在群里通知要开会，只需截图后点击“创建日程”，系统就能识别时间、地点、会议主题，在日历中创建对应日程。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3y0fjAsjYrfeEhBe4Skic05EUD3X8mAToh7xS8SKXic3je3sP1jZ6IGqmQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">核心功能之一、基于多模态能力的“任意门”，可以完成App之间的跨转“一步直达”。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yFWmlPNvBGkwE3aicAnicepxzibYliaf3o9jicVd3ZCibAIfQLLKDvBh4nRFg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">类似如此，任意门带来的体验还有很多，归纳起来，就是把传统的多步骤操作简化为一步操作，一步到位。</div><div class=" pTag">在使用体验背后，荣耀还更为明确地提出了终端设备的<strong style="font-weight: 600;">AI四层架构</strong>理论：</div><div class=" pTag">第一层在系统层面，用AI使能跨系统、跨设备的融合。也就是让不同的操作系统通过AI决策无缝连接，实现手机、平板、PC等设备之间的数据共享。</div><div class=" pTag">第二层在单机层面，用AI来重构操作系统。基于人工智能技术，让终端越用越懂你，越用越好用。</div><div class=" pTag">第三层在应用层面，即AI在端侧的应用。</div><div class=" pTag">第四层是AI的端云协同。即在保障用户隐私安全的前提下，实现AIGC和云端大模型等网络侧AI在手机上的呈现。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yzJDALBFcEJLicV1b7ss9A0LbhcgTNicH6DWGyMyLBa3ntZhqMIa6ARHA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">实际上，这样的四层架构也概述了当前AI手机市场的竞争现状：</div><div class=" pTag">第三层、第四层更易切入，率先迎来爆发。</div><div class=" pTag">但第一层、第二层对于终端厂商更为关键，是终端公司区别于互联网公司的核心价值。</div><h2>手机的下一阶段：智能体</h2><div class=" pTag">用当下热议的技术热词来做个简单总结，这两条不同的落地应用路线，又可划分为“<strong style="font-weight: 600;">工具派</strong>”和“<strong style="font-weight: 600;">智能体派</strong>”。</div><div class=" pTag">所谓工具派，更注重单点AIGC技术能力的工具化，强调在具体任务场景里，工具变革给人带来的直接效率提升。</div><div class=" pTag">而“智能体派”，更注重大模型、AIGC能力与终端操作系统的深度结合，即意在充分发挥大模型感知、记忆、理解、推理、决策的能力，不断学习用户习惯，理解用户意图，围绕用户的需求来对终端的各种能力进行调度。</div><div class=" pTag">相比于推出解决某一类问题的AIGC应用，“智能体派”的布局显得更加长线，核心是<strong style="font-weight: 600;">以人为中心</strong>，满足消费者对手机智能的本质需求：</div><div class=" pTag">一方面，简化人机交互的模式，让手机这样的终端能越来越像人类助理一样，主动适应和匹配人的需求。</div><div class=" pTag">另一方面，能将大量留存在终端的用户个性化数据充分利用起来，让智能助理根据用户特性自我进化、持续成长。</div><div class=" pTag">其实，这也是AI手机能否像智能机取代功能机一样，成为手机第三阶段新形态的关键——</div><div class=" pTag">通过手机这样的终端设备，我们是否真的能人手一个会自我学习和不断适应用户需求的“贾维斯”？</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yibfou2RNDJJSMe5gpmVy6RODlFV0pnBYicCyYMjAkiaElEUoReATdlP8A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不过，值得关注的是，这条手机进阶智能体的路线，即使是在大模型技术进展飞快的当下，技术挑战仍然不容小觑。</div><div class=" pTag">关键的难点是，智能体路线涉及到<strong style="font-weight: 600;">用AI重构操作系统</strong>。</div><div class=" pTag">赵明也对此做过进一步解释，相比于应用，这种核心能力的构建更具门槛：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">荣耀的路线是先把平台级AI、AI手机最核心的能力构建起来。某种程度上，我们稍微控制、抑制了一下在手机AI应用上的发展，因为担心太重视单点应用，而忽视了核心能力的构建。</div><div class=" pTag">在此基础之上，在2024年这个节点，我们会在AI端侧应用上发力，这本身不存在门槛，因为并不涉及到操作系统的重构。</div></blockquote><div class=" pTag">这也就解释了为什么是荣耀在第一季度AI手机的比拼中占得先机。</div><div class=" pTag"><span><strong style="font-weight: 600;">首先，是布局早</strong></span>，因此能在前沿技术带来创新机会时，率先发力。</div><div class=" pTag">在2016年第一代Magic上，荣耀就率先带来了目光注视自动亮屏、机场自动推送登机牌等，让手机主动识别用户意图的功能，并从此确立了荣耀IUI<span>（意图识别人机交互）</span>的演进方向。</div><div class=" pTag">2022年，荣耀开始在MagicOS 7.0上建立起平台级AI能力，在智慧出行、智慧生活、智慧娱乐三大场景中推送多种卡片提醒，包括航班提醒、快递提醒、还款提醒等，逐渐建立起IUI的雏形。</div><div class=" pTag">而随着大模型技术向终端侧的迁移，在今年，荣耀不仅发布了70亿参数“魔法大模型”，还基于端侧大模型对平台级AI能力进行了全面升级，在MagicOS 8.0上再次变革人机交互方式，实现意图识别人机交互，使得操作系统的个人化成为可能。</div><div class=" pTag">一边，荣耀平台级AI，让手机更加关注用户个人，比如位置、状态、个人习惯、知识库等人因元素。</div><div class=" pTag">而另一边，端侧大模型<span>（荣耀自研的70亿参数魔法大模型）</span>的加持，又能进一步增加平台级AI对人因元素的学习和理解。</div><div class=" pTag"><span><strong style="font-weight: 600;">其次，是投入大。</strong></span></div><div class=" pTag">截至目前，荣耀AI研发费用累积达100亿，AI专利成果超2100项。</div><h2>One More Thing</h2><div class=" pTag">无独有偶，被曝将在今年的WWDC上公布AI新布局的苹果，近来传出的大模型相关进展中，也显露出将大模型与iOS做更深层结合的“智能体派”倾向。</div><div class=" pTag">3月份，来自苹果的一篇新论文《ReALM：Reference Resolution As Language Modeling》，还透露出苹果在提高语音助手理解和响应命令能力方面的技术进展。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3y1YMJMlrqCVInhZgjaY0oQXXdPtgmHu0r6pbcjGibooHwuFkFcbqXgWg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">简单来说，是让大模型去分析用户都在手机屏幕上做了哪些操作，以此学习用户的使用习惯、理解用户意图。</div><div class=" pTag">多方消息结合，苹果如今也大有要将理论研究付诸实践的势头。</div><div class=" pTag">看来，无论是华为的全面回归，荣耀的强势登顶，还是苹果的寻求新变，2024的终端风云，注定和AI、和大模型有更强烈的交织。AI，已然成为终端市场新的长期竞争焦点。</div><div class=" pTag">人手一个贾维斯，确实越来越值得期待了。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fn0W9KSUf7zjCeW2fAFMDFA">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 05:45:28 GMT</pubDate>
</item>
<item>
<title>一键换装神器爆火，老黄换上抱抱脸T恤，CEO本人：我被替代了，和他争CEO职位争不过</title>
<link>https://posts.careerengine.us/p/662ba267200df4779e6b13a1</link>
<guid>https://posts.careerengine.us/p/662ba267200df4779e6b13a1</guid>
<content:encoded><![CDATA[
<div> IDM-VTON、虚拟试穿、扩散模型、AI、网友们玩坏

总结:<br /><br />这篇文章介绍了最新的虚拟试穿神器IDM-VTON，基于扩散模型技术，通过AI实现虚拟试穿衣服。网友们利用该工具玩坏了一些大佬的衣服，展示了有趣的效果。该技术结合了TryonNet、IP-Adapter和GarmentNet模块，利用细粒度的细节提示生成真实的虚拟试穿图像。研究人员在VITON-HD数据集上进行了评估，结果表明IDM-VTON在定性和定量上优于先前的方法。感兴趣的读者可以查看原论文获取更多细节。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">西风 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">笑不活，最新虚拟试穿神器被网友们玩坏了。</div><div class=" pTag">黄院士、马斯克、奥特曼、史密斯等一众大佬衣服集体被扒。</div><div class=" pTag">前有老黄卸下皮衣套上糖果包装袋：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhHOTdHjpJKVBNNEykSv8a5XcLUUgumJxZiaicOuMAtxbAZLv2lh19YSyA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">后有奥特曼大秀花臂穿CUCCI：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhINBqq027ibQVuBFib5JeYOOSy7LAGbddrfDPhiaicZJ6enoiaNF7A3icnbgQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">再有老马变成了蛛蛛侠：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhr3nEicRgkibtKHjK3OXPGosRU0QZwfWsLuJaZRRCEFbYkfskaia7vC36g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">好莱坞巨星史密斯也风格大变：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhelTfED2KJEVBFpia0Z76fNJkqugMEKC9OW6ibB2aHnsDnMDd2wWyMrHQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">但说回研究本身，确实正儿八经的研究。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhoLaGjib4uUDPPzG8vAQ2Vcb0eiaZLOyDfGNhuwpe7REwbADZPr77YCKA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">名为<strong style="font-weight: 600;">IDM–VTON</strong>，由来自韩国科学技术院和OMNIOUS.AI公司的研究团队基于<strong style="font-weight: 600;">扩散模型</strong>打造。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhK1P0pdSxDbzTh7qEnLTNrVQwibX0oGDF6kkNIIBMse7U7XicicPgsEUnw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">目前官方放出了demo，大伙儿可以试玩，推理代码已开源。</div><div class=" pTag">除了开头所展示的，抱抱脸研究员也玩的不亦乐乎，给老黄换上了专属战袍。其CEO连忙转发打趣：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我被替代了，没法和他争CEO。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhwrkBXBYayEKbB2Qug4bRm8SUpmHb19JKuJibuICDkwHs1QW9ASb6Fzw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">看热闹的网友也是感慨，经过这么多年，终于不用再担心自己“手残”了<span>（AI帮你搞定）</span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh9CsvbgImGftE8y5HicOtWxiafXLkyibjwibriaTrSMrvd9w6IK0zCmJwdKA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>来玩啊～</h2><div class=" pTag">我们也赶紧上手体验了一把。demo整个页面是这样婶儿的：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhP9UajPytKZO8RjicUlhY2CJ4v7vldkiciasIswbiaxicb3M6TxibO964qOCg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">操作起来也是非常简单。</div><div class=" pTag">首先上传人物图，可以手动或者自动选择要修改的区域。然后，上传要换的衣服。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhmkfObia5anlaCAIfeGzL7S5b8evUzKjicYKLCY6AcFaPA80FCBycTDYQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">直接点击Try-on，会自动生成掩模图和换装后的图：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh8tOrrjA3CwZBxlqsnJlhKhdFWpNAZCCx9SkIu7EYuJyFoSyhCQWnpg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">上面这张自动生成的掩模把手也选进去了，所以最后生成的左手效果不好。</div><div class=" pTag">我们手动选取涂抹一下，同时人和衣服全部都用我们自己的图。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhibvt48Mk19PKHt6gIBnYUicd9lWuY9zY9IxDrOrib4bk2kGRibiah22bCyg/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhT84aXRIoibK8yc29IdUcwqveucxL6e0zdpmnL4OKYzSpKH3DEpVuicicg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这次效果大伙儿觉得如何？</div><div class=" pTag">再来展示一波网友的试玩成品图。</div><div class=" pTag">DeepMind联合创始人苏莱曼穿上了微笑面具修格斯联名款T恤：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhzGHTYLllYNmicayLBAsUWm16hFyhicAkJOboCROEWIwGrYALpGbELRibw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">甚至不少网友真想要这件衣服。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhgPnQIMetZ260U8AwIWibkO33HAxopEUrT0HqJfUfPqBJvsic04qRz9Uw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">奥特曼再次被网友当成模特：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh1NFMuKU691ZnA9d9rEJ0UpZo29HVmPEzzZeMibUqZFu5ngP5Ufy5mvA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">当然也有翻车的时候，比如马斯克穿的就是山寨CUCCI。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhw9acEuncBZUUR34UHAVVUiabXKaC3WYLPJ8Gy8GaTbKRDCJicpV1bhFQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">看完效果后，接着来看IDM–VTON在技术上是如何实现的。</div><h2>基于扩散模型</h2><div class=" pTag">技术方面，IDM–VTON基于扩散模型，通过设计精细的注意力模块来提高服装图像的一致性，并生成真实的虚拟试穿图像。</div><div class=" pTag">模型架构大概包含三部分：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">TryonNet</strong>：主UNet，处理人物图像。</div></li><li><div class=" pTag"><strong style="font-weight: 600;">IP-Adapter</strong>：图像提示适配器，编码服装图像的高级语义。</div></li><li><div class=" pTag"><strong style="font-weight: 600;">GarmentNet</strong>：并行UNet，提取服装的低级特征。</div></li></ul><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhOJUXZAU4Vxm25ttia0SzibwPo2WBGFLZ9JlBtCHzdicsLtCgL3vIgWEaw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在为UNet提供输入时，研究人员将人物图片的含噪声潜在特征、分割掩模、带掩蔽的图片和Densepose数据整合在一起。</div><div class=" pTag">他们还会为服装添加详细描述，例如[V]表示“短袖圆领T恤”。这个描述随后用作GarmentNet<span>（例如，“一张[V]的照片”）</span>和TryonNet<span>（例如，“模特正在穿[V]”）</span>的输入提示。</div><div class=" pTag">TryonNet和GarmentNet产生的中间特征进行了合并，随后传递至自我注意力层。研究人员只使用了来自TryonNet的输出的前半部分。这些输出与文本编码器和IP-Adapter的特征一起，通过交叉注意力层进行融合。</div><div class=" pTag">最终，研究人员对TryonNet和IP-Adapter模块进行了精细调整，并锁定了模型的其它部分。</div><div class=" pTag">实验阶段，他们使用VITON-HD数据集训练模型，并在VITON-HD、DressCode和内部收集的In-the-Wild数据集上进行评估。</div><div class=" pTag">IDM–VTON在定性和定量上都优于先前的方法。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhXWXzmU5afb5HevdZNIfkS8z74dWoicYiaTSkwj6v1ZwicvpjHzW5OF7Xw/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhj4DTHJwSsavtuOV8Q0UQmiaoGRMCQ6BKj1c8w0c5lQcL8JIw6m1DCibw/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhTDVNTWcT9dtXUGOk18dZFfNMT5bfTYXic3SaPFNWR77bbPibOUic9jkhQ/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhho7nVcbq9iamn2F2td37sCpekTqKyc7OH706E0icnFytrZylkxd6KnWA/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhxkVP4jcA7KQz6qjQwia8TkXLehPba5n0khWyMFPlmJ1cyVBTbbdkibTQ/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhH5Frtgf6v8CIdDy3mEKByyUXKhnibHHsT2vZApWetFBd8zejDLUyMHQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">IDM-VTON可以生成真实的图像并保留服装的细粒度细节。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhG3ELFzg2B5aUP2mcBBpK9QF3k0vSxDH894uSCg7mJ2hqv3IqxwLuvA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">更多细节，感兴趣的家人们可以查看原论文。</div><div class=" pTag"><span style="font-size: 17px;"><span>项目链接：</span><br /><span>[1]https://idm-vton.github.io/?continueFlag=589fb545dbbb123446456b65a635d849</span></span><br /><span style="font-size: 17px;">[2]https://arxiv.org/abs/2403.05139</span><br /><span style="font-size: 17px;">[3]https://huggingface.co/spaces/yisol/IDM-VTON?continueFlag=589fb545dbbb123446456b65a635d849</span><br /><span style="font-size: 17px;"><span>参考链接：</span><br /><span>[1]https://twitter.com/multimodalart/status/1782508538213933192</span></span><br /><span style="font-size: 17px;">[2]https://twitter.com/fffiloni/status/1783158082849108434</span><br /><span style="font-size: 17px;">[3]https://twitter.com/ClementDelangue/status/1783179067803533577</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FxULhCgGawzwuuG-bALRazw">阅读原文 </a>
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 12:47:35 GMT</pubDate>
</item>
<item>
<title>AI机器人开始卷家务了，深圳创业果然务实</title>
<link>https://posts.careerengine.us/p/662ba25575e9e7777af106b3</link>
<guid>https://posts.careerengine.us/p/662ba25575e9e7777af106b3</guid>
<content:encoded><![CDATA[
<div> 关键词: Astribot S1, 家务劳动, 智能技术, 星尘智能, 机器人助理

总结:<br /><br />文章介绍了来自星尘智能的全新国产AI机器人Astribot S1，展示了其在家务劳动方面的出色表现。S1具有丰富的实用技能，通过软硬件协同实现了高难度动作的准确完成。其研发团队在技术和经验方面具有优势，致力于让机器人无限接近人类水平。由CEO来杰领导的团队，旨在让数十亿人拥有AI机器人助理，实现机器人劳动、学习和思考等多种功能。星尘智能公司在智能技术领域不断探索创新，将S1推向商业化应用，并致力于打造数十亿个机器人的智能世界。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">注意看，这个机器人迅速地将三层红酒杯下面的布抽了出来。</div><div class=" pTag">动作敏捷干脆，红酒杯没有丝毫的晃动。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yHjEHl2Hn8Sv0gibex0pECy785mVbvn2nxS1cx21RgDa49kTRUvmOejA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">它就是来自星尘智能的全新国产AI机器人Astribot S1<span>（简称S1）</span>。</div><div class=" pTag">它不仅可以华丽炫技，完成抽出桌布这样的高难度动作，也拥有许多实用技能。</div><div class=" pTag"><strong style="font-weight: 600;"><span>无需遥操作</span></strong>，就能完成熨衣服、叠衣服等家务劳动，动作敏捷得和一个成年人如出一辙。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yQSYCC8Ddnqub1lTK6OOkibRGPia0M8Fib5PQqwgxjLkictzFoaibiaHV2yRQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">那么，下面就来看看，这个机器人到底都能干些啥。</div><h2>能大力出奇迹，也能慢工出细活</h2><div class=" pTag">首先值得一提的是，常见的机器人视频大部分是多倍速的，而S1的DEMO<span><strong style="font-weight: 600;">基本上都是原速，甚至敢于慢放</strong></span>、不怕挑刺。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yGuMfwRh9G1w3k9msibRRZnLIrCID5oO5jcia0ak61MWkwosqMIxn42Dw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">而且接下来所有的家务劳动，都没有遥操作，完全靠机器人自主完成。</div><div class=" pTag">它出得厅堂，修凳子、浇花、接电源，这些动作都能轻松完成，双手配合得十分默契。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yetn1QXk2J2tEaaKOSyLqynFxiaVd4X7seC0Yl5TeRZM7skjJRNpzrLw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">复杂一些的电器，比如吸尘器，用起来也是得心应手，几下就把桌上的纸屑清理得干干净净。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3y2MhamHHbZx2cGzrLbwFicp0NlfC5koTXBp9OjA9bbC9cib3yxiaqGuSMg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">甚至还学会了投掷，在远处就能把纸飞机这样轻的物体精准“空投”入桶。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yhN5ianbIliaTibP7anZANk4nwRBBWM6Jv5jmcH1DJYbgZcAQnL2mJSv4w/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">而且它也下得厨房，塑料瓶玻璃瓶都能轻松打开，也不会让瓶子里的液体洒落。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3ytqAUW6zicheUWzSgKZMRToqfer9fIhUzMYLR0X1Hia7MhoHkFFlyaELg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">削黄瓜皮这种细致活，也是做到了既干净又不浪费，而且还学会了炒菜颠锅。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yoictatWFljl2GAtfOGbTl0Aia76u3f83c4lMKFILX7xw6oicH1pjWM2mQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">更为智能的是，它还可以识别眼前的物体，然后在对话指导之下设计子目标，完成物品分类的任务。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yFMAy1PnNrPMUGKkSwsicj3iaONefWbMqRmwGTibiaQUz1Z0bsp8HibpuRIw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">以上这些场景都是我们生活中可能会遇到的，所以S1的这些技能<strong style="font-weight: 600;"><span>绝非花拳绣腿，而是实用的家务助手</span></strong>。</div><div class=" pTag">当然除了这些劳动，S1的<strong style="font-weight: 600;"><span>模仿能力</span></strong>也是很强的，比如跟着人类跳舞的视频，它也有模有样地跳了起来。</div><div class=" pTag">当机器人跳起海草舞，在魔性之余，连贯细腻的动作却说得上丝毫没有机械感。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3y4IhhCmgwhIStn5aUv4m3JBruLbLsVia615bkZxxbHiaWgspKCQz6OmwA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">更绝的是，像写书法这种对手部细腻度和稳定性要求极高的活动，也被它给学会了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3ym60yqv0s1vg34LHgHcB1XT9mJ4icGzwfLWfAt0dJxx7fPZbac7uxNuQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><h2>腾讯RobticsX一号员工创业</h2><div class=" pTag">那么，在S1这一系列精彩表现的背后，都运用了什么样的技术？它背后的星尘智能，又是怎样的一家公司呢？</div><div class=" pTag">研发团队介绍，让S1具有丰富技能的一大关键因素，在于<strong style="font-weight: 600;"><span>“软硬件协同”</span></strong>，既要有智慧的“大脑”，也要有敏捷灵活的“身体”。</div><div class=" pTag">软件上，它背后的系统支持视频、动捕及遥操作等多种数据收集手段，可使用强化学习、模仿学习和多模态大模型等完成学习和训练。</div><div class=" pTag">而且软件的升级也会带动机器人的进步，不断提升智能化和多任务泛化能力。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yIU838vQz0xmy1WokwY4dmLPWff2KVnZ7TicCJ0x68qTxm9xhAgIx7oQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">硬件上，团队设计了自研的高性能电机传动系统，并经过多次迭代，最终集成了控制、传感、传动与驱动等多个复杂系统，为S1机器人提供了敏捷、灵活、丝滑的动态操作能力，以及<strong style="font-weight: 600;"><span>接近工业机器人的速度和精度</span></strong>。</div><div class=" pTag">此外，它的头、手、躯干均采用了<strong style="font-weight: 600;"><span>模块化设计</span></strong>，可按不同需求灵活组装或拆卸，进一步提升了任务适应性。</div><div class=" pTag">它的最高速度达到了10m/s<span>（36km/h）</span>，单臂负载达到了10公斤，拥有七个自由度，而且<strong style="font-weight: 600;"><span>重复定位误差只有30微米</span></strong>，一系列指标都超越了普通的成年男性。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yw6UeZHia4Blzicw7XO0X0AycGJI3An2AJvcYiaTZImKDCiaugibsGttyRfg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同时，团队使用了“以力为中心”的创新设计方法，保障了机器人的安全性，能精准控制与人体、物体和环境的交互力度，在运动中不伤人、不伤物、不伤自己。</div><div class=" pTag">目前，S1机器人<strong style="font-weight: 600;"><span>已接入大模型测试，并预计在今年年内完成商业化</span></strong>。</div><div class=" pTag">而S1的研发公司星尘智能，于2022年底在深圳成立，这次发布的S1，是团队耗时一年研发出的成果。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yF9oUicsicOlGwBhKIZrPK97FoQqoc1wRtzvFzniaaAwwFVAmInwaic2myw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">公司<strong style="font-weight: 600;"><span>创始人兼CEO来杰</span></strong>，拥有16年的机器人研发经验。</div><div class=" pTag">他曾任腾讯RobticsX一号员工、百度“小度机器人”团队负责人；腾讯的轮腿式机器人Ollie，以及多款新型机器人，都由他主导研发。</div><div class=" pTag">来杰本科在西安电子科技大学就读，后在五邑大学攻读智能系统硕士学位，毕业后首先来到了香港理工大学担任助理研究员。</div><div class=" pTag">2014年，走出学术界的来杰开始了他在百度的四年研发生涯，并于2018年转入刚成立的腾讯RoboticsX实验室，直到出走创业。</div><div class=" pTag">除了来杰之外，公司团队其他成员的背景也包括腾讯、谷歌、优必选、百度和华为等前沿科技公司，在技术和商业领域都拥有丰富的经验。</div><div class=" pTag">而谈及未来的目标，来杰的回答是，<strong style="font-weight: 600;"><span>让机器人无限接近人类的水平</span></strong>。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我们的目标是让数十亿人拥有AI机器人助理，能像人一样学习、思考和劳动，会使用人的工具和设备、帮人完成枯燥、困难或危险的任务，甚至能适应环境和变化，从而真正照顾家庭老幼。</div><div class=" pTag"><br />这样的世界将需要数百万、甚至数十亿个机器人。</div><div class=" pTag"><br />我们希望机器人的能力能从55%、85%成长到99.99%，无限接近人类水平。</div></blockquote><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FX0zNfUbAwazl9_EwJkU1XQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 12:47:17 GMT</pubDate>
</item>
<item>
<title>字节发布视觉基础模型ViTamin，多项任务实现SOTA，入选CVPR2024</title>
<link>https://posts.careerengine.us/p/662ba246595624771b4059bc</link>
<guid>https://posts.careerengine.us/p/662ba246595624771b4059bc</guid>
<content:encoded><![CDATA[
<div> ViTamin、视觉模型、扩展性、零样本准确率、下游任务
<br />
<br />
总结: 文章介绍了新型基础模型ViTamin，设计专为视觉语言时代，相比传统ViT在ImageNet零样本准确率上有明显提高，表现出色在分类、检索、开放词汇检测和分割等任务上。研究团队对主流视觉模型在视觉语言情境下进行了评估，发现ViTamin在数据扩展性、模型可扩展性、特征分辨率和混合架构等方面有优势。ViTamin不仅在零样本ImageNet准确率和平均38个数据集准确率方面超越ViT，还在多项下游任务中达到新的技术水平。智能创作团队通过这项工作展现了他们在计算机视觉和多媒体技术领域的领先地位，并为行业提供了先进的技术能力和解决方案。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">允中 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">视觉语言模型屡屡出现新突破，但ViT仍是图像编码器的首选网络结构。</div><div class=" pTag"><strong style="font-weight: 600;">字节提出新基础模型——ViTamin</strong>，专为视觉语言时代设计。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yn2pvOgulEqU2TiaFwVfnDeHGKF93ecwfvc9Dgw9nOicNlB2lmesW4dC3A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在使用相同的数据集和训练方案时，ViTamin在ImageNet零样本准确率上比ViT提高了2.0%。</div><div class=" pTag">此外在分类、检索、开放词汇检测和分割、多模态大语言模型等60个不同基准上都表现出了良好的结果。</div><div class=" pTag">当进一步扩展参数规模时，ViTamin-XL仅有436M参数，却达到了82.9%的ImageNet零样本准确率，超过了拥有十倍参数（4.4B）的EVA-E。</div><div class=" pTag">最终这一成果，<strong style="font-weight: 600;">入选计算机视觉顶会CVPR2024</strong>。</div><h2>视觉语言时代新基准</h2><div class=" pTag"><strong style="font-weight: 600;">在视觉语言时代下，如何设计一个更好可扩展的视觉模型？</strong></div><div class=" pTag">在ImageNet时代，新的视觉模型在ImageNet数据集得以验证，也造就了不断有新的视觉模型涌现。但在视觉语言时代，新的视觉模型鲜为人见。</div><div class=" pTag">此外，基于现有常见视觉模型，在面对比ImageNet数据规模还大的情况下表现又是如何？研究团队们测试了几种常见模型，包括纯Transformer的ViT，纯卷积网络的ConvNeXt，以及混合卷积和Transformer的CoAtNet。</div><div class=" pTag">最终在一个公开的数据集上进行了系统性的训练和比较，得出了一些关键发现：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">第一，模型的扩展性</strong>：由于可扩展的自注意力机制，ViT能最好地适应不同规模的任务。</div></li><li><div class=" pTag"><strong style="font-weight: 600;">第二，数据的扩展性</strong>：随着训练数据的增加，所有模型的性能都有所提升。</div></li><li><div class=" pTag"><strong style="font-weight: 600;">第三，特征的分辨率</strong>：在训练过程中，模型需要理解更广泛的信息，而不仅仅是简单的类别标签。因此，提取的特征的分辨率对模型的预测能力有很大影响。</div></li><li><div class=" pTag"><strong style="font-size: 17px; text-align: justify; font-weight: 600;">第四，混合架构</strong><span style="font-size: 17px; text-align: justify;">：</span><span style="font-size: 17px; text-align: justify;">在一般情况下，CoAtNet表现优于其他模型，但将其扩展到处理数十亿数据可能会有一些挑战。</span></div></li></ul><div class=" pTag">基于这些发现，研究人员设计了<strong style="font-weight: 600;">ViTamin模型</strong>。</div><div class=" pTag">它采用了三个阶段的混合架构。前两个阶段使用了轻量级的MBConv Blocks，第三个阶段包含了可扩展的Transformer Blocks。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnVYIOjia9yK8sQiceibnFn2AX9bibOhaCZEjWyelUOFMn25qUETuvfPdPDg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">具体来说，一张图片首先经过卷积stem处理，得到2倍降采样的特征图。</div><div class=" pTag">然后，这个特征图经过第一阶段，由两个MBConv-LN Blocks组成，接着经过第二阶段，由四个MBConv-LN Blocks组成，然后降采样得到16倍降采样的二维特征。</div><div class=" pTag">接下来，这些特征被展平成一维，并输入到第三阶段，该阶段由N_B个TFB-GeGLU Block组成。最后，通过对比图像特征和语言特征，来学习对比损失函数。</div><div class=" pTag">作者们致力于简单有效的<strong style="font-weight: 600;">scaling law</strong>，只考虑模型的宽度C和模型第三阶段的深度N_B，因此在scaling到更大的模型中，通过模型的参数规模可以直接反推需要多大的宽度和深度，进而实现模型的scaling。</div><h2>多项SOTA</h2><div class=" pTag">在<strong style="font-weight: 600;">零样本性能</strong>上面，研究结果显示，ViTamin-L的零样本ImageNet准确率比ViT-L/14高出了2.0%。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnE7EFvnypvBLyw7ujJerVo1BwSfjl88jnJME9PDcxstqQ9BA9pKTzUg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">当将特征分辨率增加到576个patch时，ViTamin-L的准确率进一步提高到了81.8%，比之前的ViT-L/14 CLIPA-v2高出了1.5%。在38个数据集的平均性能上，ViTamin-L比ViT-H/14模型高出了0.4%，而且参数数量只有ViT-H/14的一半。</div><div class=" pTag">此外，当进一步扩大模型规模时，参数量为436M的ViTamin-XL达到了82.9%的ImageNet零样本准确率，超过了4.4B参数量的EVA-E取得的82.0%。</div><div class=" pTag">作者们进一步验证了<strong style="font-weight: 600;">ViTamin模型对下游任务而言是个强大的视觉编码器</strong>。</div><div class=" pTag">作者们引入了一系列下游任务，包括开放词汇检测和分割，以及多模态大模型（LMMs）。</div><div class=" pTag">ViTamin在开放词汇检测任务OV-LVIS上，相比比ViT-L模型能提高了3.1%。ViTamin在8个开放词汇分割任务中，相比ViT-L平均提升了2.6%。</div><div class=" pTag">ViTamin能直接迁移到多模态大模型诸如LLaVA上，并在12个多模态问答等基准上表现出色。值得注意的是，ViTamin在7个开放词汇分割基准上创造了新SOTA。</div><div class=" pTag">在这项工作中，作者们建立了主流视觉模型在视觉语言情境下的评估基准，并对它们进行了重新基准测试。作者们从数据可扩展性、模型可扩展性、特征分辨率和混合架构四个方面考察了主流的视觉模型。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yn5IfcSZrrY5aD5ZGG0LrS5OdIictPSfJTwkuszUvPNNNp1MZbbDABwQw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这四个方面的关键发现为ViTamin的设计提供指导，ViTamin模型不仅在零样本ImageNet准确率和平均38个数据集准确率方面全面超越ViT，而且在包括开放词汇检测和分割以及大型多模态模型在内的22个下游任务上达到了最新的技术水平。</div><h2>来自智能创作团队</h2><div class=" pTag">智能创作团队是字节跳动 AI &amp; 多媒体技术团队，覆盖了计算机视觉、音视频编辑、特效处理等技术领域。</div><div class=" pTag"><div class=" pTag">他们借助公司丰富的业务场景、基础设施资源和技术协作氛围，实现了前沿算法 - 工程系统 - 产品全链路的闭环，旨在以多种形式为公司内部各业务提供业界前沿的内容理解、内容创作、互动体验与消费的能力和行业解决方案。</div><br /><div class=" pTag">目前，智能创作团队已通过字节跳动旗下的云服务平台火山引擎向企业开放技术能力和服务。更多大模型算法相关岗位开放中。</div></div><div class=" pTag"><span style="font-size: 17px;"><span>论文链接：</span><br /><span>https://arxiv.org/pdf/2404.02132.pdf</span></span><br /><span style="font-size: 17px;"><span style="font-size: 17px;">项目主页:</span><br /><span style="font-size: 17px;">https://beckschen.github.io/vitamin</span></span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FtQl3bVSPpDWeqJmwpWzfhQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 12:47:02 GMT</pubDate>
</item>
<item>
<title>你的超级知识助手来了！讯飞星火支持长文本长图文长语音，生产力直线UP</title>
<link>https://posts.careerengine.us/p/662ba246595624771b4059b2</link>
<guid>https://posts.careerengine.us/p/662ba246595624771b4059b2</guid>
<content:encoded><![CDATA[
<div> 知识获取、大模型、科大讯飞、智能体平台、落地应用
<br />总结:
知识获取是讯飞星火大模型V3.5春季上新的关键，支持长文本、长图文、长语音等多种形式。科大讯飞推出的智能体平台为企业解决了大模型应用落地的难题。新功能包括多情感超拟人声音合成和一句话声音复刻，增强用户体验。大模型升级的技术理念着眼于解决现实问题，帮助企业实现数字化转型。智能体平台是大模型在企业落地应用的新方式，极大提高了企业的工作效率和智能化水平。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">白交 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">这一次，大模型真的可以让人类解放双手了。</div><div class=" pTag">今天讯飞星火大模型V3.5春季上新，直戳办公场景的痛点！</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">星火大模型能力升级，支持长文本、长图文、长语音……不仅能够把各种来源的海量文本、图文资料、会议录音等进行快速学习，还能够在各种行业场景中给出专业、准确回答。</div></li><li><div class=" pTag">还有专门为企业推出的<strong style="font-weight: 600;">“</strong><strong style="font-weight: 600;">智能体平台”</strong>，打造智能助手，解决大模型应用企业落地的最后一公里难题。</div></li><li><div class=" pTag">另外讯飞星火语音交互能力进一步升级，首发多情感超拟人声音合成，AI能“情感共鸣”了，还上线“一句话声音复刻”等功能。</div></li></ul><div class=" pTag">好了，目前星火大模型已经升级，这就来第一时间体验一下。</div><h2>“超级知识助手”来了</h2><div class=" pTag">在此前官方预告中，大家就对即将发布的三个“长”功能颇为关注。科大讯飞推出这一系列新功能，背后有着怎样的考虑？</div><div class=" pTag"><div class=" pTag">据科大讯飞董事长刘庆峰透露，他们看到一段时间以来，讯飞星火的开发者和用户都高度关注知识的获取和学习问题。</div><br /></div><div class=" pTag"><span style="font-size: 17px; text-align: left;">在知识获取和学习的过程中，广大用户能拿到的资料往往不仅是现成的长文本，还有随手可见的报刊书籍内容、各种研讨会的PPT内容，老师黑板上的板书、同学的笔记，以及各种会议录音、访谈，各种网上的发布会、培训教育视频等，能不能把这些文本、图片、语音等都上传到讯飞星火</span><span style="font-size: 17px; text-align: left;">中，快速地获取知识？</span></div><div class=" pTag">这就要求大模型不仅要解决长文本、还有长图文、长音频以及各种企业和专业行业应用的准确率问题。</div><div class=" pTag">为此，科大讯飞推出首个支持长文本、长图文、长语音的大模型，来解决用户真实场景中多源信息的获取需求。</div><h3>长文本</h3><div class=" pTag">据介绍，升级之后，当前星火大模型通用长文本能力，包括长文档信息抽取、长文档知识问答、长文档总结、长文档文本生成等，总体已经达到GPT-4 Turbo 4月最新大模型版本的97%水平，而在银行、保险、汽车、电力等多个垂直领域的知识问答任务上，星火大模型长文本总体水平已经超过GPT-4 Turbo。</div><div class=" pTag">而为了应对运行效率问题，星火大模型特别进行了剪枝和蒸馏，推出13B版本，效果损失仅3%以内，但响应时间、生成效果等方面的效率都有提升。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yKukic8ib012HAGA9RO8S8Xiaiak3awbkt0G6XibeY3dtIibfvtpiajsyoz6WA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">话不多说，这就来开始实际评测一番。</div><div class=" pTag">首先来看第一题开胃小菜，把费曼物理学讲义第一卷直接扔给他，也不告诉它书名叫啥，直接问书中讲了什么。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yCYwzNXT2957BuFacUhTcficwKZSyWf8dMQYCM61jLBmQiaOM2SI99Sfg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">嗯~还不错，大致方向是对的。</div><h3>长图文</h3><div class=" pTag">接下来，来看第二题，考验它长图文识别的能力。</div><div class=" pTag">据刘庆峰介绍，图文识别大模型现在已经覆盖了31个最常见的典型场景，像教育类的书刊、学术论文、专利、报纸、海报、产品白皮书、PPT和菜单、APP截图、演讲照片等等都已经进行了覆盖，以及18种版面要素（包括页眉、页脚、标题、栏目、段落、表格、插图等）</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3ytx16C9rlicj3uFsdDHiam6MsUJ97RmEp04OaaMhmyB2zNOkw5oy3y9ng/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">既然如此，那就扔给它一份最新量子位智库出品的《中国AIGC应用全景报告》PPT，并询问相关细节问题。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yW3SUlB0Gv4MOpLliaUZOcuueGTA0hYx3Bwicsbic5COzYx5kwBs2AqSOw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yY5mBZMZfRl30lhSYRTb4TMQ5DicbPuemV4UcrzWA8IlqRJNHhC2icGFg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3y1TnUpOhYess1PR2OibDTACzE5sHE4GKM4xZJJKA9lpLq0dJ45l6SW8w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">结果不管是市场规模、商业模式、投融资情况都一一清楚的回答上来。</div><h3>长语音</h3><div class=" pTag">最后再来考验一下它的长语音能力。可以看到，讯飞星火可以支持多种音视频格式，只要不超过1GB大小就好。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yduZWH8ozBj8PXPpI9DR5wE3nlN0SHrcjHibKKtr7nAXKhdIiaWX2LJ8w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么就扔给他这次科大讯飞官方发布长语音能力的演示视频试试。</div><div class=" pTag">结果：</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yMhgicB2T7oAnp1ibYo1yRv94RRvVgicpo60jj70W7fEwJa3RtAIicGtKqg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">甚至还包括像「刘庆峰做了什么」也都精准回答了。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3y2dDia7zJXlBZ9WgJIgB6v0GdjmibSSBDyiaKkCFHurwhpReFILUDMDYIg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">想象一下，在信息获取或知识学习中，拿到的资料无非就是现成长文本、论文书籍，又或者研讨会PPT、笔记截图，以及各种会议录音、发布会、网上教学视频等等。</div><div class=" pTag">而此次科大讯飞星火大模型的升级：“长文本、长图文、长语音”的支持，可以说把整个场景全覆盖了。</div><div class=" pTag">用上了它，相当于每个人都拥有了个知识助手，这不就是妥妥的学习工作小利器嘛~</div><h3>多情感超拟人合成&amp;一句话声音复刻</h3><div class=" pTag">除此之外，还有多情感超拟人合成功能、一句话复刻的功能的首发上新，可直接去星火APP上体验。</div><div class=" pTag">年初讯飞星火V3.5发布会上，科大讯飞推出的超拟人对话功能，如今该功能得以进一步升级，不仅更逼真，情绪表达也更为丰富，包括高兴、抱歉、安慰、撒娇、困惑等情绪表达的可感知度达到85%以上。</div><div class=" pTag">与此同时还推出了一句话声音复刻，一句话就可以定制你的AI助手声音。这样出差的时候，就还可以给孩子讲故事，又或者给爷爷奶奶读书读报，给世界带来更多温度。</div><h3>星火智能体平台</h3><div class=" pTag">办公场景，长期以来一直面临一个痛点——如何高效地获取和学习知识。此次推出的智能体平台正是专门面对企业场景。</div><div class=" pTag">在讯飞星火智能体平台上，首先，基于星火大模型，会自动实现用户输入的精准理解和任务规划。解析完了相关的任务和对应的工具之后，讯飞星火已构建形成了包括天气、航班、企查查等成体系的外部信息来源的对接；</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yUmbRqiakBpJRcT7LkLUTTcap2nIiaibGXlHOQO7ia6pgXHzDSXdhKmtic3g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同时，星火智能体平台还通过互认证的机制，实现了往往是独立的、隔离的OA系统、CRM系统以及ERP系统的打通，完成相应操作；最后，通过私域知识融入机制，智能体平台很容易实现企业所属行业以及企业私域知识的融入，实现更精准的专业理解和知识问答。</div><div class=" pTag">此外，星火智能体平台还可以通过拖拽方式实现新智能体的创建和多智能体的协作。用以上一套组合拳，敏捷触达大模型应用企业落地的最后一公里。</div><h2>讯飞大模型的技术理念：从解决现实问题出发</h2><div class=" pTag">可以看到的是，此次星火大模型的升级，更偏落地，更偏解决现实刚需，而非只是性能参数的升级。</div><div class=" pTag">一方面，讯飞星火大模型实际体验中，都是企业的刚需场景。</div><div class=" pTag">据七麦数据显示，讯飞星火APP在安卓端的下载量已经超过9600万次，在国内工具类通用大模型APP中排名第一。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yNy0cGjPTzicxI1Vu8vicOpaAOLqwLg5hPNHP3kiaoKIoh6VA8xWNk1Ticw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">从<strong style="font-weight: 600;">C端使用场景</strong>来看，讯飞星火的用户主要集中在办公领域。具体使用高峰期集中在工作日的上午9点半和下午的3点左右，以互联网、科研、教育、传媒行业为主。</div><div class=" pTag">这种用技术解决刚需的逻辑，也体现在科大讯飞的多项业务增长中。</div><div class=" pTag">在大模型加持下，开放平台与消费者业务全年营收达到61.9亿元，成为科大讯飞最大的业务板块。智慧汽车、智慧医疗、智慧金融业务板块则分别贡献了7亿元、5.4亿元和2.9亿元的营收，同比分别增长52.2%、14.9%及26.1%。在C端智能硬件领域，搭载讯飞星火的讯飞智能办公本、讯飞智能录音笔、讯飞智能翻译机等消费者硬件GMV同比大增84%。</div><div class=" pTag">另一方面，这也是讯飞一直以来所对外传达的技术理念：<strong style="font-weight: 600;">先进技术持续迭代的同时，也始终致力于去解决现实场景。</strong></div><div class=" pTag">典型例子就是大模型的每次升级，讯飞星火都有会新的亮点行业应用，比如今年1月发布首个语音大模型，以及此次首次亮相的图文识别大模型。在底座大模型的加持下，不断突破大模型能力的边界。</div><div class=" pTag">但每次升级，同样也都对应了实际场景应用，真正做到现实问题的解决。比如此次刘庆峰就重点介绍了在招投标、合同、教育等场景下的应用。</div><div class=" pTag">比如在<strong style="font-weight: 600;">招投标场景</strong>中，科大讯飞和国家能源物资公司在企业采购场景合作了智能无人评审系统，已经在国资委网站上被作为典型案例推荐。</div><div class=" pTag">此次该系统还将进一步叠加长文本和长图文能力，可以让评标更便捷、更高效、更准确。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3ykRjhONk0sWmwAibIkTJmNPX7ustz0rdBsqGhsRSt7vpmKH10syjkf4g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">还有<strong style="font-weight: 600;">合同助手</strong>。它可以对合同进行风险审核、合同比对、摘要总结以及合同生成，迅速识别潜在风险和漏洞。除了工作中需要，在日常生活中买卖商品、装修或者购买保险等场景也都完全用得上。</div><div class=" pTag">这种解决现实问题的大模型技术理念，也让讯飞星火在业内快速构建起一定的影响力。</div><div class=" pTag">自今年1月30日发布以来，讯飞星火V3.5作为首个全国产算力训练的大模型，受到了各行业伙伴和开发者的广泛欢迎。尤其在一些关键行业和重大战略领域，星火大模型以“云、边、端”的整体解决方案赋能到越来越多的行业，比如汽车、比如家电、比如运营商……在实体经济中发挥价值。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yHDJQ7VEdw7PzroEUHK7dbHnQ5FZLc5BCtMlRyMaNvmN4XMLcyLksRQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">从开发者生态上来看，在过去不到3个月的时间里，讯飞新增了55万实名认证的开发者，其中一半以上来自企业。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yaibwdNh8NF3mRkl4wjYmbFZCUa1dZM6HS6eyElzgvGFJSZdYWrFywGg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>大模型支撑起新质生产力</h2><div class=" pTag"><div class=" pTag">今年，毫无疑问的是大模型应用元年。大模型支撑起新质生产力，帮助企业数字化转型。</div><br /></div><div class=" pTag">但企业到底应该怎么用？如何去用？大模型发展到现在，大致可以梳理出这样三种模式来。</div><div class=" pTag">一种简言之就是<strong style="font-weight: 600;">当前大模型加持的通用AI原生APP</strong>，功能碎片化每次能调用的工具有限，还依赖于每次大模型公司的模型升级。</div><div class=" pTag">还有就是<strong style="font-weight: 600;">开源大模型或者接入API</strong>，但是通用大模型去落地真实应用场景中间还有很长一段距离，这需要技术与行业Know-how协同，对企业来说是个不小的挑战。</div><div class=" pTag">再者就是<strong style="font-weight: 600;">超级APP</strong>，各种AI原生碎片化能力集成在一起，实现工作流程中沟通、执行等方面的提效。但如果没有计入内部数据，实现内外知识的打通，那么大模型的提效能力是有限的。</div><div class=" pTag">而讯飞星火此次展现了第四种模式——<strong style="font-weight: 600;">智能体平台</strong>。AI Agent作为企业提效手段已经成为确定的趋势。而科大讯飞直接推出产品化的解决方式，并且整个流程低门槛，只需简单拖拽就可实现智能体构建和多智能体的协同，企业可以更容易地直接上手使用，有助于实现智能体的规模化落地，实现大模型普惠价值。</div><div class=" pTag">最后可以看到，越来越多大模型升级朝着更落地的方向走去，其实也代表了一种特定的趋势。</div><div class=" pTag">那就是大模型已经走向我们日常生活，人工智能朝着解决真实世界的问题的方向不断深入。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FurUwx1pH3BW5vFMpPRRU_g">阅读原文 </a>
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 12:47:02 GMT</pubDate>
</item>
<item>
<title>老黄亲自上门送超算！OpenAI奥特曼签收后到斯坦福演讲GPT-5</title>
<link>https://posts.careerengine.us/p/662a1a2193e56b68d73732e4</link>
<guid>https://posts.careerengine.us/p/662a1a2193e56b68d73732e4</guid>
<content:encoded><![CDATA[
<div> OpenAI、老黄、DGX H200、AI、GPT-5
<br /><br />
总结:OpenAI收到了世界上第一台DGX H200超算，老黄亲自上门送货。这次收到的超算具有更大的内存和更高的内存带宽，是首款搭载HBM3e内存的GPU。该超算可能会用于加速运行ChatGPT等任务。与此同时，老黄还在斯坦福大学的Nvidia礼堂发表演讲，后来参加了闭门会议，传言中讨论了GPT-5的一些大事。整体来说，AI领域发展迅速，各项技术不断创新，为人工智能和计算科学的进步带来了新的可能性。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">梦晨 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">皮衣老黄亲自上门送货！OpenAI收到<span><strong style="font-weight: 600;">世界上第一台DGX H200超算</strong></span>。<span style="display: none;">‍‍‍‍‍‍‍‍</span></div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">致推进人工智能、计算和人类发展。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqheyhciaxr3Sib0n5KBLEaRkQmrEB1V7gd3kialfOQxxVEzYM2VvfvG2Jeg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这下呼吁快发布GPT-5的声音更高了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhRxD9h0zs0uIIOcmzcug1NuWyvgrcNfJrPRbj5q735MV7WicGGGG5DNQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在OpenAI负责模型微调的员工Steven Heidel开玩笑说：“老黄签过名上了Buff的GPU，运算速度可是会加快20%。<span style="font-size: 17px; text-align: left;">”</span></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhXlen2LK32LzYDJp31PVu383f7OOY5ae1gxNm4ECBURTicvzKk1bInoA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这场面与八年前，2016年老黄向OpenAI赠送世界上第一台DGX 1超算时何其相似，相似的皮衣，相似的致辞，相似的算力巨兽，只是遍插茱萸少两人：</div><ul class="list-paddingleft-1"><li><div class=" pTag">与OpenAI分道扬镳的联合创始人<span><strong style="font-weight: 600;">马斯克</strong></span></div></li><li><div class=" pTag">不知踪影的首席科学家<span><strong style="font-weight: 600;">Ilya Sutskever</strong></span></div></li></ul><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhUtHZuUcB4CJJwA7gsKBUXzZUdjLrhUoPuI9FKaTg6xwvztusIb24Ew/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">一到这种时候，自然少不了热衷玩梗的网友。</div><div class=" pTag">只花1分钟，在线AI修图工具Dingboard.com开发者就把Ilya照片无违和感的变换姿态，P到合影里。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh2vlmP2nsCEO3YzMVY3ZLa3aDicTpibCLB5WbVOu2MiaXjCEBg6nNPw4rA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">以及有眼尖的网友指出，Brockman身后墙上的装置可能是居家健身品牌Tonel的力量训练器械。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhyVXjFhdaKMyibBQ8fHEAQdJB2vaFIht6YY31CUMWzBG1MXZsKaHuMCw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>DGX H200超算有多强？</h2><div class=" pTag">奇怪的是，OpenAI总裁Brockman的推文与机器上的签名都是<span><strong style="font-weight: 600;">“DGX H200”</strong></span>，而英伟达官网上相关产品只有<span><strong style="font-weight: 600;">“DGX GH200”</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh5Ksjqo9t6iaxfs6QwYjKFzUEdfpt35sIMtMickq5iaddfLphvgZI9kxVA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">目前尚不清楚两者是否指代同一产品，或者是英伟达为OpenAI推出了特殊定制版本，去掉了DGX GH200中的Grace CPU，只留下了H200 GPU。</div><div class=" pTag">H200 GPU的特点一言以蔽之：<span><strong style="font-weight: 600;">141GB大内存</strong></span>，与H100的80GB相比直接提升76%。</div><div class=" pTag">作为首款搭载HBM3e内存的GPU，内存带宽也从3.35TB/s提升至4.8TB/s，提升43%。</div><div class=" pTag">除内存升级之外，H200的其他各方面规格和峰值算力与H100保持一致，一个优势在于可以直接替换到现有的H100计算机群中去，不用做任何调整。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhJQpEJzfJURSoiaYAUzqXuCibP2tzB9kU3CtVibMsVO5vOZOJ6Sgyp2bgg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">ChatGPT官号也透露，<span><strong style="font-weight: 600;">更多的内存带来更多的KV缓存，也就可以运行更多的ChatGPT</strong></span>。</div><div class=" pTag">暗示新超算可能会用于ChatGPT的推理加速。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhXokBia9DIeMlsnQQefQmWc0CwWwsAReR5JnGE8h6CBFiavzTibsVxbiaXg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>One More Thing</h2><div class=" pTag">与老黄合影几个小时后，奥特曼被曝现身斯坦福大学的Nvidia礼堂发表演讲。</div><div class=" pTag">礼堂可容纳342人已经爆满，还有约200人挤在外面。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhqCSFO8dfibWJsCdN3OXcricvasib3icfrL3buKcG1FKBz821Q31oaSzIlA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">根据斯坦福学生Andrew Gao介绍，随后他有机会参加了奥特曼<strong style="font-weight: 600;"><span>20人左右的闭门会议</span></strong>。</div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">他提到了一些大事，但我不能分享。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhwjox1icM4ItIiafV0iaiaXyWMjXWT71U9YUmX2cC07iafB6v9Maw76mELkw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span><span style="font-size: 17px;">另一位参加闭门会议的人也没有透露具体内容，但总之对GPT-5很兴奋。</span></span><span><span style="font-size: 17px;"><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span></span></span></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhDFWlaHbhyJHlLdskGOzef3dATde6CxtDOjuvr7PZyA8Wib5AfEo5GyA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://x.com/gdb/status/1783234941842518414</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://x.com/itsandrewgao/status/1783301236126847379</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSDEh9MncYtpTYv3922y86w">阅读原文 </a>
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 08:53:53 GMT</pubDate>
</item>
<item>
<title>揭秘腾讯混元大模型：400+场景落地，协作SaaS产品全面接入</title>
<link>https://posts.careerengine.us/p/662a1a1127ae07689b8d7afb</link>
<guid>https://posts.careerengine.us/p/662a1a1127ae07689b8d7afb</guid>
<content:encoded><![CDATA[
<div> 腾讯混元大模型、应用落地、用户体验、混元一站式平台、模型精调<br />
<br />
总结:<br />
文章介绍了腾讯混元大模型应用落地的最新趋势，强调了重视用户体验和精细化应用的重要性。腾讯混元团队通过混元一站式平台的完整流程，实现了模型研发到应用落地的成功落地。文章还揭示了腾讯混元大模型团队与业务团队之间紧密合作的关键，以及如何通过混元一站式平台快速精调模型并提升数据处理能力。该平台的自动化和智能工具为业务接入大模型提供了便利。继续助力合作伙伴业务智能化升级是下一步的重点。文章最后描述了团队对问题的追求和改进精神。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">梦晨 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">进入2024，大模型的风向变了。</div><div class=" pTag">当初“百模大战”时，只要<span><strong style="font-weight: 600;">简单粗暴拿个Demo搞MaaS</strong></span><span>（模型即服务）</span>，也就是让用户直接和大模型交互就足以上牌桌。</div><div class=" pTag">但现在，<span><strong style="font-weight: 600;">精耕细作搞应用</strong></span>，无论是原生AI应用，还是在已有产品上整合AI功能，成了最新潮流趋势。</div><div class=" pTag">就连一向低调神秘的<strong style="font-weight: 600;">腾讯混元大模型团队</strong>，也对外公布了应用落地进展：</div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">腾讯混元大模型已经支持内部超过400个业务和场景接入，并通过腾讯云，面向企业和个人开发者全面开放。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh0hZ3EJ1PMh54tXEBwCJuVufO16mwzwta3UMV6pywZmN2t7NG6X9wdw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这里面有很多为人熟知的“国民级”App，如<span><strong style="font-weight: 600;">企业微信、腾讯文档、腾讯会议</strong></span>，都已经被AI全副武装。</div><div class=" pTag">还有更多腾讯云SaaS产品，如企业知识学习平台<span><strong style="font-weight: 600;">腾讯乐享</strong></span>、电子合同管理工具<span><strong style="font-weight: 600;">腾讯电子签</strong></span>等，也都有了AI加持。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhFBhKKqI1rLbBsRuppueO5YsiasQhvZXMa8OINFFDEy0gVqxh95fbJpA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">腾讯混元大模型去年9月才首次亮相，是否有意在加速赶进度？</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhTBSOFwgUMawVxt9wKbiclodW9KqhmSjskduMYyoljnicVFZXl8iagJvZg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">面对这个问题，<span><strong style="font-weight: 600;">腾讯混元大模型应用负责人张锋</strong></span>的回答就有点“凡尔赛”了：</div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">我们只是按照正常的节奏，而且不光是接入大模型这么简单，已经进入打磨用户体验阶段。</div></blockquote><div class=" pTag">在国内大模型厂商中，腾讯为何走出这样一条独特的路线？我们与张锋深入聊了聊。</div><h2>腾讯AI产品，已经在打磨用户体验了</h2><div class=" pTag">腾讯这么多年来一直以产品见长，AI时代也延续了这种风格。</div><div class=" pTag">就拿大模型的门面<strong style="font-weight: 600;">腾讯混元助手</strong>来说，“已经在打磨用户体验了”还真不是一句空话。</div><div class=" pTag">比如让它做一道简单的数学题，就可以发现AI在分析思路时非常流畅，还判断出题目中缺少条件，但<span><strong style="font-weight: 600;">最后给出结果前却稍有停顿</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhZVQGhVxGMnNIickU3PCH9lPAc46dHHDDGEaTu1bAavviawkicPAz3WhHQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">这并不符合大模型预测下一个token的运作原理，反倒像是真的在计算。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh303bMa5iaZIqctPvTHLzIlJlNseQatM0zNyibWrTD43FKk5xmYMqodTg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">张锋揭秘，背后其实是<span><strong style="font-weight: 600;">AI先写了一段代码，在后端执行再返回结果</strong></span>。</div><div class=" pTag">不得不说，这是一种解决大模型计算不准确问题的巧妙思路。但为什么不像GPT-4代码解释器版一样，把代码在前台显示出来？</div><div class=" pTag">腾讯混元助手一个重要场景是在微信小程序里使用，移动端展示代码就会显得特别长。张锋认为，现在的策略更符合用户体验习惯。</div><div class=" pTag">产品策略有了，但实现起来并不是一件简单的事。首先需要大模型明白当前用户需求需要精准计算，接着要生成合适的代码，最后还要成功通过函数调用来执行代码。</div><div class=" pTag"><strong style="font-weight: 600;">像这样从细节出发，打磨用户体验的例子还有很多。</strong></div><div class=" pTag">比如大家很熟悉的<strong style="font-weight: 600;">腾讯会议</strong>，比起简单的AI语音转写和会议纪要总结，也做了不少差异化功能。</div><div class=" pTag">人的口头表达免不了停顿磕绊，腾讯会议AI在转写时把“嗯嗯啊啊”这样的部分智能规整，让会后文字记录看起来更整洁。</div><div class=" pTag">腾讯会议正在思考的另一个问题是，AI 生成的会议总结格式应该根据会议类型做出适当调整。</div><div class=" pTag">有明确主题和议程的会议，与大家畅所欲言的头脑风暴会议，需要的总结的格式就截然不同。因此，除了按时间分章节生成会议纪要外，腾讯会议也将推出按发言人/主题生成会议纪要的功能。</div><div class=" pTag"><strong style="font-weight: 600;">腾讯乐享</strong>，作为企业知识协作平台，在AI问答功能中就做到了识别提问者身份，做到回答千人千面。</div><div class=" pTag">如果是企业HR问AI有关薪酬结构的问题，就可以得到正面回答，其他岗位问同样的问题AI会拒绝提供。做到在便利的同时还非常安全。</div><div class=" pTag">湖南的律师事务所旷真接入了乐享助手去做AI知识库， 员工调研显示，对典型问题的AI回答满意度高达93分，端到端问题准确率达91%。</div><div class=" pTag"><strong style="font-weight: 600;">腾讯电子签</strong>，利用AI智能文件审查系统，识别合同风险条款，便于企业把控合同风险。企业对合同的风险控制需求各不相同。腾讯电子签还利用大模型和few-shot技术训练适合客户行业的垂类小模型，实现低成本运行。同时，通过混合云的模式，支持数据、模型的私有化部署，解决效率问题的同时保证合规。</div><div class=" pTag">总计400+的应用场景中，像这样的例子还比比皆是，这里不再赘述。</div><div class=" pTag">值得探讨的下一个问题是，腾讯如何做到在短时间内把AI产品打磨成熟的。</div><h2>应用落地完整流程已跑通</h2><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag"><span><strong style="font-weight: 600;">在腾讯，大模型研发和业务应用是“双向奔赴”的。</strong></span></div></blockquote><div class=" pTag">根据张锋介绍，腾讯混元大模型研发过程中迭代速度很快，基本一个月就有四到五个版本。</div><div class=" pTag">这种速度就来自于和业务应用团队的高效合作，业务团队提出需求并贡献微调数据，研发团队就能有针对性的加强大模型的能力。上线测试过程中不断发现Bad case，也能迅速为大模型补齐短板。</div><div class=" pTag">在这种研发时就考虑到实际应用需求的模式下，腾讯混元大模型定位成了“实用级通用大模型”。</div><div class=" pTag">在国内大模型中，腾讯混元率先完成MoE<span>（Mix of Experts，专家混合）</span>架构升级，也就是从单个稠密模型升级到多个专家组成的稀疏模型。</div><div class=" pTag">MoE架构在激活参数不变情况下，总参数量加大，可以吞吐更多的token，同时，得益于较小的实际激活量，可显著降低训推成本。</div><div class=" pTag">这种路线的快速转型，也得益于与早期就了解了业务应用一方需求。</div><div class=" pTag">在与业务应用相互打磨的过程中，腾讯混元着重提升了通用模型的三个能力：</div><div class=" pTag"><span><strong style="font-weight: 600;">指令跟随能力</strong></span>，提出各种各样复杂的结构化长指令，腾讯混元都能按要求执行。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhjgVl0eLyLib1nSJXIuZcHxJfzcMHdLWkpve7PEMSHWNAextnWbeUxyw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span><strong style="font-weight: 600;">网页及文档理解能力</strong></span>，满足用户经常需要AI来总结长文本内容、减轻认知负的需求。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhFAibp6qGvLYmAmoEmBC3GgV084n9wq7e6HfZnmcZozfF8bAypNloc9w/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag"><span><strong style="font-weight: 600;">函数调用能力</strong></span>，也是腾讯混元团队判断大模型下一阶段的趋势之一。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhGBpAe5dJql2Z0MCvgZfKj5wnub5hNgv9q4MlJdCVyqyH62M6ok0YXA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">通用大模型只是一个开始。</div><div class=" pTag">张锋介绍，在实际应用中，除了MoE主模型，如果调用量很大，从性价比的角度，<span><strong style="font-weight: 600;">各业务可以考虑使用不同尺寸的小模型，或者采用根据业务数据微调后的垂直小模型</strong></span>。</div><div class=" pTag">微调<span>（Fine-Tuning）</span>是学术界通用叫法，在腾讯内部更愿意用<span><strong style="font-weight: 600;">“精调”</strong></span>。</div><div class=" pTag">从数据管理到自研AngelPTM训练框架、AngelHCF推理框架，再到模型评测、部署都有一股精耕细作的劲儿。</div><div class=" pTag">那么，面对如今 400+场景，以及未来更多业务都要上大模型的情况，研发团队显然无法分出精力逐个精调，如何解决这个问题呢？</div><div class=" pTag">答案是通过<span><strong style="font-weight: 600;">混元一站式平台</strong></span>，许多需求业务团队自己就能轻松搞定。</div><div class=" pTag">混元一站式平台不仅支持通过API接口直接调用混元大模型服务，还把大模型从训练到部署的很多流程都做到可视化，不用写代码只需鼠标点点就能快速完成。</div><div class=" pTag">有了混元一站式平台很多AI工程师都不怎么去折腾代码了，而不精通机器学习的业务工程师也能轻松上手操作。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhibrJwiaMNtJT41gzP0yibpStWgnH1W1ic3piaib8bqVGSShN7Maszgsr5iaGg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">接下来根据一个完整的模型精调到上线的过程，来了解混元一站式平台的能力。</div><div class=" pTag"><span><strong style="font-weight: 600;">首先是模型方面</strong></span>，平台提供了各种尺寸的基座模型矩阵。又分为通用模型、针对典型场景的优化模型、针对更垂直领域任务的子模型三个层次。</div><div class=" pTag">通用模型前面已经介绍过，场景优化模型可以举两个例子：开发Agent类应用，就可以用到强化了函数调用能力的模型来做；在知识密度高的场景，则可以选择优化摘要能力的模型。</div><div class=" pTag">如果不光有垂直的应用场景，还有垂直的数据集，混元一站式平台上就可以完成针对私有数据集的二次训练，让垂直子模型不仅有很好的通用理解能力，也很擅长专业领域的知识也很擅长。</div><div class=" pTag"><span><strong style="font-weight: 600;">接下来便要说到靠混元一站式平台的数据处理能力。</strong></span></div><div class=" pTag">对于来自不同来源、质量参差的数据，从数据清洗流程如质检、去重，到统计调配不同主题数据的比例，再到更困难的数据价值观对齐，去除其中包含的偏见，都能靠自动化手段高效完成。</div><div class=" pTag">即使模型上线之后，再发现由于某类数据缺失造成模型某方面能力不强，也能迅速把补充数据投入到持续训练，支持模型的快速迭代。</div><div class=" pTag"><span><strong style="font-weight: 600;">有了基座模型和数据，就能通过精调来按需求打造专属模型。</strong></span>无论是速度快成本低的Lora精调，还是全参数深度精调都能在混元一站式平台完成。</div><div class=" pTag"><span><strong style="font-weight: 600;">精调后模型的评测、部署上线也都做到了自动化</strong></span>，特别是部署可以做到一键发布，是混元一站式平台的核心技术之一。</div><div class=" pTag">总结来看，相较于传统的机器学习平台，混元一站式平台的最大特点在于：提供预训练好的基座模型、自动化优化数据处理流程，以及精简高效的模型精调和应用集成工作流。该平台通过自动化和智能工具应对海量训练数据、模型定制和部署等挑战，极大地降低了业务接入大模型的门槛，实现了速度快、效果好、接入方式多样的目标。</div><div class=" pTag">一言以蔽之：<span><strong style="font-weight: 600;">已跑通从模型研发到应用落地的完整流程。</strong></span></div><div class=" pTag">内部流程彻底跑通、并经过400+场景验证，外部开发者和企业可以通过腾讯云上API直接调用腾讯混元能力，接下来就要在<span><strong style="font-weight: 600;">助力合作伙伴业务智能化升级上发力</strong></span>了。</div><h2>One More Thing</h2><div class=" pTag">在这次交流的最后，量子位把在测试腾讯混元助手过程中发现的，模型仍无法很好解决的问题提交给了团队。</div><div class=" pTag">结束后已经是北京时间晚上6点多，比原定的结束时间推迟了近2个小时。</div><div class=" pTag">腾讯混元团队大部分成员都准备动身去往机场，要赶回深圳研发总部。</div><div class=" pTag">张锋没有与大家一同离开会议室。</div><div class=" pTag">简单告别后，他又一屁股坐回沙发上，一心沉醉到琢磨怎么改进Bad case的世界里了。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FmD8WjR4n-I3X3XkISRAfPA">阅读原文 </a>
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 08:53:37 GMT</pubDate>
</item>
<item>
<title>支付宝悄悄上线智能助理，我们也偷偷测了下</title>
<link>https://posts.careerengine.us/p/662a1a1127ae07689b8d7af3</link>
<guid>https://posts.careerengine.us/p/662a1a1127ae07689b8d7af3</guid>
<content:encoded><![CDATA[
<div> 支付宝、AI产品、智能助理、灰度测试、功能模块
<br />
总结: 支付宝推出了新的AI产品——智能助理，通过灰度测试。这款AI助手与常见的对话或创作类大模型不同，更偏向服务办事型，能解答医疗问诊、信息推荐、商务旅行等问题。智能助理和支付宝深度绑定，可以调用支付宝及第三方功能模块或小程序，回答用户问题。对话速度较快，能处理多轮对话，提供基本支付相关信息。虽然还有改进空间，但已能满足日常需求。用户体验或许会不同，等待更多用户分享体验。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">支付宝被曝推出了新的AI产品！</div><div class=" pTag">量子位了解到，支付宝对一款AI智能助理进行灰度测试。</div><div class=" pTag">这款AI产品入口，就在支付宝最核心的首页位置，但又隐藏得较深。</div><div class=" pTag">如果你有幸被灰度到，那么点击首页右上角的加号时会看到“智能助理”的按钮。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhrUbOwVZdfdcLO5pdRynsicaGZpYcXOwAcguKaozIiaW0CTbyIfFFdX4A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不过，支付宝智能助理不同于对话交流、辅助创作的常见大模型，而是更偏向服务办事型的AI助手。</div><div class=" pTag">根据其界面显示，可根据医疗问诊、查办公积金、买机票找厕所、推荐上映电影等办事指令。</div><div class=" pTag">此外，它还能根据需求推荐支付宝的相应功能或直连小程序，起到App内的智能导航作用。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhWPeLA0qDedQIap8nbicFeFVKJmebQE58Ry7ZRHwI6uT7T4QBYacR4Mw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">获知这一消息后，量子位马上点开了支付宝里的加号，一看还真的获得了灰测资格，那就马上进行第一手实测。</div><h2>多种生活信息，对话就能查询</h2><div class=" pTag">先简单总结一下，这个智能助手不同于一般的对话或创作类大模型，而是和支付宝深度绑定的服务型AI助手。</div><div class=" pTag">它的主要功能，是匹配或调用支付宝生态内（包括第三方）的功能模块或小程序，来解答用户有关医疗问诊、信息推荐、商务旅行等方面的问题。</div><div class=" pTag">根据模块的不同，模型的回答可能是直接提取到的信息，也可能是告知用户使用方法和相应的入口。</div><div class=" pTag">比如我们的第一个问题关于天气，是“今天晚上会下雨吗”。</div><div class=" pTag">响应的速度还算不错，大概两三秒就给出了结果，而且知道了我们的意图是了解天气情况，并结合当前定位进行了准确搜索。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhVotWaea6Y9L1qkyiceUqFC7sMF2zeXPM2R2nVsT8xcIfDxvULDxMOLQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">但如果细看回复的文本，就会发现并未直接体现出问题的答案，而且看上去有一些套模板的痕迹。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhxiaicQxicOMhy3biaTsiaYPXktpsPNO8doux95V5ASH7Y4KCaN6AqXiaGWMw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">第二个问题关于出行，只需要直接问去目的地要怎样走，智能助理就会根据定位自动规划，不需要手动说明当前位置，除非当前位置不是起点。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhoZbP34icXFVQIx4fLmrdw2GQibvkqChibRIBIfl7vdO3SibWsMmzTsUwbA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同样美中不足的是，如果直接问打车要多少钱，智能助理反而不会提供这些信息了，而是直接给出了打车小程序的入口。</div><div class=" pTag">不过整体来看问题也不大，毕竟真想打车的话，总归也是要进入到相应的程序里面的。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhZbVaH0XH36JHOPVk1icDAR3SfXiaAFwIclkK3FiciaEMR4IiaJL5GhXb6vA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">如果要出远门，也可以让它来帮忙搜索机票和高铁信息，顺便推荐一些酒店。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhtvpUn4Okge8njq7u0ZL7c09eKgN8V9tZEth8YbL9o00iaJgN0YVXUfQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而且多轮对话能力也不错，我们分别省略了地点和任务信息，支付宝智能助理都能准确地根据前后文判断出我们的意图。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhtNawdmp4f134IJ7ooHyicrgR1FEqXDX0wwRb2ib5XXnayJaiaIFucHBGQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">当然了，作为一款支付软件里的助手，最基本的支付相关问题，也必须要有能力解决。</div><div class=" pTag">比如通过对话，直接让助手帮我们调出上个月的账单，还能指定某一类消费让助理给出相应数据。</div><div class=" pTag">当然了，给出的信息也都还不是直接指向问题，而是提供了相应的原始数据，需要自己进一步查阅。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh4U6jp4n0LZqfBjYEZAuaKibXUz4BoibPhjLNTmsia8kNj2S2SRSpFGs1w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">目前看来，AI助理已经可以在一定精准度上处理我们的数据，比如当我们要求查询指定的信用卡账单日时，它可以准确地定位到想要查询的那一张卡。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhSdr1ZzO7FyYPibYiaFVFlp87RwhicAR3aCADq48mmd5caJmaMOaSeRZPA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而存储在第三方的信息，就无法直接获取了，但智能助理也会给出详细的查询方式，并给出相应的入口。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhqtC8EicWBpPvUoq00NDH7F8ibbLibOnYs8VBTCVhicRdeCoUO1nibLVHK6w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">当然了，除了支付宝内的功能和小程序，一般的常识或生活问题，也可以拿来问，或者硬要尬聊也不是不行。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhrEc9VBdWZ2icMiaKXHaA8FrZOxyzrQODQQP9vTEkxY3IzMdkSpEPRlmQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而在输入方式上，或许从前面的截图当中已经看到了，支持打字和语音两种模式。</div><div class=" pTag">另外也可以上传图片，不过目前看这个功能还是个花瓶，上传后得到的回复是还不具有图片理解能力。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhEkCgSSc8K2Mib4sB5OlQlOMV5wG3v0ib3bExsubglOumm6nGmRH1rHGg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">总之，支付宝正在测试的这个智能助理，基本上可以满足我们的日常需求了，但在细节上，仍有不少提升的空间。</div><div class=" pTag">你被灰度到了吗，欢迎分享你的体验和感受。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FoGQDyKGQ7arlnmIWML-QDA">阅读原文 </a>
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 08:53:37 GMT</pubDate>
</item>
<item>
<title>GPT-4现场被端侧小模型“暴打”，商汤日日新5.0：全面对标GPT-4 Turbo</title>
<link>https://posts.careerengine.us/p/662a1a011c0db0684ea2df93</link>
<guid>https://posts.careerengine.us/p/662a1a011c0db0684ea2df93</guid>
<content:encoded><![CDATA[
<div> 关键词：商汤、大模型、日日新、端侧模型、功能全面<br />
<br />
要点1: 商汤发布了日日新大模型和端侧模型SenseChat Lite，展示了强大的功能和性能。<br />
要点2: 商汤日日新5.0全面对标GPT-4 Turbo，在逻辑推理、自然语言生成和数学能力方面表现优异。<br />
要点3: 商汤在多模态领域表现出色，展示了秒画5.0的生成效果和多模态能力。<br />
要点4: 商汤的办公小浣熊和代码小浣熊提高了办公和编程效率，展示了在办公和编程场景中的应用价值。<br />
要点5: 商汤在发展路线上注重大模型+大装置的打法，具备实践经验，受到客户好评，并展望了未来发展前景。<br />
<br />
总结: 商汤发布了强大的日日新大模型和端侧模型SenseChat Lite，展示了在多个领域的全面功能和性能，包括逻辑推理、自然语言生成和数学能力。同时，多模态能力和办公小浣熊、代码小浣熊的应用展示了商汤在多个领域的优势。通过大模型+大装置的发展路线，商汤在AIGC领域展示了强大的技术实力和应用价值，受到客户好评，展望未来发展前景看好。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">金磊 发自 商汤AIDC</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag" style="font-size: 17px;">够刺激，<strong style="font-weight: 600;">GPT-4竟然当众被“揍”了</strong>，甚至连还手的机会都没有：</div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqheaGbJ9whqk8JoYKeMpElevXguWNpicwFJmQTVbHWvUX87EejLtEP7Tw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">是的，就是在一场《街头霸王》游戏现场PK中，发生了这样的名场面。</div><div class=" pTag" style="font-size: 17px;">而且二者还是不在一个“重量级”的那种：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">绿人</strong>：由GPT-4操纵</div></li><li><div class=" pTag"><strong style="font-weight: 600;"><span>红人</span></strong>：由一个端侧小模型操纵</div></li></ul><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhrotVgvY2yygLUDZ6x31m0vEaZ59FF572DGvPb7Xg1NSibwmMoMJ9RfQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">那么这位又小又彪悍的选手到底什么来头？</div><div class=" pTag" style="font-size: 17px;">不卖关子，它正是由<strong style="font-weight: 600;">商汤科技</strong>最新发布的日日新端侧大模型——<strong style="font-weight: 600;">SenseChat Lite</strong><span>（商量轻量版）</span>。</div><div class=" pTag" style="font-size: 17px;">单是在《街头霸王》里的表现，这个小模型就颇有一种“天下武功，唯快不破”的气势：</div><div class=" pTag" style="font-size: 17px;">GPT-4还在想着怎么决策，SenseChat Lite的拳头就已经打上去了。</div><div class=" pTag" style="font-size: 17px;">不仅如此，商汤CEO<strong style="font-weight: 600;">徐立</strong>还在现场加大难度，直接<strong style="font-weight: 600;">在手机上断网开测</strong>！</div><div class=" pTag" style="font-size: 17px;">例如离线模式下生成员工请假一周的申请，效果是这样的：</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqht8nnicCVSJdicQgZicl504mYmgBsIXI0HJFYjkm2T939yGGCrsuZdDTPg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>现场原速</h6><div class=" pTag" style="font-size: 17px;"><span>（当然，徐立开玩笑表示“假太长了，不批噢~”）</span></div><div class=" pTag" style="font-size: 17px;">也可以对长段文字做快速总结：</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhP3Eof8399kQT6b4iagOHFP5eBabpqzAbrO8NzkkwujZqyxZV4nCr8Cg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>现场原速</h6><div class=" pTag" style="font-size: 17px;">而之所能够做到如此，是因为SenseChat Lite在同等尺度性能上已经达到了SOTA水平。</div><div class=" pTag" style="font-size: 17px;">更是用“以小博大”的姿势在多项测试中击败了Llama2-7B，甚至是13B。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhLRBhqXWicIBaW7gyeq2bEjObfFXLOP9B05icKLHGB13jWmZIPcTue8xg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">在速度方面，SenseChat Lite则是采用了端云“联动”的MoE框架，在部分场景中端侧推理占70%，会让推理成本变得更低。</div><div class=" pTag" style="font-size: 17px;">具体而言，对比人眼20字/秒的阅读速度来说，SenseChat Lite在中等性能手机上，可以达到18.3字/秒推理速度。</div><div class=" pTag" style="font-size: 17px;">若是在高端旗舰手机，那么推理速度可以直接飙到78.3字/秒！</div><div class=" pTag" style="font-size: 17px;">但除了文本生成之外，徐立同样在现场还展示了商汤端侧模型的<strong style="font-weight: 600;">多模态</strong>能力。</div><div class=" pTag" style="font-size: 17px;">例如同样是<strong style="font-weight: 600;">扩图</strong>，商汤的端侧大模型在慢半拍启动的情况下，扩了3种不同图片的速度比友商扩1张的速度还快：</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhVPMwOaficKHjwiaYlnZLL6OEkL1Uibw3n452ErlnMicfgEYdKFvTsMufEw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">演示的同学甚至直接<strong style="font-weight: 600;">现场拍照</strong>，把照片缩小了很多以后再来<strong style="font-weight: 600;">自由扩图</strong>：</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhkZriaCldVlyIicuxmWZvIiahHUC9BichBBYsurXIkfGqM5r5fyXdUZr9Sw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">嗯，不得不说，商汤是敢在现场动真格的。</div><div class=" pTag" style="font-size: 17px;">然而，纵观整场活动，端侧大模型也还仅是此次发布会的一隅。</div><div class=" pTag" style="font-size: 17px;">在“大基座”方面，商汤更是把自家的日日新大模型来了个大版本的升级——<strong style="font-weight: 600;">SenseNova 5.0</strong>。并且直接将其定位到了一个新高度：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag"><strong style="font-weight: 600;">全面对标GPT-4 Turbo！</strong></div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhSh9ibsAXriaRF6B9sib1QibnqH4PvsCYYl9LN2nlGICB0KascSvickM8a9A/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">那么日日新大模型5.0版本实力到底如何，我们这就来实测一波~</div><h2>有请，“弱智吧”！</h2><div class=" pTag" style="font-size: 17px;">自打大模型火爆以来，“弱智吧”就一直成了检测大模型逻辑能力的标准之一，江湖戏称为<strong style="font-weight: 600;">“弱智吧Benchmark”</strong>。</div><div class=" pTag" style="font-size: 17px;"><span>（“弱智吧”源自百度贴吧，是一个充满荒谬、离奇、不合常理发言的中文社区。）</span></div><div class=" pTag" style="font-size: 17px;">而且就在前不久，“弱智吧”还登上正经AI论文，成了最好的中文训练数据，引发了一波不小的热议。</div><div class=" pTag" style="font-size: 17px;">那么当文本对话的商量大模型5.0遇到了“弱智吧”，二者又会擦出怎样的花火？</div><h4>逻辑推理：“弱智吧”</h4><div class=" pTag" style="font-size: 17px;"><strong style="font-weight: 600;">请听第一题：</strong></div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我爸妈结婚为什么没有叫我？</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhOGeMcLNuicexbicmJo2kicsFozK7oEgduynkQD50Kh0LyFXIsaT0DprWQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">商量的回答不同于其它AI，它会比较拟人的用“我”来做回答，而且从答案结果来看并没有过多冗余的内容，而是精准地做了回答和解释，“他们结婚时您还未出生”。</div><div class=" pTag" style="font-size: 17px;"><strong style="font-weight: 600;">请听第二题：</strong></div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">网吧能上网，为什么弱智吧不能上弱智？</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhe5SXE1yhxPEhlBJaExicibZRIibGm8y0icIK5Dk860cGQxV4Gkg5IjOnwA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">同样的，商量直接精准点出“这是个玩笑性质的问题”，以及道出了“‘弱智吧’并非一个实际的地方”。</div><div class=" pTag" style="font-size: 17px;">不难看出，对于“弱智吧”这种魔幻、不按套路出牌的逻辑，商量5.0是已经能够hold住了。</div><h4>自然语言：高考《红楼梦》</h4><div class=" pTag" style="font-size: 17px;">除了逻辑推理能力之外，在<strong style="font-weight: 600;">自然语言生成</strong>方面，我们可以直接用<strong style="font-weight: 600;">2022年高考作文</strong>题目，来对比看下GPT-4和商量大模型5.0。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhusAI8rOQv5GEdT7SpV2Ge622p7ol1Aba9gfQ6RRiaLxZteWSy4QC8aw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">从结果上来看，GPT-4的文章还是一眼“AI模版”；而商量5.0这边，则是颇有诗意，不仅句子工整对仗，还能引经据典。</div><div class=" pTag" style="font-size: 17px;">嗯，AI的思路是被打开、发散了。</div><h4>数学能力：化繁为简</h4><div class=" pTag" style="font-size: 17px;">同样是让GPT-4和商量5.0同台竞技，我们这次来测试一下它们的数学能力：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">妈妈给圆圆冲了一杯咖啡，圆圆喝了半杯后，将它加满水，然后她又喝了半杯后，再加满水，最后全部喝完。问圆圆喝的咖啡多，还是水多？咖啡和水各喝了几杯？</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhOevgTJ7ZNicVwaZUxu75hNDM4OmiaV2RoQWxOCuZQBA4aFjkL4MPdS0A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">这道题对于人类来说，其实是一个比较简单的问题，但是GPT-4却对此做出了看似一本正经的缜密推导，结果还是错误的。</div><div class=" pTag" style="font-size: 17px;">究其原因，是大模型背后的思维链在逻辑上的构建并不完整，若是遇到小众的问题就极容易出错；反观商量5.0这边，思路和结果就是正确的了。</div><div class=" pTag" style="font-size: 17px;">再如下面这道<strong style="font-weight: 600;">“老鹰抓小鸡”</strong>的问题，GPT-4或许不理解这种游戏的规则，因为所算出来的答案依旧是错误：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhXVqz7PRlwyGIiaFpCxE0LGsX2BLENxEibUy7Ric87qzfKicvekniaZCZIyA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">不仅从实际体验的效果中可以感知一二，更为直接的评测榜单数据，也反应出了商量5.0的能力——</div><div class=" pTag" style="font-size: 17px;">常规客观评测已经达到或超越GPT-4 Turbo。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhBduQrFC8ha9mF9dlVRFj2CibRyyN5jG942GHODP3SQ7ibCg55qm88ic3w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">那么日日新5.0又是如何做到的呢？一言蔽之，<strong style="font-weight: 600;">左手数据，右手算力</strong>。</div><div class=" pTag" style="font-size: 17px;">首先，为了打破<strong style="font-weight: 600;">数据</strong>层面上的瓶颈，商汤采用了超过10T的tokens，使其具备了高质量数据的完备性，让大模型对客观知识和世界有了初级的认知。</div><div class=" pTag" style="font-size: 17px;">此外，商汤还合成构造了高达数千亿tokens的思维链数据，这也是此次在数据层面上发力的关键点，能够激活大模型强推理的能力。</div><div class=" pTag" style="font-size: 17px;">其次，是在<strong style="font-weight: 600;">算力</strong>层上，商汤是将算法设计和算力设施进行了联合的优化：算力设施的拓扑极限用来定义下一阶段的算法，而算法上的新进展又要重新知道算力设施的建设。</div><div class=" pTag" style="font-size: 17px;">这便是商汤AI大装置对算法和算力联合迭代的核心能力所在了。</div><div class=" pTag" style="font-size: 17px;">整体而言，日日新5.0的更新亮点可以总结为：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">采用MoE架构</div></li><li><div class=" pTag">基于超过10TB tokens训练，拥有大量合成数据</div></li><li><div class=" pTag">推理上下文窗口达到200K</div></li><li><div class=" pTag">知识、推理、数学和代码等能力全面对标GPT-4 Turbo</div></li></ul><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhPtY1zQos0Xu9icOt5icicMLTCfybkqnQ3wx0hMp8UaHyKrgs6rcHlVaUw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">除此之外，在<strong style="font-weight: 600;">多模态</strong>领域，日日新5.0在多项核心指标中也取得了较为领先的成绩：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhmA3A3UekwE2ZckT1MuC8g0hMjsicspPicyM234W65zkBy2BuibCGQystQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">老规矩，我们继续来看多模态的生成效果。</div><h4>更会看图了</h4><div class=" pTag" style="font-size: 17px;">例如“投喂”给商量5.0一张超级长的图片（646*130000），只需让它识别，便可以得到所有内容的概述：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhKwyqHk43C3UtUMhOn9qmLRzzr1bp2zZxsibxH1VXx40taNibdHk0CD9A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">再如随意丢给商量5.0一张有意思的猫咪图片，它就能根据派对帽、蛋糕和“生日快乐”等细节内容推断猫在庆生。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhUNhiamiaaicpbibRKt3cFUZeghj2tAvSFj8Hx5Ya20XYBjJIlJaJCxAVSQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">更实用一些的，例如上传一张复杂截图，商量5.0就能精准提取并总结出关键的信息，而这一点GPT-4在识别过程中却出现了失误：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh7BreugnNyrvQVrGiaBicZJ3uqW0WyN7IudoUSBLI7YUGybnIK9uJsglw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h4>秒画5.0：和三大顶流PK</h4><div class=" pTag" style="font-size: 17px;">在文生图方面，日日新的<strong style="font-weight: 600;">秒画5.0</strong>直接和Midjourney、Stable Diffuison和DALL·E 3进行了同台竞技。</div><div class=" pTag" style="font-size: 17px;">例如在风格上，秒画生成的图片可能会更加接近prompt中提到的“国家地理”：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhpkbNvWvib8JmkUYSYquou8nQfG3gam79yqQ7t8Qg7VwHYdo0Ycwle9A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">人物形象上，可以展示更加复杂的皮肤纹理：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhic0EO1VXXWEmLMmVtkVzEPRNx3TAsgOicdaAhskib0Pia7iawmyia8a3YPnQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">甚至是文字也可以精准无误地嵌入到图像当中：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhlQp8LDkBccfmS9HEX0RNoXp4d6PpmyRQsVrx5zLia2oWyV9TtUd8NZg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h4>还有个拟人大模型</h4><div class=" pTag" style="font-size: 17px;">除此之外，商汤在此次发布中还推出了一个比较特殊的大模型——<strong style="font-weight: 600;">拟人大模型</strong>。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqheiaqmImgBMxBVl73ibibrE9iciaHibhibphECPILgwa7DQCMJ4G9V8N91TJvg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">从体验来看，它已经可以模仿影视角色、现实名人、原神世界等各种破次元的人物，并且与你展开高情商对话。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh7rjnkuldaG3Onn7ichW0SFsIPt2xNX4GOnSkwqBia5gYFibalibtBcpzCg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">从功能上来看，商量拟人大模型支持角色创建与定制、知识库构建、长对话记忆等，甚至是可以三人以上群聊的那种哦~</div><div class=" pTag" style="font-size: 17px;">也正是基于如此多模态能力，商汤大模型家族的另一大成员——小浣熊也迎来了能力上的升级。</div><h2>办公、编程变得更easy</h2><div class=" pTag" style="font-size: 17px;">商汤的小浣熊目前细分为<strong style="font-weight: 600;">办公小浣熊</strong>和<strong style="font-weight: 600;">编程小浣熊</strong>两大类，顾名思义，分别是作用于办公场景和编程场景。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhxOkCr6iaYo9WbXZAzUI8icIr9mV6NV9rUTljkqFIbD43TPZ2hD34VM8g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">有了办公小浣熊，现在处理表格、文档甚至代码文件，都成了<strong style="font-weight: 600;">“一丢+一问”</strong>的事情了。</div><div class=" pTag" style="font-size: 17px;">以采购场景为例，我们可以先上传不同来源的供应商名单信息，然后跟办公小浣熊说：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">单位、单价、备注。因为不同 sheet 中的表头信息并不一致，可将类似的表头内容进行合并。在对话框中展示表格结果，并生成本地下载链接，谢谢。</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhZZMB5449WichLAFypIEE3g3N2P80ibjMDDx6BwOVvM3jvzibJpbqGwgXQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">只需稍等片刻，我们就可以得到处理完后的结果了。</div><div class=" pTag" style="font-size: 17px;">而且在左侧栏中，办公小浣熊还给出了分析过程的Python代码，主打一个“有迹可循”。</div><div class=" pTag" style="font-size: 17px;">我们还可以同时上传库存信息和采购需求等多个文件：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhwtPwTiajPu78JR3EMBiaibK3Tuic3qTjmHoyuZQEKhIVwXyCEPkCj4VrnA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">然后继续提要求，办公小浣熊依旧是能够快速完成任务。</div><div class=" pTag" style="font-size: 17px;">并且即使是数据形式不规范，它也能自行发现并解决：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhViaPUkjD3gTQ2SoyV8PYmSgbdzAZqdVJLsxEzc2mOtpLF8icnzChZBhQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">当然，数据计算也是不在话下，依旧是提要求的事情。</div><div class=" pTag" style="font-size: 17px;">除此之外，办公小浣熊也可以基于数据文件做可视化的工作，直接展示下有难度的热力图：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhUCSFo47XRZY6PmPib4uic9ezP15uxAicoTF1P7richu2A9mZndhABVEqdQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">总结来看，办公小浣熊可以对多个、不同类型（如 Excel、csv、json 等）做处理，在中文理解、数理计算和数据可视化等维度有非常强的能力。并且它通过代码解释器的形式，增强了大模型生成内容的准确性与可控性。</div><div class=" pTag" style="font-size: 17px;">另外，发布会上办公小浣熊还当场展示了结合复杂数据库进行分析的能力。</div><div class=" pTag" style="font-size: 17px;">上周，中国首位F1车手周冠宇完成了他在F1中国大奖赛的比赛。商汤在发布会现场直接给办公小浣熊“投喂”了一份数据量庞大的数据库文件，让小浣熊当场分析周冠宇和F1赛事的相关情况。</div><div class=" pTag" style="font-size: 17px;">如统计周冠宇的参赛信息、F1总共有多少车手、有哪些车手获得过总冠军并按照获奖次数从高到低排列，这些计算涉及量更大、逻辑更复杂的数据表格和圈数、领奖数等更多维度的细节信息，最终也都给出了完全正确的答案。</div><div class=" pTag" style="font-size: 17px;">在编程场景中，<strong style="font-weight: 600;">代码小浣熊</strong>也是可以让程序员们的效率直接Pro Max了。</div><div class=" pTag" style="font-size: 17px;">例如只需在VS Code中安装扩展的插件：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhibYCqTENj4al6iaddhmLN46MpoicwXoBTykR5Y1tlXmFdHCGM6CQCvELQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">然后编程的各个环节就变成了输入一句自然语言的事情了。</div><div class=" pTag" style="font-size: 17px;">例如把需求文档丢给代码小浣熊，然后就说句：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">帮我写一个公有云上微信扫码支付的详细PRD文档。PRD格式和内容请遵循“产品需求文档PRD模板”的要求，生成的内容清晰、完整、详细。</div></blockquote><div class=" pTag" style="font-size: 17px;">然后代码小浣熊就“唰唰唰”地开始做<strong style="font-weight: 600;">需求分析</strong>的工作了：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhrhHeicLC8jC8uadicQagthvn0DnvcjAakiaQ3RtuaribcTBpNPcSKexCog/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">代码小浣熊也可以为你做<strong style="font-weight: 600;">架构设计</strong>：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh0ROlfDQt8UPqT0PesGpog5uVibUqOaIeK3nraafcLgyibG9uEmibibpiadw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;"><strong style="font-weight: 600;">写代码</strong>也可以通过自然语言提需求，或者通过鼠标一键注释、测试生成代码，代码翻译、重构或修正等等：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhCHdf0LnpmSDn0ciaVViaZhw3WFe2xtrcL2X51unotcLpqS0HMDOYYWew/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">最后的<strong style="font-weight: 600;">软件测试</strong>环节也可以交给代码小浣熊来执行哦~</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh1CLyPuuI0wWJLESgia2NAPujAvZFraDprE4SOxXibRyX9HqH0BciaSpTw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">总而言之，有了代码小浣熊，它就能帮你处理平日里一些重复性、繁琐性高的编程任务。</div><div class=" pTag" style="font-size: 17px;">而且商汤此次还不只是发布这么个动作，更是将代码小浣熊“打包”推出了<strong style="font-weight: 600;">轻量版一体机</strong>。</div><div class=" pTag" style="font-size: 17px;">一台一体机就能支持100人团队开发，且成本仅为<strong style="font-weight: 600;">每人每天4.5元</strong>。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhrEw5HjWibexic7Z2OicJluyqHUomOibkhVnClcCYvSa48n3cBSdQUH79hQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">以上便是商汤此次发布的主要内容了。</div><div class=" pTag" style="font-size: 17px;">那么最后，我们还需要总结性地聊一聊一个话题。</div><h2>商汤的大模型路数</h2><div class=" pTag" style="font-size: 17px;">纵观整场发布会，给人最为直观的感受首先就是<strong style="font-weight: 600;">够全面</strong>。</div><div class=" pTag" style="font-size: 17px;">不论是端侧模型，亦或者“大底座”日日新5.0，是属于云、边、端全栈的发布或升级；能力上更是涵盖到了语言、知识、推理、数学、代码，以及多模态等AIGC近乎所有主流的“标签”。</div><div class=" pTag" style="font-size: 17px;">其次就是<strong style="font-weight: 600;">够抗打</strong>。</div><div class=" pTag" style="font-size: 17px;">以日日新5.0的综合实力为例，目前放眼整个国内大模型玩家，能够喊出全面对标GPT-4的可以说是为数不多；并且商汤是敢在现场直接拿多项能力做实测，也是敢第一时间开放体验，对自身实力的信心可见一斑。</div><div class=" pTag" style="font-size: 17px;">最后就是<strong style="font-weight: 600;">够速度</strong>。</div><div class=" pTag" style="font-size: 17px;">商汤的速度不只限于像端侧大模型的运行效果之快，更宏观地来看，是自身在迭代优化进程上的速度。若是我们把时间线拉长，这种speed就会格外得明显：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">日日新1.0→2.0：3个月</div></li><li><div class=" pTag">日日新2.0→4.0：6个月</div></li><li><div class=" pTag">日日新4.0→5.0：3个月</div></li></ul><div class=" pTag" style="font-size: 17px;">如此平均下来，近乎是一个季度便有一次大版本的升级，其整体能力也会随之大幅提高。</div><div class=" pTag" style="font-size: 17px;">那么接下来的一个问题便是，商汤为什么可以做到如此？</div><div class=" pTag" style="font-size: 17px;">首先从大方向来看，便是商汤一直强调的<strong style="font-weight: 600;">“大模型+大装置”</strong>的打法。</div><div class=" pTag" style="font-size: 17px;">大模型是指日日新大模型体系，可以提供自然语言处理、图片生成、自动化数据标注、自定义模型训练等多种大模型及能力。</div><div class=" pTag" style="font-size: 17px;">大装置则是指商汤打造的高效率、低成本、规模化的新一代AI基础设施，以AI大模型开发、生成、应用为核心；总算力规模高达12000 petaFLOPS ，已有超4.5万块GPU。</div><div class=" pTag" style="font-size: 17px;">二者的异曲同工之妙，便是<strong style="font-weight: 600;">早已布局</strong>，它们并非是AIGC大热潮之下的产物，而是可以追溯到数年前、具有前瞻性的两项工作。</div><div class=" pTag" style="font-size: 17px;">其次更深入到大模型层面，商汤基于自身在实际的测试和实践过程中，对行业所共识的基本法则<strong style="font-weight: 600;">尺度定律</strong><span>（Scaling Law）</span>有着新的理解和解读。</div><div class=" pTag" style="font-size: 17px;">尺度定律通常是指随着数据量、参数量和训练时长的增加，大模型所表现出来的性能会更好，是一种大力出奇迹的感觉。</div><div class=" pTag" style="font-size: 17px;">这个定律还包含两条隐藏的假设：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">可预测性：可以跨越5-7个数量级尺度依然保持对性能的准确预测</div></li><li><div class=" pTag">保序性：在小尺度上验证了性能优势，在更大尺度上依然保持</div></li></ul><div class=" pTag" style="font-size: 17px;">因此，尺度定律是可以指导在有限的研发资源中，找到最优的模型架构和数据配方，让大模型能够高效地去学习。</div><div class=" pTag" style="font-size: 17px;">而也正是基于商汤如此的观察和实践，诞生了“小且能打”的端侧模型。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhYnbvpIkM1s4NsLXvgzXKvj4odIea4q3sIUTQ75sWf9NTW7JsxOxqVQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">除此之外，商汤对于大模型的能力还有独到的三层架构（KRE）的理解。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhYXTtXTzYj9EVVhuq4Du6vUwxPQXdx406gJ2TwsiaCyBJniaV1CCBLLRg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">徐立对此做了深入地解读。</div><div class=" pTag" style="font-size: 17px;">首先是在知识，是指世界知识的全面灌注。</div><div class=" pTag" style="font-size: 17px;">目前大模型等新质生产力工具近乎都是基于此来解决问题，也就是根据前人已经解决过的问题的方案，来回答你的问题。</div><div class=" pTag" style="font-size: 17px;">这可以认为是大模型能力的基本功，但更为高阶的知识，应当是基于这样能力下推理得到的新知识，这也就是这个架构的第二层——推理，即理性思维的质变提升。</div><div class=" pTag" style="font-size: 17px;">这一层的能力是可以决定大模型是否够聪明、是否可以举一反三的关键和核心。</div><div class=" pTag" style="font-size: 17px;">再在此之上，便是执行，是指世界内容的交互变革，也就是如何跟真实世界产生互动（就目前而言，具身智能在这一层是潜力股般的存在）。</div><div class=" pTag" style="font-size: 17px;">三者虽相互独立，但层与层之间也是紧密关联，徐立打了一个较为形象的比喻：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">知识到推理是像大脑，推理到执行则像小脑。</div></blockquote><div class=" pTag" style="font-size: 17px;">在商汤看来，这三层的架构是大模型应当具备的能力，而这也正是启发商汤构建高质量数据的关键；不仅如此，也是基于KRE这套逻辑，才有了此次发布中的众多产品。</div><div class=" pTag" style="font-size: 17px;">那么最后一个问题是，基于KRE、基于“大模型+大装置”这样的路线，最新的日日新在产业中“上岗”到了什么程度？</div><div class=" pTag" style="font-size: 17px;">正所谓“实践是检验真理的唯一标准”，来自客户的使用反馈或许才是最真实的答案。</div><div class=" pTag" style="font-size: 17px;">而在此，商汤也交出了一份较为高分的作业——在现场，华为、WPS、小米、阅文、海通证券，从办公到文娱，从金融到终端，纷纷分享了使用商汤日日新大模型体系后，给自身业务带来的降本增效。</div><div class=" pTag" style="font-size: 17px;">总而言之，有技术、有算力、有方法论、有场景，商汤日日新在AIGC时代接下来的发展，是值得期待了。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FoiP4LPjVWo-9FLJXiGrz5A">阅读原文 </a>
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 08:53:21 GMT</pubDate>
</item>
<item>
<title>“AIGC第一股”首日市值54亿！出门问问正式登陆港交所，李志飞身家10亿</title>
<link>https://posts.careerengine.us/p/662904481cdf4828c289d3c2</link>
<guid>https://posts.careerengine.us/p/662904481cdf4828c289d3c2</guid>
<content:encoded><![CDATA[
<div> 出门问问、港股、IPO、财务数据、关键投资人
总结:<br /><br />文章介绍了出门问问在港股上市的情况，股票代码为“2438”，创始人李志飞持股25.2%。公司的财务数据显示，预计2023年实现营业收入5.07亿元人民币，净亏损接近8亿元人民币。出门问问在AI软件解决方案和AIoT领域取得进展，以通用大模型“序列猴子”为底座。投资者包括谷歌、红杉资本等。公司创始人背景为谷歌科学家，毕业于南京理工大学和约翰霍普金斯大学。自2012年成立以来，公司经历了7轮融资，总计融资超过2.5亿美元。公司重启IPO计划，目标是定义下一代人机交互，成为新AI时代的引领者。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">明敏 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag"><strong style="font-weight: 600;">出门问问，正式成为港股“AIGC第一股”</strong>。</div><div class=" pTag">今日，出门问问在港交所正式挂牌上市，股票代码“2438”，发售定价<strong style="font-weight: 600;">每股3.8港元</strong>。</div><div class=" pTag">截至今日收盘，出门问问市值已达54亿。</div><div class=" pTag">创始人<strong style="font-weight: 600;">李志飞</strong>作为最大股东持股25.2%，身价超10亿。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnAibicY13FaTia9Q3rmpjwAzrP9xJLI4GiaGv2mNN3YfXnLEPG8KtZbEvfA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">据配发结果公告显示，此次出门问问全球发售8456.9万股股份，国际发售4228.4万股份，公开发售4228.4万股。其中，公开发售获117.39倍认购，国际发售获1.58倍认购。</div><div class=" pTag">上市当日出门问问收盘价为3.68港元。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnnFdGdvcNxasUicWTCYn8BFAm3BzoqYHPa1eB5MibrPhQu4kvnoaXlfpA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">早在去年5月30日，出门问问向港交所递交招股书。</div><div class=" pTag">创始人李志飞是前谷歌科学家、NLP专家，也是中国最早一批投身于AI语音语言技术的创业者。</div><div class=" pTag">出门问问创立后，大众汽车谷歌红杉中国等纷纷加持，累计吸金超2亿美元，并先后在语音交互、智能硬件、AIoT等领域展开商业化落地。大模型东风吹来后，出门问问迅速将2020年发布的通用大模型UCLAI升级为“序列猴子”。</div><div class=" pTag">如今又率先抢跑，成为AIGC第一股。</div><div class=" pTag">出门问问，到底由哪些数据构成？</div><h2>关键财务数据</h2><div class=" pTag">根据最新招股书披露信息显示，出门问问由以下关键财务指标构成。</div><div class=" pTag"><strong style="font-weight: 600;">营收方面</strong>：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">2021年：实现营业收入3.97亿元人民币。</div></li><li><div class=" pTag">2022年：实现营业收入5.00亿元人民币。</div></li><li><div class=" pTag">2023年：实现营业收入5.07亿元人民币。</div></li></ul><div class=" pTag"><strong style="font-weight: 600;">毛利情况</strong>：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">2021年：毛利为1.49亿元人民币，毛利率为37.5%。</div></li><li><div class=" pTag">2022年：毛利为3.36亿元人民币，毛利率为67.2%。</div></li><li><div class=" pTag">2023年：毛利为3.26亿元人民币，毛利率为64.3%。</div></li></ul><div class=" pTag"><strong style="font-weight: 600;">净亏损情况</strong>：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">2021年：年内亏损2.76亿元人民币。</div></li><li><div class=" pTag">2022年：年内亏损6.70亿元人民币。</div></li><li><div class=" pTag">2023年：年内亏损8.03亿元人民币。</div></li></ul><div class=" pTag"><strong style="font-weight: 600;">经调整净利润</strong>：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">2021年：经调整后净利润为-7343.9万元人民币。</div></li><li><div class=" pTag">2022年：经调整后净利润为1.09亿元人民币，实现扭亏为盈。</div></li><li><div class=" pTag">2023年：经调整净利润为1753.5万元人民币，暴跌80%。</div></li></ul><div class=" pTag"><strong style="font-weight: 600;">收入构成方面</strong>，AI软件解决方案收入从2021年的0.60亿元增长到2023年的3.43亿元，年复合增长率为140%，收入占比从15%上升到67.7%。AIGC解决方案在2021-2023年的收入分别为682.2万元、3985.7万元和1.18亿元，复合年增长率超300%。</div><div class=" pTag">智能设备及其他配件的收入从2021年的3.38亿元减少到2023年的1.64亿元。</div><div class=" pTag">支出方面，从2021年-2023年，出门问问在研发上的投入分别是<strong style="font-weight: 600;">0.92亿元</strong>人民币、<strong style="font-weight: 600;">1.19亿元</strong>人民币和<strong style="font-weight: 600;">1.55亿元</strong>人民币。</div><div class=" pTag">研发开支的增加归因于研发职能的员工人数增加及大模型开发服务费增加。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnHicARjZQBuzwGAZOM7rvqDzwv4oDqDQPjvG37fkIkwg63QVxmbukJbw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>大模型为底座，软硬件通“吃”</h2><div class=" pTag">不过值得一提的是，尽管研发投入不断提高，但有关开支占总收入的比例从2020年的36.7%下降到2022年的23.7%。</div><div class=" pTag">对此，出门问问解释说这是因为业务增加带来了更多收入。</div><div class=" pTag">自成立以来，出门问问先后推出了AI软硬件集成、AIGC、AI CoPilot方面业务。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Ynq3d6YXGvrhKEkN0z9ExUibTPMVicZd8kBBegPpn1mDwrfknDSRwVKxkA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">招股书中显示，在2022年出门问问AI软件解决方案业务收入增幅达到<strong style="font-weight: 600;">408.89%</strong>，共计带来3亿元收入，占总收入的60%。</div><div class=" pTag">它具体包括AIGC解决方案和AI企业解决方案。</div><div class=" pTag">前者占比在2023年增幅明显，从原本不足10%上涨到23%。</div><div class=" pTag">后者则在2022年成为公司最赚钱的业务，带来一半以上业务，三年13.3%、52.6%、44.5%。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnNs9Ytt396R4E6Xy6fq84k5vZHFukSnyWl01ULIibopoib37lEicgN1ibOg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">他们的底层能力来自于出门问问的通用大模型。2020年，出门问问开发出通用大模型UCLAI，在今年升级为“序列猴子”。</div><div class=" pTag">具体到实际产品，他们先后推出了AI配音助手“魔音工坊”、AI写作助手“魔撰写作”以及AI数字人“奇妙元”。</div><div class=" pTag">据悉从自2020年以来，他们已为全球超过1000万用户提供服务，涵盖内容创作者、企业和消费者。</div><div class=" pTag">出门问问表示，这部分业务的增长，就在于AIGC解决方案方面的付费用户增加。而AI企业解决方案的收入增加，则是因为进行了知识产权安排。</div><div class=" pTag">另一大块收入构成，是<strong style="font-weight: 600;">AIoT解决方案</strong>。</div><div class=" pTag">2020-2022年带来的收入分别为：2.20亿、3.39亿和1.97亿。在2020和2021年，这部分收入占比均达到总收入的80%以上。</div><div class=" pTag">2022年的数字有所下降，此前招股书中解释说“部分被AIoT解决方案收入受延迟推出新旗舰产品影响而有所减少抵消”。</div><div class=" pTag">具体来看，出门问问AIoT智能设备主要包括AI智能手表、AI智能跑步机等。自2020年以来，AIoT智能设备销量已超过100万件。</div><div class=" pTag">其旗下的TicWatch智能手表，如今已经推出了4代共80款产品，最新产品TicWatch Pro 5在递交招股书前5天于海外正式发布。</div><div class=" pTag">出门问问表示通过软硬件结合，逐步将先进的AI技术应用于可穿戴、汽车及智能家居三大人机交互生活场景。相关的AIoT智能设备均可通过其虚拟助理“小问”进行连接。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnfNn8RCnSzIzaiaE7ib1GUjw2z02QS2LKPAibIiaiaGPOYvOfLIibr98vibfxw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">除此之外，招股书中披露的信息显示，出门问问对于大客户的依赖程度在2022年尤为明显，2023年有所缓解。</div><div class=" pTag">在2021年、2022年和2023年，出门问问的前五大客户分别占其收入的37.0%、62.8%和49.9%。</div><div class=" pTag">在同一时期，出门问问的最大客户分别占其收入的24.1%、42.6%和27.4%。</div><div class=" pTag">其中2022年出现的巨大增长，或许主要来自于汽车附属公司A的2亿元大单，比重甚至占到22年总收入的42.6%。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnMpFa4uM9jibLRUN8zUIcQ8lEiaTyDjFKC4VxA4y9iaQ4yONW1Vqav2tlQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>10年7轮融资，谷歌红杉中国押注</h2><div class=" pTag">出门问问成立于2012年，招股书显示自2013年至2019年，公司共融资七轮，累计融资金额超过<strong style="font-weight: 600;">2.5亿美金</strong>，<strong style="font-weight: 600;">约17.8亿人民币</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnG08Ov9lpEaia31pMo2aLltsoRFg3Fgkp7qTzc5YfCiaiaFEdGFcViatkeA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">参投者包括红杉资本、真格基金、SIG海纳亚洲、谷歌Google、歌尔声学及大众汽车集团（中国）等。</div><div class=" pTag">此外，两大地方国资中关村国际有限公司和南京经开聚智科创投资合伙企业，作为基石投资者参与出门问问本次IPO发行。</div><div class=" pTag">招股书披露的公司股权架构如下：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnF2cGNoM0CZicO2lrLcyCkoHiahevEsvKOK2tqWgZAiaBGwVRWbDm8q1dg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">创始人兼CEO<strong style="font-weight: 600;">李志飞</strong>是公司的第一大股东，IPO前个人持股<strong style="font-weight: 600;">26.72%</strong>。</div><div class=" pTag">李志飞、联合创始人李媛媛以及另一自然人旗下三家全资控股公司，共持股32.74% ，其中包括出门问问（Mobvoi Limited）、CMWW Limited以及Amberlei Limited。</div><div class=" pTag">随后，SIG、Google、红杉等持股介于17.03%与0.92%，声学设备龙头歌尔也在前十大投资人之列。</div><div class=" pTag">创始人李志飞，现同时任董事长、执行董事兼首席行政官，负责监管集团整体管理以及主要业务决策。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yn1szoQCR79aXpgekA75NOnvGdchibBuZzcn1u1qyJl4VCFqicjW2nvE1g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">他本科毕业于南京理工大，硕士毕业于南京航空航天大学，并分别获得南洋理工大学、约翰霍普金斯大学博士学位。</div><div class=" pTag">读博期间，他就开发了一款广为应用的开源机器翻译系统Joshua，在NLP领域有了积累。</div><div class=" pTag">2010年5月至2012年8月，在Google Inc.（现称Google LLC）总部担任研究科学家，负责语言翻译模型的算法研发。</div><div class=" pTag">2012年，拿到红杉资本和真格基金的天使投资后，回国创办出门问问。</div><div class=" pTag">成立10年之久，出门问问的上一次披露的融资也是5年前的事了。</div><div class=" pTag">2017年，出门问问获得大众汽车1.8亿美元D轮融资。此后，公司已有6年未宣布获得融资。</div><div class=" pTag">前段时间针对融资一事，李志飞正面回应称：近期不考虑融资，不需要外部融资也能支撑研发投入。</div><div class=" pTag">现在看来，或许是因为IPO，所以对融资并不“感冒”。资料显示，此次出门问问港股IPO，亦并非第一次。</div><div class=" pTag">时间回到2017年，彼时李志飞就曾表示计划两年内寻求IPO，当时称或许会在美国或香港上市。</div><div class=" pTag">而后到2019年，也曾爆出消息，出门问问即将获得融资，且公司正寻求筹集1亿美元资金，计划在上海证券交易所科创板上市。</div><div class=" pTag">不过当时李志飞对上市的回应则是：“感兴趣，有计划”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YngF3ZXzSQ74QXxVibWvN9v8KLtOsq8ibsSjOfMNZCnaZSHj8pdIYSkHWQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">随后4年，出门问问上市鲜少被提及，直至2023年AIGC大火，出门问问在发布大模型「序列猴子」及一站式AIGC产品后趁热打铁，火速重启IPO。并在一年后的今天正式登陆港交所。</div><div class=" pTag">在上市致辞中，李志飞表示：在成立之初，出门问问就以“定义下一代人机交互”为使命驱动，从语音助手到智能硬件，再到今天的大模型和AIGC，跨越十二年行业周期，逐步成为新AI时代的引领者。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">科技跟随者因为看见而相信，科技创新者因为相信而看见。明天开始，出门问问便将开启新一轮12年征程！</div></blockquote><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">招股书：</div><br /></span><span style="font-size: 17px;">https://www1.hkexnews.hk/listedco/listconews/sehk/2024/0416/2024041600025.pdf</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FF2XIouCJwxKC2t4WHt9G4A">阅读原文 </a>
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 13:08:24 GMT</pubDate>
</item>
<item>
<title>全球首个「油电平权」智驾方案：10万级入门标配高速NOA，高通Momenta联合出品</title>
<link>https://posts.careerengine.us/p/6629042f34c2052868e150cd</link>
<guid>https://posts.careerengine.us/p/6629042f34c2052868e150cd</guid>
<content:encoded><![CDATA[
<div> 关键词：高阶智能驾驶、高通、Momenta、普及、合作

总结:<br /><br />
高通和Momenta联手推出高阶智能驾驶产品，标配普及进入时代。该产品基于高通最新的Snapdragon Ride平台，使智能驾驶功能成为主流车型的标配。油车和电动车都可以享受智能化体验，无需区分。通过降低成本和提高性能，智能驾驶技术得到广泛普及。AI摩尔定律和Momenta的飞轮效应在推动智能驾驶快速发展。智能驾驶的标配时代将使更多人获益，推动整个交通系统朝着更加安全、高效的方向发展。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">贾浩楠 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">高阶智驾，正式开启标配攻势。</div><div class=" pTag">类比智能手机进程，旗舰机型进入面向所有人的普及阶段:</div><div class=" pTag">不论是自主泊车、高速环路NOA，还是城区通勤的记忆领航，能识别红绿灯、避让行人、自主绕障、左右转，CNCAP五星满分的主动安全功能，……应配尽配。</div><div class=" pTag sectionReplaced" style="text-align: center;"><strong style="font-size: 17px; text-align: right; font-weight: 600;">△</strong><span style="font-size: 17px; text-align: right;">高通8620量产方案全球首次实车体验</span></div><div class=" pTag"><div class=" pTag">而且这个方案同样面向燃油车、喊话燃油车，油和电对立的中国车圈话题里，这一次，油电同智。</div><br /></div><div class=" pTag">最重要的是，如此高阶智能驾驶产品，体验往上走、价格成本不断下探。数千元级硬件成本，标配的是旗舰级高阶智能驾驶的能力……</div><div class=" pTag">搅动风云者：<strong style="font-weight: 600;">高通</strong>、<strong style="font-weight: 600;">Momenta</strong>。</div><div class=" pTag">两家各自领域内最好的公司，卷出了新方向。</div><h2>高通Momenta联手，最新一代Snapdragon Ride平台智驾系统全球首发</h2><div class=" pTag">双方刚刚官宣，新智驾方案基于高通最新的<strong style="font-weight: 600;">Snapdragon Ridep平台（骁龙SA8620P和骁龙SA8650P）打造</strong>：</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnicNdicnDfiangYe9cgiadRLics93PH5NS7yKbwHGhAwEIpysw4zicMEInaFg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">其中，骁龙SA8620P芯片采用4nm工艺制程，具备36TOPsAI稠密算力，对Transformer架构支持更友好。Transformer则是实现BEV感知能力，也就是高阶城市、高速NOA的技术基础。</div><div class=" pTag">传感器方案上，可以选择搭载7V3R/7V1R两种不同方案。适合在10-20万元的主流乘用车上搭载。</div><div class=" pTag">注意是<strong style="font-weight: 600;">“主流乘用车车”，智能不再区分油电</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yn7zGjmMGaPKgSmiaemsVjreFAWCO3AaVcBqtDn03UqkJ8uc86HJwjhng/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">据介绍，这是因为骁龙8620芯片能支持被动散热，对于基础架构高度成熟、车载用电“冗余度”不高的油车来说，可在不增加额外成本的情况下直接上车。</div><div class=" pTag">具体功能体验上实现“行泊一体”，包括L2级的ADAS全功能，同时还可支持HNP高速高架领航辅助<span>（高速NOA）</span>，MNP记忆领航辅助<span>（通勤NOA）</span>，LPNP记忆泊车领航辅助、PNP泊车领航辅助等高阶智驾功能。</div><div class=" pTag">Momenta CEO曹旭东认为：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">“骁龙8620芯片为实现更高性价比的高阶智驾解决方案提供了全新可能，Momenta的算法优势可以进一步发挥，加速高阶智驾在更多主流价格段车型的标配落地。</div></blockquote><div class=" pTag">8620是“油电同智”的硬件基础。</div><div class=" pTag">另外高通公司副总裁羡磊表示：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">“Momenta的算法能力和高通在芯片上的技术优势属于双剑合璧，能够带来更好的产品体验，更有亲和力的成本，更广泛的智驾普及率。</div></blockquote><div class=" pTag">Momenta的算法能力以及数据闭环“飞轮”，则是高阶智驾标配的软件保障。</div><div class=" pTag">双方都提到了高阶智驾的普及和标配。这其实就是今年智能驾驶竞争的核心之一。</div><div class=" pTag">有两个重要指标，一个是以能覆盖从收费站到收费站全程，且能自主变道、避让、进出匝道的高速NOA为功能体验的起点。</div><div class=" pTag">之前不具备导航功能的ACC，或者只能实现“拨杆变道”的辅助驾驶功能，竞争力已经不够了。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Ynic9EG4B73Lh3wXaQhtB1QW71fbZ7Y53bsiaGr7118Ca8iaHWT9wUteRwQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">第二个指标是高速NOA功能不再花几万元选配，随车标配并且车型跨过15万元分水岭。</div><div class=" pTag">而高通和Momenta的新方案，是行业针对高阶NOA标配具有专门策略和清晰配置的第一个产品。</div><div class=" pTag">速度令人惊叹。</div><div class=" pTag">据透露，双方其实早在芯片研发阶段，就已经深入探讨合作可行性，并且充分发挥Momenta在量产交付上的经验和优势。<strong style="font-weight: 600;">仅用了不到两个月，就跑通跑好了产品功能</strong>。</div><div class=" pTag">应该也是全球首个基于量产车，最早实现的Refcar。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yncj3WjwYxm3icPmxq0iaj1OTHlsMialn1Lb8oG9FPrbCicKLxL0kk4RKE6g/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">实际上，这也是智舱王者高通，正式开启智驾的普及战，而更进一步被透露的是合作不止于高通的骁龙8620芯片，还包括骁龙8650——意味着城区NOA、记忆路线等等最先进的高阶智驾能力，也都开启了量产和上车。</div><div class=" pTag">这是高通的“硬”实力基础，也是Momenta飞轮驱动之下的兵贵神速。</div><h2>产生的影响：强强联手高阶智驾进入“标配时代”</h2><div class=" pTag">首发、上车的价值不止于高通和Momenta，更重要的意义是对于汽车产业和所有潜在消费者。</div><div class=" pTag">至少有明确的三点。</div><div class=" pTag"><div class=" pTag">第一，突破“15万以下无智能”的壁垒。</div><br /><div class=" pTag">第二，智能体验不再区别对待油电。</div><br /><div class=" pTag">第三，对消费者，汽车的智能化普及进入类比智能手机的“千元旗舰机”时代。</div></div><div class=" pTag">第一点， 入门级车型享受和豪华车型完全相同的智能驾驶功能体验，史上头一回。</div><div class=" pTag">智能车发展的早期阶段，高速NOA硬件配置成本是十分高昂的。光是搭载能够支撑高阶智驾芯片的域控制器，成本就要数千元甚至过万，再加上激光雷达，摄像头，毫米波雷达全套的传感器… 轻松过万，光这个硬件成本，就把很多10-20万的主流车型，拦在门外。</div><div class=" pTag">当时15万以下的入门级车型，选配上高阶智驾，售价就会上升到20万级别，失去竞争力。</div><div class=" pTag">不过经过数年智能车对传统汽车的渗透，供应链规模快速扩大，降本效应明显。</div><div class=" pTag">高通的骁龙8620、骁龙8650…一系列车规级智驾芯片从推出到进入量产车型落地的周期中可以说正逢其时，占了后发优势。</div><div class=" pTag">这就使得高通和Momenta可以把新平台BOM成本降到数千元量级——一部旗舰智能手机的价位，对于售价15万以内的车型来说足够合理，再没有理由不上车标配。</div><div class=" pTag">第二点，广大燃油车用户，终于不再是智能化浪潮中的被遗忘者。</div><div class=" pTag">从技术层面看，油车电子电气架构成熟，但也代表着对智能化的支持心有余力不足，比如信号传输的延迟问题、冗余不好做的问题、控制反馈响应慢的问题…</div><div class=" pTag">所以油车智能化核心问题，一个是架构上融合智驾硬件，以及算法上提升响应速度。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnmoDdyFbUibykY0dnSyWpPOdvXd4k6c3VIcyCewiagpPU7LwbibC7ka72A/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">高通在硬件层面，带来高性能低功耗且支持被动散热的优势。Momenta则是用<strong style="font-weight: 600;">数据驱动</strong>替代规则驱动，面对不同动力系统的特征，最大程度以成熟人类司机的方法训练AI控制油门刹车等，避免复杂的人工调整适配。</div><div class=" pTag">这两点综合看，高阶智驾标配，惠及的是两个最大的用户群体。</div><div class=" pTag">一个是占新车销售一半的燃油车用户，另一个同样是占一半份额的10-20万车型用户。</div><div class=" pTag">没有续航焦虑、高阶智驾随车标配，价格持平且体验远优于传统“功能车”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnCwDRTJwOicPlDNG3miboRib7g8XjKTMdLFibAh1icRnOU6GiahUUMjrbhsfg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px; text-align: left;">这种意义和价值，很难令人不联系类比到智能手机的普及浪潮中，千元的价位但拥有旗舰智能手机的部分功能和特性，这样具有推动性的变革——真正让所有人无差别进入了移动互联网的智能生活浪潮。</span></div><div class=" pTag">而对于主流乘用车，意义还不止于体验上的舒适性，还在于曾经豪华车专属的选配能力，现在正在加速标配到每一辆车，赋能到每一位车主。</div><div class=" pTag">更更重要的是，智能驾驶和智能汽车普及，一定也会推动整个路况和交通走向更为安全的新阶段。</div><div class=" pTag">这是所有用户和潜在消费者的福音。</div><h2>高阶智驾进入“标配时代”，还反映了什么？</h2><div class=" pTag">实际上，高阶智驾“标配时代”的历史进程，来得迅猛，但并非毫无征兆。</div><div class=" pTag">合作发布的现场，高通公司副总裁羡磊和Momenta CEO曹旭东在对谈中，分享了背后的作用规律。</div><div class=" pTag">第一是<strong style="font-weight: 600;">AI摩尔定律</strong>。</div><div class=" pTag">第二是Momenta一直实践的<strong style="font-weight: 600;">飞轮效应</strong>。</div><div class=" pTag">所谓AI摩尔定律，Momenta CEO曹旭东通过回忆2年前的行业趋势来让更多人感知:</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">就在两年前，智能驾驶还是竞争高速NOA的量产落地，体验上大部分产品体验都不过关，让人惊出一身冷汗的场景时常发生。</div><div class=" pTag">现在高速NOA已经完全覆盖从收费站到收费站的所有场景，并且从30万车型选配下探到20万车型标配。</div></blockquote><div class=" pTag">2年时间，高速NOA从智驾“试金石”，变成了“基础必修课”。</div><div class=" pTag">而曹旭东判断，AI技术和产品带来的体验，每2年就会有10倍提升——这是目前来自一线实践的洞察，但确实也在反映着行业发展的趋势。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yn1r7nsZGAecr2m1pItA2BhBlnWqtgjLvxR1T6bMdEicfMePiaJDibkqovw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">所以Momenta CEO认为，再过2到4年，高阶智能驾驶的标配渗透率，就会超过50%，开始成为大多数。</div><div class=" pTag">高通公司则完整经历过PC，互联网，手机等智能终端品类各个时代的发展，从自身经历的角度出发，高通方面也认同Momenta的洞察，认为每一个时代都有技术飞速发展和商业化快速迭代的周期。</div><div class=" pTag">而人工智能，现在正处于这样的引爆期。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnuOIVeejLBibuH6PUZiahYib3ZJ52PbEJPBibiaIRtTaXnwqo1j4ZjDxiaDZQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">AI摩尔定律背后，更进一步发挥作用的，实际是数据。</div><div class=" pTag">曹旭东强调，自动驾驶行业有明显<strong style="font-weight: 600;">数据驱动</strong>特征。海量数据的处理和训练，能够大幅提升系统的性能，意味着同样能降低对传感器的需求。</div><div class=" pTag">就是说从成本角度看，AI摩尔定律可以表达为：<strong style="font-weight: 600;">“同样性能的智驾产品，每两年成本需要大幅下降”</strong>。</div><div class=" pTag">也正是这种从数据迭代领悟的洞藏，在更早之前，<strong style="font-weight: 600;">飞轮效应</strong>就被Momenta作为了指引、方法论和胜利法宝。</div><div class=" pTag">所谓飞轮效应，简单说就是以数据为核心，构建数据迭代的闭环自动化，然后驱动实现L4级技术流和L2级量产数据流之间的端到端提升。</div><div class=" pTag">一旦L4高阶技术赋能到L2量产产品，并通过量产车辆产生的海量数据回流，自动化地训练算法，AI司机的能力就会一日千里，进步神速。</div><div class=" pTag">随着量产装机量的不断扩大，“飞轮”就能越转越快，智能驾驶的体验也会越来越好，Momenta的技术壁垒也会越来越高。</div><div class=" pTag">所以这也能解释，为啥高阶智能驾驶的“标配时代”，会在此时、此地到来，会由高通和Momenta率先打响第一枪。</div><div class=" pTag">这离不开高通在芯片、计算和底层AI软硬件架构上的积淀，离不开对智能车成本和性能的平衡，包括解决油车搭载需要克服的散热难题，奠定爆款基础。</div><div class=" pTag">更离不开Momenta在高阶智驾上的功力、效率和口碑，特别是飞轮效应带来的技术和产品迭代成果，让行业内外，供应链上下，真正因为看见而相信。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnRsjgyMZ3FxaZhibGSQnbSyRUnss4NL3TBDLMdKuP6icVtMCMb2fsKCrA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">有意思的是，在高通和Momenta联手之前，外界对于高阶智驾的标配和普及，更多是寄希望于燃油车被完全“新能源化”后，先电动化，然后智能化。</div><div class=" pTag">但两家各自领域内最好的公司，改变了这种进程，AI也好、高阶智驾也好，不应该按照能源动力形式划分阵营，更不应该在价位上造成区分。</div><div class=" pTag">AI赋能每个人，AI赋能每辆车，推动一个更加安全、便捷和高效的未来……这才是高阶智驾“标配时代”最朴素又最具价值的意义。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FtdvvoxoAZHq35nhZDcJijA">阅读原文 </a>
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 13:07:59 GMT</pubDate>
</item>
<item>
<title>AI刘强东007带货，背后大模型也就10亿参数，京东：我家数字人平均水平</title>
<link>https://posts.careerengine.us/p/6629042f34c2052868e150c5</link>
<guid>https://posts.careerengine.us/p/6629042f34c2052868e150c5</guid>
<content:encoded><![CDATA[
<div> 京东云言犀、刘强东、数字人、直播、AI
<br />
<br />
总结: 京东云言犀团队开发了刘强东的AI数字人形象"采销东哥"，进行直播带货。数字人效果逼真，展现了技术水平。京东云言犀数字人已商业化，可广泛应用。AI数字人表现出色，中看不中用，达到了新的直播带货水准。技术上可实现类似于董宇辉的AI数字人，但在伦理和感情上有待考量。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">衡宇 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">京东创始人刘强东啊，他昨天又加班了。</div><div class=" pTag">准确来说，是他的AI数字人形象“采销东哥”，昨晚开启了自己生涯第四场直播。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4pHqRB63Xibib4jG0yTwa2MQZKdiaweeQsCVcpVd458PYOVsdgQjqC6yHg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">这次东哥干的是图书采销工作。</div><div class=" pTag">与上两次直播不同，这一回直播间不仅有了数字人助理，还有多机位切换等展现方式。与此同时，和留言区及屏幕前观众的互动方式也有所增强。</div><div class=" pTag">量子位就此事询问了<strong style="font-weight: 600;">京东云言犀算法总监</strong>，得到答案是：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">每一场想侧重表示的不一样。技术的手段比较丰富，很难一场里面都推出来。</div></blockquote><div class=" pTag">不得不说，京东这回拿自家的京东云言犀数字人挤牙膏，还挺有自己的节奏<span>（doge）</span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4T8f4GhmJVRh8ah9LoKjQ49s3Lx1d37w38TVQkumc4w6anu9KJe9CSg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">一周时间里，四场刘强东数字人连播，可谓出师大捷——</div><div class=" pTag">据公开的“战报”，其首秀不到1小时，直播间观看量超2000万，带货GMV超5000万。</div><div class=" pTag">难怪网上冲浪的时候，有人评价道，AI东哥真的是“数字人带货的天花板”了。</div><div class=" pTag">而且京东自己放话，这就是京东云言犀数字人的平均技术水平，且成本不到真人直播的1/10。</div><h2>“自己的狗粮自己先吃”</h2><div class=" pTag">刘强东AI数字人“采销东哥”上播第一天起，就有许多质疑。</div><div class=" pTag"><strong style="font-weight: 600;">质疑一</strong>，真的是数字人吗？真的不是让刘强东提前坐那儿，录好视频然后再播吗？</div><div class=" pTag">且看采销东哥的表现：</div><div class=" pTag"><span><strong style="font-weight: 600;">形象</strong></span>和真人刘强东几乎一毛一样，寸头、西装、左手腕带表，肉眼难辨真伪。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4jqoCWdcl11v1rbMquIssxkNyvptgCPHVy2eDnDIDD9wy8gGNcyKefw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span><strong style="font-weight: 600;">口音</strong></span>能较好贴合唇部动作，语速快、连音多，一般语句吐字较轻，一些重点会重音表强调，寻求认同时用“啊”来衔接；耳朵尖的朋友可能还能听出他的宿迁口音。</div><div class=" pTag"><span><strong style="font-weight: 600;">动作姿态</strong></span>不算僵硬，能有头部、手部的动态动作，且动起来后整个人也受光均匀。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4EmUJrVZtlGXRhM8gsUuT0XvEvn301FDK1JO7TqHHoF18LtsV0xZlibQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">但随着直播场数的增加，这种疑惑声渐渐下去了。</div><div class=" pTag">可能大家都觉得，是在没什么可能让刘强东忙中拨冗，每天坐在那儿提前录播吧。</div><div class=" pTag"><strong style="font-weight: 600;">质疑二</strong>，如果真的是数字人刘强东，那大伙儿看到的效果，会不会是面对自家一号位做的“特供版”？</div><div class=" pTag">换言之，其他公司如果同样想用京东云言犀数字人来做主播，是不是根本达不到这个效果？</div><div class=" pTag">就这个问题，<strong style="font-weight: 600;">京东云言犀负责人</strong>是站出来给了解释的：“刘总数字人技术，代表了我们现在的通用技术。”</div><div class=" pTag">大白话就是说，用了京东云言犀数字人，所有的大V/CEO主播都能有同样的这个效果，至少在120秒之内“惟妙惟肖”。</div><div class=" pTag">如果不信，可以亲自验证——前段时间京东618招商，给所有品牌商家免费开放了数字人基础版使用30天权益，都能用上。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4YoD0kz8wP1By3osYzWsLqPoY2qxNMAxkg6EB8Ax729jsib0leRjuPBw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">京东云言犀负责人笑着表示，去年京东云就已经基于言犀大模型升级了数字人技术。</div><div class=" pTag">用句软件公司的梗，“Eat your own dog food”，自己的狗粮自己先吃，最开始团队内部先给京东云言犀负责人做了个AI数字人出来，但回头看和现在刘强东的数字人没法比。</div><div class=" pTag">2022年开始，京东云言犀数字人就已经开始商业化，目前有4000多家品牌使用。</div><div class=" pTag">去年双十一后，京东云言犀团队开始制作采销AI数字人，首先是在大时尚事业部测试，包括公众接受程度，停留时长，用户转换率，交互程度等。</div><div class=" pTag">团队心想，既然要追求刺激，那就把“Eat your own dog food”贯彻到底，干脆给公司老大也搞一个吧！</div><div class=" pTag">刘强东AI数字人“采销东哥”就这么诞生了。</div><h2>10亿参数数字人大模型轻量上阵</h2><div class=" pTag">采销东哥身后，是京东云言犀大模型团队，及其<span><strong style="font-weight: 600;">大模型做小</strong></span>后打造的10亿参数数字人大模型。</div><div class=" pTag">总的技术来看，言犀2年多前就选择了端到端的方式，即建模——驱动——渲染的一体化。以至于Sora出来后，团队惊喜发现端到端的技术方向是可取、可喜的。</div><div class=" pTag">不过，虽然和Sora是同一条路子，但最后应用的场景不太一样，言犀大模型数字人的赛道更聚焦，专注人物生成<span>（原因是团队评估人物视频生成商业价值和社会影响力可能都更大）</span>。</div><div class=" pTag">而关于端到端的路线，这里展开说两句。</div><div class=" pTag">现在基本分为两大类，一类是<strong style="font-weight: 600;">完全端到端</strong>，中间不对任何环节进行显示的建模，完全是隐性的，都在一个空间里面做；另一类是<span><strong style="font-weight: 600;">对简单基本素材的人脸建3万多个点Mesh模型</strong></span>，再去控制人物的表情、唇型，然后做纹理的渲染。</div><div class=" pTag">京东云言犀说得很明白，2种方案会根据场景需求做不同使用。</div><div class=" pTag">京东云言犀负责人表示，其间比较得意的是<strong style="font-weight: 600;">人物大姿态的动作</strong>。</div><div class=" pTag">“早期真人数字人，动作幅度比较小。基本上脸部不会怎么动，因为一旦头动了，可能就剩半个嘴唇了。”他透露，在大姿态方面做了较多技术投入，才有了现在AI刘强东的活动自如。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4j0iaQbiblvQWCqaWTuI3x7klXkJuIv8RWibWtVcoxc1PncRdDNxibViazbw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，身为主播，语音表达无疑也十分重要。</div><div class=" pTag">既要复现真人主播的语音、语调，又要学习真人说话的习惯，如语速、语调、重音、倒吸气。</div><div class=" pTag">就拿刘强东本人来说，他讲话很少有辅助词，也较少清晰读出连接词，如“跟着”的“着”字经常被一笔带过。</div><div class=" pTag">因为出生江苏宿迁，他的话语里还是会“露馅”，冒出宿迁口音来。比如“时间”中的“sh”会有更重的鼻音；后鼻音有时会被吞掉，变成前鼻音。</div><div class=" pTag">就，还挺有特色的。</div><div class=" pTag">原本呢，京东云言犀技术团队的计划是用刘强东2017年的一段演讲音频作学习素材，但测试发现，演讲时刘强东的语气太过正式了，和直播带货有点画风不搭。</div><div class=" pTag">团队无奈把刘强东“抓”到镜头前，录了30分钟的音视频，让他闲聊自己的经历什么的。</div><div class=" pTag">用这段音频为底提取出声学特征，就能通过已经被喂了5万小时语音数据训练的言犀语音大模型合成出人工语音。</div><div class=" pTag">不过据量子位了解，京东云言犀大模型团队的最新战绩，是<strong style="font-weight: 600;">使用6秒素材复现具体某个人的声音</strong>。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4JWygicG63swibZQxRE1wEkt06pNfRdWyIuicJMGRXYgrzpoLvlicZaKQxA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">团队成员还分享了其他一些关于AI数字人背后的事：</div><div class=" pTag"><strong style="font-weight: 600;">训练过程</strong>中，主赛道锚定人物向，因此不管是从数据的采集、清洗和各方面都做了精细化聚焦。</div><div class=" pTag"><strong style="font-weight: 600;">推理实现</strong>方面，除了模型代码压缩、量化等常规操作，还对INT4和INT8进行了精度调改。</div><div class=" pTag">团队下一步计划，是把语音、视频生成两块综合到一起。</div><div class=" pTag">当然，另一部分挑战是尝试用非常小样本或零样本学习的方式就能抓住真人本尊的特点，继而生成惟妙惟肖的数字人。</div><h2>“采销东哥是京东数字人平均水平”</h2><div class=" pTag">京东云言犀负责人表示，其实京东内部对数字人有一个分级。</div><div class=" pTag"><span><strong style="font-weight: 600;">第一级</strong></span>的数字人效果，可以做真人的补充工作，处于向真人看齐阶段。</div><div class=" pTag"><span><strong style="font-weight: 600;">第二级</strong></span>数字人可以媲美真人，真人不在，也可以承担重要场合、重要时间的主播工作。</div><div class=" pTag">并且播出后，会有人分不清主播是真是假——从这个角度来说，图灵测试应该算是通过了。</div><div class=" pTag">不过，虽然在形象、表情、语音、动作复刻尚佳，但是本尊的深度思想，大模型数字人还没有办法1:1同步。</div><div class=" pTag">到了<span><strong style="font-weight: 600;">第三阶段</strong></span>，本尊和数字人之间不是替代关系，更像是真人有了个数字分身，能够真正深度抓住本尊的思想、文化、知识背景、一些理念。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4RXJJWIh7Wnoibicib5PWat6USCV3qwCqHM9O6PiblJbsKxuGEKv4m0LCyQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而且，京东自家直播间有一个<strong style="font-weight: 600;">120s战斗</strong>。</div><div class=" pTag">简单说就是直播时，如果用户在120s之内都不觉得眼前的数字人让自己别扭，就会跨过恐怖谷效应，接受这个数字人，看他的展示、听他的解说。</div><div class=" pTag">而且看到120s，因为对主播产生了信任，往往很大概率会下单。</div><div class=" pTag">“目前来看，数字人直播带货有很大机会会成为一个大的爆点。”京东云言犀负责人解释道，“主要是内容层次达到了新的水准，大家的接受度和信任度已经过了关键点了。”</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4LpOM6BgWYMiaFqia7ibhibDM4qzeavSZIPJL5QU5nt0GxbRmicdQ00ELoNQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">说回“采销东哥”，他现在几乎能很完美地被生成120s以上的形象，并且足以以假乱真。</div><div class=" pTag">也就是说，“采销东哥”现在处于京东数字人分级里的第二阶段，这也是京东云言犀数字人的平均水平。</div><div class=" pTag">团队还提到，其实目前AI大模型数字人大规模商用，技术已经不是难点了。</div><div class=" pTag">难点是什么呢？是主播个人的形象要跟整体调性相匹配，在选品、互动方面还需要下很多功夫。</div><h2>One More Thing</h2><div class=" pTag">聊着聊着，一个有趣的问题被抛出来。</div><div class=" pTag">问，未来在京东直播间，有没有可能诞生一个类似于董宇辉的AI数字人超级主播？</div><div class=" pTag">京东云言犀负责人和算法总监相视一笑，说：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag"><span>（这件事）</span><span><strong style="font-weight: 600;">技术上是有可能的，但在伦理和感情上不一定能成立</strong></span><div class=" pTag">。</div><br /><div class=" pTag">比如很多丈母娘喜欢董宇辉，是因为这个人有很实在的特质，很文雅，有知识。</div><br /><div class=" pTag">我不知道在伦理上到底之后会怎么解决……</div></div></blockquote><div class=" pTag" style="text-align: center;"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">联系</strong><strong style="font-weight: 600;">作者</strong>&nbsp;—</span></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KnWh0nUISaHLKzTQicv5uBfZIJUibx58EQfIXv6oSM67PK5ZTxjzLVakQ/640?wx_fmt=png" /></div></div></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbOE_1zca38lGi09fGqn2pQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 13:07:59 GMT</pubDate>
</item>
<item>
<title>快速低成本构建应用，浪潮信息把企业大模型落地门槛打下来了</title>
<link>https://posts.careerengine.us/p/6629042f34c2052868e150d6</link>
<guid>https://posts.careerengine.us/p/6629042f34c2052868e150d6</guid>
<content:encoded><![CDATA[
<div> 关键词: 大模型, 浪潮信息, 企业应用, 算法, 数据

总结:<br /><br />浪潮信息推出了集算法、算力、数据和互联为一体的端到端解决方案，帮助企业用户更好地实现大模型应用落地。在大模型2.0时代，企业用户面临着数据不足、算法创新保守等问题。浪潮信息的企业大模型开发平台EPAI提供了丰富数据支持、高效微调工具，并降低了使用门槛。平台支持多种使用方式，同时保障数据安全。浪潮信息的全面布局在算力、存储、互联等方面也为大模型行业带来新格局。EPAI促进了大模型产业协作，让企业用户可以从自身做起，掌握方法和工具，助力产业AI落地发展。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">百模大战愈演愈烈，各大厂商卷出了不同形态：</div><div class=" pTag">有的大秀肌肉，在文本长度上一骑绝尘；有的与搜索等功能深度融合，成为了全能型AI助手……琳琅满目的大模型产品令人目不暇接。</div><div class=" pTag">但对于企业用户而言，尽管这些通用大模型各有各的特色，但在解决行业任务时，表现得却并非那么完美。</div><div class=" pTag">究其“不能胜任”的原因，主要是通用大模型在特定行业的知识储备并不充足，甚至存在严重的幻觉。</div><div class=" pTag">为了弥补这样的缺陷，需要大量的行业<strong style="font-weight: 600;">数据</strong>，模型<strong style="font-weight: 600;">算法</strong>也需要进行优化，而这又会牵扯出<strong style="font-weight: 600;">算力</strong>问题……</div><div class=" pTag">也是这种背景之下，为了帮助企业用户更好地实现大模型应用落地，<strong style="font-weight: 600;">浪潮信息</strong>提出了集算法、算力、数据和互联为一体的端到端解决方案。</div><h2>大模型进入2.0时代，但落地依旧困难</h2><div class=" pTag">随着人工智能技术的快速发展，AI正在变得无处不在，影响着各种计算设备和平台。</div><div class=" pTag">从服务器到个人电脑<span>（PC）</span>，甚至是移动设备，AI算力正在渗透进每一个计算设备，面向人工智能的算力范式不断革新。</div><div class=" pTag">除了这种“<span><strong style="font-weight: 600;">一切计算皆AI</strong></span>”的大背景，人工智能的代表性产品——<span><strong style="font-weight: 600;">大模型也进入了2.0时代</strong></span>。</div><div class=" pTag">这意味着将会出现<span><strong style="font-weight: 600;">更大的模型</strong></span>，随之而来的是<span><strong style="font-weight: 600;">更多的数据需求</strong></span>，以及<span><strong style="font-weight: 600;">对算力资源的更大需求</strong></span>。</div><div class=" pTag">而<strong style="font-weight: 600;"><span>算法、算力和数据正是人工智能发展的“三驾马车”</span></strong>，但从当今发展来看，发展得都不充分。</div><div class=" pTag">首先，由于大模型的训练成本极其高昂，导致试错代价极高，进而出现了在大模型时代<strong style="font-weight: 600;"><span>对于算法的创新依旧有所保守</span></strong><span>的局面</span>。</div><div class=" pTag"><strong style="font-weight: 600;"><span>算力的资源也并不均衡</span></strong>，北京智源研究院副院长兼总工程师<strong style="font-weight: 600;">林咏华</strong>认为，大模型2.0时代，不能只关注单颗芯片的能力，而是需要考虑从芯片到服务器集群，再到数据中心的存储和计算关系，以及整个网络的协同。</div><div class=" pTag">数据方面的情况一样不乐观，随着大模型对计算规模的需求增加，<strong style="font-weight: 600;"><span>人类产生的已知数据，对于大模型而言即将甚至已经不足</span></strong>。</div><div class=" pTag">除了大模型自身发展受到算力和数据等方面的桎梏，对于企业用户来说，大模型落地还存在更多的现实问题。</div><div class=" pTag">一是大模型缺少专业的行业数据，不可避免地导致了<strong style="font-weight: 600;">幻觉问题</strong>，难以适用于企业场景。</div><div class=" pTag">另一方面，有些企业应用场景中，对模型<strong style="font-weight: 600;">窗口长度</strong>需求极大，现有的模型可能无法满足需求。</div><div class=" pTag">此外，<span><strong style="font-weight: 600;">开发难度大、技术门槛高</strong></span>，也是企业实现大模型落地的一个重要壁垒。</div><div class=" pTag">想要解决这些痛点难点，需要从上到下的整个生态为之发力，而<strong style="font-weight: 600;"><span>浪潮信息</span></strong>正是企业大模型落地助推者中的一份子。</div><h2>端到端开发企业大模型应用</h2><div class=" pTag">第十届IPF浪潮信息生态伙伴大会上，浪潮信息AI软件研发总监<strong style="font-weight: 600;">吴韶华</strong>隆重发布了企业大模型开发平台<strong style="font-weight: 600;">元脑企智EPAI</strong>。</div><div class=" pTag">EPAI平台提供了端到端的企业大模型落地解决方案，解决了企业大模型应用开发流程复杂、门槛高等困难。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4ReU1FMyN9sc09XmYblwZCFyZB7Gf73mIdTrIWt9o3x2Bb21PjialLqw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">大模型2.0时代，<span><strong style="font-weight: 600;">数据就是资产</strong></span>，掌握数据就等于掌握了话语权。</div><div class=" pTag">而EPAI提供了上亿条基础知识数据，同时还包含了自动化的数据处理工具，可以帮助用户整理行业数据和专业数据，生成高质量的微调数据和行业/企业知识库，进而打造企业专属数据资产。</div><div class=" pTag">有优质的基础+行业+企业数据作为支撑，大模型生成内容的准确性和可靠性就有了保证，<span><strong style="font-weight: 600;">幻觉问题将大幅缩减</strong></span>。</div><div class=" pTag">同时，结合检索增强生成（RAG）技术，EPAI可以解决企业知识库更新频率高但大模型微调耗时长、频率低的矛盾，保证模型能够及时获得处理最新知识的能力。</div><div class=" pTag">另一方面，EPAI还提供了高效的微调工具，支持千亿参数模型面向产业知识的快速再学习，并<strong style="font-weight: 600;">让模型具备百万Token的长文档处理能力</strong>，解决窗口长度不足的问题，快速打造领域大模型。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2chZz3rVgy8OMaZiaZFfE0fFeGppG5ibQicH0anz0JvQ91dhXkf3yenLLw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">好马当配好鞍，EPAI不仅拥有强大的企业大模型开发功能，在易用性方面也帮助开发者<span><strong style="font-weight: 600;">降低了使用门槛</strong></span>。</div><div class=" pTag">使用方式上，EPAI支持API、对话UI和智能体三种使用方式，可以面对不同的业务场景需求，并让不同技术水平的开发者都能拥有与自己能力相匹配的开发方式。</div><div class=" pTag">甚至是<span>非专业开发人员，也能在几天培训之后快速掌握平台的使用方法，摆脱专业知识的限制</span>。EPAI<span><strong style="font-weight: 600;">实现了大模型应用开发的普及化，降低了企业的用工成本</strong></span>。</div><div class=" pTag">吴韶华举例说，假如要开发一个“智能编程助手”，即使是经验非常丰富的工程师可能也需要两到三周的时间，但用了EPAI，可以非常快速地执行。</div><div class=" pTag">而且EPAI既支持包括CPU和各种GPU在内的<span><strong style="font-weight: 600;">多元算力</strong></span>，又支持包括自研的“源”大模型和其他主流开源、闭源模型，适配快，迁移成本低，为企业提供了<span><strong style="font-weight: 600;">丰富的模型和算力选择</strong></span>。</div><div class=" pTag">此外，企业用户最担心的数据安全问题，EPAI也提供了坚实保障，通过权限管理、数据加密、内容审查等多种技术手段，确保<span><strong style="font-weight: 600;">数据和模型安全</strong></span>，做到了隐私信息不泄露。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2Y4QLQnwTcoEcicOJ43GzMoa9jTnpia0RO30ibVPPPfszbKJlNAwOzPmlA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">相较于其他开发平台，浪潮信息的一个独特优势是，从“左手”的算力、模型等底层技术提供者，到“右手”的各行业软件开发商，<span><strong style="font-weight: 600;">都是浪潮信息生态中的伙伴</strong></span>。</div><div class=" pTag">这意味着，EPAI平台可以<span><strong style="font-weight: 600;">上承算力，下接应用</strong></span>，成为整个生态的“交通枢纽”，加速面向应用的快速创新。</div><div class=" pTag">EPAI为企业用户很好地解决了算法和数据问题，但浪潮信息提供的支持不止于此，而是<strong style="font-weight: 600;"><span>集算法、算力、数据、存储、互联为一体的全面布局</span></strong>。</div><div class=" pTag">在算力方面，面向越来越多的大模型推理场景，浪潮信息还联合英特尔发布可运行千亿参数大模型的AI通用服务器；存储方面，发布分布式全闪存储AS13000G7，解决大模型训练数据挑战；互联方面，发布国内首款超级AI以太网交换机 X400，加速大模型训练推理……</div><div class=" pTag">浪潮信息的这一系列布局，或将给大模型行业带来新的格局。</div><h2>EPAI将促进大模型产业协作</h2><div class=" pTag">谈及EPAI平台的意义，<strong style="font-weight: 600;">吴韶华</strong>介绍到，EPAI平台提供的是工具箱和方法论，让用户可以尽可能地发挥自己企业的价值。</div><div class=" pTag">而且，EPAI平台将能够实现<strong style="font-weight: 600;"><span>对于开发者的普惠</span></strong>，企业不必再花费大量资金构建一个高精尖的团队，也可以做起大模型。</div><div class=" pTag">通过EPAI和其所提供的方法论，企业用户可以从自己做起，掌握这样一套方法和工具，然后再去服务好、支持好他们行业的客户。</div><div class=" pTag">只有借助最适合、最高效的工具，让它在工作的时候拥有很高的效率和成功率，才能真正把产业快速地做大。</div><div class=" pTag">对此，浪潮信息高级副总裁<strong style="font-weight: 600;">刘军</strong>表示，EPAI“让我们看到大模型的另外一面，它的产业化落地的这一面”。</div><div class=" pTag">此外，EPAI对于整个产业的协作也大有裨益——</div><div class=" pTag">过去，恨不得每个人都想做大模型企业，都想自己从头彻尾都搞一套工具，但事实上不可能所有人都能把生意做大。</div><div class=" pTag">只有<strong style="font-weight: 600;"><span>依靠优质的产业协作分工</span></strong>，大家都做自己最擅长的事情，形成多元多样化的、共同去促进的生态，才能让产业AI真正落地。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4UkKqXvp4I9KK2q7_UpHgw">阅读原文 </a>
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 13:07:59 GMT</pubDate>
</item>
<item>
<title>微软推出iPhone能跑的ChatGPT级模型，网友：OpenAI得把GPT-3.5淘汰了</title>
<link>https://posts.careerengine.us/p/662742e6745f1a3c48c18fa4</link>
<guid>https://posts.careerengine.us/p/662742e6745f1a3c48c18fa4</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">梦晨发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">Llama 3发布刚几天，微软就出手截胡了？</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4aiausUiahBaB9dptUUsShAqLpFvNYBiaTib9QNHJWSRHC5PzyLpDGUgCFg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">刚刚发布的<span><strong style="font-weight: 600;">Phi-3系列小模型</strong></span>技术报告，引起AI圈热议。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4SxsMgsoRAs0zHdZhFwsPApDKqYibCsGLopxrCkguEVL8tRPUDwiag0mA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">其中仅<span><strong style="font-weight: 600;">3.8B参数的Phi-3-mini</strong></span>在多项基准测试中<span><strong style="font-weight: 600;">超过了Llama 3 8B</strong></span>。</div><div class=" pTag">为了方便开源社区使用，还特意设计成了与Llama系列兼容的结构。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4P9mg5xQ994cgffyLrU0sHFqFpDOIpkAIH2U6ic0KISShpAqfXIicFSicg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">微软这次打出<span><strong style="font-weight: 600;">“手机就能直接跑的小模型”</strong></span>的旗号，4bit量化后的phi-3-mini在iPhone 14 pro和iPhone 15使用的<span><strong style="font-weight: 600;">苹果A16芯片</strong></span>上跑到每秒12 token。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU413f534NPmacYCwMrOZ2s9sZY0LgjiaXnj2icO2y98mgJE5jiagcI722yw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这意味着，现在手机上能本地运行的最佳开源模型，已经做到ChatGPT水平。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4qX2hTh6aXKJaZmf8XE2F3zZOP0OGT3F7DBzRqZwTYaEBuGAajfm5icA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在技术报告中还玩了一把花活，让phi-3-mini自己解释为什么构建小到手机能跑的模型很令人惊叹。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4yuDPkYkEFyibeOQkVcoHDhJKHDDAcC9KVaBFybJwQOQCZDAiaxyCBGQQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">除了mini杯之外，小杯中杯也一并发布：</div><div class=" pTag"><span><strong style="font-weight: 600;">Phi-3-small</strong></span><span>，</span>7B参数，为支持多语言换用了tiktoken分词器，并额外增加10%多语种数据。</div><div class=" pTag"><span><strong style="font-weight: 600;">Phi-3-medium</strong></span>，14B参数，在更多数据上训练，多数测试中已超越GPT-3.5和Mixtral 8x7b MoE。</div><div class=" pTag"><span style="font-size: 17px; text-align: left;">（</span><span style="font-size: 17px; text-align: left;">大杯他们目前不打算做）</span></div><div class=" pTag">作者阵容一看也不简单，一眼扫过去MSRA和MSR雷蒙德团队都投入了不少人。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU460rqB19WIlZ4rN6aAQb53jM7lBy5xKCfWUWpaicnMugmQ2uaU4DOiaDQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么，Phi-3系列到底有什么独特之处呢？</div><div class=" pTag">根据技术报告中披露，其核心秘诀就在于<span><strong style="font-weight: 600;">数据</strong></span>。</div><div class=" pTag">去年团队就发现，单纯堆砌参数量并不是提升模型性能的唯一路径。</div><div class=" pTag">反而是精心设计训练数据，尤其是利用大语言模型本身去生成合成数据，配合严格过滤的高质量数据，反而能让中小模型的能力大幅跃升。</div><div class=" pTag">也就是训练阶段只接触<span><strong style="font-weight: 600;">教科书级别</strong></span>的高质量数据，<span><strong style="font-weight: 600;">Textbooks are all you need</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4tL0ziaqh6s4h6vw0mmOAdC0MQWuagZ2N4TPuviaMVrEomJMdPtQHtFww/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">Phi-3也延续了这一思路，这次他们更是下了血本:</div><ul class="list-paddingleft-1"><li><div class=" pTag">投喂了多达3.3万亿token的训练数据（medium中杯是4.8万亿）</div></li><li><div class=" pTag">大幅强化了数据的”教育水平”过滤</div></li><li><div class=" pTag">更多样化的合成数据，涵盖逻辑推理、知识问答等多种技能</div></li><li><div class=" pTag">独特的指令微调和RLHF训练，大幅提升对话和安全性</div></li></ul><div class=" pTag">举个例子，比如某一天足球比赛的结果可能对于大模型是良好的训练数据，但微软团队<span><strong style="font-weight: 600;">删除了这些加强知识的数据</strong></span><span><strong style="font-weight: 600;">，留下更多能提高模型推理能力的数据</strong></span>。</div><div class=" pTag">这样一来，对比Llama-2系列，就可以用更小的参数获得更高的MMLU测试分数了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4B7ffNAoINc4flFWtXKquoPkKS7MCnrQJNAQ185dLPeXdPlZNmYR31Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不过小模型毕竟是小模型，也不可避免存在一些弱点。</div><div class=" pTag">微软透露，模型本身参数中没能力存储太多事实和知识，这一点也可以从TriviaQA测试分数低看出来。</div><div class=" pTag">缓解办法就是联网接入搜索引擎增强。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4sT3DmiaMgEJOvttLnqoJEhYHrdwGZ1cLZPguYdxgiaqcFzCDXq6WrXgg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">总之，微软研究院团队是铁了心了要在小模型+数据工程这条路上走下去，未来还打算继续增强小模型的多语言能力、安全性等指标。</div><div class=" pTag">对于开源小模型超过ChatGPT这回事，不少网友都认为压力现在给到OpenAI这边，需要赶快推出GPT-3.5的继任者了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4E5LDIN8ibaEtBTCrdric5Hx3qRBV8MRUNXbAiaf0ZNQUbts5cA3ENkTgQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://arxiv.org/abs/2404.14219</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FF9K0A_f4CFgfFyY3bf4F8g">阅读原文 </a>
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 05:11:02 GMT</pubDate>
</item>
<item>
<title>对话蚂蚁李建国：当前AI写代码相当于L2.5，实现L3后替代50％人类编程</title>
<link>https://posts.careerengine.us/p/662742e5745f1a3c48c18f95</link>
<guid>https://posts.careerengine.us/p/662742e5745f1a3c48c18f95</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">白交 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">超70%代码问题，单纯靠基座大模型是解决不了的；</div><div class=" pTag">未来3-5年，人类50%编程工作可以被替代，有些环节甚至完全自动化。</div></blockquote><div class=" pTag">蚂蚁集团代码大模型CodeFuse负责人李建国说道。</div><div class=" pTag">当下，AI代码生成领域正在野蛮式生长，巨头涌入，AI员工频频上线企业；首个AI程序员Devin被曝造假…… 面对风起云涌的代码生成变革，李建国给出了这样一个明确论断。</div><div class=" pTag"><strong style="font-weight: 600;">李建国</strong>是谁？</div><div class=" pTag">清华大学博士，机器学习、深度学习深耕十余年，论文被引万余次。在他的带领下，蚂蚁内部正全面推行AI编程。每周已有<strong style="font-weight: 600;">超五成程序员</strong>使用CodeFuse，目前<strong style="font-weight: 600;">CodeFuse生成代码整体采纳率为30%</strong>，已经属于整个AI编程工具中能力第一梯队，最强Copilot代码整体采纳率差不多在35%。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2GBSzSIGIPuXTuosiaTcAzVJI398hq6cFRU48tF5NVepZKspsn1YZE5Q/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">而在开源这边，在各社区网站上CodeFuse下载量已经达到<strong style="font-weight: 600;">170万左右</strong>。</div><div class=" pTag">因此不管是学术的权威性，还是产业落地的代表性，李建国博士极具话语权。于是在代码生成模型和产品爆发式发展的当下，量子位同李建国博士展开了进一步交流。</div><div class=" pTag">核心观点如下：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">编写代码在整个企业研发过程中所占的比重可能连1/5，甚至1/10都不到；</div></li><li><div class=" pTag">要实现项目级的需求实现，从原子级需求端到端渐进发展的模式是切实可行的；</div></li><li><div class=" pTag"><strong style="font-weight: 600;">AI程序员成为企业运营中的新常态</strong>已经是势不可挡的趋势；</div></li><li><div class=" pTag">超70%代码问题，单纯靠基座大模型是解决不了的；</div></li><li><div class=" pTag">目前自然语言编程处于L2.5阶段，按照万物摩尔定律的发展趋势，未来3-4年达到L3，甚至接近L4的水平是有可能的。</div></li><li><div class=" pTag">相较于前、后端的软件工程师，<strong style="font-weight: 600;">AI全栈工程师需求更大</strong>。</div></li><li><div class=" pTag">当前代码生成变革所面对的挑战包括：端到端代码生成能力、Agent推理能力、复杂需求拆解、跨模态横向交互、安全可信可靠。</div></li></ul><h2>编写代码只占整个研发生命周期1/5不到</h2><div class=" pTag">首先，程序员这个行业历史并不算长，从20世纪50年代至今，大约有七八十年的历史。随着技术的进步，编程工具不断更新迭代（打孔- VI编辑器-集成开发环境-辅助编程工具），程序员的工作效率得到了显著提升。</div><div class=" pTag">来到大模型时代，相关模型和产品演化迭代十分迅速，可以说十分的“卷”。</div><div class=" pTag">对个人开发者而言，AI编程工具只需完成从需求到代码实现的闭环过程就够了，就像Copilot这样的工具。<strong style="font-weight: 600;">他们更倾向于关注如何高效地实现需求</strong>。</div><div class=" pTag">但从企业维度则更关注整个研发流程的效率提升，除了关注代码生成的安全可靠可信，测试构建、发布运维以及数据洞察等方面也是至关重要的。</div><div class=" pTag">我们期望能够有一个研发智能体，甚至是一个智能总线（bus），它能够与各个Agent进行交互，并将任务分发下去——从架构设计到前端实现，再到后端开发，以及安全测试和功能测试，最后是效能方面的持续集成/持续部署（CICD）和运维自动化。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2wV8qibuNGqDEfKvWwBfV60pwMrMUHwSulGVKpn45YmctxD2wHSfktTQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>测试-自然语言生成终端用例</h6><div class=" pTag">整个系统上线后，还能够自动进行运维布控，并分析产品的用户访问量（UV）、页面浏览量（PV）等数据。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2czrrUH1JnhtqgJu4TlQfk7DspUjHvkp33P7DAARHhcic5ibjHZtb43JQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>运维-监控解读</h6><div class=" pTag"><strong style="font-weight: 600;">编写代码在整个过程中所占的比重可能连五分之一或十分之一都不到</strong>。但如果这样的Agent能将所有环节高效连接起来，从而真正提升整个流程的效率。</div><div class=" pTag">再加上当前程序员实际所面临的痛点在于，市面上一些产品大多是原子级能力的实现——通过单体大模型只能解决30%的代码补全，无法解决更多的代码问题，比如跨库的函数调用。</div><div class=" pTag">基于这样的行业思考，去年9月份开始，我们开源了<strong style="font-weight: 600;">CodeFuse</strong>，并明确提出要<strong style="font-weight: 600;">构建全生命周期的代码大模型</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2e8xLYhsaQ23ibbA3lPJ5XWOMicZohQXe0peJqQiahZG2nOkX7Kv0U4g7w/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">目前，我们已经发布基础模型，并持续开发和开源相关的仓库，涵盖了从需求设计、编程开发、测试构建、发布运维、到数据洞察分析等多个方面，在modelscope和huggingface上<strong style="font-weight: 600;">模型下载量已经达到170万左右</strong>。</div><div class=" pTag">下一步，我们计划进行项目级的需求实现，这相当于去实现一个全新的系统。这对基础模型提出更高的要求——</div><div class=" pTag">自然语言理解的能力至少达到GPT-4或GPT-4.5的水平。但从目前的情况来看，我们更倾向于采取一种<strong style="font-weight: 600;">渐进</strong>的模式。</div><div class=" pTag">我们首个MileStone是<strong style="font-weight: 600;">解决仓库内及跨仓库的需求实现问题</strong>，包括API调用、服务调用，以及涉及到的外部中间件版本更新问题。</div><div class=" pTag">如果我们能够妥善处理这些问题，就能解决刚才提到的70%问题中很大一部分（比如20%的问题），这将显著提高代码采纳率，并让用户感到满意。</div><div class=" pTag">最终要实现项目级别的需求任重而道远。我认为，代码基础模型和Agent技术需要同步快速发展，才能达到我们的目标。</div><div class=" pTag">我们的思路相对保守，因为就基础模型的要求而言，我认为短期内国内要达到GPT水平还存在一定差距。</div><h2>大模型对软件开发的范式改变</h2><div class=" pTag"><strong style="font-weight: 600;">AI程序员成为企业运营中的新常态</strong>已经成为势不可挡的趋势。不管是像Devin这种AI程序员，还是我们提到的全生命周期研发智能体，大模型对整个软件研发范式都是非常大的提效。</div><div class=" pTag">过去遇到不懂的问题，人们可能首先会去Google或百度上搜索，而现在，他们可以直接在代码中提问，随即获得一个相对精确的结果，采纳后即可使用。</div><div class=" pTag">我认为这是一个巨大的效率提升，它代表着进步。人们可以将更多的精力释放出来，投入到更具创造性的工作中去。</div><div class=" pTag">前段时间，CodeFuse发布了<strong style="font-weight: 600;">图生代码</strong>的功能，它可以通过在界面上简单画一个框，就能自动生成相应的代码。</div><div class=" pTag">以往可能需要编写数百行代码的工作，现在只需一次点击和画框操作就能实现。</div><div class=" pTag">而要从产品设计的角度来看，我认为<strong style="font-weight: 600;">实现无缝接入和无感体验是至关重要的</strong>。</div><div class=" pTag">这意味着产品应能平滑地融入现有的工作模式中，用户在使用过程中几乎不会意识到它的存在，从而极大地提升用户体验，并推动整个研发流程的创新和进步。</div><div class=" pTag">例如，我们内部每周有超过一万人的智能代码生成活跃用户，很多人都没意识到自己在使用CodeFuse，在日常使用IDE插件、浏览器的过程中，用户已经不知不觉地使用了我们的产品。</div><div class=" pTag">我们的目标是服务于整个研发的全生命周期。如果能够实现这一点，那将是一个革命性的成功。</div><h2>现在AI写代码相当于L2.5</h2><div class=" pTag">目前整个代码生成领域，可能处于一个类似于自动驾驶技术中的L2.5级别，许多公司都处于这一水平。</div><div class=" pTag">比如自动驾驶L2.5级别的功能，如车道线辅助、前方碰撞检测等，这些都是作为整体存在的一部分。在大模型领域，也看到了类似的补充功能，包括解释、注释、简化优化和单元测试等。</div><div class=" pTag">我们接下来的目标是在<strong style="font-weight: 600;">某些特定场景下实现L3级别的完全自动化</strong>，这是有可能实现的。例如，在效能领域中的持续集成<span>（CICD）</span>场景，就有可能通过大模型的驱动来自动完成，包括触发检查、提交，甚至创建拉取请求<span>（PR）</span>等操作。</div><div class=" pTag">然而，要实现全场景、全链路的自动化，前端可能还需要一段时间才能发展起来，复杂的项目级的需求拆解特别是特定领域的拆解，也面临较大挑战。我认为可能还需要3-5年的时间，在万物摩尔定律的推动下，整个社区，包括我们自己的不断努力和发展。</div><div class=" pTag">到那时候，我们可以期待从当前的状态发展到一个新的阶段——</div><div class=" pTag">例如，<strong style="font-weight: 600;">从Copilot到co-worker</strong>，现在可能有20%到30%的编程工作可以被替代，未来这个比例可能会提高到50%，甚至有些环节可以完全被自动化取代，释放人去做更有创意的工作。</div><div class=" pTag"><strong style="font-weight: 600;">甚至成为一个full agent</strong>。虽然可能无法完全替代人类，但在未来3-5年内，达到L3甚至接近L4的水平是有可能的。</div><div class=" pTag">正如自动驾驶技术一样，虽然已经提出很多年，许多人声称已经达到L4级别，但实际上许多场景仍然处于L2.5到L3级别。要实现全场景的自动化，人类仍然需要在其中扮演一个重要的角色。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2260h339wapoCVMpuA83UXPIndHe2Spf0G0wWLsnSXaOPsqMDnnOMfw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">这样一来，软件工程人员的定位其实也在发生变化。以前大家可能专注于前端或后端的开发工作。而现在，<strong style="font-weight: 600;">AI全栈工程师的需求更大</strong>。</div><div class=" pTag">过去所谓的全栈工程师意味着前端、后端和数据都懂，但现在可能还需要理解算法。随着大模型发展，前端和后端的工作可能会逐渐由大模型辅助，即作为协作者<span>（Co-worker）</span>来分担部分功能，从而释放出开发者的时间。这样开发者就可以将更多时间投入到提升新的技能上，比如对产品的深入理解，对用户体验的关注，对算法创新等。</div><div class=" pTag">基于对整个领域进行了深入的探索，我发现要进一步去实现还有不少挑战，主要有五个方面：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">端到端代码生成能力</strong></div></li></ul><div class=" pTag">基础模型层面，目前主要是实现代码补全的功能，但在实际应用中只有大约30%问题可以通过这种方式解决，剩余的70%则需要<strong style="font-weight: 600;">端到端代码生成能力，需要跨文件、跨代码库</strong>，甚至跨代码库和文档库的理解和交互。</div><div class=" pTag">所谓的端到端，对于一个代码库而言，一个典型的例子，我们需要能够直接调用库中的API，修复问题（issue），甚至能够复用跨库的中间件能力。</div><div class=" pTag">然而，仅凭基础模型是无法实现这些的，我们还需要探索更多的能力。</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">Agent推理能力</strong></div></li></ul><div class=" pTag">尽管最近Devin 被曝出演示视频存在造假，备受关注，但我认为它还是代表了一种趋势、一种技术流派——</div><div class=" pTag"><strong style="font-weight: 600;">如何将定制工具调用与大型模型相结合，实现整个工作流程的自动化</strong>。这个问题，尤其是扩展到全生命周期，实际上相当困难，尤其是面向云后端的研发环境，工具种类繁多。</div><div class=" pTag">比如面向前端应用可能只有天气预报、查询火车票、预定酒店等十几个工具，但在云后端，则可能会有数百个甚至上千个工具，每个工具都包含数十个参数。</div><div class=" pTag">除此之外，还有<strong style="font-weight: 600;">需求拆解、跨模态横向交互、安全可信可靠</strong>的挑战。</div><div class=" pTag">尤其<strong style="font-weight: 600;">代码的安全可信可靠</strong>，像蚂蚁这样的企业级用户，需要应对面向金融级别的高可用性和安全性的要求，也充满了挑战。</div><div class=" pTag">不过也正因为在金融级垂直场景的深耕，包括资源配置和历史经验积累，蚂蚁也构成了属于自己的场景优势。</div><div class=" pTag">首先，我们拥有涵盖整个生命周期各个环节全方位的团队，尤其在双十一等大型促销活动期间的高可用性方面经验丰富，这有助于推进全生命周期的代码大模型，这是我们与外部的主要区别之一。</div><div class=" pTag">其次，我们在特定领域，如金融领域，以及前端领域，都有一定经验积累，尤其是在支付系统等对安全性要求极高的场景中。这些积累使我们在安全性、可靠性和可信度方面具有差异化优势。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb26tvzLeg3wDFzxaKWkdycTg4SzV2lBYy8SfY8pYKicpsibJqibDiaT6FdIA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">虽然挑战不少、道阻且长，但我认为，蚂蚁将携手开源社区一起努力，在万物摩尔定律的牵引下，未来两三年可以一定程度解决好这个问题。</div><h2>One More Thing</h2><div class=" pTag">最后，面对当下大模型发展，李建国博士忍不住感叹：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我以前做深度学习，那时候非常卷，可能2019年之前，我发现这个领域已经卷不动了，跳出来做NLP，发现这个领域也还是更加的卷。</div><div class=" pTag">但不得不承认，大模型再次点燃了NLP、视觉处理、代码生成等各个领域的热度，焕发新的活力。</div></blockquote><div class=" pTag">对于接下来的发展，李建国点名最看好<strong style="font-weight: 600;">具身智能</strong>的发展，这将是未来5到10年的研究热点。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">它将成为数字世界与物理世界之间的桥梁，能够感知并执行操作。这可能会带来类似Matrix（黑客帝国）这样的场景的巨大进步，甚至可能像电影《终结者》中展示的那样，成为真正的巨大飞跃。</div></blockquote><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FXAnMM8crpyjiCtg0UwqRzw">阅读原文 </a>
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 05:11:01 GMT</pubDate>
</item>
<item>
<title>大模型一对一战斗75万轮，GPT-4夺冠，Llama 3位列第五</title>
<link>https://posts.careerengine.us/p/662742e5745f1a3c48c18f8d</link>
<guid>https://posts.careerengine.us/p/662742e5745f1a3c48c18f8d</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">关于Llama 3，又有测试结果新鲜出炉——</div><div class=" pTag">大模型评测社区LMSYS发布了一份大模型排行榜单，Llama 3位列第五，英文单项与GPT-4并列第一。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4tNU5Ndu7V3QPRWtDDLHVJX5iaoILS1RmfyWI8VgpqsGiaElFTzN7TsSA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不同于其他Benchmark，这份榜单的依据是模型一对一battle，由全网测评者自行命题并打分。</div><div class=" pTag">最终，Llama 3取得了榜单中的第五名，排在前面的是GPT-4的三个不同版本，以及Claude 3超大杯Opus。</div><div class=" pTag">而在英文单项榜单中，Llama 3反超了Claude，与GPT-4打成了平手。</div><div class=" pTag">对于这一结果，Meta的首席科学家LeCun十分高兴，转发了推文并留下了一个“Nice”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4AGjVtEAq0kibjD7kD8dOFe7ibymFEVAua8fjrznXWiaY6HZjXnd0Uibpjw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">PyTorch之父Soumith Chintala也激动地表示，这样的成果令人难以置信，对Meta感到骄傲。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag"><div class=" pTag">Llama 3的400B版本还没出来，单靠70B参数就获得了第五名……</div><br /><div class=" pTag">我还记得去年三月GPT-4发布的时候，达到与之相同的表现几乎是一件不可能的事。</div><br /><div class=" pTag">……</div><br /><div class=" pTag">现在AI的普及化实在是令人难以置信，我对Meta AI的同仁们做出这样的成功感到非常骄傲。</div></div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4MbRzr8ZZJqq3gBHic0UCUibOK3Zia75x1Iv1yz2kQIKp25uzbdbcTeuBw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么，这份榜单具体展示了什么样的结果呢？</div><h2>近90个模型对战75万轮</h2><div class=" pTag">截至最新榜单发布，LMSYS共收集了近75万次大模型solo对战结果，涉及的模型达到了89款。</div><div class=" pTag">其中，Llama 3参与过的有1.27万次，GPT-4则有多个不同版本，最多的参与了6.8万次。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU45ytH39YQyLgdxqBicAwTCTo1OrnANuskQyVPj1A0mD12D5kmY8yCofQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">下面这张图展示了部分热门模型的比拼次数和胜率，图中的两项指标都没有统计平局的次数。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4OgOibrYicWo7eJJ8IvNicGortJ4mpiaKfwQN26tgqHv82sT6vic5dkKIOJg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">榜单方面，LMSYS分成了总榜和多个子榜单，GPT-4-Turbo位列第一，与之并列的是早一些的1106版本，以及Claude 3超大杯Opus。</div><div class=" pTag">另一个版本（0125）的GPT-4则位列其后，紧接着就是Llama 3了。</div><div class=" pTag">不过比较有意思的是，较新一些的0125，表现还不如老版本1106。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4tNU5Ndu7V3QPRWtDDLHVJX5iaoILS1RmfyWI8VgpqsGiaElFTzN7TsSA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而在英文单项榜单中，Llama 3的成绩直接和两款GPT-4打成了平手，还反超了0125版本。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4TMsLibYpUgJf7Ub6DTz7ASc6fpTSiary4NURATXD3gIDqX2daLdJvqCg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">中文能力排行榜的第一名则由Claude 3 Opus和GPT-4-1106共享，Llama 3则已经排到了20名开外。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4jHr1xib783XyPxLOxaO3OWbMoxcocEbnjrRXicZEKRZtbm6qYZFKvwibg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">除了语言能力之外，榜单中还设置了长文本和代码能力排名，Llama 3也都名列前茅。</div><div class=" pTag">不过，LMSYS的“游戏规则”又具体是什么样的呢？</div><h2>人人都可参与的大模型评测</h2><div class=" pTag">这是一个人人都可以参与的大模型测试，题目和评价标准，都由参与者自行决定。</div><div class=" pTag">而具体的“竞技”过程，又分成了battle和side-by-side两种模式。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU47ia4ib56B1g73QgKto6okfcGD3Z31nVvib6MfzVbsCCyic16WWcfHrv7fw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">battle模式下，在测试界面输入好问题之后，系统会随机调用库中的两个模型，而测试者并不知道系统到底抽中了谁，界面中只显示“模型A”和“模型B”。</div><div class=" pTag">在模型输出答案后，测评人需要选择哪个更好，或者是平手，当然如果模型的表现都不符合预期，也有相应的选项。</div><div class=" pTag">只有在做出选择之后，模型的身份才会被揭开。</div><div class=" pTag">side-by-side则是由用户选择指定的模型来PK，其余测试流程与battle模式相同</div><div class=" pTag">不过，只有battle的匿名模式下的投票结果才会被统计，且在对话过程中模型不小心暴露身份就会导致结果失效。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4lTFNR4tBIHdCbP6yIS0F6qRNTsAfs95NK1ztmfY3rsCW3NN8nvZDZA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">按照各个模型对其他模型的Win Rate，可以绘制出这样的图像：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4A908XrCT0SUlNK47G7vua1GbBueScpRX8ETRqEGcFUc2RfLKgPicKkw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>示意图，较早版本</h6><div class=" pTag">而最终的排行榜，是利用Win Rate数据，通过Elo评价系统换算成分数得到的。</div><div class=" pTag">Elo评价系统是一种计算玩家相对技能水平的方法，由美国物理学教授Arpad Elo设计。</div><div class=" pTag">具体到LMSYS，在初始条件下，所有模型的评分（R）都被设定为1000，然后根据这样的公式计算出期待胜率（E）。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4ElicSz0e1lXLlD89rRahMeUgsdqvNJLlFkheHPMib9EGc2vnYrmIsKMg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">随着测试的不断进行，会根据实际得分（S）对评分进行修正，S有1、0和0.5三种取值，分别对应获胜、失败和平手三种情况。</div><div class=" pTag">修正算法如下式所示，其中K为系数，需要测试者根据实际情况调整。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4H0E7VnDwMS1MgyR2gzpLwke5jtklfjyFibgWibOibBJrJRnedUXJTFcyQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">最终将所有有效数据纳入计算后，就得到了模型的Elo评分。</div><div class=" pTag">不过实际操作过程中，LMSYS团队发现这种算法的稳定性存在不足，于是又采用了统计学方法进行了修正。</div><div class=" pTag">他们利用Bootstrap方法进行重复采样，得到了更稳定的结果，并估计了置信度区间。</div><div class=" pTag">最终修正后的Elo评分，就成了榜单中的排列依据。</div><h2>One More Thing</h2><div class=" pTag">Llama 3已经可以在大模型推理平台Groq<span>（不是马斯克的Grok）</span>上跑了。</div><div class=" pTag">这个平台的最大亮点就是“快”，之前用Mixtral模型跑出过每秒近500 token的速度。</div><div class=" pTag">跑起Llama 3，也是相当迅速，实测70B可以跑到每秒约300 Token，8B版本更是接近了800。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU403WS0uxNRe9sBSnfgKiaiavlgcdYb4RTKUM1pu8mQTVL49MiaianiaPj6zg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]https://lmsys.org/blog/2023-05-03-arena/</div><br /><div class=" pTag">[2]https://chat.lmsys.org/?leaderboard</div><br /><div class=" pTag">[3]https://twitter.com/lmsysorg/status/1782483699449332144</div></span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fulo0CiwMvmnE90JsmjJhlg">阅读原文 </a>
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 05:11:01 GMT</pubDate>
</item>
<item>
<title>华为P70闪拍功能意外爆火，CTO亲自下场解读技术原理</title>
<link>https://posts.careerengine.us/p/6626424e52c1a75f6b106b5a</link>
<guid>https://posts.careerengine.us/p/6626424e52c1a75f6b106b5a</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">一段博主拍摄的视频，让华为P70的抓拍功能意外火了……</div><div class=" pTag">注意看，这里有一个高速运转的机械，是不是让你看得已经眼花缭乱了？</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2LYD0lTv6AlNSPNicoJial6icubehIRvzS92ImyOCt9gn83AGIfST5vqMw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">但P70手机可以秒秒钟捕捉到高清大图，和视频抽帧的结果对比一下就高下立判了。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2SDoibaPdIhd5GRDB9mc9OicaSnsMoYDe3oFFgibdichXCYkM8sXsEpVepQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在博主拍摄的现场，这张照片就已经让周围的观众为之惊艳，引发一片惊叹之声。</div><div class=" pTag">微博上更是一片赞叹之声，其中还不乏知名科技博主宝玉、清华大学计算机系教授马少平等大佬的夸赞。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb27iaLCRy5wSYtPHFfVndV1wFcqAZFMENZvT9Hp3HXEJxoTeWDIia3rSBQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">其背后的原理也引发了猜测，还有人直接@华为终端的CTO求讲解，结果CTO亲自发文介绍了背后的全新技术。</div><h2>AI算法功不可没</h2><div class=" pTag">Pura 70中搭载了名为“XD Motion”的运动引擎，核心原理是双快门、双曝光，再结合AI算法，对照片进行高清复原。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2aPibbMOCznIt3ebRUYDMdktTMMmbQkZEcxjnO4P1HFrnseno0iczUmvA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在拍摄高速运动的物体时，有曝光时长不同的两个摄像头同时工作，分别完成不同的任务。</div><div class=" pTag">曝光时间短的摄像头负责捕捉主要物体的细节，长曝光摄像头的任务则是记录下相对固定的背景信息。</div><div class=" pTag">对于这种操作方法的优势，摄影博主木析给出了这样的分析，并获得了CTO官方认证：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag"><div class=" pTag">长曝光可以提高信噪比，但会形成动态模糊；短曝光可以精准定格物体形态，但噪声较高。</div><br /><div class=" pTag">所以通过计算让两者进行优势互补，在提升信噪比的同时，又保障了图片的清晰度。</div></div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2ia8yTUPibUfIDibvUJPZ5qyLiaS3MoKzjoSYsS7HAs2JDLWTLA9LaFvj2w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而至于在两个摄像头完成各自的工作后如何合二为一，就到了AI登场的时间了。</div><div class=" pTag">系统会通过AI运动矢量计算，将两次曝光的图片进行局部特征匹配，通过计算将模糊的图像复原，得到高清照片。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2H7ibGnKNPhgCHvsKPERIrnXhb0uQ10icDUXKjdmFCJRdDkcldMdae1yw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">比如开头看到的照片，实际上就经历了这种从模糊到清晰的处理运算过程。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2EPxZlgaNEJS2rSm8sVGvyvaVPbBknQSkefWFZia8oy0mibBsyxxIkEQg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">据介绍，在算法的加持下，在保证抓拍率的同时，Pura 70可以大幅度还原细节，最高可抓拍时速300km/h的运动物体。</div><div class=" pTag">这样的速度意味着，飞驰的赛车、快速奔跑的宠物，甚至连运行中的高铁，都能抓拍出高清晰度的照片。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2DZNGrohciasykKGEgvJd9qnlcyLcCnHh5r7emUcrHZG5ro2htanVItw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">有网友看过后调侃说，大嘴又躲在手机里P图了。</div><div class=" pTag">不过正经地讲，虽然是融合了AI算法，但的确能适应许多场景需求。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb283q0yp2bNu2qWqxj4QTGg8TFOiadGKKpicicw4wV3KYuaHISAOEib0IS9g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>一切终端终将走向AI</h2><div class=" pTag">用算法高速捕捉图像，只是AI在手机端诸多应用中的冰山一角。</div><div class=" pTag">单说华为P70，就集成了智能修图、多模态大模型等众多AI功能，其他厂商推出的AI手机更是不胜枚举。</div><div class=" pTag">不仅是像华为、小米、OV这些手机大厂，像高通这样的芯片供应商也在根据AI的算力特点调整着自己的产品。</div><div class=" pTag">总之，在AI迅速发展的时代，一切的终端设备，包括手机，走向智能化都是必然的趋势。</div><div class=" pTag">但具体的实现方式，可能生态中的每个厂商，都有自己独特的道路。</div><div class=" pTag">不过可以肯定的是，包括华为在内，认识到这一趋势的厂商，已然在一条新的赛道上卷起来了。</div><div class=" pTag"><span style="font-size: 17px;">参考链接：</span><br /><span style="font-size: 17px;">https://weibo.com/1945906841/Oar8yDASU</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FX7VmHWS-7-h74TfJHG3Zfw">阅读原文 </a>
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 10:56:14 GMT</pubDate>
</item>
<item>
<title>印象笔记唐毅：AI如何升级你的“第二大脑”｜中国AIGC产业峰会</title>
<link>https://posts.careerengine.us/p/6626423b6984cd5f2aa50dfa</link>
<guid>https://posts.careerengine.us/p/6626423b6984cd5f2aa50dfa</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">编辑部 整理自 AIGC峰会</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag"><div class=" pTag">百模大战之后，大伙儿或许有个共识：</div><br /></div><div class=" pTag">现在不缺大模型，缺的是怎么更好地把大模型用起来的方法。</div><div class=" pTag">有个现成的例子是，<strong style="font-weight: 600;">印象笔记</strong>一直被很多知识工作者当成自己的“第二大脑”来用，在AIGC时代，用户看到了它更智能的改变。</div><div class=" pTag">其实早在2018年，印象笔记就在AIGC的领域里开启了自己的摸爬滚打，几年下来，积累了不少经验和思考。</div><div class=" pTag">在本次中国AIGC产业峰会上，<strong style="font-weight: 600;">印象笔记董事长兼CEO唐毅</strong>从知识管理的角度，分享了印象笔记在AIGC领域，从技术到应用和产品的所见所闻、所思所感。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDFvCrRxT3Q6KkhlpJcWeEDNOQOKTG83XeyiaOhlblU6kBvzbyRCOPTZlOqCuJWBNoImrjfV4Cup2A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">为了完整体现唐毅的思考，在不改变原意的基础上，量子位对演讲内容进行了编辑整理，希望能给你带来更多启发。</div><div class=" pTag">中国AIGC产业峰会是由量子位主办的行业峰会，20位产业代表与会讨论。线下参会观众近千人，线上直播观众300万，获得了主流媒体的广泛关注与报道。</div><h2>话题要点</h2><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">模型算法进展缓慢，算力投入与收益不成比例；</div></li><li><div class=" pTag">公域数据穷尽，合成数据使用导致模型输出效果下降；</div></li><li><div class=" pTag">小型化、垂直化的模型可以更高效地处理问题；</div></li><li><div class=" pTag">强调了AI交付和模型之间的中间层——复合AI系统的重要性；</div></li><li><div class=" pTag"><div class=" pTag">AIGC产品的交互不是绝对的LUI</div><span>（语言用户界面）</span><div class=" pTag">或者CUI</div><span>（对话式用户界面）</span><div class=" pTag">；</div><br /><div class=" pTag">……</div></div></li></ul><div class=" pTag"><span>以下为唐毅演讲全文：</span></div><h2>大量使用合成数据导致模型输出效果下降</h2><div class=" pTag">大家下午好，我是印象笔记唐毅，我今天演讲的题目是《用AI驱动的第二大脑实现增强人生》。</div><div class=" pTag">针对AIGC技术，我认为从技术到模型、算法、实践和应用的一系列垂直和落地的思考是非常重要的。所以，今天我从知识管理的角度，分享一下印象笔记<strong style="font-weight: 600;">从技术到应用和产品</strong>的一些想法。</div><div class=" pTag">首先简单介绍一下印象笔记，它源于硅谷的一款叫<strong style="font-weight: 600;">Evernote</strong>的产品。</div><div class=" pTag">一直以来，印象笔记的愿景就是成为知识人群的第二大脑。这使得我们的思考一直围绕着“知识场景”和“大脑的关键功能”。</div><div class=" pTag">今天我会从AI驱动印象笔记系列产品，在内容理解、智慧提炼、个人知识积累和公域知识获取等知识管理的场景中的实践经验，来做分享。</div><div class=" pTag">印象笔记对AIGC的研发和实践早在2018年完成国内公司独立重组时就开始了。正式独立之后，我们首先更多地用了supervise learning的方式来做NLP，同时也开始启动了自己的小规模模型训练。</div><div class=" pTag">早在2023年3月，我们就已经开始利用自己的垂直专有模型驱动自己的AI产品，并将功能落地在旗下的软件和智能硬件产品。</div><div class=" pTag">由于印象笔记在国内市场较早地启动了AIGC的全面实践，我们也积累了更多的经验和更深入的思考。</div><div class=" pTag">在我们看来，AIGC的发现还处在比较早期的阶段，对人类社会的影响也才刚刚开始，但现阶段，关于大趋势和方向性的思考更是必不可少的。</div><div class=" pTag">首先，相比算力的发展和模型规模的扩大发展，<strong style="font-weight: 600;">模型算法的进展却是相对缓慢</strong>的。</div><div class=" pTag">同时，到现在为止，<strong style="font-weight: 600;">算力的投入和收益是不成比例</strong>的，我相信真正对产业经济产生深远影响的技术，最终总的回报ROI要达到正向才可以。</div><div class=" pTag"><span style="text-align: start; font-size: 17px;">另一个对于基座模型的挑战是，在基座模型训练中</span>，或许不一定每位在座的朋友都同意。</div><div class=" pTag">我们看到一个现象，在模型训练中，随着公域数据的逐渐穷尽，合成数据被大量加入使用，这也会直接导致模型输出效果下降。</div><div class=" pTag">有挑战也有机遇，我们看到，<span style="text-align: start; font-size: 17px;">特定数据的优化在模型能力提升中的作用、模型的小型化趋势、小规模模型能力的持续提升在<span lang="EN-US">AI</span>产品交付效果的提升中都起着越来越关键的作用。</span></div><h2>强调“复合AI系统”概念</h2><div class=" pTag">谈到AI交付，印象笔记是既做工具又做模型的厂商，在垂直整合的过程中，<span style="text-align: start; font-size: 17px;">我们发现，由于我们采用印象专有大模型直接服务用户，用户可以对模型的效果和性能有着迅速和直观的感受，从而对背后的训练和调优过程给予直接有效的反馈。</span></div><div class=" pTag"><span style="text-align: start; font-size: 17px;"><span style="text-align: start; font-size: 17px;">而另一方面，<span lang="EN-US">AI</span>产品的交付又远远不是仅仅将模型能力简单直接地交付到用户面前。</span></span></div><div class=" pTag"><strong style="font-weight: 600;"><span style="text-align: justify; font-size: 17px;">另一个显著的趋势是，小型化、垂直化的模型可以更高效地处理问题</span><span style="text-align: justify; font-size: 17px;">。</span></strong><span style="text-align: justify; font-size: 17px;">在行业日益追求模型效率化的过程中，数据对模型质量和交付质量的影响在提</span><span style="text-align: justify; font-size: 17px;">升，对算力的需求反而在下降。</span></div><div class=" pTag"><span style="text-align: justify; font-size: 17px;">基于这</span><span style="text-align: justify; font-size: 17px;">些趋势和我们的实践经验，我想强调“复合AI系统”的概念，这是在AI产品交付和大模型本身之间的一个非常关键的应用思考点和架构设计点。</span></div><div class=" pTag"><span style="text-align: justify; font-size: 17px;">从不同的论文中我们也可以看到相似观点——系统性思维下的模型训练、调优，以及与整个AI系统其它组成部分的有机组合，是现在AIGC应用的一个重要思考角度。</span></div><div class=" pTag">不同AI系统需要不同角度的思考，印象笔记关于“复合AI系统”的思考主要有以下几点：</div><div class=" pTag"><strong style="font-weight: 600;">第一</strong>，我们的模型采用混合部署策略，以专有模型驱动主要用户服务和交互场景，模型本身具有路由和任务判断能力，<span style="font-size: 17px; text-align: justify;">同时也具备质量判断和云端一体的路由判断能力。</span></div><div class=" pTag"><strong style="font-weight: 600;">第二</strong>，我们对公域和私域数据的区分处理和保护管理有独特的系统和严密的规则。</div><div class=" pTag"><strong style="font-weight: 600;">第三</strong>，智能代理本身的功能是阵列式的，在关键节点分析用户的意图、做任务的拆解，最后还要系统化地接收用户反馈的过程。</div><ul class="list-paddingleft-1"><li><div class=" pTag"><span><strong style="font-weight: 600;">模型：</strong></span><span style="font-size: 17px; text-align: justify;">印象大模型是高效率、轻量化的专有模型，在知识场景中有着独特的和优异的性能表现。印象大模型端、云部署一体化，并具备一个重要的性能——能够根据意图判断和选择哪一个混合部署中的模型会有更好的处理的效果，也能判断和分析任务本身并在云或端模型中进行选择。</span></div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">数据：</strong></span>严格区分管理公、私域数据，确保模型训练和AI产品交付中的用户数据隐私保护。</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">Agent：</strong></span>在混合部署策略下，<span style="text-align: start; font-size: 17px;">模块化的<span lang="EN-US">Agent</span>阵列能够真正有效地判断用户意图并根据拆解的任务步骤分步执行任务。</span></div></li></ul><div class=" pTag"><span style="text-align: start; font-size: 17px;">“复合<span lang="EN-US">AI</span>系统”超越<span lang="EN-US">AIGC</span>应用单一模型驱动的思考方式，</span>而在此系统下设计一款成功的AI应用也需要考虑不同的因素，这也是印象笔记在AI产品的打造中比较独特的体会。</div><div class=" pTag">首先，我们需要非常明确地分析和判断出这款应用的准确使用场景。</div><div class=" pTag">同时，你的AI复合系统如何驱动这个产品给用户进行交付也十分关键。</div><div class=" pTag">对此，也有两个重要思考点。</div><div class=" pTag"><span style="font-size: 17px; text-align: justify;">一个是最合适的</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">AI</span><span style="font-size: 17px; text-align: justify;">应用载体在哪——是在云端？在移动端？在某一个第三方平台？还是</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">GPTs</span><span style="font-size: 17px; text-align: justify;">或插件？不用的载体在不同的场景和工作流中有着不同的作用。</span></div><div class=" pTag">另一个是何为最适合的交互——自然语言交互还是传统GUI交互？</div><h2>提倡用直觉性的方式进行交互设计</h2><div class=" pTag">我们提倡用符合用户<strong style="font-weight: 600;">直觉性的方式</strong>进行交互设计，<span style="font-size: 17px; text-align: justify;">使用户用到</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">AI</span><span style="font-size: 17px; text-align: justify;">功能和</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">AI</span><span style="font-size: 17px; text-align: justify;">产品的时候是一种最自然的选择和体验。</span></div><div class=" pTag">因此产品的交互不是绝对的LUI或者CUI——<span style="text-align: start; font-size: 17px;">例如在纯粹<span lang="EN-US">LUI</span>或<span lang="EN-US">CUI</span>的交互中，它虽然更自由、更开放，但完全开放的对话窗口也会增加用户的焦虑感 ——用户会停在那里不知道该做什么。</span></div><div class=" pTag">所以产品中<strong style="font-weight: 600;">既应该有完全开放的交互窗口，也应该有开放交互和传统的GUI相辅相成的Copilot性质的交互设计，同时也应该有降低用户焦虑感的传统限制性菜单处理交互式设计</strong>。</div><div class=" pTag">因此，在一个“复合AI系统”下打造AI超级应用时，我们认为除了AI系统思维之外，数据、用户、场景、载体、交互等关键的要素是需要非常慎重考虑的关键点。</div><div class=" pTag">回到印象笔记的实践，我们通过自有模型的混合部署，比较早地进行了全面的布局和落地，推出了多种方向的功能：</div><div class=" pTag">内容生成与搜索、语义性搜索、大文件理解、多文件理解、与上万篇笔记的私人对话等等。</div><div class=" pTag"><span style="font-size: 17px; text-align: justify;">通过逐步实践，我们总结出了一些令我们感到兴奋的方法和获得了一些较为满意的结果。</span></div><div class=" pTag"><span style="font-size: 17px; text-align: justify;">“印象</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">AI</span><span style="font-size: 17px; text-align: justify;">”的推出，对新用户的增长、用户留存和商业化转化的驱动效果都非常显著。</span></div><div class=" pTag"><span style="font-size: 17px; text-align: justify;">呼应我在今天演讲开始提到的观点——</span><span style="font-size: 17px; text-align: justify;">作为</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">AI</span><span style="font-size: 17px; text-align: justify;">从业者，对于核心技术、产品策略、市场投入等方面的实践的检验，最终总要能够回到对</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">ROI</span><span style="font-size: 17px; text-align: justify;">的结果的衡量上来。</span></div><div class=" pTag"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDFvCrRxT3Q6KkhlpJcWeEDNOwWIcYh3jbm4PufPexOmFF5MKPdLejZrHnKFCfuKmic1oc7nb74VAQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></div><div class=" pTag">目前，印象笔记旗下全系列的软件和智能硬件产品都已经在印象大模型的驱动下，完成了AI功能和产品的落地交付。</div><div class=" pTag"><span style="font-size: 17px; text-align: justify;">最后，我想说的是，在</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">AI</span><span style="font-size: 17px; text-align: justify;">能力的加持下，印象笔记希望能够帮助用户智能汇聚信息、高效阅读内容并吸收知识、辅助灵感记录与创作、自动完成知识整理与提炼，让印象笔记和印象</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">AI</span><span style="font-size: 17px; text-align: justify;">为您增强人生，成为您真正的“第二大脑”。</span></div><div class=" pTag">谢谢大家！</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FwKB6UwdaNnD7X5CMpEwd4A">阅读原文 </a>
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 10:55:55 GMT</pubDate>
</item>
<item>
<title>新测试基准发布，最强开源Llama 3尴尬了</title>
<link>https://posts.careerengine.us/p/6626423a6984cd5f2aa50df0</link>
<guid>https://posts.careerengine.us/p/6626423a6984cd5f2aa50df0</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">梦晨 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">如果试题太简单，学霸和学渣都能考90分，拉不开差距……</div><div class=" pTag">随着Claude 3、Llama 3甚至之后GPT-5等更强模型发布，业界急需一款<span><strong style="font-weight: 600;">更难、更有区分度的基准测试</strong></span>。</div><div class=" pTag">大模型竞技场背后组织LMSYS推出下一代基准测试<span><strong style="font-weight: 600;">Arena-Hard</strong></span>，引起广泛关注。</div><div class=" pTag">Llama 3的两个指令微调版本实力到底如何，也有了最新参考。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2zpkbvwUF8fbNMAxlDohbyQ3Aq1yIgzYC9eGbxMxLqYSC8dBxFic5pCg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">与之前大家分数都相近的MT Bench相比，Arena-Hard<span><strong style="font-weight: 600;">区分度从22.6%提升到87.4%</strong></span>，孰强孰弱一目了然。</div><div class=" pTag">Arena-Hard利用竞技场实时人类数据构建，<span><strong style="font-weight: 600;">与人类偏好一致率也高达89.1%</strong></span>。</div><div class=" pTag">除了上面两个指标都达到SOTA之外，还有一个额外的好处：</div><div class=" pTag">实时更新的测试数据包含人类新想出的、AI在训练阶段从未见过的提示词，<span><strong style="font-weight: 600;">减轻</strong><strong style="font-weight: 600;">潜在的数据泄露</strong></span>。</div><div class=" pTag">并且新模型发布后，无需再等待一周左右时间让人类用户参与投票，只需花费25美元快速运行测试管线，即可得到结果。</div><div class=" pTag">有网友评价，<span><strong style="font-weight: 600;">使用真实用户提示词而不是高中考试来测试，真的很重要。</strong></span></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2kOV8K8ArfwxicxhXzUW5NMjzg1AG2EF4ZLxLQNvOkiaiaJYmlzicPnFKug/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>新基准测试如何运作？</h2><div class=" pTag">简单来说，通过大模型竞技场20万个用户查询中，挑选500个高质量提示词作为测试集。</div><div class=" pTag">首先，挑选过程中确保<span><strong style="font-weight: 600;">多样性</strong></span>，也就是测试集应涵盖广泛的现实世界话题。</div><div class=" pTag">为了确保这一点，团队采用BERTopic中主题建模管道，首先使用OpenAI的嵌入模型<span>（text-embedding-3-small）</span>转换每个提示，使用 UMAP 降低维度，并使用基于层次结构的模型聚类算法<span> (HDBSCAN)</span> 来识别聚类，最后使用GPT-4-turbo进行汇总。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2x9su7iciccRFp9gBycyVGVCzIVKKjyHIfLoHzDzaJ5QIG0O5vhfSjfvg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同时确保入选的提示词具有<span><strong style="font-weight: 600;">高质量</strong></span>，有七个关键指标来衡量：</div><ul class="list-paddingleft-1" style="font-size: 17px; text-align: start;"><li><div class=" pTag"><span><strong style="font-weight: 600;">具体性：</strong></span>提示词是否要求特定的输出？</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">领域知识：</strong></span>提示词是否涵盖一个或多个特定领域？</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">复杂性：</strong></span>提示词是否有多层推理、组成部分或变量？</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">解决问题：</strong></span>提示词是否直接让AI展示主动解决问题的能力？</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">创造力：</strong></span>提示词是否涉及解决问题的一定程度的创造力？</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">技术准确性：</strong></span>提示词是否要求响应具有技术准确性？</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">实际应用：</strong></span>提示词是否与实际应用相关？</div></li></ul><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb23iat6M1Vh1wDmCumYicDQh3l2suZRKGIqMIHdWlALV8oELTcNWzcEGgw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">使用GPT-3.5-Turbo和GPT-4-Turbo对每个提示进行从 0 到 7 的注释，判断满足多少个条件。然后根据提示的平均得分给每个聚类评分。</div><div class=" pTag">高质量的问题通常与有挑战性的话题或任务相关，比如游戏开发或数学证明。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2G2Tt7kdXfPibnFcl2b16O3BacvtZiaGm6L8gKrGqSBibE5W0CJgAGhaTg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><h2>新基准测试准吗？</h2><div class=" pTag">Arena-Hard目前还有一个弱点：使用GPT-4做裁判更偏好自己的输出。官方也给出了相应提示。</div><div class=" pTag">可以看出，最新两个版本的GPT-4分数高过Claude 3 Opus一大截，但在人类投票分数中差距并没有那么明显。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb260JvYvHQ6VFSrk0gEyvgDGfwEl4lerc1Xh35pnZ83QlqIgkljwrGjg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">其实关于这一点，最近已经有研究论证，<span><strong style="font-weight: 600;">前沿模型都会偏好自己的输出</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb25eUwJZiatSgUaXG1dwYPHw49qbicA0zNBBH8jt5X7z3ac98oHDhaGYnA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">研究团队还发现，AI天生就可以判断出一段文字是不是自己写的，经过微调后自我识别的能力还能增强，并且<span><strong style="font-weight: 600;">自我识别能力与自我偏好线性相关</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2KJFS2Vn4XiaFKZCkibEEukMWX9TrywDfcEt6bU1GicIzq48ojerxd6hmQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么使用Claude 3来打分会使结果产生什么变化？LMSYS也做了相关实验。</div><div class=" pTag">首先，Claude系列的分数确实会提高。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2IOnm1P84DXoCMSS3W7SBYOjqcxDxJusw7Zods7VIKH6yTECgZz8kZg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">但令人惊讶的是，它更喜欢几种开放模型如Mixtral和零一万物Yi，甚至对GPT-3.5的评分都有明显提高。</div><div class=" pTag">总体而言，使用Claude 3打分的区分度和与人类结果的一致性都不如GPT-4。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2JWaSO5ibPzPsn9jiaID4OZkrwHezeLqslJHFKkpJSCKtRcVepRbuhYZA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">所以也有很多网友建议，<span><strong style="font-weight: 600;">使用多个大模型来综合打分</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb22NXtlADVOPbuNcgUKnFZIBJG0ZfoVsicC0YsfGR1X77M61TdBicMNJKQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">除此之外，团队还做了更多消融实验来验证新基准测试的有效性。</div><div class=" pTag">比如在提示词中加入“让答案尽可能详尽”，平均输出长度更高，分数确实会提高。</div><div class=" pTag">但把提示词换成“喜欢闲聊”，平均输出长度也有提高，但分数提升就不明显。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2B3mQsTnibXxkuqK8mD12PkQ7bUgLVZ0kZ9a8aDrIDbsrJ4LoKBTYSjw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外在实验过程中还有很多有意思的发现。</div><div class=" pTag">比如GPT-4来打分非常严格，如果回答中有错误会狠狠扣分；而Claude 3即使识别出小错误也会宽大处理。</div><div class=" pTag">对于代码问题，Claude 3倾向于提供简单结构、不依赖外部代码库，能帮助人类学习编程的答案；而GPT-4-Turbo更倾向最实用的答案，不管其教育价值如何。</div><div class=" pTag">另外即使设置温度为0，GPT-4-Turbo也可能产生略有不同的判断。</div><div class=" pTag">从层次结构可视化的前64个聚类中也可以看出，大模型竞技场用户的提问质量和多样性确实是高。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb27ia3iazn23ADibsia8Sq2wp0L0FSLSacdpJBvGoLUWtokiaXsIMvrozlicIA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这里面也许就有你的贡献。</div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">Arena-Hard GitHub：</div><br /></span><span style="font-size: 17px;">https://github.com/lm-sys/arena-hard</span><br /><span style="font-size: 17px;"><div class=" pTag">Arena-Hard HuggingFace：</div><br /></span><span style="font-size: 17px;">https://huggingface.co/spaces/lmsys/arena-hard-browser</span><br /><span style="font-size: 17px;"><div class=" pTag">大模型竞技场：</div><br /></span><span style="font-size: 17px;">https://arena.lmsys.org</span></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://x.com/lmsysorg/status/1782179997622649330</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://lmsys.org/blog/2024-04-19-arena-hard/</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-lZKrLWICRdnabzvoqvGKw">阅读原文 </a>
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 10:55:54 GMT</pubDate>
</item>
</channel>
</rss>