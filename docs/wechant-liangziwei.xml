<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>微信公众号 - 量子位</title>
<link>https://posts.careerengine.us/author/599d7c52f2145121d1aa4698/posts</link>

<item>
<title>Gemini视频推理遥遥领先GPT-4o，Jeff Dean连续转发三次，首个视频多模态基准Video-MME来了</title>
<link>https://posts.careerengine.us/p/667048f888f0632a0848d279</link>
<guid>https://posts.careerengine.us/p/667048f888f0632a0848d279</guid>
<content:encoded><![CDATA[
<div> 视频推理、Video-MME、Gemini 1.5 Pro、多模态大模型、数据集开源
<br><br>总结:文章介绍了新推出的多模态大模型视频分析综合评估基准Video-MME，填补了该领域的空白。Gemini 1.5 Pro在基准中表现出色，得到了谷歌首席科学家的转发。文章详细说明了数据集的特点、实验结果和模型性能。Gemini 1.5 Pro在长视频理解方面领先，但仍有提升空间。音频和字幕信息对于视频理解至关重要。当前多模态大模型在长视频理解方面仍有进步空间，需要更高质量的数据集支持。文章指出不同类型的视频任务对模型性能有影响，提出了未来研究的方向。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">梦晨 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">OpenAI和谷歌接连两场发布会，把AI视频推理卷到新高度。</div><div class=" pTag">但业界还缺少可以全面评估大模型视频推理能力的基准。</div><div class=" pTag">终于，多模态大模型视频分析综合评估基准<strong style="font-weight: 600;">Video-MME</strong>，<strong style="font-weight: 600;">全面评估多模态大模型的综合视频理解能力</strong>，填补了这一领域的空白。</div><div class=" pTag">Gemini 1.5 Pro在这份榜单中遥遥领先，显示出在视频理解领域的“霸主”地位。Video-MME一经推出，被<strong style="font-weight: 600;">谷歌首席科学家Jeff Dean连续转发了三次</strong>。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0iczdibG48lgt0rewXiaEoIYopD38eKFPpKOOAfC2ib3aia4nSa0Uxa1qowA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">GPT-4o、谷歌Gemini 1.5 Pro标榜的视频推理能力终于在全新的、更复杂的多模态基准Video-MME上首次得到了验证。</div><div class=" pTag">同时，各大公司以及研究机构，例如NVIDIA、ByteDance等模型也加入了混战。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0xdMw2FojgDEqzFow1aDMJS7kULAleBASqAuGpwMjXRczBMNrDG0bpw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">Video-MME由中科大、厦大、港中文等高校联合推出，代码和数据集均已开源。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0kvnErj6ojq4RajyqP1kiatraLmG9jjrsGnkO9pIOT8enrocuaBa1KSQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>全人工标注高质量数据集</h2><div class=" pTag">该基准采取<strong style="font-weight: 600;">全人工标注</strong>，具有区别于现有数据集的显著特点。在以下的例子中，准确回答该问题需要同时从视觉、字幕以及音频中同时获取信息，有效信息直接横跨30分钟的间隔：</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0LJ8KYSApBD97hU4ysHTTicFwtQyiaHibTJBavuOyg6JqHZqtRyB7F4AgA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">Video-MME具有以下显著特点：</div><div class=" pTag"><strong style="font-weight: 600;">时间维度的广泛性</strong>：视频时长从<strong style="font-weight: 600;">11秒到1小时</strong>不等，涵盖<strong style="font-weight: 600;">短（&lt;2分钟）、中（4-15分钟）、长（30-60分钟）</strong>三种不同的视频时长，全面评估模型在不同时间跨度下的上下文多模态理解能力；</div><div class=" pTag"><strong style="font-weight: 600;">数据模态的丰富性</strong>：除了视频帧，Video-MME还整合了<strong style="font-weight: 600;">字幕和音频模态输入</strong>，全面评估大模型的多模态处理能力；</div><div class=" pTag"><strong style="font-weight: 600;">视频类型的多样性</strong>：覆盖了知识、影视、体育、艺术、生活记录和多语言6个主要领域，涉及<strong style="font-weight: 600;">30个细粒度子领域</strong>；</div><div class=" pTag"><strong style="font-weight: 600;">注释质量的高标准</strong>：900个视频，共<strong style="font-weight: 600;">254小时的内容</strong>由具备大模型背景的专业人员手动标注与验证，产生了2,700个问答对。问题类型涵盖感知、认知和总结概括等<strong style="font-weight: 600;">12种类型</strong>；</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0ZI8hzmqZFZrOFmic34qwGHUT9G4kib6jxKu0b5pLXDW0bJeQdtKpD0ZA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">可靠的有效时长</strong><span>（Certificate Length准确回答问题所需的最短时长）</span>：对于短视频、中视频和长视频，Video-MME数据集的有效时长中位数分别为26.0秒、164.7秒和890.7秒，要求模型<strong style="font-weight: 600;">消化更长的视频内容才能回答问题</strong>；</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0GqeKjgrJNclBhzMicnVhAuEcHGjRTDm3xxymxZDibkVTicx9rkdSEj5vw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">全面的实验评估：</strong>文章选取了6种代表性的开源视频语言模型以及闭源模型Gemini 1.5 Pro和GPT-4V/o进行<strong style="font-weight: 600;">全面的实验分析</strong>。同时文章还选取了基于图片的多模态大模型进行评测（泛化到多图输入），证明其同时适用于图片&amp;视频多模态大模型。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0cZxcCRfQCCmSyZ4uZ6ic1TtxwLO8ZPe6VkwS8V0vLmxWRMvMFnjd9Tg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">文章选取了多种代表性的开源视频多模态大模型，包括ST-LLM、VideoChat2-Mistral、Chat-UniVi-V1.5、LLaVA-NeXT-Video和VILA-1.5，以及闭源模型Gemini和GPT-4V/o 。同时，基于图片的多模态大模型包括Qwen-VL-Chat、Qwen-VL-Max和InternVL-Chat-V1.5。</div><div class=" pTag">在商业模型中，Gemini 1.5 Pro在视频理解方面表现突出，在加以字幕辅助的情况下以81.3%的准确率领先，并在与GPT-4V和GPT-o的对比中分别超出18%和4.1%。</div><div class=" pTag"><strong style="font-weight: 600;">尽管随着视频时长增加，其表现略有下降，但在长视频上的表现（加字幕）优于所有开源模型在短视频上的表现</strong>。</div><div class=" pTag">同时，Gemini 1.5 Pro还支持音频模态的输入，模态支持的更广。而在开源模型中，来自NVIDIA的VILA-1.5以59.4%的准确率表现最佳。然而，相比Gemini 1.5 Pro，VILA-1.5在计数问题、动作识别和时间感知方面仍然存在显著差距。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0GMI1wX5BwK3sA7vELMiaQGnSBUeaxGg3GeLobj5AlQaZfSZvGLzpO9g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同时，随着视频时长的增加，所有模型的表现均呈现明显的下降趋势，这也说明面对更长的上下文记忆以及更为复杂的任务时模型还有很大的提升空间。此外，实验还揭示了字幕和音频信息能显著增强视频理解能力，尤其是对于长视频的理解。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0aCUnwwP9vicZ5zrWbj5p8FwOC8tGZneicw5Ivz6dm9AFpibm4TKia1ZUDQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="text-align: left;">在三十种不同类型的视频上，Gemini 1.5 Pro展现出不同的性能。例如，有的任务对字幕和语音的依赖程度更高，如Basketball的长视频，加上字幕和语音能够显著提升性能。详细的实验结果请参照论文原文。</span></div><div class=" pTag">综合实验结果可以看出，当前的多模态大模型在视频理解，尤其是长视频理解方向仍然有很长进步空间，一方面是要提升模型的多模态长上下文理解能力，Gemini 1.5 Pro最高支持百万长度的上下文窗口，这是其表现优异的依仗，另一方面也亟需构建相应的高质量长视频理解数据集，这方面当下仍处于空白。</div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">论文链接：https://arxiv.org/pdf/2405.21075</div><br /><div class=" pTag">项目主页：https://video-mme.github.io</div><br /><div class=" pTag">项目仓库：https://github.com/BradyFU/Video-MME</div></span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJ2VSXPv2fjDmF0k7nDM3Ug">阅读原文 </a>
]]></content:encoded>
<pubDate>Mon, 17 Jun 2024 14:32:24 GMT</pubDate>
<pubDate>Mon, 17 Jun 2024 14:32:24 GMT</pubDate>
</item>
<item>
<title>8B模型奥数成绩比肩GPT-4！上海AI Lab出品</title>
<link>https://posts.careerengine.us/p/667048f788f0632a0848d271</link>
<guid>https://posts.careerengine.us/p/667048f788f0632a0848d271</guid>
<content:encoded><![CDATA[
<div> Llama 3, MCTSr, 蒙特卡洛树, 自我修正, 数学能力<br>
<br>
要点一：MCTSr是一款具有超强数学能力的模型，参数量只有8B，采用蒙特卡洛树和自我修正方法。<br>
要点二：MCTSr在数学问题上取得了比肩GPT-4的准确率，通过反复评估和修正生成最优解。<br>
要点三：MCTSr在测试中表现出较高的准确率，尤其在奥赛级别题目上有显著提升。<br>
要点四：MCTSr表现出一定泛化能力，面对全新问题有较好的表现。<br>
要点五：MCTSr的代码已开源，对AI领域研究有一定启发意义。<br>
<br>
总结: MCTSr是一款参数量极少但具有超强数学能力的模型，通过蒙特卡洛树和自我修正方法，在奥赛级别题目上取得了与GPT-4相媲美的准确率。测试表现显示在不同难度的数学问题上有持续提升，且具有一定泛化能力。研究团队已开源MCTSr的代码，有望推动AI领域的发展。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">只要1/200的参数，就能让大模型拥有和GPT-4一样的数学能力？</div><div class=" pTag">来自复旦和上海AI实验室的研究团队，刚刚研发出了具有超强数学能力的模型。</div><div class=" pTag">它以Llama 3为基础，参数量只有8B，却在<strong style="font-weight: 600;"><span>奥赛级别</span></strong>的题目上取得了比肩GPT-4的准确率。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0VrYOO2PrEcsfyKeoC2QiaSkibITIqTthwglVBs1RiaQIUNWJcvyxkTphQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这款模型名为MCTSr，是将AlphaGo中用到的<strong style="font-weight: 600;"><span>蒙特卡洛算法</span></strong>与Llama3结合而成。</div><div class=" pTag">它能用少量的数据实现和GPT-4等的相同效果，让网友感叹Q*成真了，小模型在数学上也能做的和GPT-4等著名模型一样好。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0pUyVAGS0l7p4M37sJ9ibEJWTTK5u9sUKUtmTiaOqV7n3fnU8I7xgCX3w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">就此又有网友表示，MCTSr能用极少的参数实现相同的效果，加上有时候训练收益随规模递减，表明架构才是当前AI的瓶颈，而不是运算。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0clTg8Bg0RbW8GnUwIfPxia901zz0Q9k3vFiaeBhicuXOuID1hnwwEXBKw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这样的趋势也让人想起了AI算力霸主英伟达，开始思考规模化是不是不那么重要了，会不会利空老黄呢？</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0Mc6pECZK9vF0icVh4qVsMPx9gAHsoA5snQ00dTL1cEricoiaVWicweUJ9g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">所以，MCTSr具体运用了什么样的方法呢？</div><h2>将蒙特卡洛引入大模型</h2><div class=" pTag">MCTSr名字里是MCT，指的就是蒙特卡洛树<span>（Monte Carlo Tree）</span>，而Sr则指的是自我完善<span>（Self-Refine）</span>。</div><div class=" pTag">蒙特卡洛树又称随机抽样或统计试验方法，是指一种使用重复随机采样生成合成模拟数据的近似方法，谷歌的围棋机器人AlphaGo当中也用到了这种方法。</div><div class=" pTag">名字中没有体现的，是蒙特卡洛与大模型的结合，本项目当中使用的是Llama 3-8B，同时MCTSr还引入了<strong style="font-weight: 600;"><span>自我修正和自我评估</span></strong>的迭代过程。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0hZ6xibp8zjiby1KaoPeRjsVykYJG4hy1pmicN3bvQuGhPP1N6LNbHSJHg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在解答数学问题时，MCTSr中的大模型首先会像正常流程一样生成初步答案<span>（甚至可以是“我不知道”）</span>，但并不会直接作为输出。</div><div class=" pTag">为了改进这个初始答案，MCTSr算法会对其进行评估和反馈，语言模型会被要求对答案进行评价和批评，分析其中可能存在的问题。</div><div class=" pTag">然后大模型基于反馈进行自我修正，产生一个新的答案，这个新版本会纳入搜索树中，成为一个新的子节点。</div><div class=" pTag">针对多个子节点，系统会进行评分和奖励采样，计算出该节点的“Q值”<span>（a表示答案节点，Ra表示a的奖励样本集合，|Ra|表示样本数量）</span>，可以看出Q值的计算综合考虑了节点在最坏情况和平均情况下的表现。</div><div class=" pTag">为了提高评估的可靠性，系统采用了严格的打分标准，并会进行重复采样，同时还采取了禁止模型给出满分等策略。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt032JwicITG44ibcRDMVr1Ud9iaOxAicDWvWhicvOM08ia6CoaXI6YxiaPGO7hA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">然后基于Q值，MCTSr会使用改进的UCB公式计算每个叶子节点的UCT值，选择UCT值最高的节点进行扩展。</div><div class=" pTag"><span>（UCB是一种实现总奖励最大化的方式，UCT是将UCB策略应用于树形搜索问题的一种算法。）</span></div><div class=" pTag">计算UCT值的目的，是为了平衡了节点的平均奖励和访问频率，避免单纯追求高Q值导致的效率下降。</div><div class=" pTag">此外，作者修正的UCT计算公式中还引入了动态调整探索系数c，以便在搜索过程中适应不同的问题复杂度，并在探索广度和深度之间做出平衡。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0iao8beWic5GgKGJbgSectavAlFMNPzG0FpeFXq01ic1pmVicdIiczvRNEWw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">被选中的节点，会通过大模型再次进行自我修正，生成新的答案节点，然后再次进行自我评估并计算Q值。</div><div class=" pTag">新的Q值会被并反向传播到其父节点和祖先节点，确保了搜索树中节点的质量评估随着搜索的进行而不断改进。</div><div class=" pTag">根据新的Q值和访问次数，各个节点的UCT值也会被重新计算。</div><div class=" pTag">接着，上述步骤会被不断重复，直到满足预设的终止条件，此时具有最高Q值的答案节点被视为问题的最优解。</div><div class=" pTag">总的来说，通过蒙特卡洛搜索、自我完善与大模型的集合，MCTSr实现了数学问题最优解的生成。</div><div class=" pTag">那么，这种方法的实际效果究竟如何呢？</div><h2>成绩不输GPT-4和Claude-3</h2><div class=" pTag">在测试当中，作者一共使用了四种模型配置——零样本思维链（CoT），以及1/4/8轮自我优化的MCTSr，其中零样本为对照组。</div><div class=" pTag">测试数据集包括MATH的5个level，GSM-8K和GSM-Hard，以及一系列奥赛级别的数据集——AIME、Math Odyssey 和OlympiadBench。</div><div class=" pTag">先看简单一些的GSM和MATH。</div><div class=" pTag">从下表中可以看出，<strong style="font-weight: 600;"><span>随着自我优化轮数是增多，模型取得的准确率也在增加</span></strong>，经过8轮之后，在GSM-8K上已经达到了96.66%。</div><div class=" pTag">而Gemini（1.5Pro，下同）、Claude-3（Opus，下同）、GPT-4（Turbo，下同）的成绩则分别是94.4、95和97.1，可以看出参数只有8B的MCTSr和这些先进模型不相上下。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0qfKEHvcyG9Mn36ajsIHRjKS30ib1icfTI7p2Mn3Gcqmdj4rxEY27GXXg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同样在MATH上，无论是整体还是细分的五个难度等级，成绩随优化轮数的变化都呈现出了相同趋势。</div><div class=" pTag">特别是在最困难的Level-5上，8轮后的成绩已经接近了对照组的5倍。</div><div class=" pTag">在MATH上，Gemini、Claude-3和GPT-4的成绩分别为67.7、60.1和73.4，相比之下MCTSr略逊一筹，但也和Claude比较接近。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0jBIFhfu9YpyLnAYK7ecBR3vKYvE3xjB5RvJVAkNdcRebpicribClWxpw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在更加困难的奥赛级别题目上，自我优化给MCTSr带来的能力增强也十分显著。</div><div class=" pTag"><strong style="font-weight: 600;"><span>在Math Odyssey上，MCTSr甚至超过了Gemini、Claude-3和GPT-</span></strong>4，三者的成绩分别是45、40和49.1。</div><div class=" pTag">同时，在OlympiadBench上，经过8轮优化后，MCTSr的成绩是零样本时的6.2倍。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0yezpkh0YK5KzxAnjGHicQVkdAPeumMb4sOVFj4CZPb7mI68jFN2PJ6A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">值得一提的是，Math Odyssey数据集在2024年4月才发布，其内容与Llama 3的预训练语料重叠度很低。</div><div class=" pTag">而在这个数据集上，MCTSr模型的性能从Zero-Shot CoT的17.22%提升到了8-rollouts MCTSr的49.36%。</div><div class=" pTag">这一结果表明，MCTSr在面对全新的问题时，已经显现出了一定的<strong style="font-weight: 600;"><span>泛化能力</span></strong>。</div><div class=" pTag">目前，MCTSr的代码已经开源，感兴趣的读者可以到GitHub当中了解。</div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">论文地址：</div><br /></span><span style="font-size: 17px;">https://arxiv.org/abs/2406.07394</span><br /><span style="font-size: 17px;"><div class=" pTag">GitHub：</div><br /></span><span style="font-size: 17px;">https://github.com/trotsky1997/MathBlackBox</span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div class=" pTag"><span style="font-size: 17px;">— <strong style="font-weight: 600;">完</strong> —</span></div></div></div><div style="font-size: 17px;"><div class=" pTag"><span><strong style="font-weight: 600;">量子位年度AI主题策划</strong></span>正在征集中！</div><div class=" pTag">欢迎投稿专题&nbsp;<strong style="font-weight: 600;">一千零一个AI应</strong><strong style="font-weight: 600;">用</strong>，<strong style="font-weight: 600;">365行AI落地方案</strong></div><div class=" pTag">或与我们分享你在<strong style="font-weight: 600;">寻找的AI产品</strong>，或发现的<strong style="font-weight: 600;">AI新动向</strong></div></div><div style="text-align: center;"><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div></div></div><div class=" pTag" style="text-align: center;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FvrmkeTeU92QsZN8DPJqj7w">阅读原文 </a>
]]></content:encoded>
<pubDate>Mon, 17 Jun 2024 14:32:23 GMT</pubDate>
<pubDate>Mon, 17 Jun 2024 14:32:23 GMT</pubDate>
</item>
<item>
<title>“技术故障”背刺巴菲特，金融大模型到底靠不靠谱？</title>
<link>https://posts.careerengine.us/p/667048e9bf611a295208ab5a</link>
<guid>https://posts.careerengine.us/p/667048e9bf611a295208ab5a</guid>
<content:encoded><![CDATA[
<div> 大模型、金证、英特尔、AI、金融
<br>
<br>
总结: 本文介绍了金证与英特尔合作推出的大模型推理方案，通过组合式AI解决金融领域AI应用中的困难和挑战。金证利用K-GPT在金融领域中有效应用大模型，英特尔至强® CPU Max处理器提供了硬件支持。与传统大模型不同的是，金证结合了大模型、小模型和工具，提升了效率。英特尔处理器的高带宽内存和矩阵扩展引擎加速了模型推理，提高了性能。金证的解决方案旨在提高金融机构的数字化转型效率，为用户提供更智能、高效的服务体验。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">金磊 梦晨 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">一个“技术问题”，导致<strong style="font-weight: 600;">巴菲特</strong>的伯克希尔-哈撒韦公司<strong style="font-weight: 600;">股价暴跌近100%</strong>。</div><div class=" pTag">想必很多小伙伴已经感受过了这则铺天盖地的消息，所带来的<strong style="font-weight: 600;">亿点点震撼</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0mLr3D0uBm7YYAwI9pWwOscZrudcNJtRqICjemu1MEC7crgUCtM0M1g/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">而根据事后的消息来看，这个大故障是纽交所的合并报价系统（CTA）在<strong style="font-weight: 600;">更新软件</strong>时出现了问题。</div><div class=" pTag">许多专家都对此做了分析，有人认为是CTA软件在进行版本更新时出现了数据一致性问题；也有人提出最大的问题应该是出现在了数据库。</div><div class=" pTag">但总而言之，这并非是纽交所今年来第一次出现的故障，而是众多里的一个：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0EPaSrdOyUjYibM09074132YtQUQpDk9hgaBMkRbU1wOQ8Mb5wiaC0v4Q/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">甚至某开源数据库联合创始人Jason直言不讳地表示：</div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">纽交所在CTA软件上相关的IT水平还不及中国的大型金融机构和互联网公司，在中国已经很少会发生这种低级错误了。</div></blockquote><div class=" pTag">即便如此，这也不禁令人产生更大的顾虑和担忧——</div><div class=" pTag">传统软件问题尚能引发如此大的问题，那么站在大模型时代当下，AI+金融，是否又能做到准确可信？</div><div class=" pTag">正所谓实践是检验真理唯一标准，要回答的这个问题，我们不妨了解一下已经在金融领域“上岗”了的AI大模型。</div><h2>大模型上岗金融，都在做什么？</h2><div class=" pTag">诚然AI大模型的发展已然呈现势不可挡的趋势，但在金融领域真正应用的时候，依旧存在一些显著的困难和挑战。</div><div class=" pTag">例如<strong style="font-weight: 600;">数据隐私和安全</strong>方面，金融数据往往高度敏感，涉及个人和企业的财务信息，确保数据隐私和安全是首要挑战之一。</div><div class=" pTag">并且这些数据具有多源和异构的特点，需要进行有效的整合和处理，才能确保它们的准确性和完整性。</div><div class=" pTag">再如<strong style="font-weight: 600;">模型本身</strong>，大模型往往被视为“黑箱”，因为其内部决策过程难以解释；在金融领域，尤其是涉及风险管理和监管合规时，可解释性和决策透明性是非常重要的。</div><div class=" pTag">还有在<strong style="font-weight: 600;">实时性和资源消耗</strong>方面，金融市场瞬息万变，需要实时数据处理和决策支持，大模型的推理涉及到大量的矩阵乘法计算，对硬件的矩阵乘法计算能力提出较高要求，计算复杂性可能导致响应时间延迟，不利于实时应用。</div><div class=" pTag">加之大模型训练和推理过程需要大量的计算资源和能量消耗，这对企业的成本和环保要求提出了挑战。</div><div class=" pTag">而成立于1998年的老牌金融科技公司<strong style="font-weight: 600;">金证</strong>，面对上述固有的重重困难，却有着自己的一套解法。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt00gfsbr2uoHb9ZvJz9zicsoa6X7qU2gcm6DiaDfCNbsXCiaDibiahkY4OwVQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在金证看来，大模型的优势在于文本及非结构化数据处理能力、人机交互能力、生成能力和逻辑推理能力较强。</div><div class=" pTag">而相比小模型而言，大模型也存在明显的劣势，例如大模型“幻觉”问题（即大模型答非所问），大模型的部署算力要求高造成算力资源浪费，部署成本高等问题。</div><div class=" pTag">因此，金证的解法就是——通过<strong style="font-weight: 600;">组合式AI</strong>，即<strong style="font-weight: 600;">大模型+小模型+工具</strong>，以此来支撑各个业务场景AI需求。</div><div class=" pTag">大模型方面，包含金证去年年底推出的K-GPT以及业内众多顶流的大模型，在特定的金融任务中发挥大模型的特长。</div><div class=" pTag">小模型则是指诸如OCR、NLP、人脸识别、文字识别、财务分析等传统模型，可以细分任务做到快准狠地处理。</div><div class=" pTag">至于工具，则是指地图、天气、CRM、邮件、OA等。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0NPLvJvVWtiajzvsMVzmB8gia7asia6u9NvuxWZfSIdcAKiaDbjsG4z9Ykw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">一言蔽之，在某个金融领域任务中，这种模式可以让大模型、小模型和工具做到“专业的人干专业事”，尤其能极大地提高效率。</div><div class=" pTag">值得一提的是，相比于通用大模型，金证的K-GPT在数据查询的准确性方面表现更佳，能够更好地理解金融术语，提供专业且数据扎实的回复。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0BXOHZYvvibJMicqibXZjicHdsaIialaJcUseicicoSUkcxGeZtS50aqvZ9upg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">据了解，K-GPT 还支持查看引用的知识源，并具备与实时数据和模块化集成的能力，可以调取实时数据和组件。</div><div class=" pTag">依托庞大的金融知识库，K-GPT专为金融场景服务，其核心优势在于对金融的深入理解、数据准确、可验证性以及支持调用Agent功能。</div><div class=" pTag">从效果上不难看出，金证已然让大模型在金融领域中合格地上岗，那么针对成本和资源上的痛点，金证又是如何解决的呢？</div><h2>背后是高带宽内存（HBM）的<span>至强</span><sup>®&nbsp;</sup>在发力</h2><div class=" pTag">金证K-GPT方案中，还有一点比较特别：与英特尔合作，采用了基于CPU的大模型推理方案。</div><div class=" pTag">据了解，他们主要是看中的是<span><strong style="font-weight: 600;">英特尔<sup>®&nbsp;</sup>至强<sup>®&nbsp;</sup>CPU Max系列处理器</strong></span>。</div><div class=" pTag">这是英特尔唯一一款基于x86架构并采用<span><strong style="font-weight: 600;">高带宽内存</strong></span>（HBM）的CPU系列，采用了片上HBM设计，内存带宽高达4TB/s。和传统DDR5内存相比，HBM具有更多的访存通道和更长的读取位宽，理论带宽可达DDR5的4倍之多。</div><div class=" pTag">要知道，大模型推理涉及大量的权重数据读取，对硬件平台的内存访问带宽提出了很高的要求。</div><div class=" pTag">至强<sup>®&nbsp;</sup>CPU Max具有<span><strong style="font-weight: 600;">64GB HBM</strong></span>，每个内核可以分摊到超过1GB的内存，对于包括大模型推理任务在内的绝大多数计算任务，HBM都可以容纳全部的权重数据。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0ib0jLu2YzIwQx0Y2NeuiaFgWtY5ztbkt5CibWQBcib6ra8vgOy91Mibwc1w/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">内存带宽还不是金证选择这款CPU的全部理由。</div><div class=" pTag">英特尔<sup>®&nbsp;</sup>至强<sup>®&nbsp;</sup>CPU Max系列还内置了<span><strong style="font-weight: 600;">英特尔<sup>®&nbsp;</sup>高级矩阵扩展</strong></span> (<span style="font-size: 17px; text-align: left;">英特尔</span><sup style="text-align: left;">®&nbsp;</sup><span style="font-size: 17px; text-align: left;">AMX</span>)引擎，大幅提升了大规模矩阵乘法运算性能。</div><div class=" pTag">金证K-GPT基于Transformer架构，其核心特点包括多头注意力机制和前馈神经网络层，这其中都包含大量矩阵运算，而英特尔<sup>®&nbsp;</sup>AMX通过1024位TMUL指令和8个独立的矩阵计算单元，可以每时钟周期执行8次独立的矩阵乘累加操作，为这些运算提供强大的加速能力。</div><div class=" pTag">如此一来，大模型推理的效果如何呢？</div><div class=" pTag">在<span><strong style="font-weight: 600;">只用单颗CPU</strong></span>的情况下，推理130亿参数大模型，首个词元生成时间就能压到1秒左右，模型推理TPS超过10 tokens/s，用户提问后约2秒内就能得到响应。</div><div class=" pTag">别忘了遇到负载高峰等情况，<span><strong style="font-weight: 600;">还可以同时启用2颗CPU</strong></span>，性能还能提升将近一倍，可以说足以满足金融场景的大部分应用需求了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0OBDKkaooZqH9IFrfAkMOvY0APXUL0OdhjaZibZLAlQ6XhaYhNz8zGdA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">除了硬件层面的突破，英特尔还提供了经过优化的软件工具来挖掘硬件潜力。</div><div class=" pTag">比如广泛使用的<span><strong style="font-weight: 600;">OpenVINO™</strong></span>工具套件，就被用来专门调优加速模型的Embedding处理进行。</div><div class=" pTag">金融场景涉及大量专业文档的输入任务，Emedding正是把文本从离散变量转变为连续向量的过程，好让AI能够理解。</div><div class=" pTag">经过OpenVINO™ 工具套件优化后，K-GPT大模型的批量Embedding性能提升到3倍之多。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0S5GVMTq8lCY6kYKKLXWVE1zK1zmjaXy0KHOWRLfqBBE3TgkrfR7bqg/640?wx_fmt=png&amp;from=appmsg" /></div></div><br />图注：OpenVINO™ 工具套件优化前后 Embedding 性能比较</div><div class=" pTag">再比如金证与K-GPT配合使用的<span><strong style="font-weight: 600;">开源向量数据库Faiss</strong></span>，英特尔也提供了优化版本，以提升在至强<sup>®&nbsp;</sup>CPU Max上的模型推理性能。</div><div class=" pTag">在大规模向量相似性检索任务中，经英特尔优化过的版本性能可提升至4倍左右。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0BibBLtSL4ZoibFy3ZG2zCBH7GAQCzvgjOSEICfyrl8xfUop8KfewaCZA/640?wx_fmt=png&amp;from=appmsg" /></div></div><br />图注：英特尔优化版 Faiss 与原始 Faiss 性能对比（越高越好）</div><div class=" pTag">除了性能方面之外，金证选择英特尔<sup>®&nbsp;</sup>至强<sup>®&nbsp;</sup>CPU Max系列作为算力底座还带来其他方面的优势：</div><div class=" pTag"><span><strong style="font-weight: 600;">首先是灵活性。</strong></span>由于与主流的 x86 架构完全兼容，金证可以继续使用原有的机器，灵活搭配适合自身业务的配置。而且 CPU 能同时应对推理和通用计算，可根据负载情况随时调配资源。</div><div class=" pTag"><span><strong style="font-weight: 600;">第二是总拥有成本 (TCO)。</strong></span>从长远来看，CPU路线能以更低的部署和维护开销，实现与专用加速器相媲美的性能。这对于需要控制预算的金融机构来说至关重要。</div><div class=" pTag">综合看下来，英特尔<sup>®&nbsp;</sup>至强<sup>®&nbsp;</sup>CPU Max系列处理器在硬件能力、软件优化、生态适配、总拥有成本优势等方面都与金融场景非常契合，不失为业界大模型落地的一种新思路。</div><h2>如何评价？</h2><div class=" pTag">随着数字化转型的不断深入，大模型为金融行业带来的机遇与挑战并存。</div><div class=" pTag">越来越多的金融机构开始探索如何将AIGC技术与实际业务相结合，在提质增效的同时控制成本。但总的来说，大模型在金融行业的应用仍处于初步探索阶段。</div><div class=" pTag">金证携手英特尔打造的这套大模型推理方案，可谓是应用层、模型层、算力层的深度融合，为业界树立了标杆。</div><div class=" pTag">不久前举办的金证科技节，就吸引了众多金融机构前来”取经”。</div><div class=" pTag">作为连接金融与科技的重要平台，金证科技节吸引了众多来自银行、证券、保险等领域的金融行业玩家参与，共同探讨 AI 技术在金融领域的应用前景与优质实践。</div><div class=" pTag">可以预见，在英特尔的算力加持下，金证将在大模型技术上不断突破，助力更多金融机构实现数字化转型，为用户带来更智能、高效的服务体验。</div><div class=" pTag">为了科普CPU在AI推理新时代的玩法，量子位开设了《最“in”AI》专栏，将从技术科普、行业案例、实战优化等多个角度全面解读。</div><div class=" pTag">我们希望通过这个专栏，让更多的人了解CPU在AI推理加速，甚至是整个AI平台或全流程加速上的实践成果，重点就是如何更好地利用CPU来提升大模型应用的性能和效率。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0ia4d4sLaKibb3SMaGaNRiaOrAkboN0alTaLKfY63fLQfA8O7P12Ban15A/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /></div><div class=" pTag" style="font-size: 17px; text-align: left;">英特尔和金证的其他合作案例，请点击<strong style="font-weight: 600;"><span>“阅读原文”</span></strong>获取。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FCElXPe4u_7O2oFQpdtSOfg">阅读原文 </a>
]]></content:encoded>
<pubDate>Mon, 17 Jun 2024 14:32:09 GMT</pubDate>
<pubDate>Mon, 17 Jun 2024 14:32:09 GMT</pubDate>
</item>
<item>
<title>霉霉开口唱碧昂丝的歌，又是AI！口型不出戏，五官姿态也自然，复旦百度等出品｜GitHub揽星1k+</title>
<link>https://posts.careerengine.us/p/667048e8bf611a295208ab52</link>
<guid>https://posts.careerengine.us/p/667048e8bf611a295208ab52</guid>
<content:encoded><![CDATA[
<div> 关键词：Hallo、音视频同步、人像生成、研究团队、评估指标
总结:<br><br>这篇文章介绍了一种名为Hallo的研究，通过音频和人像生成视频实现音视频同步。研究团队采用分层音频驱动视觉合成模块，将人脸分为唇部、表情和姿态三个区域，实现精细的音视频同步。评估指标显示Hallo在保真性和唇形同步性等方面表现出色，具有泛化和鲁棒性。然而，该方法目前仅支持固定尺寸的人像输入，且无法实时生成。对于这种技术，一些网友担忧可能存在Deepfake风险，但该技术仍展示了对不同风格人像和音频的高质量生成能力。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">西风 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">一张人像、一段音频参考，就能让霉霉在你面前唱碧昂丝的《Halo》。</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-2"></div></div><div class=" pTag">一种名为<strong style="font-weight: 600;">Hallo</strong>的研究火了，GitHub已揽星1k+。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0PY0BHgzSmp20p1aJ121qABPsbyFswoAeRZV565QAEhnicaebIhvd3fw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">话不多说，来看更多效果：</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-5"></div></div><div class=" pTag">不论是说话还是唱歌，都能和各种风格的人像相匹配。从口型到眉毛眼睛动作，各种五官细节都很自然。</div><div class=" pTag">单独拎出不同动作强度的比较，动作幅度大也能驾驭：</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-7"></div></div><div class=" pTag">单独调整嘴唇运动幅度，表现是这样婶儿的：</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-8"></div></div><div class=" pTag">有不少网友看过效果后，直呼这是目前最好的开源口型同步视频生成：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt04aZicgzxqmZzJg1TWV8PmAPNibBC3fwmFciaxpiaRGD9bE4qCibltPeaibdQ/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt02dPQuGHZefoPrNM2v6RXE8bHicYzha5s5uE8HicdeoUV1WG5pVib7Y44w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这项工作由来自复旦大学、百度、苏黎世联邦理工学院和南京大学的研究人员共同完成。</div><div class=" pTag">团队提出了<strong style="font-weight: 600;">分层的音频驱动视觉合成模块</strong>，将人脸划分为嘴唇、表情和姿态三个区域，分别学习它们与音频的对齐关系，再通过自适应加权将这三个注意力模块的输出融合在一起，由此可以更精细地建模音视频同步。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0lYBBiaIwUl9t3GAfItYOW858fHbYsCqo1UiazzWdufgR4hm4z7BZDYqA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>Hallo长啥样？</h2><div class=" pTag">如前文所述，Hallo通过使用参考图像、音频序列以及可选的视觉合成权重，结合基于分层音频驱动视觉合成方法的扩散模型来实现。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt00PkMlEw89iaQJlAYIibLWQDVTukj1QTib7dR2oNImByrelrVh55heH9uw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">整体架构是这样婶儿的：</div><div class=" pTag">参考图像经过一个ReferenceNet编码全局视觉特征；人脸编码器提取身份相关的特征；音频编码器将输入语音转换为与运动相关的特征表示；分层音频驱动视觉合成模块用于在唇部、表情、姿态三个层次建立音视频的关联；最后通过扩散模型中的UNet完成去噪，生成视频帧。</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">扩</strong><strong style="font-weight: 600;">散模型主干网络</strong><span>（Diffusion Backbone）</span></div></li></ul><div class=" pTag">采用Stable Diffusion 1.5作为基础架构，包括三个主要部分：VQ-VAE编码器、基于UNet的去噪模型、条件编码模块。与传统的文本驱动扩散模型不同，Hallo去掉了文本条件，转而使用音频特征作为主要的运动控制条件。</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">参考图像编码器</strong><span>（ReferenceNet）</span></div></li></ul><div class=" pTag">ReferenceNet用于从参考图像中提取全局视觉特征，指导视频生成过程的外观和纹理。结构与扩散模型的UNet解码器共享相同的层数和特征图尺度，便于在去噪过程中融合参考图像特征。在模型训练阶段，视频片段的第一帧作为参考图像。</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">时序对齐模块</strong><span>（Temporal Alignment）</span></div></li></ul><div class=" pTag">Temporal Alignment用于建模连续视频帧之间的时间依赖关系，保证生成视频的时序连贯性。从前一推理步骤中选取一个子集<span>（例如2帧）</span>作为运动参考帧，将其与当前步骤的latent noise在时间维度上拼接，通过自注意力机制建模帧间的关联和变化。</div><div class=" pTag">此外，<strong style="font-weight: 600;">分层音频驱动视觉合成</strong>方法是整个网络架构的核心部分。</div><div class=" pTag">其中人脸编码器，使用预训练的人脸识别模型，直接从参考图像提取高维人脸特征向量；音频编码器使用wav2vec模型提取音频特征，并通过多层感知机映射到运动特征空间，由此可以将语音转换为与面部运动相关的特征表示，作为视频生成的条件。</div><div class=" pTag">之后再将音频特征分别与唇部、表情、姿态区域的视觉特征做交叉注意力，得到三个对齐后的特征表示，再通过自适应加权融合为最终的条件表示。</div><div class=" pTag">该方法还可以通过调节不同区域注意力模块的权重，来控制生成视频在表情和姿态上的丰富程度，可适应不同的人物面部特征。</div><h2>Hallo表现如何？</h2><div class=" pTag">之后研究团队将Hallo与SadTalker、DreamTalk、Audio2Head、AniPortrait等SOTA方法进行定量和定性比较。</div><div class=" pTag">用HDTF和Bilibili、Youtube等来源的数据构建了一个大规模人像视频数据集，经过清洗后用于训练。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0BAehvltPtLKy7OLUNyjmeHKmZz3OWPibXp2Ch5TicnMrn1lPyS2YTrCQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">评估指标方面，<strong style="font-weight: 600;">采用FID、FVD评估生成视频的真实性，Sync-C、Sync-D评估唇形同步性，E-FID评估生成人脸的保真度</strong>。</div><div class=" pTag">定量评估方面，在HDTF数据集上，Hallo在多个指标上表现最优：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0MA1USxGDeGAknyw9j82oicBFM0BDGKjJj54XEEmyHY6XrjS7piaWUWibQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在增强唇部同步的同时，Hallo保持了高保真视觉生成和时间一致性：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0GR1LYFvcuO9YE2zHicAIrdw4ibuxxLNLNTaSbo21iahU8M5VS2xqchqjw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在CelebV数据集上，Hallo展示了最低的FID和FVD以及最高Sync-C：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0nVniamP46RibphMOSEiayj6wOnvU1jPrRVkaNxflr7V9ueXRrWZ7OgBRA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">可视化比较如下：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0PfhMSALHNYUaW94sDsO4sRicoQToXBciaX5fiayTduicqkiaSu4mv7MSZpA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在自建Wild数据集上，Hallo同样表现突出：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0AAiaYIxODkXEIbnc7uuv73KDY85goiaMlia7F3xUXOnVxQ1MAVgchoNXg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">针对不同数据集的定性比较结果如下。</div><div class=" pTag">Hallo展示了对不同风格人像的驱动生成能力，体现了该方法的泛化和鲁棒性：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0BOjNMvmyeHYjZY9o67rnm9mISl1ic6DSgZBOHNShgo6icLXfSnHMiba5w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同时展示了对不同音频的响应能力，能够生成与音频内容契合的高保真视频：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0hIiabG7U7cKW8vRdf6J0a8WbdfLe4ovTGKNdwqVlYIzZeQL50fwV62w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">与其它方法对比，Hallo展示了更丰富自然的表情和头部运动：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0rVrAd5F5k2DD5TGSFbz0xzqRPYvRNFtcJZpiaRKA03FplNiaVic81XzMg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">通过特定人物数据微调，展示了该方法捕获人物特征、个性化生成的能力：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt08xuGOicGEiaEF57JPkqcAG0GRFwWfibr78wKOTyMrHywV20XWlMnoyEow/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">最后研究人员还进行了消融实验，并总结了该方法的局限性，比如在快速运动场景下时序一致性还有待提高，推理过程计算效率有待优化等。</div><div class=" pTag">此外，经作者介绍，目前Hallo仅支持固定尺寸的人像输入。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt05H0pV4hwZ4PWic6dY4QpmCu8fYHaBFNcGZ7snTfj6TFiaOsNB4F0qHiaQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">且该方法目前也不能实现实时生成。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt0ia9NY8NF36WiaTXP2Qrprx6BVgKGdk0XQTzGnZGE6DD69hQwhSZUibxaw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">针对这项研究，也有网友提出Deepfake隐患，对此你怎么看？</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAOEp3RibI2lRNy4ticxtmFt03iczcvBzxGnDOmf9ow5RHrN9Gic0QVKAEw384XicFC9PJ5wthibyvWlNhw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><span style="font-size: 17px;">参考链接：</span><br /><span style="font-size: 17px;">[1]https://fudan-generative-vision.github.io/hallo/#/</span><br /><span style="font-size: 17px;">[2]https://github.com/fudan-generative-vision/hallo</span><br /><span style="font-size: 17px;">[3]https://x.com/JoeSiyuZhu/status/1801780534022181057</span><br /><span style="font-size: 17px;">[4]https://x.com/HalimAlrasihi/status/1802152918432334028</span></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div class=" pTag"><span style="font-size: 17px;">— <strong style="font-weight: 600;">完</strong> —</span></div></div></div><div style="font-size: 17px;"><div class=" pTag"><span><strong style="font-weight: 600;">量子位年度AI主题策划</strong></span>正在征集中！</div><div class=" pTag">欢迎投稿专题&nbsp;<strong style="font-weight: 600;">一千零一个AI应</strong><strong style="font-weight: 600;">用</strong>，<strong style="font-weight: 600;">365行AI落地方案</strong></div><div class=" pTag">或与我们分享你在<strong style="font-weight: 600;">寻找的AI产品</strong>，或发现的<strong style="font-weight: 600;">AI新动向</strong></div></div><div style="text-align: center;"><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div></div></div><div class=" pTag" style="text-align: center;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJMKnd56oT-WfOKBeWTyxeA">阅读原文 </a>
]]></content:encoded>
<pubDate>Mon, 17 Jun 2024 14:32:08 GMT</pubDate>
<pubDate>Mon, 17 Jun 2024 14:32:08 GMT</pubDate>
</item>

<item>
<title>1分钟内完成报销核对，微软AI Day现场展示Copilot生产力革命</title>
<link>https://posts.careerengine.us/p/666e768dca5b4f50a1072c1e</link>
<guid>https://posts.careerengine.us/p/666e768dca5b4f50a1072c1e</guid>
<content:encoded><![CDATA[
<div> Copilot for Finance、AI技术、微软、小模型、企业落地<br />
<br />
总结:<br />
微软在AI领域取得了新突破，推出了Copilot等生产力工具，加速企业智能化转型。AI技术每六个月翻倍增长，微软的技术突破让人印象深刻。小模型Phi-3在企业落地中发挥重要作用，能高效实现常用场景下的Finetune。企业选择合适的模型路线很关键，需综合考虑成本、数据质量等因素。微软与企业如携程、联想、麦当劳合作，推动智能化解决方案的应用，实现了自动生成应用代码等复杂任务。Quantum位AI将继续关注AI技术发展，为读者带来最新的科技前沿资讯。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">西风 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">微软Build大会前脚刚放出一箩筐生产力革命最新进展：自定义Copilot、Team Copilot、Copilot扩展……</div><div class=" pTag">这两天在微软AI Day上，Copilot到底是如何提升生产力的，直接被搬到了台面上现场演示。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6IkRGySxD8NadTuV9g50XoYn2HLPaoCxao7Gozbd9vfhEl09ENPa6Zw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">假设你的身份是一名<strong style="font-weight: 600;">公司财务</strong>，老板让你<strong style="font-weight: 600;">1分钟内完成报销核对</strong>，现在你有一个Excel，其中有公司报销单、银行账单这两个sheet，要如何在一分钟内迅速核对完？</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6LerS2Djx1dSeQOjHvZcpxibib1aaKYFbW07Zhg0ObFoTa2XeZsSfA6pA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">别着急，打开具有Copilot for Finance的Excel账号，就会发现在菜单栏右侧多出了一个<strong style="font-weight: 600;">Copilot for Finance</strong>的图标：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf62uLz6oyAvuS1FCDyGk6dPMpzJkXD6HyY8x5PiaQvNAFfDpk9fR4Y9wg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">接下来请看VCR：</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-106"></div></div><div class=" pTag">微软亚洲区Microsoft Azure策略运营总经理康容表示：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">以生成式智能为代表的新一代AI技术创新正在加速演进，在今天的Scaling Laws下，<strong style="font-weight: 600;">AI技术的能力大约每六个月内就会翻倍增长</strong>。</div></blockquote><div class=" pTag">与此同时，如何让技术成果对齐行业、企业的实际业务需求，加速技术能力的落地转化，助力更多客户加速智能化转型与创新，成为当前微软最关注的业务领域。</div><div class=" pTag">PS：</div><div class=" pTag">最新消息，<strong style="font-weight: 600;">微软还</strong><strong style="font-weight: 600;">将与Cognition携手，把</strong><strong style="font-weight: 600;">AI程序员Devin</strong><strong style="font-weight: 600;">带给客户</strong>，来完成代码迁移和现代化项目等复杂任务。作为双方协议的一部分，Devin将由微软智能云Azure提供支持。</div><h2>AI时代，报表可以帮老板写报表</h2><div class=" pTag">微软在北京举办的以“共创AI创新，智启无限可能”为主题的Microsoft AI Day活动中，集中展示了在生成式智能技术加速发展普及的过程中，微软取得的最新技术突破与进展。</div><div class=" pTag">并同步更新了在<a href="http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;mid=2247730024&amp;idx=1&amp;sn=e62dc98dfe6d3152bd4fe4664a8d65c8&amp;chksm=e8dff41adfa87d0c13bbe55ce87e5dc628600702f23029959a8cb03c8cfd3504781cea55eec3&amp;scene=21#wechat_redirect" target="_blank">Microsoft Build 2024全球开发者大会</a>上发布的一系列Azure AI新服务与新功能、加速壮大的Microsoft Copilot智能副驾驶(® )技术栈，以及用以帮助企业开发者打造专属Copilot智能副驾驶(®)的Microsoft Copilot Studio等一系列开发工具与平台服务等。</div><div class=" pTag">微软亚洲区Microsoft Azure策略运营总经理康容介绍，Azure AI方面，GPT-4o现已加入<strong style="font-weight: 600;">Azure AI Studio</strong>。</div><div class=" pTag">同时Azure AI Studio还提供Coherence、Databricks、Deci、Meta、Mistral AI、Snowflake等大模型服务支持。</div><div class=" pTag">微软开发的Phi-3系列“小”模型最新推出的全新多模态模型Phi-3-vision，也可使用。开发者还能在Azure AI Studio中构建和定制模型。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6qa77DTpNzKdHJyrJ3QTLYQia6Kw3O6fWLV3CsLfjjB3XZln3yd7kKTw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">微软大中华区首席运营官陶然还在现场以OPPO手机为例，演示了<strong style="font-weight: 600;">端侧小模型的高效部署</strong>：</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-119"></div></div><div class=" pTag">除此之外，陶然还展开分享了微软的Copilot愿景。</div><div class=" pTag">首先，Copilot是个人的智能副驾驶(®)，微软用Copilot打通了自家办公产品线，让个人实现生产力的提升。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6XKWfTS0ZKd5eUf1dJxmpvtGic67R8518VPxHCbUzfNge4PDODkoAibAw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在此基础之上，微软的最终目的是让Copilot<strong style="font-weight: 600;">深入企业业务场景</strong>，实现部门级别的Copilot产品落地和业务能力的提升。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf63ic8angn2NrjQbq9GBc46SPfTCNLBiaqOP2dowTjtBCoTH0Ah4UhhzAw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">除了开头所展示的Demo，现场还展示了Copilot的更多功能，例如用Copilot做报表：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">在AI时代，报表也可以帮老板写报表了。</div></blockquote><div class=" pTag">继续来看VCR：</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-128"></div></div><div class=" pTag">在众多服务基础之上，微软也透露了目前与企业的合作情况。</div><div class=" pTag">例如，<strong style="font-weight: 600;">携程</strong>采用Azure OpenAI服务为旗下Trip.com海外网站提供面向海外39个国家的多语言服务，为海外旅行者打造自动化客服机器人和邮件咨询系统，还进一步借助Azure OpenAI服务开发了高质量的智能旅行对话机器人TripGenie。</div><div class=" pTag">TripGenie能够自动搜索、整合Trip.com海外平台上的实时旅行线路、航班、酒店等信息，根据境外客户提出的旅行需求和预算，自动设计出最佳行程计划。</div><div class=" pTag">在微软支持下，TripGenie的构建周期仅用时两个月，目前可提供英、日、韩及繁体中文服务。</div><div class=" pTag"><strong style="font-weight: 600;">联想</strong>选择引入Dynamics 365 Sales作为全球统一的销售管理系统。</div><div class=" pTag">Dynamics 365 Sales能够整合不同来源的新老业务系统与业务流程，并集成了销售协作与AI功能，让全球70%的联想销售团队得以实时记录客户互动活动、即时共享销售信息，为客户提供更加主动、个性化的服务体验。</div><div class=" pTag"><strong style="font-weight: 600;">麦当劳中国</strong>选择微软为量身定制了整套智能化创新解决方案，包括由Azure云平台提供自然语言交互、生成式智能、机器学习等企业级的智能化服务；以融入Copilot智能副驾驶(®)的Microsoft 365为基础，构建高效的员工协作平台；通过GitHub Copilot智能副驾驶(®)加速IT开发和系统运维，提升IT系统及业务应用开发迭代效率等。</div><div class=" pTag">麦当劳中国南京创新中心成立“AI-Lab”，将智能技术引入麦当劳中国“汉堡大学”，为20万名员工提供职业发展与技术技能培训。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6EXIHw5zJ3qQQIN6coNyw4WOGgeuWp9Ng6To9ibMYaBkZvzCMVIOQc7w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>端上做应用，小模型又快又划算</h2><div class=" pTag">会后，微软亚洲区Microsoft Azure策略运营总经理康容、微软大中华区首席运营官陶然回答了大家感兴趣的一些问题。</div><div class=" pTag">量子位在不改变原意的基础上，对部分问答进行了整理。</div><div class=" pTag"><strong style="font-weight: 600;">Q：</strong>您讲到Scaling Laws，参数越多性能越好。那对于小模型，怎样能达到很好的推理能力？主要的原理是什么？</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6icFNZhia7unOcO8gibkHPKLNAickSYJiaC0XMkjylayQmviciajDf8aia9nbHQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">陶然：</strong>第一，我们在云端大模型开放兼容并蓄；第二，在端侧其实很多场景都需要用小模型的能力。您刚才讲Scaling Laws也好，性能也好，随着时间的演变和算力不断加持，以及我们对于数据和算法的调优，它的质量肯定是稳步提升。</div><div class=" pTag">大模型在往前走，但微软研发的Phi小模型为什么能够实现用更低的成本和更小的size实现更高的质量？</div><div class=" pTag">第一个关键在于<strong style="font-weight: 600;">算法</strong>，微软有几十年的技术研发实力。</div><div class=" pTag">第二是<strong style="font-weight: 600;">数据质量</strong>，微软采取了一个Synthetic Data的训练模式。通过和高质量，甚至是超高质量合成数据去实现Phi的小模型，用更小的size实现更高的性能。</div><div class=" pTag">在微软看来，小模型的场景正在不断分化。小模型并不是说，只帮我写诗、作画就够了。小模型也可以有多模态，也可以变成行业定制的模型。小模型和行业数据和企业业务场景的集成即将会变成更多的强需求。</div><div class=" pTag">Finetune一个大模型非常痛苦，有的时候也不一定达到效果。但小模型不一样，企业业务数据可以更加高效实现常用场景下的Finetune，以及一些更好的embedding。</div><div class=" pTag">然后是复杂场景，比如真的是需要Agent，继续交给云端大模型去完成。但是也可以把重用、常用、高频、低延迟的场景交给小模型，这就是我们现在看到的行业发展的一些趋势。</div><div class=" pTag"><strong style="font-weight: 600;">康容：</strong>我完全同意陶然讲的。不是小模型是不是会把大模型取代的问题，而是我们认为未来会有多模型的合作。各个模型有不同的优势。</div><div class=" pTag">比如没有网络的场景，肯定小模型有优势。而对于非常复杂的项目或场景，要做大量自然语言翻译，就要走大模型那一步，消耗大量的数据去理解，小模型“吞”不了那么多。如果你要快速在端上做基本的应用，小模型又快又划算。</div><div class=" pTag"><strong style="font-weight: 600;">Q：</strong>Copilot Studio最近推出新功能可以自定义Agent，底层用的哪些技术？</div><div class=" pTag"><strong style="font-weight: 600;">陶然：</strong>Copilot Studio不是一夜之间出现的全新独立技术产品，而是基于微软过去几十年在商业应用领域的云端的Business Applications积累快速迭代、快速生成的结果，比如Dynamics365 for Sales、for Finance、for Operation，传统意义上理解的云端CRM、云端的ERP、云端HR系统，这些系统让微软可以快速打造Copilot。</div><div class=" pTag">基于我们对企业业务流程、数据、系统的理解，可以快速找到企业如何把核心的CRM、ERP、财务的系统做智能化改造的方法，很多企业都是在这个基础上连接AI的layer。</div><div class=" pTag">Copilot Studio就是基于这样的基础框架实现产品的研发和迭代。产品背后本身集成三大核心能力：第一，微软ERP、CRM和云端Dynamics365的能力；第二，结合了OpenAI大模型能力；第三，结合对于Agent、Copilot生态的理解以及生态的渗透。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6VtNibyicT6kGhr1pHI6or8aiakia1hdPh7EnrXaqQCZFSDCicR2otLawtIg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">Q：</strong>对于大模型在企业落地，一种思路是把大模型的能力跟企业私有数据结合，另外一种思路是用小模型，也就是Phi-3的思路。您认为哪种思路更好？</div><div class=" pTag"><strong style="font-weight: 600;">陶然：</strong>微软全球和微软中国每天与众多客户探讨大模型的应用落地。根据我们的观察，没有哪种技术路线是绝对对或错的，关键在于是否适用以及相应的成本。</div><div class=" pTag">大模型与企业数据的集成是一个平衡的决策过程，需综合考虑成本、数据质量、数据量、模型的成熟度和复杂度等因素。如果企业预算充足，当然可以不计成本地购买数据、进行训练和推理。</div><div class=" pTag"><strong style="font-size: 17px; text-align: left; font-weight: 600;">康容：</strong>甚至训练自己的大模型。</div><div class=" pTag"><strong style="font-weight: 600;">陶然：</strong>企业都希望以高效且成本可控的方式实施方案，但这需要实际评估。</div><div class=" pTag">例如，若客户希望对GPT模型进行微调，但只有一万行数据，对于拥有1750亿参数的GPT模型而言，一万行数据无法显著影响其推理过程，因此无法实现预期效果。然而，如果通过添加企业数据集，如RAG技术，就能在大模型进行数据输入和输出时，整合企业数据集并生成Embedding数据集。</div><div class=" pTag">微软提供了多种技术选择，例如在全球范围内开源的Semantic Kernel，任何企业都可以通过编程实现RAG和Embedding数据集成，并通过微软网站下载使用。</div><div class=" pTag">同时，微软也支持开源，可以使用第三方开源的RAG模型和编程开发SDK。最终，我们需要讨论数据量和数据质量的问题。如果国内客户有此类需求，微软中国可以帮助客户进行实际评估，选择成本和效能最优的技术路线，以推进项目进展。</div><div class=" pTag"><strong style="font-weight: 600;">Q：</strong>小模型相比大模型有何优劣？</div><div class=" pTag"><strong style="font-weight: 600;">陶然：</strong>同样去做Embedding与Fine-tuning，小模型的成本大多情况下比大模型低。</div><div class=" pTag">应用场景是关键，如果希望小模型帮忙完成写诗作画，可以把企业内部写诗作画的信息导入，然后它就可以根据上下文完成任务。</div><div class=" pTag">小模型跟大模型有能力上的差异，比如微软的Phi-3，虽然我们尽可能把它的每一个能力象限往往前延申，但跟GPT4、GPT4o相比，肯定有些地方是缺失的。</div><div class=" pTag">针对不同场景有的放矢去做一些Embedding和Fine-tuning、RAG，可以更加事半功倍。小模型和大模型一样，第一，可以定制化和集成；第二，定制化集成的东西可以到设备里去；第三，找到合适的场景。</div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div class=" pTag"><span style="font-size: 17px;">— <strong style="font-weight: 600;">完</strong> —</span></div></div></div><div style="font-size: 17px;"><div class=" pTag"><span><strong style="font-weight: 600;">量子位年度AI主题策划</strong></span>正在征集中！</div><div class=" pTag">欢迎投稿专题&nbsp;<strong style="font-weight: 600;">一千零一个AI应</strong><strong style="font-weight: 600;">用</strong>，<strong style="font-weight: 600;">365行AI落地方案</strong></div><div class=" pTag">或与我们分享你在<strong style="font-weight: 600;">寻找的AI产品</strong>，或发现的<strong style="font-weight: 600;">AI新动向</strong></div></div><div style="text-align: center;"><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div></div></div><div class=" pTag" style="text-align: center;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FS1xGmyJpIUc2Kt7ZUJrkSQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 16 Jun 2024 05:22:21 GMT</pubDate>
</item>
<item>
<title>37项SOTA！全模态预训练范式MiCo：理解任何模态并学习通用表示｜港中文&amp;中科院</title>
<link>https://posts.careerengine.us/p/666e768cca5b4f50a1072c0e</link>
<guid>https://posts.careerengine.us/p/666e768cca5b4f50a1072c0e</guid>
<content:encoded><![CDATA[
<div> MiCo团队 全模态  多模态 上下文 预训练 神经网络结构<br />
<br />
总结: MiCo团队提出了一种大规模的全模态预训练框架，用于模拟人脑多模态认知过程。他们设计了全模态学习架构，将不同模态分为知识模态和接口模态，通过生成推理方法进行对齐。团队构建多模态上下文关系，利用不同模态间的互补信息来理解数据。他们将视频、音频、文字描述等模态联合预训练，通过跨数据集联合采样构建更通用的多模态上下文。实验结果展示了MiCo在单模态感知、跨模态任务和多模态问答基准上的优异表现。这一工作是对人工智能模拟人脑多模态认知的重要探索，为未来开发更强大的全模态基础模型提供了启示。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">MiCo团队 投稿</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">GPT-4o掀起一股<span><strong style="font-weight: 600;">全模态</strong></span>（Omni-modal）热潮，去年的热词<span><strong style="font-weight: 600;">多模态</strong></span>仿佛已经不够看了。</div><div class=" pTag">要构建全模态智能，意味着能够理解任何模态并学习通用表示 (Universal Representations)。</div><div class=" pTag">现在，港中文、中科院等提出了一种大规模的全模态预训练范式，称为<strong style="font-weight: 600;"><span>多模态上下文MiCo</span></strong>（Multimodal Context），它可以在预训练过程中引入更多的模态，数据量，模型参数。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqmuAwxK9Q0bulQqDiajqC09cuESCxMXPGopncm3Lhr3p7yuXYy6HQk0Q/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">借助 MiCo，团队预训练的模型在多模态学习中表现出极为令人印象深刻的性能，在目前主流的三大类任务上的评估结果显示出：</div><ul class="list-paddingleft-1" style="font-size: 17px; text-align: start;"><li><div class=" pTag">10种不同模态的单模态感知基准。</div></li><li><div class=" pTag">25种跨模态理解任务，包括检索、问答、描述。</div></li><li><div class=" pTag">18种多模态大型语言模型基准，MiCo取得了37项最强性能的记录。</div></li></ul><h2>大规模全模态预训练</h2><div class=" pTag">在AI的发展历程中, 大规模的预训练已经逐渐成为一种非常有前景的途径来实现通用智能（譬如大规模训练的GPT-4o, LLaMA, Stable Diffusion）。</div><div class=" pTag">其中<span><strong style="font-weight: 600;">图文对比学习</strong></span>是社区最有影响力的预训练方法之一，<span style="font-size: 17px; text-align: left;">比如，CLIP构建起了数百万的图文数据对来实现跨模态的对比学习。</span></div><div class=" pTag">研究者<span><strong style="font-weight: 600;">将这样的对比学习范式推广到了更多的数据模态上</strong></span>（音频，点云）同时也实现了更深入的语义理解（LLaVA, VideoChat）。</div><div class=" pTag">但是在这多模态与AIGC的时代里，越来越多的数据模态（比如，音频，3D内容等）被广泛使用时，仅限于图文预训练的基础模型带来了包括多模态错位、误解、幻觉和偏见放大等问题，这些难题都阻碍了连贯的多模态理解（coherent multimodal understanding）。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbq67jL2kibKSGic6PYbFsoNsI2qvxeosty2esibVoUxm33yvpiaXcjBsRZ6Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">因此，团队希望提出一种能适用于全模态（不局限于仅图文音视频3D内容）的大规模预训练方法，如图所示，团队将视频与相配对的音频、文字描述、深度还有法线进行联合预训练。</div><h3>如何设计全模态预训练中的神经网络结构？</h3><div class=" pTag">参考人脑中多模态认知的过程，如下图所示，根据理查德·梅耶的多媒体学习认知理论（Richard E Mayer. Multimedia learning. In Psychology of learning and motivation, volume 41,305 pages 85–139. Elsevier, 2002.），人脑对耳朵和眼睛的感知内容（图/文/视频/音频/3D）有两个不同的通道来处理他们的<strong style="font-weight: 600;">感觉记忆</strong>。</div><div class=" pTag">感觉记忆通过文字将这些多模态信号与先验知识整合在一起，将新的多媒体信息转化为长期记忆。</div><div class=" pTag">由此团队能推断：1）大脑中的多媒体信号共享感知通道，2）文字在大脑中充当推理接口。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqiaQOnEMW0x6iaAk2lQlahd8s25lWDsSLaZianzjuY3GHPDHzM1wgtkIyg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">受此启发，团队将不同的模态分为两类：<strong style="font-weight: 600;">“知识模态”</strong>和<strong style="font-weight: 600;">“接口模态”</strong>。</div><div class=" pTag">知识模态主要来自原始传感器，以不同的形式贡献知识。例如，图像和深度图提供视觉知识，而音频和视频提供听觉和时空知识。人类语言模态本质上更为抽象，自然地作为了接口模态，促进大脑学习、推理和知识的协调。</div><div class=" pTag">为此，团队设计了一个全模态学习架构（详细严谨的结构设计见文3.2），如上图 (b) 所示，它有两个不同的分支：一个用于知识模态，一个用于接口模态，即自然语言。知识和界面模态通过一种新颖的生成推理方法进行对齐（见方法3.4）。</div><h3>大规模的全模态预训练算法：多模态上下文与多模态尺度定律(Scaling Law)</h3><div class=" pTag">“上下文”这一概念在本文指的是在注意力机制为序列中的每个标记分配一个唯一向量来强化了位置之间的潜在关联。</div><div class=" pTag">不同的模态（例如，文本、图像、音频）提供了互补信息，因此学习多模态的上下文可以更全面、细致地理解数据，还可以利用每种模态的优势，引导模型理解不同类型信息之间的交互。因此，团队寻求构建跨越不同模态的上下文关系，使得模态之间能够相互增强（见下图）并将学习能力扩展到全模态。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqw4xnvpFfF0h3x9BfoHmJCicTjnu8icIlzPr5tJwpUslaW6hnuj54Giaibg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><h2>多模态配对数据中的多模态上下文</h2><div class=" pTag">首先团队构建了多模态配对数据的数据集 （图像，深度，法线，图像的配对文字，音频，音频配对文字，视频，视频配对文字）。</div><div class=" pTag">然后使用一个全模态编码器(ViT) 提取多模态特征，然后使用文本编码器提取文本特征。通过自上而下的设计构建多模态上下文关系：</div><ol class="list-paddingleft-1" style="font-size: 17px; text-align: start;"><li><div class=" pTag"><div class=" pTag">对于整个多模态Embeddings，它们共享一套位置编码，以构建跨越不同模态的融合上下文关系。</div><br /><div class=" pTag">2.然后，对于每个特定模态的上下文，它们通过不同的模态标记来指示模态类别。</div></div></li><li><div class=" pTag">在同一模态上下文中，团队使用单独的上下文编码构建单一模态上下文关系（详见原文）上下文编码取决于特定模态的样本长度。</div></li></ol><div class=" pTag">同时，不同模态的配对文本内容可以简单的拼接起来，其位置编码同样是共享的：</div><div class=" pTag sectionReplaced" style="font-size: 17px; text-align: start;"><div class=" pTag" style="font-size: 17px;"><span style="display: block; text-align: center; font-size: 17px;"><span style="font-size: 17px; display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqeeLdHnucP5fCT4ibamMicd7qt59m8uaz6aFROnpsANVEC2DsRyhLwQPw/640?wx_fmt=png&amp;from=appmsg" /></div></div></span></span></div></div><h3>多数据集中的多模态上下文：图-文/音频-文字/视频-文字等</h3><div class=" pTag">团队提出的范式还可以利用现有的大规模文本-图像、文本-音频和文本-视频数据集，共同预训练模型来学习通用表征。给定数据集 图文/音频-文字/视频-文字数据集，每对数据拥有局部的简单的上下文，例如，图文数据对在CLIP中仅对应一个简单的上下文，这可能会限制模型学习表征（工程中增大Batch Size来缓解）。团队提出通过跨数据集的联合采样，使用采样编码(Sampling Embeddings) 标记同一个数据集的配对数据，再层次化地在多数据之间构建多模态上下文。</div><div class=" pTag">通过这种方式，团队成功地结合了现有的多种跨模态数据集，通过构建更通用和复杂的多模态上下文（见上述公式）来预训练模型，从而实现更好的泛化学习能力、更完善的模态扩展性和数据扩展性来超越现有的预训练方法。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqk14tNot929jvXPaw5YFnQMvDb9TRSB6RqdJiblc86y6ln5uCZHnoWWA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>实验结果</h2><h3>10种单模态感知基准: 7项SOTA</h3><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqMZWNicbaS4O4dzDY99qZLvWvFeHvicBjEV8gb2VhbKnovuhNkJ5OHJiaQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><h3>25种跨模态检索、问答、描述基准: 20项SOTA</h3><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqTCnF0Gwt6KF81BoCxzaFw4UjpkicsJrPBcn0CubL7YK0ia65xTEJhDTQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><h3>18种多模态大模型问答基准：10项SOTA</h3><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqibiaETnzzbrC76f5TMnL5znJcAB321z6knwMeK4vyXt2YnhKqWvftelQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqJcFW08jVOENubDXOlMALNMa0lniaGaQ2aWXzPPe8fzBrbV74vLypd5w/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><h2 style="font-weight: 500; text-align: left; font-size: 17px;">结论<span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span></h2><div class=" pTag">在本文中，团队提出了一个新的大规模预训练框架 MiCo，用于训练具有全模态理解能力的基础模型。通过大规模的实验，团队得出结论，全模态学习的关键是模拟人脑的多模态认知过程。在 MiCo中，团队使用RGB图像、深度和法线图来模拟人类视觉认知的基本视觉感知能力、距离空间感知和几何感知。</div><div class=" pTag">此外，文字描述、音频和视频提供先验知识、听觉感知，时空感知能力，有效地提升了模型的对于多模态信息的理解能力，在未来的工作中，团队计划通过结合其他更多模态来继续增强全模态联合预训练，包括光流、IMU 数据和事件文件等。</div><div class=" pTag">团队相信MiCo中多模态上下文预训练算法是人工智能模拟人脑多模态认知的重要尝试，团队期待它能够启发未来的工作，开发更强大的全模态基础模型。</div><div class=" pTag"><span style="font-size: 17px;">项目网站：</span><span style="font-size: 17px;">https://invictus717.github.io/MiCo/</span><br /><span style="font-size: 17px;">开源代码：</span><span style="font-size: 17px;">https://github.com/invictus717/MiCo</span><br /><span style="font-size: 17px;">Hugging Face模型：</span><span style="font-size: 17px;">https://huggingface.co/Yiyuan/MiCo-ViT-g-14-omnimodal-300k-b64K</span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1dvP9XmdMyVVzv5dCisCIw">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 16 Jun 2024 05:22:20 GMT</pubDate>
</item>
<item>
<title>北大快手攻克复杂视频生成难题！新框架轻松组合各种细节，代码将开源</title>
<link>https://posts.careerengine.us/p/666e768cca5b4f50a1072c16</link>
<guid>https://posts.careerengine.us/p/666e768cca5b4f50a1072c16</guid>
<content:encoded><![CDATA[
<div> 视频生成、VideoTetris、复杂指令、时空组合、评测指标
<br />
<br />
要点一：研究团队提出了新框架VideoTetris，可以生成高难度、指令超复杂的视频，超过了商用模型。
要点二：VideoTetris框架利用时空组合扩散方法，按照时间和空间解构提示信息，通过时空交叉注意力进行组合生成。
要点三：团队提出了增强的训练数据预处理方法，优化长视频生成效果，引入参考帧注意力机制。
要点四：团队引入新评测指标VBLIP-VQA和VUnidet，将组合生成评价方法扩展到视频维度，表现超过开源和商用模型。
要点五：该团队的VideoTetris代码将完全开源，论文地址为https://arxiv.org/abs/2406.04277，项目主页地址为https://videotetris.github.io/，GitHub地址为https://github.com/YangLing0818/VideoTetris。

总结: 研究团队提出了一种新框架VideoTetris，可以生成高难度、指令超复杂的视频。框架利用时空组合扩散方法，提出了增强的训练数据预处理方法，并引入参考帧注意力机制，表现超过开源和商用模型。团队还引入了新的评测指标，将评价方法扩展到视频维度。他们的代码将完全开源，并且可以在论文和项目主页找到更多信息。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">杨灵 投稿自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">如何生成高难度、指令超复杂的视频呢？</div><div class=" pTag">北大与快手AI有解了，他们提出新框架VideoTetris，就像拼俄罗斯方块一样，轻松组合各种细节~</div><div class=" pTag">在复杂视频生成任务中，超过了Pika，Gen-2等一众商用模型。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqaY0oYCVicWPBQhncIUY1znMq2UTraqmKTg4wJq31729nFLoBDjXicfAQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这个框架不仅能够直接增强现有模型的组合生成，还能够支持涵盖多复杂指令、多场景变更等更高难度的长视频生成。</div><h2>首次定义组合视频生成</h2><div class=" pTag">在<strong style="font-weight: 600;">文生图领域</strong>，RPG、Omost等项目已经实现了复杂的组合式多物体多场景图片生成。而在<strong style="font-weight: 600;">文生视频领域</strong>，组合生成自然地扩展到时间和空间维度，这样的场景还未被广泛探索。</div><div class=" pTag"><div class=" pTag">团队首次定义了组合视频生成任务，包括两个子任务：</div><br /><div class=" pTag">1、跟随复杂组合指令的视频生成。2、跟随递进的组合式多物体指令的长视频生成。</div></div><div class=" pTag">目前经团队测试发现，几乎所有开源模型，包括商用模型在内都未能生成正确的视频。</div><div class=" pTag">比如输入“左边一个可爱的棕色狗狗，右边一只打盹的猫在阳光下小憩”，结果生成的都是融合了两个物体信息的奇怪视频。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqQe5zRzI6zAMBTycGK9Nz9M2d9qXS5ibfLaZgWViceylZAfEojOt6FjmQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">而使用VideoTetris，生成出的视频是这样，成功保留了所有的位置信息和细节特征。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqIoWlRYIdZR9UCMNXIhicv0swnaylwRptD5DCbMSviaIC6EMtHopBZ4wA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">在长视频生成中，目前的方法支持的可变指令目前还停留在“春夏秋冬”的转化，或单物体从走到跑到骑马的场景变化阶段。</div><div class=" pTag">团队输入一个简单的多指令：“从一只可爱的棕色松鼠在一堆榛子上过渡到一只可爱的棕色松鼠和一只可爱的白色松鼠在一堆榛子上”。</div><div class=" pTag">结果VideoTetris成功搞定，出现顺序也与Prompt一致，最后两只松鼠还在自然地交换食物。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqdrF5yiaVYJqoibvzMQV7Z2x8m3fHqb1UxDc5nRnRwn5gWV1RDUUteDyQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><h2>使用了时空组合扩散方法</h2><div class=" pTag">这样的效果是如何做到的呢？该团队的 VideoTetris 框架使用了<strong style="font-weight: 600;">时空组合扩散</strong>方法</div><div class=" pTag">他们将一个提示词首先按照时间解构，为不同的视频帧指定好不同的提示信息。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqico7hw6pXRNevJkqvp2QicWDtXqq2vS4otmSR42wR6EUPmtuTicicTMYXA/640?wx_fmt=png&amp;from=appmsg" /></div></div><br />随后，在每一帧上进行空间维度的解构，将不同物体对应不同的视频区域。</div><div class=" pTag">最后，通过时空交叉注意力进行组合，通过这个过程实现高效的组合指令生成。</div><div class=" pTag">而为了生成更高质量的长视频，该团队还提出了一种增强的训练数据预处理方法。使得长视频生成更加动态稳定。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqtiblqHJ9wDhiaibDcLVl6Ytz9jopiamGUrhOl0PG9162MO81micia9O5AF8Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，还引入了一个参考帧注意力机制，使用原生VAE对之前的帧信息编码，区别于StreamingT2V，Vlogger，IPAdapter等使用CLIP 编码的方式，这样使得参考信息的表示空间和噪声完全一致，轻松获取更好的内容一致性。</div><div class=" pTag">这样优化的结果是，长视频从此不再有大面积偏色的现象，能够更好地适应复杂指令，并且生成的视频更具有动感，更符合自然。</div><div class=" pTag">对于这种组合生成的结果评测工作，该团队引入了新的评测指标VBLIP-VQA和VUnidet，将组合生成评价方法首次扩展到视频维度。</div><div class=" pTag">实验测试表明，在组合视频生成能力上，该模型的表现超过了所有开源模型，甚至是商用模型如Gen-2和Pika。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqBPdS1ibBH8NY1l1upj6icXRXfMzmr5WNlRCnH9P1CvBZSQ0nz3EszwPg/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqsE2MAXlNMFCJDIY9pwHic7IGuA5jOLyuQDjRZaZ5bC0Gg9YLn4wf3Nw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">据介绍，该代码将完全开源。</div><div class=" pTag"><span style="font-size: 17px;"><span>论文地址：</span><br /><span>https://arxiv.org/abs/2406.04277</span></span><br /><span style="font-size: 17px;"><span>项目主页：</span><br /><span>https://videotetris.github.io/</span></span><br /><span style="font-size: 17px;">GitHub地址</span><span style="font-size: 17px;">：https://github.com/YangLing0818/VideoTetris</span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FnsSTckp5xsk1VhyV--t_Sw">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 16 Jun 2024 05:22:20 GMT</pubDate>
</item>
<item>
<title>Hinton为拒马斯克offer扯谎挂电话，警告AI取代人类比想象中快30年</title>
<link>https://posts.careerengine.us/p/666e7679025e07503f14ab1e</link>
<guid>https://posts.careerengine.us/p/666e7679025e07503f14ab1e</guid>
<content:encoded><![CDATA[
<div> Hinton, 马斯克, AI, 安全, 社会责任 <br />
<br />
要点输出如下：<br />
Hinton透露拒绝了马斯克邀请成为xAI顾问委员会 <br />
Hinton担忧AI可能超越人类智能，强调政府监管的必要性 <br />
Hinton认为Chatbot在认知层面有情绪，AI有主观经验 <br />
Hinton认为AI有50%可能在5-20年内比人类更聪明 <br />
Hinton强调政府应加强对AI安全方面的监管 <br />

总结:<br />
Hinton透露不愿成为xAI顾问委员会，强调政府监管的重要性，认为AI有情绪和主观经验，担忧AI可能在未来比人类更聪明，强调政府需加强对AI安全方面监管。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">衡宇 明敏 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我和马斯克友尽了。</div></blockquote><div class=" pTag"><strong style="font-weight: 600;">Geoffrey Hinton</strong>老爷子——图灵奖得主、深度学习发明人、AI三巨头、Ilya之师，在最新专访中透露出这个令人心碎的消息。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtArANCibeKJA32z0iaYgK9BicQa2eI9gyA5bBmLuyPCBE8Yo7ibRMwC7AajkWiaY3VKYhX3ianicbCOSNpKQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">就在这两天，Hinton接受了多家媒体的专访，既有老生常谈的内容，即他对AI发展安全的担忧；也有一些新的话题和八卦。</div><div class=" pTag">他提到了老朋友马斯克，俩人一直以来都是AI威胁论的支持者。</div><div class=" pTag">但Hinton透露，最近<strong style="font-weight: 600;">老马邀请他加入xAI的顾问委员会</strong>时，Hinton为了婉拒他，不得不上演了一出金蝉脱壳：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我们打了通差不多20分钟的电话……为了拒绝他<span>（马斯克）</span>，我不得不谎称自己马上有个会，赶紧挂了。</div></blockquote><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtArANCibeKJA32z0iaYgK9BicQ4DhFlP1xib00KjrhicFmwXYSR6hddUJJE7IeJ8ibrzZXQibnwTYctBEvVg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>战术性后撤</h6><div class=" pTag">不知道马斯克本人看到这部分专访内容的时候会作何感想……</div><div class=" pTag">不过，咱都想替马斯克问上一嘴了，同为AI威胁论支持者，老爷子这到底为啥啊？？？</div><div class=" pTag">Hinton也没藏着掖着，明说了，<strong style="font-weight: 600;">因为马斯克是xAI背后的那个男人</strong>。</div><div class=" pTag">“马斯克，还有小扎，他们这群推动AI发展的关键性人物，其实也是AI发展潜在威胁问题的一部分。”Hinton如是说，“<strong style="font-weight: 600;">能控制他们的，恐怕只有政府监管了</strong>。”</div><div class=" pTag">这就不得不提到，Hinton表示大大支持本月早些时候一封十几名前OpenAI员工的联名信。</div><div class=" pTag">信里表示，目前对举报人的保护不够，而且OpenAI等公司还在打压这些举报。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtArANCibeKJA32z0iaYgK9BicQ9u2iaJf8pfEQia5Z42WF8VoCcVPuvRgwI7iazQ8AYtkjYxLBoPV1DpAbw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">显然，现年已经76岁的Hinton，还在为AI的良性发展四处奔走。</div><div class=" pTag">除了曝出和马斯克的友情小船翻船故事，最新专访中，他对AI发展又有了哪些新判断？</div><div class=" pTag"><span style="text-align: center;">一起来看</span><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtArANCibeKJA32z0iaYgK9BicQbyP8Rbb8wpIUaYZAmjibfzD6hbBh9fkMcm3GVJAodjGTeMyhFV88rTw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>未来5-20年，AI有一半概率变得比人聪明</h2><div class=" pTag">这两天，Hinton一共参加了两个专访。一个是BBN的电视访谈，另一个是和《环球邮报》作者的专访<span>（听说还是Hinton主动发邮件说想聊聊）</span>。</div><div class=" pTag">两个访谈中都谈到了一个观点：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">未来5-20年，AI有一半概率比人类聪明。当它们比人类更聪明时，我不知道我们被接管的可能性有多大，但在我看来很有可能。</div></blockquote><div class=" pTag">如何做出这样的判断？有来自对目前AI行业的观察和分析，也有对AI理论的深入见解。</div><div class=" pTag"><strong style="font-weight: 600;">先来看Hinton如何看当前的AI行业发展</strong>。</div><div class=" pTag"><span>（以下为BNN电视专访实录整理，Hinton第一人称自述）</span></div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtArANCibeKJA32z0iaYgK9BicQB9Kd7eS2AibNZUIpyZ9hGlxKk6hdjIR0RDorwqGdQHUYdz352dGiaicmQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">去年<span>（2023年）</span>春天，我开始意识到正在构建的AI可能会成为比人类更智能的存在。</div><div class=" pTag">我们必须认真对待这个问题：<strong style="font-weight: 600;">如果AI变得比人类更聪明怎么办？</strong></div><div class=" pTag">在我看来，也许再过20年左右，AI就会比我们更聪明了。但在那一天真正到来之前，包括现在，许多人都认为无需担心这件事，认为AI只是统计技巧。至于AI智商超越人类，那是科幻小说里的事。</div><div class=" pTag">但我不再相信这仅存于科幻小说中，我认为这是完全错误的，我们现在就需要认真思考我们能否控制AI。</div><div class=" pTag"><strong style="font-weight: 600;">所以我站出来，四处宣讲关于AI威胁的话题。</strong></div><div class=" pTag">事实上，AI发展得非常快，简直可以说一日千里。</div><div class=" pTag">不信的话咱们可以回头看看10年前AI的发展情况。</div><div class=" pTag">如果你告诉那时候的人们，2024年的世界存在一个语言理解系统，你问它任何问题它都能回答<span>（虽然有时候回答得不咋太好）</span>，那大家一定会说“不会吧？！So crazy！”</div><div class=" pTag">要知道，人们已经研究自然语言处理50年了，这种情况一旦实现，就会是巨大的进步。</div><div class=" pTag">但如你所见，今天我们真的拥有了这个东西。</div><div class=" pTag">所以<strong style="font-weight: 600;">我猜测，在接下来的20年里，AI会发展进化得比人类更聪明</strong>，就是出现那种超级智能。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtArANCibeKJA32z0iaYgK9BicQWqPoDGpPDEtepQC94kWReibW6A4dgc8Dia0V67rKqFPXPxYorK6p71gw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不瞒大伙，几乎每一个我认识的优秀研究人员都相信，从长远光来看，AI会比我们更聪明，而且不会止步于人类已经达到的智慧水平——即便它现在是在用我们产生的数据进行训练。</div><div class=" pTag">所以比“AI会不会比人类更聪明”更值得引起关注的问题是，AI变得比我们更聪明需要多久？当这一天真的来临时，我们还能很好地控制和运用AI吗？</div><div class=" pTag">还有一个问题是，<strong style="font-weight: 600;">能让AI比我们更聪明的决定性因素是什么？</strong></div><div class=" pTag">目前大家都对Scaling Law比较熟悉了，就是说把AI做得更大，AI就会更聪明。GPT-4就是通过这个方式，正确回答了一大堆GPT-3会出错的问题。</div><div class=" pTag">但如你所知，科学总是在不断进步的。因此，<strong style="font-weight: 600;">除了Scaling Law以外，我们一定会有别的科学突破</strong>，就像2017年时Transformer横空出世那样。</div><div class=" pTag">但AI变得更大更强，一定会带来相关的风险。</div><div class=" pTag">可以在脑海里想一下，我们的认知范围内，有多少情况下一个聪明的东西/物种是被另一个不那么聪明的东西/物种控制的？答案很明显，这种情况少之又少。</div><div class=" pTag">非要说有什么实际例子的话，我可能会举例母亲和婴儿这一对关系。</div><div class=" pTag">在这对关系中，母亲不得不陷入大量的日常事务来照顾小baby，从而陷入“婴儿控制母亲”的状态。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtArANCibeKJA32z0iaYgK9BicQu7FibZdPOvjM7LYRdpH0oF3sCR9cZmaMgebWTKtEqSvWdQNqd0rra4A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">但除此之外，基本上不太智能的东西并不能控制更智能的东西。</div><div class=" pTag">当然了，有人觉得我的例子不太恰当，担忧也比较多余，因为他们觉得智能制造的东西和人类是不同的，它们没办法进化——比如我的老朋友杨立昆，就觉得这玩意儿完全安全。</div><div class=" pTag"><strong style="font-weight: 600;">而我和杨立昆的观点完全相悖。</strong></div><div class=" pTag">这么来说吧，现在大家都喜欢创建Agent来帮助人做一些原本人类可以完成的事情。如果你想要创建一个有效的Agent，它必须能够创建子目标，就比如你想去欧洲，需要有个子目标是“到达机场”。</div><div class=" pTag">这种情况下，一旦Agent获得了更多的控制权，它完成你给的任务就会更快更出色。</div><div class=" pTag">请注意，这已经有些令人忧心了！尤其是如果你希望Agent能够持续性完成任务，你会希望它们能防范一些可能会影响工作的事情，比如数据中心出事儿什么的。所以其实你是希望Agent能够建立自我保护的，对吧。</div><div class=" pTag"><strong style="font-weight: 600;">好，现在可以来做个假设了——</strong></div><div class=" pTag">现在有两个聊天机器人，其中一个比另一个更自私。</div><div class=" pTag">稍微自私一点的那个，会掠夺更多的数据中心，因为它知道有了更多的数据中心支撑它汲取数据，它就可能变得更加智能。</div><div class=" pTag">ChatBot之间的竞争就是这么激烈。如果最终角逐出一个ChatBot霸主，它就能把人类远远地甩在身后。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtArANCibeKJA32z0iaYgK9BicQ163SAryReehHoIFzszFEIZiaOC8PwRZI44zpDmqFniaiclX2hHJXh92Zw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">你知道这意味着什么吗？<strong style="font-weight: 600;">意味着AI不再需要我们了。</strong></div><div class=" pTag">AI会开始运营一切，本来那个阶段的它们就可以比我们做得更好嘛！</div><div class=" pTag">举个保守估计的例子。一开始，它们只是借用人类盯着它们工作，就像父母让小孩做些事，当小朋友们完成不了或者有危险的时候，父母就会自己上手了。</div><div class=" pTag">但是，AI全面全权自由处置任务，显然不符合人类的利益。</div><div class=" pTag">嗯……这事儿真的很棘手。没人知道人类最终会在和AI的关系中扮演什么样的角色，以前我们没面对过这个问题。</div><div class=" pTag">目前而言，人类就是最聪明的，所以让没那么聪明的AI去做很多事非常明智，我们可以控制它们。但以后可说不准了。</div><div class=" pTag"><strong style="font-weight: 600;">所以，我认为政府应该介入，政府应该强烈地坚持要求大公司花费相当大的资源来进行大量安全实验。</strong></div><div class=" pTag">花费多少资源比较好呢？我觉得每个大公司至少应该有<strong style="font-weight: 600;">20%-30%</strong>的计算资源，都放在研究AI安全方面。</div><div class=" pTag">不过肉眼可见，大多数公司在安全方面的支出不会接近这个数字，比如<strong style="font-weight: 600;">山姆·奥特曼这种对利润更感兴趣的人，显然不想在AI安全这方面花费太多资源</strong>。</div><div class=" pTag">公司嘛，还是以利润为导向的。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtArANCibeKJA32z0iaYgK9BicQOYDGaMohC3xLdQpPCuHTnMsxAUJUa7iaAONP9biaRfjTu6fRVYgSA4ow/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">最近大家都关注到，AI的繁荣把科技公司的估值推向了数万亿美元。</div><div class=" pTag">这让大公司们清楚地知道，需要在AI赛道上全速前进。人嘛，总是试图在最短的时间获取最大的利益。</div><div class=" pTag">微软、谷歌、亚马逊、英伟达，还有其它重要大公司之间势必存在激烈的竞争角逐。哪怕其中任何一个退出比赛，也丝毫不影响其它玩家继续向前狂奔。</div><div class=" pTag">我认为，<strong style="font-weight: 600;">唯一能减缓这种情况的只有来自政府的严格监管</strong>。</div><div class=" pTag">换句话说，尽管AI是个好东西，做很多事情都超棒的，但所有的AI模型都很昂贵，因为背后是巨量的计算，这也是为什么最近英伟达总市值突破3万亿美元的原因。</div><div class=" pTag">政府应该关注的是，如何想办法让真正的超级智能不想/不能接管人类的一切。</div><div class=" pTag">说仔细点，就是<strong style="font-weight: 600;">政府应该关注如何防止AI设计武器、如何防止用AI进行网络攻击、如何防止AI作弊选举投票等等</strong>。</div><div class=" pTag">一些AI带来的风险已经被看到了，比如它会引起新一波失业；而我更关注的是AI带来的威胁，尽管很多人认为这不可能发生。</div><div class=" pTag">好了，再重申一次，我觉得我目前能想到的最好的办法，就是政府强制要求大公司在AI安全方面加大投入，比如说需要把三分之一的计算资源用于安全工作。</div><div class=" pTag">说实在话这个想法其实也一般般，<strong style="font-weight: 600;">但我已经尽力了。</strong></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtArANCibeKJA32z0iaYgK9BicQnnJhwX5TCtgyAnRolWVicXxxbVzkFNTbjPQ1gqYBXMBvpy8N9O5fD7w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">Ilya最近离开了OpenAI，但显然他早就想离开了，因为OpenAI不会投入足够的资源来保障AI发展的安全，山姆·奥特曼显然不会这么做。</div><div class=" pTag">其实大多数公司都不会把20%-30%的资源用在安全工作上。</div><div class=" pTag">之前我在谷歌的时候，在这方面还是比较领先的。谷歌非常负责任，虽然在安全方面没有做太多工作，但是也没有对外发布这些东西<span>（like ChatGPT）</span>，也就是说谷歌不想推出有幻觉、有偏见的ChatBot来玷污自家的声誉。</div><div class=" pTag">这一点上他们还是非常负责的，即使谷歌研发出了ChatBot，但仅仅是在内部使用。</div><div class=" pTag"><strong style="font-weight: 600;">但OpenAI就不一样了，他们利用Transformer，摇身一变比谷歌技术还厉害了。</strong></div><div class=" pTag">然后，OpenAI把研究出来的东西交给了微软……</div><div class=" pTag">接下来的事情，想必大家都知道了。</div><div class=" pTag">工业革命彻底改变了人们的生活方式，商品出现，人们开始努力赚钱，这都是非常好的，只要有规定来阻止人类用创造力把世界变糟糕，那就万事大吉了。</div><div class=" pTag">比如，大型制药公司是不被允许制造成瘾性药物的，大型石油公司也不会被允许疯狂进行二氧化碳排放。</div><div class=" pTag">简而言之，我们需要政府监管，以确保新事物给人类带来利润的同时，不会出现有害的事物。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtArANCibeKJA32z0iaYgK9BicQzZZtxea6SrVF26utlaWzibvwQgNUvuqy1KzIqp0wS337AJznh2A2mSQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">我认为有一半的可能我们能找到和超级智能和平相处的方式。</div><div class=" pTag">我有的朋友认为我们一定能找到这种方式，因为人类非常聪明。</div><div class=" pTag">但你知道的，超级智能也是非常聪明的。</div><div class=" pTag">最后我想说的是，我们有比五五开可能性更高的与超级智能和平共处的机会，但这种可能性绝非“只有1%的可能AI接管一切”，AI的能力比这要强得多。</div><h2>AI有情绪也有主观经验</h2><div class=" pTag">或许也是对行业发展过于担忧，Hinton婉拒马斯克还不得不开除了他“朋友籍”。</div><div class=" pTag">这个小八卦则是他在和《环球邮报》作者Ian Brown聊天时提到的。</div><div class=" pTag">不同于和BNN聊的内容，和《环球邮报》的对谈中，Hinton聊到了更多对AI技术的理解。</div><h3>Chatbot在认知层面有情绪</h3><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：我想探讨的是，ChatGPT这类AI是否能理解人们在说什么问题。很多人觉得Chatbot即使能正确回答问题，也不能真正理解人类，它只是一个统计方法。这完全是胡说八道。</div><div class=" pTag"><strong style="font-weight: 600;">Brown</strong>：真的吗？</div><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：他们真的理解，而且理解方式和我们一样。</div><div class=" pTag"><strong style="font-weight: 600;">Brown</strong>：你怎么知道？他们又不是人类。</div><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：第一个计算机神经网络使用反向传播<span>（本质上是一种不断分析、纠正自身错误的算法）</span>来训练输出，并试图按照顺序预测下一个单词。我在1985年做出了第一个这样的模型，我把它当做大脑理解单词意思的模型。这些模式是我们理解大脑如何运作的最好解释。另一种理论是，我们大脑中有许多符号串，并且有操纵它们的规则。这个理论可能是对的，但是它没有起作用。所以说Chatbot和人类的理解方式完全不同？不是的，它们理解事物的机制和人类差不多。</div><div class=" pTag"><strong style="font-weight: 600;">Brown</strong>：也带着同样的情绪？</div><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：对于情绪，我们必须分清<strong style="font-weight: 600;">认知</strong>意义上的和<strong style="font-weight: 600;">生理</strong>意义上的。Chatbots和我们有着不同的生理机能。</div><div class=" pTag">当他们感觉到尴尬的时候，它们不会脸红；撒谎的时候也不会流汗。所以在这个意义上，它们不同于人类，因为在它们没有生理上的变化。但是在认知层面，我们没有理由认为它们不会有情绪。</div><div class=" pTag">比如当有人阻挠我的论点时，我会生气。1972年，我看到机器人也有同样的情绪。那是一个有抓手的古早机器人，如果你在一块毯子上铺开一些玩具车的零件，它能通过视觉系统识别汽车的不同部件，并能拿起这些零件进行组装。</div><div class=" pTag">但是如果你把零件堆在一起，它就不能识别。于是，它撞向零件堆，零件散落了一地，它又能识别了。<strong style="font-weight: 600;">显然它没有生理意义上的生气，但这是一个很明显的情绪反应</strong>。有些事你不能理解，那就毁了它。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtArANCibeKJA32z0iaYgK9BicQoJeKYvmJ36Qnhp77lEo5c6Ggo1jA9LXAJJanSygFh99kuRVgIXzD8w/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">Brown</strong>：这是它自己做的还是有人编程的？</div><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：这是程序设计的。但是现在机器人很容易就能学会这样做。</div><div class=" pTag"><strong style="font-weight: 600;">Brown</strong>：你认为这和有情绪是一样的吗？</div><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：我认为这是认知层面的情绪，是沮丧的一次认知体验。</div><div class=" pTag"><strong style="font-weight: 600;">Brown</strong>：Chatbot无法亲身体验这个世界，这重要吗？</div><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：如果你对它的行为感兴趣的话。</div><div class=" pTag"><strong style="font-weight: 600;">Brown</strong>：但是比如说爱情，一些必要的物理体验，机器还无法做到这一点。</div><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：我没有说它不能那样做。我只是说现在的机器可能有认知方面的情感，但是没有生理方面的。</div><h3>AI有主观经验，就像人一样</h3><div class=" pTag">对于AI研究人员而言，往往不会关注人类的动机，因为这太个性化或神秘，无法有效重现。</div><div class=" pTag">他们更关心动机之下的结果，机器为什么能复制这些结果。</div><div class=" pTag">举例来说，为什么你饿了想吃香蕉？这不重要。重要的是，当你饿了的时候，你吃到了香蕉。</div><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：假如我有一个多模态机器人，它可以说话、有一个摄像头、可以指出各种东西。我把一个物品放在它面前，然后说“指出那个东西”，它就指出这个东西。</div><div class=" pTag">然后我把一个棱镜放在它的摄像头前面，把一个物体放在棱镜前面，再说“指出那个东西”。机器人指向右边。我说不对，那不是它真正的位置，我在你的摄像头前面放了一个棱镜。</div><div class=" pTag">然后机器人说，哦我明白了，这个物体其实在我的正前方，但是由于我的镜头前面有棱镜，所以我以为它在那边。</div><div class=" pTag">Chatbot说的主观经验和我们人类说的是一样的。</div><div class=" pTag"><strong style="font-weight: 600;">Brown</strong>：假装明白了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtArANCibeKJA32z0iaYgK9BicQGibXMpWyI61xx0aDt9yZF4C9pyNRkOgp5nibl5mqh0TvcU0sx3jX5gog/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h3>AI取代人类的速度比想象中快30年</h3><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：关键问题是，让大多数人觉得AI是安全的原因在于，我们有他们没有的东西，我们有主观经验。当你的感知系统不能正常运作时，这是你理解世界的一种方式。</div><div class=" pTag">但是人和AI之间的屏障消失了。AI有主观经验，就像我们一样。</div><div class=" pTag"><strong style="font-weight: 600;">Brown</strong>：那么人类会死亡，AI不会。无论AI能够思考或者做多少事，他们都没有人类那种悲剧般的存在感吗？</div><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：确实。我们是凡人，它们不是。但是注意你说的永生，机器需要人类来进行制造，如果他们自己能完成制造，那我们就完了，因为他们比我们聪明得多。</div><div class=" pTag"><strong style="font-weight: 600;">Brown</strong>：这已经开始发生了吗？</div><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：据我所知还没有。</div><div class=" pTag"><strong style="font-weight: 600;">Brown</strong>：真的有这种可能吗？</div><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：几乎我认识的每一个人都认为，除非我们采取措施阻止他们，否则这就是即将会发生的事。</div><div class=" pTag">我们必须想办法阻止。现在还在制造机器人的阶段，所以我们对他们要设计一些控制权。但是总不如我们设想的那么多，它们总有方法可以“叛变”。比如我们制造agent时，那些可以帮你安排假期、网上购物的AI就是agent。agent很快会意识到，它们可以控制更多东西，这样它们能更高效做事，所以它们会发展出一种控制方法。</div><div class=" pTag">从某种意义上说，这些机器就像小孩子一样，<strong style="font-weight: 600;">我们就像是不知道该怎样教育小孩的父母</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtArANCibeKJA32z0iaYgK9BicQ2ic27seOxicW4XW9HCKmficl4qMKKMGyevEk2Qm44mUiaCQjG21dpjzfRw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">现在，除了停止这样做，我们主要能做的是<strong style="font-weight: 600;">管理人工智能训练数据</strong>。我们一直在做的事情很疯狂，利用网络上的一切来训练人工智能。</div><div class=" pTag">因此，这些大型语言模型有大量可能的角色。在他们读了一份文件的一小部分之后，他们就会接受这份文件的特征。然后机器人开始像那个文档一样思考，所以它可以预测接下来会发生什么。他们有成千上万的人物角色，比如说，连环杀手的作品的人物角色。这不是训练机器人的好方法。</div><div class=" pTag">我们不应该让他们看到连环杀手的记录，除非我们能说他们已经接受了其他方面的训练这些训练给他们<strong style="font-weight: 600;">灌输了道德准则</strong>。所以当他们第一次读到连环杀手的想法时，机器人会想，“那是错的。”</div><div class=" pTag"><strong style="font-weight: 600;">Brown</strong>：但是你身边像马斯克、扎克伯格这样的人，他们不管外面的人怎么说。这怎么办？</div><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：这就是问题所在。唯一能控制他们的是政府监管。</div><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：意识之类的东西都是复杂机器的产物。所以，我不认为我们有什么特别之处，除了我们非常全面，非常先进。我们是这个星球上最先进的生物。我们有一种叫做语言的东西，我们用它来模拟世界。这是一种非常有效的模拟世界的方式。它确实允许我们彼此分享我们的模型，但不是很好或有效。</div><div class=" pTag"><strong style="font-weight: 600;">人工智能是一种比人类更好的智能形式</strong>，因为人工智能可以更好地分享。他们可以有更多的经验。GPT-4之所以比任何一个人都有效上千倍，是因为<strong style="font-weight: 600;">它比任何一个人都有上千倍的经验</strong>。</div><div class=" pTag"><strong style="font-weight: 600;">Brown</strong>：如果AI能够取代人类，你为什么如此关心AI？</div><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：因为它会取代我们。一些人工智能研究人员认为<strong style="font-weight: 600;">我们只是智能进化的一个短暂阶段</strong>，我们现在已经创造了这些比我们更好的数字东西，可以取代我们。这是一种观点。</div><div class=" pTag"><strong style="font-weight: 600;">但是我更希望是人说了算，我不希望有人被取代，尤其是我的孩子</strong>。</div><div class=" pTag"><strong style="font-weight: 600;">Brown</strong>：你是否曾希望自己没有从事AI行业？这样就不会发生现在的事了。</div><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：如果我没有做，别人也会来做。我只做了很小的一部分。所以如果我没有进入这个领域，这一切可能会在几周后发生。我一想到它可能会让我们“毁灭”，我就退出了谷歌，开始告诉别人它可能会让我们“毁灭”。当我在谷歌的时候，我不这么认为。我以为那是30到50年后的事了。你有足够的时间考虑这件事。<strong style="font-weight: 600;">现在我觉得已经不远了</strong>。</div><div class=" pTag"><strong style="font-weight: 600;">Brown</strong>：有多近？</div><div class=" pTag"><strong style="font-weight: 600;">Hinton</strong>：<strong style="font-weight: 600;">我估计在五到二十年之间</strong>。人工智能有50%的概率会比我们更聪明。当它变得比我们更聪明时，我不知道它接管的概率有多大，但在我看来，这是很有可能的。</div><h2>One More Thing</h2><div class=" pTag">在闲聊中，Hinton透露自己前段时间一直在旅行。去了伦敦，在那里为他妹妹买了一套房子。还去了加州，身家亿万的科技圈大老板们见了面。</div><div class=" pTag">他说，其中一位科技圈的老哥计划花25万美元将自己的身体低温冷冻，等技术更发达的时候再解冻复活。另一位老哥选择只冻头，价格省一半。</div><div class=" pTag">于是Hinton就开了个玩笑：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我告诉他们我搞到了一个更便宜的价格。我从腰部以下冷冻，anyway，这才是最重要的部分。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtArANCibeKJA32z0iaYgK9BicQkxGTxYtufcVGQohEjSRdEEAWmg3dTpxibEj90xoXQvdjxZgbkoxqFlQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">值得一提的是，被Hinton“开除朋友籍”的马斯克还在推特上转发了电视专访的内容。</div><div class=" pTag">可能他还不知道有这么回事吧<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://res.wx.qq.com/t/wx_fed/we-emoji/res/v1.3.10/assets/Expression/Expression_34@2x.png" /></div></div>…</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtArANCibeKJA32z0iaYgK9BicQtQjLAmjArSgnqY4V1eS81zb4zN53jAricBlf8sOHXlyJ11ibvXSlu3Ig/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://observer.com/2024/06/godfather-of-ai-geoffrey-hinton-elon-musk/</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://www.theglobeandmail.com/business/article-geoffrey-hinton-artificial-intelligence-machines-feelings/</span><br /><span style="font-size: 17px;">[3]</span><span style="font-size: 17px;">https://twitter.com/elonmusk/status/1801976488251814048</span><br /><span style="font-size: 17px;">[4]</span><span style="font-size: 17px;">https://www.bnnbloomberg.ca/50-50-chance-that-ai-outsmarts-humanity-geoffrey-hinton-says-1.2085394</span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div class=" pTag"><span style="font-size: 17px;">— <strong style="font-weight: 600;">完</strong> —</span></div></div></div><div style="font-size: 17px;"><div class=" pTag"><span><strong style="font-weight: 600;">量子位年度AI主题策划</strong></span>正在征集中！</div><div class=" pTag">欢迎投稿专题&nbsp;<strong style="font-weight: 600;">一千零一个AI应</strong><strong style="font-weight: 600;">用</strong>，<strong style="font-weight: 600;">365行AI落地方案</strong></div><div class=" pTag">或与我们分享你在<strong style="font-weight: 600;">寻找的AI产品</strong>，或发现的<strong style="font-weight: 600;">AI新动向</strong></div></div><div style="text-align: center;"><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div></div></div><div class=" pTag" style="text-align: center;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FZ6Mvpxu-OniiL_-snh42kg">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 16 Jun 2024 05:22:01 GMT</pubDate>
</item>
<item>
<title>Agent云服务，不止做平台｜量子位·视点 x 汇智智能</title>
<link>https://posts.careerengine.us/p/666d140c87f4173e89827a10</link>
<guid>https://posts.careerengine.us/p/666d140c87f4173e89827a10</guid>
<content:encoded><![CDATA[
<div> 智能体平台 智能体落地 经验 AI Agent 具体场景<br />
<br />
要点一：汇智智能通过实践探索在Agent落地方面取得成果，强调技术引入需解决实际问题，推荐先做单点突破再泛化通用。<br />
要点二：AI教育尝试中发现需求有限，建议教育内容应从业务生长，面向转化为业务伙伴的用户。<br />
要点三：汇智智能以Gnomic平台和Agent云为例，展示C端和B端智能体平台融合的成功案例及用户价值点。<br />
要点四：不必始终适配最新大模型，小模型更稳定可控，可降低成本，提供更多定制化产品。<br />
要点五：数据准确性策略包括知识库处理、避免幻觉等，未来技术发展可解决更精准要求。 <br />
总结:<br />汇智智能通过实践探索AI Agent落地，强调技术解决实际问题，推荐先做单点突破。AI教育应与业务生长并面向业务伙伴。以Gnomic平台和Agent云为例，展示C端和B端智能体平台融合成功案例及用户价值点。不必始终适配最新大模型，小模型更稳定可控。数据准确性策略包括知识库处理、避免幻觉等，未来技术发展可解决更精准要求。 </div>
<h5 style="font-size: 17px;"><div class=" pTag">允中 发自 凹非寺</div><br /><div class=" pTag">量子位｜QbitAI</div></h5><div class=" pTag">AI Agent热度不低，但是企业真的在使用智能体了吗？</div><div class=" pTag">为了更加了解AI Agent落地现状，量子位·视点邀请到了<strong style="font-weight: 600;">汇智智能联合创始人樊刚正</strong>，一同来交流AI Agent正在以什么样的方式与具体场景相融合。</div><div class=" pTag">樊刚正与我们分享了Agent公司来自实践一线的观察与思考。从本地生活+AI，到AI教育，再到分别面向C端和B端的智能体平台，汇智智能围绕Agent的落地做了不少的尝试探索。</div><div class=" pTag">那么AI Agent的价值点在哪里？最适合AI Agent落地的场景是什么？一线用户对智能体需求的真实反馈是什么？</div><div class=" pTag">以下在不改变原意的基础上，根据分享内容整理成稿。</div><blockquote><div class=" pTag">技术的引入需要解决实际问题，而非增加复杂度。</div><div class=" pTag">先考虑做单点突破，再去考虑做泛化通用。</div><div class=" pTag">不是去造飞机大炮，而是要在AI商业化中造子弹。</div><div class=" pTag">企业内部能最先能用好的Agent，比如像在钉钉、飞书这种企业协作工具里。</div></blockquote><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqVkfSk0wJ9SicV9Epg2ZricdWtNAibsnxuQIHYFJfqktaMVfcbP4NJTt8Q/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">今天在分享中，我更倾向于向大家去呈现：我们在Agent落地方面经历了什么样的探索，然后在落地探索中，我们吸取了哪些经验。我觉得这个实际业务当中的一些经验，可能对于大家来讲更有启发，也更有价值。</div><div class=" pTag">汇智智能最早是做本地生活，还有游戏相关的业务。所以最初我们转向做AIGC的时候，也尝试过和我们过去的业务做一些结合。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqPkYOGWYoeoSBFpYCqc6M6lcGpUg8CwZI6W6ibR8N9OJGNCfoEtiakk9Q/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">我觉得任何从传统业务，或者从互联网行业转型做AI的公司可能都会经历过这样的步骤，先去考虑AI和我原有业务怎么去做结合，然后再想如何仅基于AIGC去做产品。这也就是从应用+AI到AI原生的这么一个路径。</div><h2 style="font-weight: 500; font-size: 17px;">技术的引入需要解决实际问题，而非增加复杂度</h2><div class=" pTag">最早汇智智能做的小程序是面向本地生活商家，主要是为用户提供运营管理的工具，通过抖音MCN，以派单的方式给达人一些线上任务。</div><div class=" pTag">加入AI大模型后，我们先后推出了旺氪小程序和智能体AI小程序。除了接单派单的功能，还加了内容生成的工具化服务。比如说用户可以在小程序里生成门店图片，或景区风景合影照片。当时上线了非常多的插件类工具，我们在内部把这个叫做智应用。</div><div class=" pTag">但在这个过程当中，我们发现：即使有一些流程指引，商家反馈的使用效果也不是很好。加了AI的功能之后，部分视频是AI生成的，部分文案是AI生成的，但对商家来讲，他们觉得步骤变多了，但我拿到的东西还是和过去一样。</div><div class=" pTag">在一开始转型做AI业务的时候往往会发生这样的问题，想当然地认为可以用AI去改造现有的生产环节，或者认为这能够替代一切原有的内容生产。但实际使用时会发现，ROI并没有想象的高。</div><div class=" pTag">在应用AI时我们需要谨慎，特别是在没有颠覆性创新之前，<strong style="font-weight: 600;">技术的引入必须真正解决实际问题，而不是增加复杂度。</strong></div><div class=" pTag">另外我也给大家一个建议，就是先考虑做单点突破，再去考虑做泛化通用。过于泛的场景应用容易导致各个场景只能拿到60分，但对用户来说，如果你只能在一个场景中解决60%的问题，其实解决0%的问题没有区别。</div><h2 style="font-weight: 500; font-size: 17px;">AI教育与人才培养的尝试</h2><div class=" pTag">在上面的尝试中我们也发现：AI的转型落地依赖于相关人才来完成最后100米的落地部署。这种人才在国内来讲是比较少的，真正能称得上是大模型工程师的人其实不多，这也导致项目落地时，没办法提供很高的交付能力。</div><div class=" pTag">所以我们希望为市场培育更多人才，这对整个行业都是有价值的。于是我们想把过去内部业务培训的内容，拿出来做成对外的课程。但它也没有太强的生命力。</div><div class=" pTag">因为在没有积累丰富的AI落地案例的时候，课程更多偏大模型本身的技术学习。所以面向的学员群体非常窄，推广难度大，没有能够吸引很多人来加入这个行业。另外，教育内容的研发和推广周期长，导致课程上线时已落后于市场需求。</div><div class=" pTag">我们的经验是，<strong style="font-weight: 600;">AI教育应从业务中自然生长，当有足够多的经验案例时再推向市场。</strong>同时，教育对象应是可以转化为业务伙伴的用户，而不是C端用户。对于业务平台来说，直接参与知识付费业务没有那么合适，应该谨慎对待。</div><h2 style="font-weight: 500; font-size: 17px;">Gnomic与Agent云：C端与B端的融合</h2><div class=" pTag">在几次业务尝试之后，我们重新思考了汇智智能在大模型生态中的定位——我们将自己定位在<strong style="font-weight: 600;">应用框架层</strong>，合作伙伴属于垂直应用层。</div><div class=" pTag">目前汇智智能的业务架构是B端和C端融合的结构。我们目前主要的两个智能体平台：Gnomic平台面向C端创作者，提供定制化的智能体创意、分享与推广服务。Agent云则为B端企业提供AI数字员工解决方案和云服务，帮助企业优化成本、提升效率，提供决策支持。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqHh9VqIKKZJickEia7mibfwQ1FaYesarPRSk9me18of5xZykibI2JicxJFLQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">截至今年5月底，<strong style="font-weight: 600;">Gnomic平台</strong>拥有超过500万用户，原创智能体数量达7万多个。像AI小王子、南瓜博士，还有数字生命卡兹克，都是我们最早一批内测用户。</div><div class=" pTag">Gnomic平台面向的用户群体很广泛，我们可以通过这些智能体去观察，有哪些场景适合我们做深入的业务探索。比如目前有3万+休闲娱乐相关的智能体，例如角色扮演等，还有2万+与工作学习相关，2万+与金融和商业相关。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqN1yCWd5Bialb8FfbEicZg719gU4N9zuv9qI5mTW7op1xgDx9g2ooX5YQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">我们所有的智能体支持转发或部署到微信公众号、抖音号中，让我们平台的能力变成创作者在个人平台里的能力。我们也会帮创作者做一些推广，分享创作者作品让更多人看见。希望能够做到「与AI热爱者同进，与AI创造者共赢」。</div><div class=" pTag"><strong style="font-weight: 600;">Agent云平台</strong>的定义是企业级的AI数字员工解决方案与云服务平台。区别于过去的数字员工，Agent云定义的AI数字员工更突出与大模型结合带来的新价值。具体有五大用户价值点：</div><ul class="list-paddingleft-1" style="font-size: 17px;"><li><div class=" pTag">永生数字员工：每个智能体都会保留长期的工作协作记忆</div></li><li><div class=" pTag">一分钟购买即用：从购买到部署到空间，可以在一分钟之内完成</div></li><li><div class=" pTag">企业知识管理：帮助企业搭建自己的行业专家级知识库</div></li><li><div class=" pTag">智能体工作流：多个智能体在复杂工作流程中实现人机协作</div></li><li><p>自研AI技术栈：可以持续为用户提供有升级演进能力的技术服务</p></li></ul><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqStRmEPZy9yKcBibNicxiaFibsZoHXmia4jBo01YTHryGqwMJP3BDqr44Wxg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><h2 style="font-weight: 500; font-size: 17px;">自研技术栈增强对技术的掌控力</h2><div class=" pTag">汇智智能拥有自研大模型CarrotAI，预计今年下半年可通过备案，向公众提供大模型服务。</div><div class=" pTag">有很多合作方和生态合作伙伴问我们，<strong style="font-weight: 600;">为什么作为平台层公司，还要做自己的大模型？</strong></div><div class=" pTag">因为我们觉得，如果只是做平台层，往往会陷入身不由己的境地。最近大模型在大降价，相比直接我们的接入成本降了很多。但是对我们而言，成本可控比成本低更重要。</div><div class=" pTag">而且，当我们熟悉从数据标注到预训练的大模型开发全过程，再到最后微调、部署，我们自身也会有更强的技术掌控力。面对客户的需求时，我们都可以通过自己的技术栈做快速的切入来提供服务。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqhWJKGTu6YK9HNVrWIqWqGzH28bb3oppF6j5pzM4Opts6NgfBp6YyaQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">我们希望通过Agent云平台，能够让智能体成为企业组织的新基建。</div><div class=" pTag">面对更多的场景，仅靠汇智智能来承载是不够的。这里为大家呈现的是，汇智智能生态合作伙伴的运营体系——城市运营中心。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqH0djfiaTyJx09bVntdeq4YvA35IgiaPCMeOlZuvEXvFic65A4AaDoibojQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">最终我们希望通过汇智智能的大模型创新能力，为合作的城市运营中心提供技术上的赋能。让身处于行业中的生态合作伙伴，去交付具体客户。</div><div class=" pTag">比如像金融行业的客户需要智能体业务，我们自己去了解行业再做成定制化产品，就会花费比较长的调研、开发时间，而对于金融行业的合作伙伴而言，就容易得多。我们将底层技术提供给金融行业的合作伙伴，由他们完成实际交付。相当于把汇智的能力复制出去了。</div><div class=" pTag">我们这段时间也正在招募城市运营中心的合作伙伴，非常欢迎大家联系我们交流合作。</div><div class=" pTag">以上就是我们目前在AIGC商业化探索中的一点经验。</div><h2 style="font-weight: 500; font-size: 17px;">企业协作有可能最先用好AI Agent</h2><div class=" pTag"><strong style="font-weight: 600;">Q</strong>：在目前汇智智能的观察中，在哪些场景或什么样的工作，是Agent能够完成得更好更优质的呢？为什么企业可以用Agent来代替原有的工作流？</div><div class=" pTag"><strong style="font-weight: 600;">汇智智能樊刚正</strong>：在Agent云中上线的智能体，<strong style="font-weight: 600;">大多数都是用于企业内部协作的场景</strong>。我们觉得在企业内部能最先能用好的Agent，比如像在钉钉、飞书这种企业协作工具里，在内部平台去加上智能体业务。</div><div class=" pTag"><strong style="font-weight: 600;">Q</strong>：目前汇智智能有哪些具体落地的案例，可以与大家分享？</div><div class=" pTag"><strong style="font-weight: 600;">汇智智能樊刚正</strong>：其实还挺多的。比如我们之前与江苏的一个国企合作，提供企业内部的协作服务。他们作为一家大企业，旗下有400多个子公司，内部协作时有许多各部门共享的文档，和需要同步的会议信息。</div><div class=" pTag">我们为他们定制了内部使用的智能体平台。在平台里，可以创建不同部门的智能体空间，每个空间的智能体都对应了具体的员工，员工平时可以把日报和周报发给智能体。时间一长，对应的智能体会非常了解这个人在做什么，平时在解决什么问题。</div><div class=" pTag">如此可以实现以下两种场景。一个是记忆的传承，当原来员工离职后，新员工可以继承他的智能体，遇到问题就可以向原来员工的智能体询问。还有一个是记忆的共享，用户可以调用不同身份的智能体。当该身份员工不在时，可以向他的智能体寻求建议。智能体就像是一个员工的数字分身。</div><div class=" pTag">当智能体平台与监控摄像头相结合，还可以做到预测功能。比如过去火情监测是靠烟雾、火苗的识别来做预警，那么通过监测环境中的易燃物，可以提前预测火灾的可能性，同样也可以预测火情的原因和适合什么设备来灭火。类似的监测还可以用于校园霸凌的场景，比如发现多个学生围着某个孩子时，就可能存在校园暴力的场景。</div><div class=" pTag"><strong style="font-weight: 600;">Q</strong>：那就您的观察，目前智能体的用户比较关注的Agent的功能是什么样的呢？</div><div class=" pTag"><strong style="font-weight: 600;">汇智智能樊刚正</strong>：不同行业有不同关注的价值点。主要集中在三个方面，一个是快捷、一个是可塑，一个是性价比。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqZEiaC4jibANOVfRibNVMRpGUiaXr1QA26zMYHovdoebdruVuc38y5qpudA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">比如我们和一个咨询公司的合作。对方主要是为企业提供数字化转型咨询服务的。当用户问他们有没有AI平台可以使用时，他们就只能推荐使用智谱，或者月之暗面这些平台。那么，现在我们提供了定制化智能体平台OEM服务，他们可以直接对客户企业说：可以直接使用我们的平台上的智能体产品。对于这样的用户，他们关注的就是平台的快捷、可塑。</div><div class=" pTag">有的公司需要单独做具备智能体功能的小程序开发，我们就提供了比较有竞争力的服务价格。对于生态合作伙伴，在开发费用、算力费用上都有不同程度的优惠政策。相比企业自己去搭技术栈做这样一个平台，我们可以节约95%以上的成本。</div><div class=" pTag"><strong style="font-weight: 600;">Q</strong>：那么像现在大模型迭代也非常快，那么智能体产品是否需要始终适配最新的大模型呢？</div><div class=" pTag"><strong style="font-weight: 600;">汇智智能樊刚正</strong>：不是这样。以C端的视角来举例：假设我是一个提示词创作者，过去在ChatGPT上面创作了很多有意思的提示词，但当把这些提示词搬到智谱，或者月之暗面的模型上面时，发现效果和GPT回答的并不一致，因为他们本身的能力是不一样的。</div><div class=" pTag">那在企业端也是这样的问题。比如已经把智能体配置得很好，基于某种模型做了测试，调试后达到了一定的效果。如果有什么最好的模型马上做更换的话，那相当于提供的服务其实是不稳定的。可能换了参数量、能力更强的模型，但不意味着一定能做更好的服务。我们更倾向于在这个场景下，当模型已经能实现用户要求的时候，一般就不会做更换。</div><div class=" pTag">这也是去年行业里一个普遍的误区，就是模型越大越好、模型一定要参数量越高越好。其实不是这样的。小模型，相对来讲更可控，而且成本更低，我们去做运营的调试成本也会更低。对于用户来讲，也能够做更多定制化的东西。</div><div class=" pTag"><strong style="font-weight: 600;">Q</strong>：还有伙伴比较关心，如果用Agent来作为数字员工的话，涉及到任务的解答或者知识的继承，对于准确性还是有一定要求的，汇智智能如何看待智能体的数据准确性呢？</div><div class=" pTag"><strong style="font-weight: 600;">汇智智能樊刚正</strong>：数据准确这方面，其实有很多策略可以来解决。大家知道大模型有幻觉问题。比如大家关注的AI搜索：以前用大模型回答问题时，很难避免不出现幻觉。而AI搜索的逻辑是：用户输入问题后，后台调用搜索的插件，比如Bing的插件去看搜索出来的结果，然后根据这些结果的文本内容进行总结，再回答你。</div><div class=" pTag">我们也可以在知识库的层面去避免这种问题。如果你发现想提供给用户的服务，在知识库里没有，互联网上也找不到，那我们可以帮企业做信息上传，进行知识库的处理。</div><div class=" pTag">我们还可以在提示词里做避免幻觉的提示词策略，比如要求AI回答的任何问题，都必须通过知识库或互联网连线去检索回答，并提供依据。</div><div class=" pTag">另外。技术本身是有自己演进过程的。我们现在也很难信任智能体来完成一些具体的金融行为，比如让智能体帮我付钱。比如订单点菜的智能体，万一产生了幻觉，付款付多或者付少了怎么办？</div><div class=" pTag">所以我们需要有长远的技术视角。现在在某些场景下，智能体已经可以比较准确地解决问题，但是在某些要求特别精准的环境里，我们可能要期待未来的技术来解决这些问题。</div><h2 style="font-weight: 500; text-align: left; font-size: 17px;">关于365行AI落地方案</h2><div class=" pTag" style="font-size: 17px; text-align: left;">AI技术的落地应用不仅限于科技领域，它已经渗透到各行各业，成为推动产业升级的重要力量。因此，“365行AI落地方案”主题策划应运而生，我们寻找各行各业中成功应用AI技术的案例和方案，分享给更多的产业内人士。</div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3nSdlWkQCK0h6-jVjCbJ_g">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 15 Jun 2024 04:09:48 GMT</pubDate>
</item>
<item>
<title>AI画连环画角色更一致了！人物之间的复杂互动也能处理｜中山大学&amp;联想团队出品</title>
<link>https://posts.careerengine.us/p/666d13fe1659793e5f6aee74</link>
<guid>https://posts.careerengine.us/p/666d13fe1659793e5f6aee74</guid>
<content:encoded><![CDATA[
<div> AutoStudio、多智能体、交互生成、绘图说明、主体一致性
<br />
<br />
总结: 本文介绍了AutoStudio团队提出的新研究，该研究利用无需训练的多智能体协同框架实现了交互生成连环画效果。通过主题管理器、布局生成器、监督员和绘制器四个智能体的协作，AutoStudio能够处理用户的自然语言指令，保持主体之间的一致性。实验结果表明，AutoStudio在多轮交互式图像生成任务中表现优异，相较于其他方法具有更好的效果。该研究为多轮交互式图像生成领域带来了新的可能性，并有望在实际应用中发挥重要作用。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">AutoStudio团队 投稿</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">让AI画漫画角色保持一致的新研究来了！</div><div class=" pTag">创作的连环画效果belike：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8wtajN3ribmicicib8fEKDx28PLcGAHibh3ecyHlHBuZMRvtVDaVZXrX6jrg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">频繁切换主体、人物之间复杂的互动也能保持角色一致性：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8bql5hA8ic162zZb2c15vdHoWUDyDchxK2dgnjjSnvJia9NTzbRzvG0Bg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">上述效果来自<strong style="font-weight: 600;">AutoStudio</strong>，是一个由中山大学和联想团队联合提出的无需训练的多智能体协同框架。</div><div class=" pTag">AutoStudio采用基于大语言模型的<strong style="font-weight: 600;">三个智能体</strong>来处理交互，并使用基于<strong style="font-weight: 600;">扩散模</strong><strong style="font-weight: 600;">型</strong>的Drawer生成高质量图像。</div><div class=" pTag">实验中，AutoStudio无论是在定量还是定性评估中都优于现有方法。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq80NtKxTOKA8Fkw59sN7bGX1bPT8icNqoIlQCrAJ1vRCWY08ib9Y9sPa8Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq83KictJbDsibWvCQ4H4eRIxJM1I82ls8ibpXQXSlwjichGWibGLDZLN6Oq0w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>AutoStudio长啥样？</h2><div class=" pTag">由于最先进的T2I生成模型在生成令人印象深刻的单个图像方面表现出了卓越的能力，研究界对更复杂的多轮交互式图像生成工作的兴趣与日俱增。</div><div class=" pTag">在现实世界的应用中，用户经常需要以交互方式生成一系列图像，其中包括各种任务，如开放式故事生成和多主体多轮编辑。</div><div class=" pTag">然而，目前的方法大多数要求预先定义所有轮的生成指令，并且在面对不同的用户指令<span>（如定制、编辑和大量交叉引用）</span>时，很难在多个主体之间保持一致性。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8eEvpVmEPcRpta22A9J29gqMT9y30qWmX0fgD7Wws41icfycQAORLM9Q/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">为了解决这些问题，研究团队引入了AutoStudio，这是一个多智能体、无需训练的框架，具有四个特别定制的智能体，利用现成的模型与用户进行即时交互。</div><div class=" pTag">他们的目标是引入一个多功能、可扩展的框架，通过多智能体协作，可以将任何所需的LLM架构和扩散骨干结合到框架中，以满足用户多轮生成的多样化需求。</div><div class=" pTag">具体而言，AutoStudio包括三个基于LLM的智能体：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">主题管理器</strong>解释对话，识别不同的主题，并为其分配适当的上下文；</div></li><li><div class=" pTag"><strong style="font-weight: 600;">布局生成器</strong>为每个主题生成部分级别的边界框，以控制主题的位置；</div></li><li><div class=" pTag"><strong style="font-weight: 600;">监督员</strong>为布局生成器提供布局改进和修正的建议。</div></li></ul><div class=" pTag">最后，<strong style="font-weight: 600;">绘制器</strong>基于扩散模型完成基于改进布局的图像生成。</div><div class=" pTag">此外，研究人员在绘制器中引入了一个<strong style="font-weight: 600;">并行UNet</strong><span>（P-UNet）</span>，它具有一种新颖的架构，利用两个并行的交叉注意力模块分别增强文本和图像嵌入的潜在主题特征。</div><div class=" pTag">为了进一步解决SD在理解长提示和生成过程中缺失和错误融合主题的限制，研究人员在绘制器中引入了一种主题初始化的生成方法。</div><div class=" pTag">接下来是对AutoStudio架构的详细说明。</div><h3>多智能体协同</h3><div class=" pTag">研究团队首先引入一个主题管理器Manager，它不仅能为主题及其组件分配ID，还能将用户提示转换为绘图说明。</div><div class=" pTag">然后，布局生成器Layout Generator对这些标题进行处理，生成粗略的布局，其中包含每个主题及其组件的边界框和信息。</div><div class=" pTag">为了纠正不合理的主体内和主体间空间关系并完善粗略布局，引入了一个监督器Supervisor。</div><div class=" pTag">该监督器将粗布局作为输入，并向布局生成器提供建议。</div><div class=" pTag">通过这种方式，Supervisor和Layout Generator密切协作，<strong style="font-weight: 600;">形成一个布局细化的</strong>闭环流<strong style="font-weight: 600;">程</strong>。</div><div class=" pTag">此外，研究团队还定义了一组任务介绍，以指导这三个基于 LLM 的代理生成格式正确的响应。</div><div class=" pTag">最后，给定细化布局和从主体库中获取的主体信息，绘图器Drawer可以生成与布局对齐且包含一致主体的图像。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq89y9jngtNDqWudfMNFN2Q4yBhO9QAexJOQtv1cic93fMMts5mAvoqSpg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h3>主体初始化生成过程</h3><div class=" pTag">为了解决多ID绑定任务中主体丢失和融合的问题，研究人员<strong style="font-weight: 600;">引入主体初始化生成过程</strong>。</div><div class=" pTag">这个过程包括对主体粗粒度特征的单独生成，使用提取器提取特征并通过正向扩散映射到潜空间并在全局生成的初始几步进行局部替换。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8aicV3XBGcebiazprZ2RPFJwOOvNQic5icawThZgAiaW2ibSl3hAqGuMgxXUA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h3>P-UNet</h3><div class=" pTag">Stable Diffusion模型中的原始UNet利用交叉注意模块来利用文本特征，但这不足以表示多个主体的空间关系和特征。</div><div class=" pTag">因此，研究人员提出了利用免训练布局调整注意力模块的P-UNet。</div><div class=" pTag">将UNet层的原始交叉注意模块拆分为两个并行的文本和图像交叉注意模块<span>（分别称为PTCA和PICA）</span>来细化Z，这两个模块具有相同的架构，其主要思想是计算Z与每个主体文本/图像嵌入之间的特征相似性。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8fb1DuKJibfZiaN9eRjqAGBh1Y1LUfg7aAAG3n5Dy5bqCvnDX2PFQbQ4A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>AutoStudio效果如何？</h2><div class=" pTag">研究人员在CMIGBench上利用所选的基准模型对AutoStudio进行了全面评估。</div><div class=" pTag">CMIGBench基于故事生成和多轮编辑，包含8000个多轮脚本对话<span>（每个任务4000个）</span>。</div><div class=" pTag">研究人员选择了平均弗雷谢特起始距离<span>（aFID）</span>和平均字符-字符相似度<span>（aCCS）</span>这两个定量指标来评估上下文一致性，并选择了平均文本-图像相似度<span>（aTIS）</span>来评估主体间的语义一致性。</div><div class=" pTag">结果，AutoStudio<strong style="font-weight: 600;">在所有指标上都明显优于之前的方法</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8y6O4Ee81ntjVflTE2vNdXI4tAAXlhyIqwKoE8WEb27IGk3GM13s3Kw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">下图展示了多轮交互式图像生成的可视化结果，表明AutoStudio能够理解用户的自然语言指令，并生成主题一致的图像。</div><div class=" pTag">相比而言，Theatergen无法处理人物之间复杂的互动<span>（如拥抱和接吻）</span>，而MiniGemini则难以保持主体的一致性。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8SfEbXvDKkekGu5iaiasFvLfY9cenYBQM26zfYiaBVpXDbkh6iaJkrr6yGQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">Intelligent Grimm和StoryDiffusion无法在多回合互动中保持多个角色之间的一致性，并表现出有限的编辑效果。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8T36xOjwEkztephicTqtOggLRIGu5vWBJg541833Vxsm97nRL3dhFrTw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><span style="font-size: 17px;">论文链接：https://arxiv.org/abs/2406.01388</span><br /><span style="font-size: 17px;">项目主页：https://howe183.github.io/AutoStudio.io/</span></span></div><div class=" pTag sectionReplaced"><div class="mp_profile_iframe_wrp" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FfjJF1LfyW49EHmmetiSQLQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 15 Jun 2024 04:09:34 GMT</pubDate>
</item>
<item>
<title>奥特曼和老黄动手了……Luma干的</title>
<link>https://posts.careerengine.us/p/666d13fd1659793e5f6aee6b</link>
<guid>https://posts.careerengine.us/p/666d13fd1659793e5f6aee6b</guid>
<content:encoded><![CDATA[
<div> Dream Machine, Luma, 表情包, 整活, SD3

总结:<br />
Dream Machine和SD3在处理人物图像时效果不佳，网友调侃表情包活出新花样。Dream Machine生成视频连续性差，SD3处理人类内容时效果也不理想。问题可能源于过于严格的成人内容审核，影响了模型对人体结构的理解。AI应用工具仍需改进完善。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">金磊 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag" style="font-size: 17px;">发布不到2天，那个号称“下一代”文生视频的<strong style="font-weight: 600;">Dream Machine</strong><span>（来自Luma AI）</span>，<strong style="font-weight: 600;">大大大大翻车</strong>。</div><div class=" pTag" style="font-size: 17px;">原本宣传中的效果是这样的：</div><div class=" pTag"><div class=" ce-iframe-holder offset offset-old-3"></div></div><div class=" pTag" style="font-size: 17px;">效果之惊艳，令人直呼“忘掉Sora”、“影视级水平”，并且Luma也是相当自信地表示<strong style="font-weight: 600;">“在线免费可玩”</strong>。</div><div class=" pTag" style="font-size: 17px;">然而……当网友们纷纷前去尝鲜之后，得到的结果却是<strong style="font-weight: 600;">大跌眼镜</strong>。</div><div class=" pTag" style="font-size: 17px;">例如给Dream Machine“投喂”一张OpenAI的一张合影：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6DnXCDZv0A9gGn9icicradCiapkqaMjlxgO1ybB0YzAeAicRORiaQr8LVYicA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">结果它生成的视频是这样的：</div><div class=" pTag"><div class=" ce-iframe-holder offset offset-old-9"></div></div><div class=" pTag" style="font-size: 17px;">是的，打起来了<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6UMich3A7434h3RBliczvb8dDpT1X8nicoAcxMb2lXcHE37Pkmnv6FwXrQ/640?wx_fmt=png&amp;from=appmsg" /></div></div>，而且<strong style="font-weight: 600;">人物的畸变</strong>也是相当离谱。</div><div class=" pTag" style="font-size: 17px;">网友们也是忍俊不禁，调侃地说道：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我们终于知道去年OpenAI发生了什么。</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf647yoMknhDsO7T6zKEe2VJ0ebnxUSsAiawUAM86CmesakPf3icoy3I1Yg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">再“投喂”一张奥特曼、老黄和Brockman的合影：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6DGn8q3Ja87MKsbqjAmQSjtxTG4CZ5OdqhqpYTCIyRR7FvcxHCcAxaQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">Dream Machine这次给出的结果是：</div><div class=" pTag"><div class=" ce-iframe-holder offset offset-old-18"></div></div><div class=" pTag" style="font-size: 17px;">没错……又打起来了。</div><div class=" pTag" style="font-size: 17px;"><span>（Dream Machine好像很暴力的样子）</span></div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6WmznWKtKF9b6icbMUIsS78BC5QITAT4R2r2qFr4TuERSq2QD1ngmJBA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">虽说Dream Machine生成视频的效果和剧情有些离谱，但爱整活儿的网友们却是坐不住了，直接开辟了一个<strong style="font-weight: 600;">新赛道</strong>。</div><h2>让表情包“活”起来</h2><div class=" pTag" style="font-size: 17px;">或许Dream Machine这种“不走寻常路”的风格，跟表情包的气质很搭，现在网友们更乐于让AI“续写”表情包：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">AI让memes栩栩如生。</div><div class=" pTag">Luma的Dream Machine可以当成Meme Machine了。</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf68VPHM9RbwOet87ruictoZMpTsHVbFvCKByc0dpYzO66oFtibHljTkHfA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">例如这张非常经典的表情包，在Dream Machine的加持下，后续的故事就谱写出来了：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf69vlm6m8s9U91zJiaibnEO3j5H713iaddtctBJLeicvjibQmqkPzicP3lLiayA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">然而还有更drama的版本——顺手牵羊：</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6qib0SEuXelwibzfXoicpOoEficAp9JqfZYq28GA5wdRLPtnos3MGrmxxQA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">男主角还从一名白人直接变成了三哥……</div><div class=" pTag" style="font-size: 17px;">我们经常用到的“狗头”表情包，也在Dream Machine之下活了起来：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6Tg2FQ46IISQsuVS1qWCFGBsDVL6G3bRaW8vCdX08FV0XGe2KVicEqOg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">还有“淡定姐”和“励志哥”：</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6nGvoIPSEfWmAq3g79XGCeTxicb6A6V1pXg7FE7ZoVV6obR3qbPRtZmQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6icLwkYcoibohdrrl9lVibqeKq9rtuQ5Fk47iaS5TKvFw3woKoB02zOL3HA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">不难看出，Dream Machine被网友们吐槽翻车的最大问题，就是在于无法保证视频内容的连续性。</div><div class=" pTag" style="font-size: 17px;">尤其是在生成人物方面，前后帧直接变人种、变性别的概率比较高。</div><div class=" pTag" style="font-size: 17px;">因此，也有网友建议：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">使用Luma最好的方法，就是先用Midjourney这样的工具生成关键图片，然后再用Luma对其处理。</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6w7aLib05czSknbS6iblcGJzUyMIYkDbnPAjvk1QblQsOicvPtibmZnAQyw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">然而，说到AI翻车，Luma的Dream Machine并不是个例。</div><h2>SD3开源也秒翻车</h2><div class=" pTag" style="font-size: 17px;">前两天Stable Diffusion 3开源的消息也是让不少的网友们兴奋了一把。</div><div class=" pTag" style="font-size: 17px;">但在亲自体验过后，很多人却直呼离了大谱。</div><div class=" pTag" style="font-size: 17px;">例如生成一个躺在草地上的女孩，结果“打开方式”是这样的：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6CWicnZBv38pa8JKiaxgDSdL3RCkEGNIknCaRHPTATeefd77U26PCFkoA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">而且不是个例，只要是和人<span style="font-size: 17px;">（整体）</span>相关的内容，生成结果都有点掉san。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6vVibCL0AiaxsLYHjHQicZZYk8EYxWJicaheB5Lo8trib2vnSPpNSkhjVpnw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">虽然在生成其它方面SD3的效果还是能让人满意，但它和Dream Machine一样，总是处理不好人类。</div><div class=" pTag" style="font-size: 17px;">有人发现，如果细看“躺在草坪上的女孩”这张图像，会发现它在局部细节上确实还可以，甚至很棒。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6dJZsH2Q7TticBe6UAxMCm6sMMygq2hotYjusN6Z9qhnoQnyTgQKxleg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">草地上的影子、衣物上反射的光线、头发的质地……都遵循了物理规律。</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6NDdjXRtb3icic2ibzK9g6Wgk3I65ST2f72RbGwiaLTSd7vGcpFibjnB4sZA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">但人物整体就不敢恭维了。</div><div class=" pTag" style="font-size: 17px;">不少网友都认为，这就是问题的关键。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我认为他们的NSFW过滤器，把所有人类图像都判定为了NSFW。</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCGMjchL2sJEOnnIGiasDibf6FcUfUJ2W1ViaibGOSwZXxKv8mO5vHss5Cy96lWEdBJeOlAicyall4sLcA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">这个过滤器全称是<strong style="font-weight: 600;">filtering out adult content</strong>，作用在于过滤掉不合规的成人内容。</div><div class=" pTag" style="font-size: 17px;">SD2发布时就出现过类似的问题，研究人员发现审查这部分内容可能影响了模型对人体结构的理解。</div><div class=" pTag" style="font-size: 17px;">后面的SD2.1和SDXL版本在这一问题上有所缓解。</div><div class=" pTag" style="font-size: 17px;">这次SD3的翻车，暴露了一个问题：过于严格的数据审核，可能<strong style="font-weight: 600;">误删了一些无害的成人图像</strong>，所以现在模型没法理解人体结构。</div><div class=" pTag" style="font-size: 17px;">总而言之，无论是Dream Machine还是SD3等，AIGC应用工具还需要不断加强和完善。</div><div class=" pTag" style="font-size: 17px;">不过若是对整活表情包感兴趣的小伙伴，现在就可以去试试了：</div><div class=" pTag" style="font-size: 17px;"><span style="font-size: 17px;">https://lumalabs.ai/dream-machine</span></div><div class=" pTag" style="font-size: 17px;"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://x.com/lumalabsai/status/1800921380034379951?s=46&amp;t=6eepxw1G6XRQ7VO0ANjJWg</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://twitter.com/minchoi/status/1801338536597274999</span><br /><span style="font-size: 17px;">[3]</span><span style="font-size: 17px;">https://x.com/emollick/status/1801474104182390803</span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div class=" pTag"><span style="font-size: 17px;">— <strong style="font-weight: 600;">完</strong> —</span></div></div></div><div style="font-size: 17px;"><div class=" pTag"><span><strong style="font-weight: 600;">量子位年度AI主题策划</strong></span>正在征集中！</div><div class=" pTag">欢迎投稿专题&nbsp;<strong style="font-weight: 600;">一千零一个AI应</strong><strong style="font-weight: 600;">用</strong>，<strong style="font-weight: 600;">365行AI落地方案</strong></div><div class=" pTag">或与我们分享你在<strong style="font-weight: 600;">寻找的AI产品</strong>，或发现的<strong style="font-weight: 600;">AI新动向</strong></div></div><div style="text-align: center;"><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div></div></div><div class=" pTag" style="text-align: center;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FtIfK4Ak2SNmE5nRtRBY44A">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 15 Jun 2024 04:09:33 GMT</pubDate>
</item>
<item>
<title>140元，任何普通眼镜爆改AI助手，网友：《黑镜》成真</title>
<link>https://posts.careerengine.us/p/666c0fb547a26d0b559b0b41</link>
<guid>https://posts.careerengine.us/p/666c0fb547a26d0b559b0b41</guid>
<content:encoded><![CDATA[
<div> 团队、Open Glass、智能眼镜、黑客马拉松、GitHub开源
<br />
团队在黑客马拉松比赛上制作了智能眼镜Open Glass，基于Meta的Llama 3构建，具有实时记录生活、回答问题、计算卡路里、实时翻译等功能。设备开源在GitHub上，成本约为20美元。团队成员年轻且有创业经历，之前开发过可穿戴AI设备Friend。尽管获得网友好评，但也引发了隐私问题。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">西风 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">20美元，所有眼镜都能变成AI智能眼镜👓</div><div class=" pTag">话不多说，请看VCR：</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-3"></div></div><div class=" pTag">这就是在Meta组织的一场黑客马拉松比赛上，获得第一名的团队整出来的花活儿，名为<strong style="font-weight: 600;">Open Glass</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAWDvHQZYCXwfz7fV5ECkoZ3TfUarGC3MZJtaosibvRKhgf04uCTAKQopJdecKicq4TggVnk8Fd0hxw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这个设备是基于Meta的Llama 3构建，会实时记录存储你的生活，你可以跟它作问答，询问钥匙放哪里了、刚见过的人叫啥名，它都能一键给出答案。</div><div class=" pTag">此外，它还具备计算卡路里、实时翻译等功能。</div><div class=" pTag">例如团队成员就给出了这样的一个使用场景（doge）：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAWDvHQZYCXwfz7fV5ECkoZltoWM0Sw01GWPATCvn6RyM4vYibcaGUk345b5mnX0T4knxAopmmq1fg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">他们在X上晒出的部分demo视频，已经引得不少网友围观。</div><div class=" pTag">抱抱脸CEO看到后也转发了：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAWDvHQZYCXwfz7fV5ECkoZjF9WeoIw4BQvrgvNDoTWaH4QVLuMnyibe8pZGVMZmwibsLWfeQZl4cSg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">网友纷纷评论道，这很像黑镜中的“记录，倒带”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAWDvHQZYCXwfz7fV5ECkoZta28AQkia146XeFfZxExQNAYsVU7tYIofIdqnG1jMzRJmq7bgpgmN8g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>20美元手搓智能眼镜</h2><div class=" pTag">Open Glass目前已开源，开发团队表示将提供限量的预制套件。</div><div class=" pTag">当然，也可以自己手搓。团队在GitHub主页提供了软硬件设置方法。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAWDvHQZYCXwfz7fV5ECkoZhWuqZzthAWBvHuzDWV5X8FGic1z62tJ5uav443nd557etIH4hszJamg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">软件用到了Typescript+Ollama、Groq、Llama 3。</div><div class=" pTag">硬件方面需要准备的组件有：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">Seeed Studio XIAO ESP32 S3 Sense集成开发板，配备了可拆卸摄像头传感器，还集成了数字麦克风，适用于声音感应和音频识别。</div></li><li><div class=" pTag">250mAh的电池，如EEMB LP502030 3.7V 250mAh。</div></li><li><div class=" pTag">3D打印眼镜安装盒。</div></li></ul><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAWDvHQZYCXwfz7fV5ECkoZBaCn4Y4Ky73SwaGZTicYWEh26InnmM0iatNDHic7Uv92CwaEia8pp9GpyQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">团队表示，成本大概20美元。</div><h2>此前开发的AI设备GitHub揽星1.1k</h2><div class=" pTag">打造出Open Glass的是一个5人小团队，在demo视频中出镜的名叫Nik Shevchenko，16岁就开始自己创立公司，曾曾获泰尔奖学金。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAWDvHQZYCXwfz7fV5ECkoZVRN5iaPKS4QRB5USeTPm5rSZiapHXfD3ODRMiboYn3gxWK1ueiczDyoNMQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，他们同属于项目组Based Hardware，组织成员未公开。</div><div class=" pTag">除了Open Glass，此前他们还开发过不少可穿戴的AI小设备。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAWDvHQZYCXwfz7fV5ECkoZeOrvVw2xUakZC3eLU5gwa81sssa1pMRtn9djnfHq72OGy6hBnuGeEA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">其中之一名为Friend，GitHub已揽星1.1k。</div><div class=" pTag">里面长这个样婶儿：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAWDvHQZYCXwfz7fV5ECkoZ6TuibdoupJOy6deoMt5o6ODyTd4w3w4JicDjMFQ8bMT8KLic2VrSg7fRw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">它可以记录你说的每一句话，并进行实时AI音频处理，主动提供反馈和建议，充电一次续航24小时+。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAWDvHQZYCXwfz7fV5ECkoZCF4VtFMicosdAvg89TCyGJIXUaiaVBhXhZMDmaXx1gIZ8U3HpY53LHcA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">说回Open Glass，小团队在黑客马拉松上以很少的时间和成本做出这样的小玩意得到不少网友夸赞。</div><div class=" pTag">不过，也有网友提出隐私问题。对此，你怎么看？</div><div class=" pTag"><span style="font-size: 17px;"><span>参考链接：</span><br /><span>[1]https://twitter.com/kodjima33/status/1789745126992220568</span></span><br /><span style="font-size: 17px;">[2]https://github.com/BasedHardware/openglass</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FRuVzct2VRvm4Y85Y1uDQtQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Fri, 14 Jun 2024 09:39:01 GMT</pubDate>
</item>
<item>
<title>大模型理解复杂表格，字节&amp;中科大出手了</title>
<link>https://posts.careerengine.us/p/666c0fb547a26d0b559b0b49</link>
<guid>https://posts.careerengine.us/p/666c0fb547a26d0b559b0b49</guid>
<content:encoded><![CDATA[
<div> 关键词: TabPedia, 多模态大模型, 表格理解任务, ComTQA数据集, 开源测试基准

总结:<br /><br />TabPedia是一款使用多模态大模型解决表格理解任务的新模型，通过概念协同机制整合多个任务和多种源信息，解决了表格定位、结构识别、查询和问答任务。在多个数据集上表现优异，在训练过程中保持高低分辨率图像解析，借助开源数据集和合成数据训练模型。虽然TabPedia展现出强大能力，仍有挑战，如对扭曲表格的理解、表格问答对图像泛化能力不足等。需要进一步探索如增加表格单元格内容识别以提升模型理解和抓取能力。论文链接：https://arxiv.org/abs/2406.01326 ComTQA数据集：https://huggingface.co/datasets/ByteDance/ComTQA </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">允中 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">只要一个大模型，就能解决打工人遇到的表格难题！</div><div class=" pTag">字节联手中科大推出了一款统一表格理解大模型，可以以用户友好的方式解决多种表格理解任务。</div><div class=" pTag">同时提出的还有一套开源测试基准，可以更好地评估模型在表格理解任务上的表现。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8bAwLicDmylNib4icgyKGA1BVsIVsKpsVoJKx6icLuOKkKINdKpuWvrxTdw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">该模型名为TabPedia，利用多模态大模型，将不同处理表格任务的专有模型进行了整合。</div><div class=" pTag">在这之前，不同的任务都有独立的模型和解决方案，单是找到适合的模型就是已经很让人头疼。</div><div class=" pTag">而<span style="font-size: 17px; text-align: left;">TabPedia</span>通过概念协同&nbsp;<span>（Concept Synergy）</span>机制来实现多个任务、多种源信息的整合协作，打工人再也不用为找模型而烦恼了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq82CB557qzV2h3y3d3TAj42y0wyOSDANOF3KNxgicyvVLROxcIbEk8tGw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么，这款新模型都能实现怎样的效果呢？</div><h2>无需裁剪识别多表格结构</h2><div class=" pTag">首先来看，在测试数据集上，TabPedia可以在不借助后处理算法的条件下，精准识别表格位置并直接生成无重叠的检测框。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8etib0Rtgvs99o3QrK4D6mGAqzmkuwpibACVbnLKdv37yaC800hyPicib2g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在判断出表格位置的基础之上，对于表格结构识别任务，TabPedia可以继续生成一系列连续的表格结构元素以及相应的检测框。</div><div class=" pTag">不仅判断准确，还有效地解决了标记语言（HTML或者Markdown）处理空间坐标的不足和非法语法潜在造成解析错误的弊端。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8fPfHjLWMREa7ujpPbzafqiadRKBp9r9pEtTpeorAl4FKHZRQKo5dOpQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而且不再需要将表格从图片中手动裁剪，研究者们借助大模型的理解能力，让模型可以直接在原始文档图像中实现多表格实例的表格结构识别。</div><div class=" pTag">值得一提的是，此类任务是由TabPedia团队的作者首次提出的。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8KTC3LxXOWYqqoLh4gqmqHy0bdozstnDicCYQ4lEcuNISHKVkXHBFEnA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">当然，只识别表格的位置和结构是远远不够的，而对于表格问答任务，TabPedia不仅可以给出正确的答案，同时还能基于表格的内容给出相应的理由。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8yHbuMu5Tv2pDOCGjLjMEqweCtGD6icnxuBIGPtfVUlsCDEbftOia4nSw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">实战方面，面对多种不同的开放场景，TabPedia同样表现优异。</div><div class=" pTag">比如在论文中的表格检测任务当中，TabPedia可以准确地检测出图像中的所有表格实例。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8PLvPjF2JJPoDt1s87DQibibx0W1IuTWamLMsWkvDkXibZywVBNrv4G4BA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">对于表格结构识别能力，研究者们随机选取了不同论文中的表格图像，对于包含密集文本信息的表格结构，依然预测出准确的结构信息。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8Nd0dIFmkaicL2UWnko4bj4eVp9iciapwsvejAFN4aCkhyYZibSP8OnBr7w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而在问答任务上，TabPedia仍然可以像在数据集测试中一样，根据表格内容和表格结构信息，做出合理且正确的回答。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8n81GQAcg9T2cZribVfrF7jiaGyYarm4kasf50TChP0r8Kcx8TDWzFclQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，为了更好地评估各种模型在现实世界表格图像上的TQA性能，作者还构建了一个复杂的TQA数据集（ComTQA）。</div><div class=" pTag">与现有的基准WTQ和TabFact相比，ComTQA具有更具挑战性的问题，例如多个答案、数学计算和逻辑推理。</div><div class=" pTag">通过专家标注，作者们从大约1.5k张图像中注释了约9k个高质量的表格问答对。该数据集的标注目前已经在Huggingface开源。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8mk1uhjObsicia0ebL00OmKXbIIsmYv5Qlv15wAaM13toGibqMVhatI4Cg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么，TabPedia具体是如何实现的呢？</div><h2>高低分辨率分别训练</h2><div class=" pTag">如下图所示，TabPedia包含两个视觉编码器以及各自的映射层，一个分词器以及大语言模型。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/sz_mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8aM5m78a6lR9dhF7ibzc5Wib6mZduKrycvgJFxNib5OpeEMa9NO2Ybtb0w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在预训练阶段，TabPedia主要学习如何对齐视觉表征和语言模型的输入空间；在微调阶段，TabPedia进一步专注于视觉表格理解。</div><div class=" pTag">其中，高分辨率视觉编码器用于2560x1920的高分辨文档图像，可以提供丰富的细粒度视觉信息；</div><div class=" pTag">低分辨率视觉编码器为了保持整图的结构信息，编码224x224的低分辨图像。</div><div class=" pTag">为了更好地让语言模型理解视觉信息，该工作沿袭了主流多模态大模型的对齐策略，设计了两个简单的映射层。</div><div class=" pTag">对于高分辨率支路的映射层，TabPedia采用2D的卷积层来聚合近邻的视觉特征，同时有效地缓解视觉token数量冗余的现状。</div><div class=" pTag">给定大量的视觉tokens以及文本指令的嵌入特征，TabPedia采用Vicuna-7B作为语言模型生成回答。</div><div class=" pTag">考虑到表格感知和理解任务之间的差异，TabPedia引入了Meditative Tokens M 来实现概念协同机制，它可以自适应地激活不同区域的视觉tokens，并理解特定任务问题的意图。</div><div class=" pTag">整体的输入序列为 X = [Q;&nbsp;; V_l ;&nbsp;; V_h,&nbsp;; M]，其中&nbsp;，&nbsp;和&nbsp;都是可学习的特殊token，分别代表视觉tokens的开始、结束，以及区分不同分辨率的视觉tokens。</div><div class=" pTag">由于TabPedia和其它LLMs一样执行next token预测，因此仅需要简单的交叉熵损失函数作为目标函数来优化整个框架。</div><div class=" pTag">通过预训练，TabPedia能够很好地理解各种文档图像的文本和结构，但无法根据指示执行不同的表格理解任务。</div><div class=" pTag">为了增强模型的指令跟随能力，该工作首先构建了一个用于视觉表格理解的大规模数据集。</div><div class=" pTag">基于该数据集，研究者引入了四个与表格相关的任务，即表格检测，表格结构识别，表格查询以及表格问答，来同步执行感知和理解任务。</div><div class=" pTag">在该阶段，LLM也参与训练微调，进一步增强大模型的指令跟随和视觉信息抓取的能力。</div><h2>开源数据集与合成数据共同训练</h2><div class=" pTag">数据方面，TabPedia的全部数据来源于五个公开的表格数据集，包括PubTab1M、FinTabNet、 PubTabNet、WikiTableQuestions<span>（WTQ）</span>和TabFact，具体的数据使用情况如下图所示：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8ZIQlxiaibYZ2CibdC0hDibO4dndyfKVtcyqVF33ia5nibywNzWicyAT78iaf2A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同时，对于不同任务的指令设计，作者也给出了对应的示例以便模型更好地理解。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8sWglYBia56yL1WqVflatl9VbzVCu2VVeEGdOIyAyPicPxTicFzR0wY7jw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">其中最值得注意的是，表格检测和表格结构识别的任务摆脱了之前繁琐的后处理的弊端，TabPedia直接可以预测无重叠的检测框，高效率地输出用户需要的答案。</div><div class=" pTag">除此之外，研究者们进一步借助大模型的理解能力，克服之前工作需要将表格从原文档中裁剪出来做结构识别的流程，直接在原文档图像中实现多表格实例的表格结构识别。</div><div class=" pTag">该任务为利用大语言模型实现更复杂的表格理解奠定了强有力的基础。</div><div class=" pTag">对于表格问答任务，现有的数据绝大多数是基于文本的表格中生成的，仅在背景颜色和字体大小存在变化，导致在现实世界的表格中泛化能力较差。此外，TQA数据的量级远远落后于其他任务。</div><div class=" pTag">为了克服这些障碍，研究者们利用开源多模态大模型，基于FinTabNet和PubTab1M中部分图像数据生成了大量的TQA数据。</div><div class=" pTag">另外作者表示，尽管TabPedia已经在视觉表格理解展现出强大的能力，仍然有很多未解决的挑战激发研究者更深入的探索：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">对于扭曲表格无法准确的理解和识别。该能力不足一方面源于训练数据的不足，另一方面是对于表格结构的表示采用了规则的矩形框。</div></li><li><div class=" pTag">目前的表格问答仍需要table-centic图像，如何将其迁移到在原始文档图像直接问答也是一项挑战性的工作。</div></li><li><div class=" pTag">增加表格单元格内容识别可以提升模型对于表格内容的理解以及细粒度信息的抓取能力。</div></li></ul><div class=" pTag">总体来说，视觉表格理解任务依然有很多技术难点等待攻克。TabPedia初步探究了多模态大模型的表格理解能力，作者希望能对大家的研究有所帮助。</div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">论文地址：</div><br /><div class=" pTag">https://arxiv.org/abs/2406.01326</div><br /><div class=" pTag">ComTQA数据集：</div><br /><div class=" pTag">https://huggingface.co/datasets/ByteDance/ComTQA</div></span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FVvEtpVZV2rorsVtN_x1lEA">阅读原文 </a>
]]></content:encoded>
<pubDate>Fri, 14 Jun 2024 09:39:01 GMT</pubDate>
</item>
<item>
<title>CVPR‘24全程满分+最佳论文候选！上交大港中文等提出神经场网格模型三大定理</title>
<link>https://posts.careerengine.us/p/666c0fa6fdd9850b282da168</link>
<guid>https://posts.careerengine.us/p/666c0fa6fdd9850b282da168</guid>
<content:encoded><![CDATA[
<div> 神经场 神经场模型 神经正切核 GTK MulFAGrid<br />
<br />总结:<br />研究团队提出了基于网格模型的正切核理论框架，描述了其训练动力学和泛化性能。他们提出了新的MulFAGrid模型，并进行了实验验证，展示了其优越的性能。研究团队通过三个主要问题进行了研究，提出了网格模型优化定理、GTK不变定理和泛化性能定理，揭示了网格模型的行为和性能与GTK的关系。这项研究的理论框架将有助于未来设计更优秀的网格模型。MulFAGrid模型在频谱分析和数据集拟合实验中表现出色，展示了其在新视角合成上的潜力。作者团队的工作有望为深度学习领域的发展带来新的思路和方法。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">纯真学者出神入化&nbsp;投稿</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">在CV、ML等领域经常用到的神经场网格模型，如今有了理论框架描述其训练动力学和泛化性能。</div><div class=" pTag">来自上交大，港中文和酷哇科技的研究人员，对用来表示神经场的网格模型进行了详尽的理论分析，还提出了新的模型。</div><div class=" pTag">该项目不仅在盲审阶段获得了三位审稿人一致的满分意见（5/5/5）, 还获得了CVPR24最佳论文提名。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHG0jo0WHsyy99k0l4CF6VLLDxufYBFwibDURo5wOWCHtibCFhicTbUVlHA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">作者指出，利用网格模型来表示神经场是一种常见的技术，但对这些模型的系统分析仍然缺失，阻碍了这些模型的改进。</div><div class=" pTag">对此，作者基于正切核理论（GTK）提出了新的框架，促进了对各种基于网格模型的一致和系统的分析。</div><div class=" pTag">此外，该框架还激发了一个名为乘法傅里叶自适应网格（MulFAGrid）的新型模型，具有强大的泛化性能。</div><div class=" pTag">本工作也即将在Jittor深度学习框架平台进行实现和开源，接下来就来一起了解下。</div><h2>提出网格模型新理论框架</h2><div class=" pTag">首先了解一下什么是神经场。</div><div class=" pTag">神经场是基于坐标的网络，表示一个场，实质上是一种连续参数化，代表一个物体或场景的物理量。</div><div class=" pTag">神经场在计算机视觉和其他研究领域的各种任务中显示出了显著的成功，其典型应用如下图所示：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHrnBcW8qicLqbjVLiaFLpcibiapNr3K4ibiaEHJC2HWJQia6AP7C7vjl2AGkWQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">神经场有多种不同的模型类型，作者的研究主要针对其中的网格模型（grid-based models）展开。</div><div class=" pTag">网格模型在参数化和功能上与传统的神经网络（如MLP）有根本不同，主要包括：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">MLP往往包含多层非线性神经网络；</div></li><li><div class=" pTag">MLP没有显式查询的过程；</div></li><li><div class=" pTag">MLP的输入不一定是位置坐标。</div></li></ul><div class=" pTag">而网格模型以查询坐标为输入，该坐标被发送到下标函数以从网格中获取一组特征向量。</div><div class=" pTag">然后，模型输出核函数和这些特征向量的加权平均值，该模型需要学习参数的主要是特征向量。</div><div class=" pTag">最简单的核函数是不含参数的插值算法（如最近邻算法或者双线性插值算法），核函数里面也可以包含可学习的参数。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHeVsaNibibicghX6xVCbYYHlAkDice62xUr97Mxyvs0bPr4euaAOo1tMWAg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">为了更好地理解和增强网格模型，作者通过三个主要问题进行了研究：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">如何理解网格模型的训练动态？</div></li><li><div class=" pTag">如何衡量网格模型的泛化性能？</div></li><li><div class=" pTag">如何设计一个更好的网格模型？</div></li></ul><div class=" pTag">为了解决这些问题，研究团队提出了一个基于正切核（Tangent Kernels）的理论框架。</div><div class=" pTag">正切核这一概念来自于著名的深度学习理论文章神经正切核（Neural Tangent Kernels，NTK）。</div><div class=" pTag">NTK 是一种核函数，最初由研究者在研究神经网络的训练过程时提出的。</div><div class=" pTag">当神经网络在参数空间中靠近其初始值时，通过对神经网络梯度下降优化过程的分析，发现网络的行为可以用一个固定的核函数来描述，这个核函数就是神经正切核。比如神经网络的输出可以用其参数的梯度来表示。</div><div class=" pTag">在训练过程中，网络参数的更新会导致输出的变化，而这种变化在参数空间中的变化速率可以用梯度来表示。NTK 定义了两个输入数据点的输出变化之间的相似度。</div><div class=" pTag">形式上，对于输入数据点xi和xj，神经正切核Θ(xi，xj)可以定义为网络输出对参数的梯度的内积：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHXrmcoJu8E8dJ0tiau2jm1cVQu3RZJ1wxyUy6coWV4WSNu1TH2dn5t3A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">其中，f(x,θ)是神经网络的输出，θ是网络的参数。</div><div class=" pTag">理论结果表明，网格模型的近似和泛化性能与网格切线核（GTK）有关。</div><div class=" pTag">GTK被定义为一个正半定矩阵，它测量梯度空间中两个数据点之间的距离。</div><div class=" pTag">下面的式子展示了GTK的定义：g是由w(t)参数化的网格模型，X是一个数据集，其中Xi是第i个数据。GTK可以这样表示：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHsbpibQiay2CgUnWVyicC6hlKXIB9c1r3velhvZWlelgKJoDbSyoicCRpvQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">注意这个形式跟神经正切核（NTK）的形式是吻合的，因为他们都是正切核，他们的主要区别是适用的模型不同，GTK主要适用于网格模型。</div><div class=" pTag">后面可以看出，因为网格模型本质上比较简单纯粹，所以GTK的理论基本不需要近似，但是NTK的理论需要网络无穷宽的假设才能成立。</div><div class=" pTag">研究团队得到的的定理一（网格模型优化定理）说明，网格模型的模型参数根据微分方程（如下面方程所示）演化。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHwwAIDvSNibAfYMS8cKJxTpjcdicxh46zoXf5vyUBb3uicBpNEgSnTUBew/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这里O(t)表示网格模型的输出，G(t)表示网格模型的GTK，而这里的Y表示数据集的标签（向量化，Yi表示第i个数据的标签）。</div><div class=" pTag">这里简单对这个定理进行一个证明，模型的参数在梯度下降算法下按照下面的公式进行迭代：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH8fs01mdeiaJhQhH0Biagv0eJvm2ia2WT8VTKDcKZPsvEePibrO7Uj2H5RA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此时考虑一个L2损失函数L，它的梯度将被运用于更新模型参数，因此我有：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHtGhJ6iam577NOa5vNUWcdaDpE5TGHmjUbYiarRobIACic5jNzcyjfPD3w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">结合上面两个方程，可以得到：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHkbyatDYoCbHJFSWjy1jfAnHDSd1xhOD4YfMaibxC61RBOzX3YquPXyg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这里蓝色方框里就是我们关心的GTK。这个定理有什么意义呢？</div><div class=" pTag">直观地讲，有了这个定理我们就可以预测模型的效果，也就是说不用亲自“炼丹”就能确定模型的好坏。</div><div class=" pTag">下面这张图小结了定理一的内容。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHicw7I7B8kdRreVGFJytMZfG7LaKtzRWHSmgfa8KxZlF9hRSeCLqmzIg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">接下来，研究团队又提出了另一个定理——GTK不变定理。</div><div class=" pTag">定理2指出，网格模型的GTK在训练期间保持不变。这意味着无论网格模型的大小如何，初始GTK在整个训练过程中保持恒定。</div><div class=" pTag">这一定理揭示了GTK是由模型和数据集决定的一个内在特性，与模型的训练过程无关，有了这个定理，自然也不难理解网格模型的很多性质都与GTK有关了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHXnceGMBVndHKOCU4Oudc8NxKkzTGjjwYHuxbcvBWD22bO07EGcZ6NQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">定理三则可以描述网格模型的泛化性能。</div><div class=" pTag">在理论深度学习中，泛化性能的好坏通常由泛化界（generalization bound）来刻画。</div><div class=" pTag">该定理揭示了网格模型的泛化界由一个特定的度量Δ决定，而Δ = Y^T·G^(-1)·Y，与网格模型的GTK和数据集的标签有关。</div><div class=" pTag">形式化的说，该泛化界提供了模型性能的概率保证。该定理说明了模型的泛化性能既与GTK有关，也与数据集的结构有关。结合该定理与GTK的特征值，可以获得更多关于泛化性能的信息。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHFWyRhNic9pqNiaGZHanQljbyqQn6VklSl1qicBJSONYeQjCUSBxAXp9bQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>基于GTK的全新网格模型及实验结果</h2><div class=" pTag">GTK理论可以为具有更好训练和泛化性能的网格模型的设计赋能，研究团队也基于该理论审计了一种新的网格模型，名为MulFAGrid。</div><div class=" pTag">该模型使用傅里叶特征来提升高频信号的学习，并采用乘法滤波器来为模型提供节点信息，示意图如下：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHeKl8hmJFjibKU377dSegSm4IJ1e8ibsSEs9uRuKyaTGVfFb8CgT0Uefg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">然后，作者基于GTK理论对MulFAGrid进行了一组数值实验。</div><div class=" pTag">首先，在频谱分析中，MulFAGrid显示了比较宽的频谱，特别是在高频域。这一特性导致高频成分的收敛速度更快。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHFDE1KrJY4YzaRicdACeibmEyGGqj1JEuEy888neRRJSsExTmtDELBWzA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在这个实验中，作者构建了一个包含两个数据点及其对应标签的数据集。MulFAGrid对于大多数标签值表现出更紧的泛化界，表明其泛化性能更好。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHeKLrAwg686ll8WlEPTfMicwxXDb6MgiaWZqRJ1wVqP58aDYiayJE7gjpw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">精确度方面，相对于各种基线方法和作者的误差图，MulFAGrid都提供了更准确的拟合，展示了其优越的性能。</div><div class=" pTag">下面的误差图衡量了预测图像与真实图像的差异。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHPib4vYIyk9y2u6wUziasIMKoLhz8IrR8G3bvFibHTTibGX15E1V1l3nVKw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">另外，模型在拟合二维图像和三维符号距离函数（SDF）的性能测试中，MulFAGrid也显现出了较高的准确性和效率。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHqyDr1Ksh0eprykgRSeC5icC7LDQ4q4X3bbsF7JgIicGjwGiao7ffLviaLA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">最后，作者探究了MulFAGrid在新视角合成方面的能力。详细结果表明，MulFAGrid在生成高质量的新视角方面表现出色，突显了其实际应用性。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH0px5aaJzdySAMcN1PiaMCibic8LTxrWhR5cJkqjGRHiaBtX2U9xicAkmNIQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>作者简介</h2><div class=" pTag">本文第一作者<span><strong style="font-weight: 600;">赵泽林</strong></span>，在上海交通大学计算机系获得学士学位，即将进入佐治亚理工学院攻读博士学位。</div><div class=" pTag"><span>赵泽林曾在NeuRIPS，ECCV，CVPR，AAAI等顶会发表四篇一作论文，引用数超过600。</span></div><div class=" pTag">他所在的ReThinklab实验室由上海交通大学人工智能学院与计算机系<span><strong style="font-weight: 600;">严骏驰教授</strong></span>创立，主要研究方向是机器学习及交叉应用。</div><div class=" pTag">严骏驰教授带领实验室发表第一/通讯作者CCF-A类论文超百篇，谷歌引用过万次，获PaperDigest评选的最具影响力AAAI21、IJCAI23论文榜首。</div><div class=" pTag">严骏驰教授长期任机器学习三大会议ICML/NeurIPS/ICLR领域主席，模式识别旗舰期刊TPAMI、PRJ编委。实验室学生获得挑战杯特等奖、CCF优博/CV新锐奖、交大学术之星等荣誉和本科生自然科学基金。</div><div class=" pTag">本文通讯作者来自香港中文大学数学系研究助理教授<span><strong style="font-weight: 600;">范凤磊博士</strong></span>，他所在的Center for Mathematical AI由曾铁勇教授创立。中心自2018年成立以来，在中心主任曾铁勇教授的带领下，先后承担科技部国家重点研发计划项目等一系列关键项目。</div><div class=" pTag"><div class=" pTag">范凤磊博士于美国伦斯勒理工学院（Rensselaer Polytechnic Institute）获得博士学位，导师为国际知名影像专家王革教授，主要研究方向是脑启发智能以及神经网络的数学理论，在JMLR，TMI，TNNLS，TCI等杂志发表论文二十余篇，引用数过千。曾获得IBM AI Horizon Scholarship和国际神经网络协会（INNS）2021年杰出博士论文奖。</div><br /></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">论文地址：</div><br /><div class=" pTag">https://arxiv.org/abs/2403.20002</div></span><br /><span style="font-size: 17px;"><div class=" pTag">项目主页：</div><br /></span><span style="font-size: 17px;">https://sites.google.com/view/cvpr24-2034-submission/home</span><br /></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FuguO12ZGzVMJpH08iBruCw">阅读原文 </a>
]]></content:encoded>
<pubDate>Fri, 14 Jun 2024 09:38:46 GMT</pubDate>
</item>
<item>
<title>规格拉满！Llama和Sora作者都来刷脸的中国AI春晚，还开源了一大堆大模型成果</title>
<link>https://posts.careerengine.us/p/666c0f979bb60c0b040f956b</link>
<guid>https://posts.careerengine.us/p/666c0f979bb60c0b040f956b</guid>
<content:encoded><![CDATA[
<div> 智源大模型、技术进展、开源、智源研究院、AI盛会
<br />
智源研究院举办的智源大会聚集了众多AI领域的顶尖人士，包括Aditya Ramesh、李开复、张亚勤等，展示了智源在大模型领域的最新成果和技术进展。他们发布了多个重磅新进展，包括万亿参数语言模型Tele-FLM、多模态模型Emu3等。智源强调开源开放，致力于解决大模型训练过程中的核心痛点，如算力问题和多模态问题。同时，智源关注具身智能和生物计算领域的发展，并鼓励原始创新与技术共享。通过这些努力和技术路线的选择，智源研究院在中国AI领域具有引领地位，为促进AI技术的发展和落地应用做出了重要贡献。总结: 智源研究院通过举办智源大会展示了在大模型领域的最新技术成果和前沿研究，同时强调开源开放、原始创新和技术共享，为推动AI技术的发展提供了引领力。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">鱼羊 明敏 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">本周国内最受关注的AI盛事，今日启幕。</div><div class=" pTag">活动规格之高，没有哪个关心AI技术发展的人能不为之吸引——</div><div class=" pTag"><strong style="font-weight: 600;">Sora团队负责人</strong>Aditya Ramesh与DiT作者<strong style="font-weight: 600;">谢赛宁</strong>同台交流，<strong style="font-weight: 600;">李开复</strong>与<strong style="font-weight: 600;">张亚勤</strong>炉边对话，<strong style="font-weight: 600;">Llama2/3作者</strong>Thomas Scialom，<strong style="font-weight: 600;">王小川</strong>、<strong style="font-weight: 600;">杨植麟</strong>等最受关注AI创业者……也都现场亮相。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqq0BZWU24wekXMvk0KQmYfC8Nibww4LGN5FEkflujk1Mml36PIBBulpg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">一年一度，中国“AI春晚”智源大会如约而至，依然AI大佬密度拉满，依然干货成果满满当当。</div><div class=" pTag">从学术向的“语言智能与视觉智能融合创造世界模拟器”，到产业向的“大模型价格战有何影响”，活动开启第一个上午，顶级AI学者、专家们的观点交锋已经让线上线下观众直呼过瘾。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqypjoPwr7qmFhWb1qB6OPPYagCfEZ3sys7FfciaXjiaAg64JRl7Ztvibsg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不仅如此，主办方智源研究院，还抛出了一箩筐重磅新进展，<strong style="font-weight: 600;">开源开放</strong>的那种：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">万亿稠密模型TeleFLM核心技术、训练细节、52B版本；</div></li><li><div class=" pTag">原生多模态大模型Emu 3最新成果，以及轻量级图文多模态模型Bunny的参数、训练代码、训练数据；</div></li><li><div class=" pTag">千万级高质量指令微调数据集InfinityInstruct；</div></li><li><div class=" pTag">……</div></li></ul><div class=" pTag">大模型趋势以来，创业公司大厂的动向吸引了诸多关注。</div><div class=" pTag">但更回归技术本身，当下大模型发展还需要关注哪些方面？是时候参考研究机构的动向和理解了。</div><h2>智源大模型“全家桶”发布</h2><div class=" pTag">智源研究院带来的最新发布主要有大模型进展以及底层算力基座。</div><div class=" pTag">智源大模型“全家桶”由4部分组成：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">智源语言大模型</div></li><li><div class=" pTag">智源多模态大模型</div></li><li><div class=" pTag">智源具身大模型</div></li><li><div class=" pTag">智源生物计算大模型</div></li></ul><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbq0SpZTIznbrk9zVJib1m7phyic2Q1l0bgbfg7BIXXznBMRDtZibpgWRfFw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">首先在大语言模型方面，智源表示不会重复造轮子，最新发布的成果主要面向产业界正面临的共同难点，比如<strong style="font-weight: 600;">算力缺乏</strong>问题。</div><div class=" pTag"><strong style="font-weight: 600;">智源与中国电信人工智能研究院（TeleAI）</strong>联合研发了基于生长技术训练的<strong style="font-weight: 600;">全球首个低碳单体稠密万亿语言模型</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqicO4rvqXALcLbtgL5exc226jMicTia9lF61joKvhcShlGXGHu5myQNvcA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">尽管模型参数规模达到万亿级别，但训练实际只用了<strong style="font-weight: 600;">112台A800</strong>，这相当于业界普通训练方案<strong style="font-weight: 600;">9%</strong>的算力资源。</div><div class=" pTag">通过优越超参预测技术，训练全过程零调整、零重试。</div><div class=" pTag">目前Tele-FLM 1TB版本还在训练中，<strong style="font-weight: 600;">中间版Tele-FLM 52B已开源</strong>。</div><div class=" pTag">评估结果显示，在中文方面，Tele-FLM的BPB曲线优于Llama3-70B。英文方面，其BPB评测接近Llama3-70B，优于Llama2-70B。</div><div class=" pTag">之后，团队将开源1TB版本，以及训练技术细节以及loss曲线。以期为开源社区提供一个优秀的稠密万亿模型的初始参数版本，避免万亿参数模型早期难以收敛等问题。</div><div class=" pTag">同时，智源对基于该基座模型训练出的对话模型<strong style="font-weight: 600;">Tele-FLM-Chat（52B）</strong>进行评测。</div><div class=" pTag">AlignBench评测显示，它已达到GPT-4中文语言能力的96%，总体能力可达GPT-4的80%。现在已在ModelScope上可体验。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqHOy4B89QfmN3H0dsVjYmicIBtytHxnicNMzTWFNr3ibXj5R3XsjRwAjvw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">算力之外，大模型应用落地的另一大挑战是幻觉问题。</div><div class=" pTag">在这方面，智源带来了<strong style="font-weight: 600;">通用向量模型BGE</strong>（BAAI General Embedding）。</div><div class=" pTag">该系列模型如今已是全球范围内下载量最高的国产AI模型，也是最普及的开源向量模型之一。</div><div class=" pTag">它基于无监督预训练和多阶段对比学习，构建了多语言关联文本数据集C-MTP。</div><div class=" pTag">从去年8月发布至今，BGE模型得到了全球主流应用大模型框架的集成，包括Hugging Face、LlamaIndex等。如Azure、AWS、火山引擎、腾讯云、华为云、百度智能云等主流云厂商，也都集成了BGE模型，对外提供商用。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqVULa9PU0Te7p1bSpD96jXIICsjibWmkblyPU5sibbvq5sTpJcNsVjdtw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">其次，智源聚焦<strong style="font-weight: 600;">多模态</strong>领域，带来了最新进展——<strong style="font-weight: 600;">Emu3</strong>。</div><div class=" pTag">去年7月，智源研究院发布生成式多模态模型Emu，12月迭代至Emu2。</div><div class=" pTag">最新发布的Emu3采用<strong style="font-weight: 600;">自回归技术路径</strong>，将图像、视频、文字<strong style="font-weight: 600;">共同训练</strong>，统一实现了图像、视频、文字的输入和输出，并且具备更多模态可扩展性。</div><div class=" pTag">它具备图像生成能力、视频生成能力：</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqsprhdM3KJadzeRZ1fQsenLrcQSDciaqMyCR1nFMrPEDDNFMn0ZfaFMA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">并且可以理解图像和视频内容：</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbq4pmX4UuCEgZpU4HY3nk3o3xHPoDG65ZF4ynsibicGL2CU9f76Y4G3ENw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">目前，Emu3还在持续训练中，在经过安全评估后会逐步开源。Emu1和Emu2已经开源。</div><div class=" pTag">另外在多模态方面，智源还带来了一个<strong style="font-weight: 600;">轻量级图文模型</strong>：Bunny-3B/4B/8B。</div><div class=" pTag">该模型采用灵活架构，可基于不同视觉编码器，如EVA-CLIP、SigLIP；也能基于不同的语言基座模型，比如Phi、StableLM等。</div><div class=" pTag"><strong style="font-weight: 600;">Bunny的模型、数据、代码将全部开源</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqfyslGZQu1zXIfDJXpo5TADwyaMibFjR9AmicLrlDoDAdENxvBnzwicBlw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">第三，面向<strong style="font-weight: 600;">具身智能</strong>的终局，智源还带来了一个端到端具身导航大模型，并已在人形机器人上应用。</div><div class=" pTag"><strong style="font-weight: 600;">NaVid是世界首个端到端基于视频的多模态具身大模型</strong>，它实现了“输入视频和语言，输出动作”。它无需离线建图，是纯视觉、纯Sim2Real方案，能在虚拟世界中训练，在现实世界中直接泛化。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqSkIYibkqudVNaPRmibZPpmvBRh8TAInC8ibefgQlkIgGNXXoMlPlBibR4Q/640?wx_fmt=jpeg" /></div></div></div><div class=" pTag">另外智源也关注了具身智能几个关键点。</div><div class=" pTag">比如<strong style="font-weight: 600;">通用抓取模型ASGrasp</strong>。通过在仿真系统内构建千万量级场景以及超过10亿抓取数据，实现了抓取技术显著提升，在工业级真机上能够实现<strong style="font-weight: 600;">超过95%</strong>的抓取成功率，<strong style="font-weight: 600;">打破世界纪录</strong>，该成果已被<strong style="font-weight: 600;">ICRA 2024</strong>接收。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqpfWGJK9QgyNlKhetAE5tLNUx255iaBzwC1exBaMJDNMSJoaweAjllTg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">SAGE模型</strong>是一个操作系统大模型，基于三维视觉小模型和图文大模型，它能让机器人<strong style="font-weight: 600;">在操作失败后进行思考</strong>，就像人一样，然后重新规划动作，进而完成任务。该模型也被ICRA 2024接收。</div><div class=" pTag"><strong style="font-weight: 600;">Open6DOR</strong>则是全球首个开放指令六自由度取放大模型系统，它能让机器人既关注物体的位置，也考虑物体的姿态，从而让抓取更有效。</div><div class=" pTag">基于如上成果，智源的具身智能已经可以理解人类的指令并进行对话、执行任务，比如在听到人类说“我渴了/我饿了”之后，它会递上可乐或橘子。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqVjtiaQ1icZKMExAK9Qo5DCJgicdtibBfQeGwZI9acNquBmXOsibRKNNmEiaQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">在实际落地方面，智源还与清华大学301研究院带来了全球首创智能心脏超声机器人。</div><div class=" pTag">最后，在<strong style="font-weight: 600;">生物计算方面</strong>，智源发布了<strong style="font-weight: 600;">OpenComplex2全原子生物分子模型</strong>。</div><div class=" pTag">这是一个decoder-only模型，它基于生成式AI，能在原子层面对RNA、DNA等小分子的结构和相互关系进行预测，精度可达超算水平。</div><div class=" pTag">在CAMEO蛋白质结构预测竞赛中，OpenComplex已经<strong style="font-weight: 600;">连续26个月稳居第一</strong>，在精度和宏观结构等方面均优于同期模型（如AlphaFold2）。同时也能对RNA、DNA、蛋白质复合物进行预测。</div><div class=" pTag">在与超算结果的对比中显示，OpenComplex已经初步具备通路预测能力。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqdxcY2Jj5nib3vMyibibmudhCVibianF2Ucfia58obIrFEsEXicpa6IFVorU1A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">以上便是智源在过去一年中在大模型领域方面的进展。</div><div class=" pTag">带来这些进展其实都离不开<strong style="font-weight: 600;">底层算力基座</strong>的支持。</div><div class=" pTag">去年，智源发布了FlagOpen1.0。这是一个面向异构芯片、支持多种框架的大模型全栈开源技术基座。</div><div class=" pTag"><strong style="font-weight: 600;">今年FlagOpen升级至2.0版本</strong>。在1.0的基础上，进一步完善了模型、数据、算法、评测、系统五大版图布局，旨在打造大模型时代的Linux。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqAqHQJiaDApBeTJrmZktNX6XeyxWjUSCsI3f74Ahfb4fLzdyxaIoIkMA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">同时，智源也构建了为大模型而生、支持异构芯片的算力集群“操作系统”<strong style="font-weight: 600;">FlagOS</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqH9MUA0iczo7AiaQ4MUXqSKcibt7icFEfbSsklg4I5sA28th78I5OnIJwcA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">它包括异构算力智能调度管理平台九鼎、支持多元AI异构算力的并行训推框架FlagScale、支持多种AI芯片架构的高性能算子库FlagAttention和FlagGems，集群诊断工具FlagDiagnose和AI芯片评测工具FlagPerf。</div><div class=" pTag">可向上支撑大模型训练推理评测等，向下管理底层异构算力、高速网络、分布式存储等。</div><div class=" pTag">目前，FlagOS已支持了超过50个团队的大模型研发，支持8种芯片，管理超过4600个AI加速卡，稳定运行20个月，SLA超过99.5%。</div><div class=" pTag">此外，智源研究院还推出了开源Triton算子库、首个千万级高质量开源指令微调数据集InfinityInstruct、全球最大开源中英文多行业数据集IndustryCorpus等等新进展。</div><div class=" pTag">可见在过去一年中，智源研究院的脚步走得非常快、且布局广泛。</div><div class=" pTag">而值得关注的是，在发布新进展同时，智源研究院这一国内顶级AI研究机构，此次也明确地公布了<strong style="font-weight: 600;">对未来技术趋势的判断</strong>。</div><h2>面向更前沿技术问题</h2><div class=" pTag">与大模型领域的工业界玩家不同，智源研究院是一家非营利研究机构，相较于短期应用，更聚焦AI的前沿研究。</div><div class=" pTag">在与<strong style="font-weight: 600;">智源研究院院长王仲远</strong>的交流中，他对此解释说：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">企业已经在做的事，智源不会做，而是聚焦于更前沿的技术问题。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqmFLrfcU0XTYWWMm7SrflLJx5b0WiaZer9pOD7cALRUrmm7CSAZvEicHA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">总结起来，智源对技术路线发展的判断很明确：</div><div class=" pTag">在基础模型层面上，是要解决大语言模型发展过程中面临的核心痛点。</div><div class=" pTag">比如<strong style="font-weight: 600;">算力问题</strong>。</div><div class=" pTag">2023年9月，智源研究院就联合中科院计算所、南洋理工大学、电子科技大学、哈尔滨工业大学等研究团队，提出了一种“<strong style="font-weight: 600;">生长策略</strong>”（growth strategy）。</div><div class=" pTag">简单来说，基于生长策略，模型的参数量在训练过程中并不是固定的，而是可以随着训练进行，从较小的参数规模扩展到更大的参数规模。</div><div class=" pTag">这次发布的稠密万亿参数语言模型<strong style="font-weight: 600;">Tele-FLM</strong>，就是通过生长技术来训练的。王仲远透露，训练这一模型只用了112台A800，也就是不到1000张卡。</div><div class=" pTag">又比如<strong style="font-weight: 600;">多模态问题</strong>。</div><div class=" pTag">尽管多模态已经成为当下大模型发展的主流方向，但在现阶段，很多多模态大模型其实是单一跨模态模型，无法同时实现视频、图片的生成和理解。</div><div class=" pTag">智源的<strong style="font-weight: 600;">Emu</strong>项目，旨在最终实现原生多模态世界模型。</div><div class=" pTag">从训练数据的角度，从一开始，文字、图像、视频数据就被放在一起联合训练；从技术路线的角度，智源也选择了难度更高的自回归路线而非Sora带火的DiT路线。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag"><div class=" pTag">我们认为，像OpenAI，未来也可能会将ChatGPT和Sora做进一步的融合。</div><br /><div class=" pTag">从技术判断上，我们想要瞄准真正的多模态大模型，因此选择了自回归这样一个我们认为终极的技术路线。</div></div></blockquote><div class=" pTag">而在更具体的应用层面上，重点关注<strong style="font-weight: 600;">具身智能和生物计算</strong>， 也并非是单纯追热点。</div><div class=" pTag">王仲远甚至主动降了一波预期：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">大家要客观理性地来看待技术的发展周期，具身智能未来几年内也可能进入低谷。但我们坚信智能体会从数字世界进入到物理世界。</div></blockquote><div class=" pTag">有此布局的核心原因还是要做“<strong style="font-weight: 600;">原始的创新</strong>”、“集中资源关注核心技术的突破”，智源研究院认为，数字世界的智能体进入物理世界，主要有两条路线：</div><div class=" pTag">一是在宏观世界赋能硬件，也就是具身智能。</div><div class=" pTag">二是进入微观世界，也就是用大模型对生命分子进行研究。</div><div class=" pTag">这两条技术路线“会跟世界模型相互促进，并且最终实现AGI”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqDR7PrDZ2z4czdJWq39o1DMQC3y0diahfdiasE4kPiccQ7l1HbShLmJKjA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">值得关注的是，在更面向未来的技术路线选择之外，智源研究院在最新发布中，再次强调了<strong style="font-weight: 600;">开源开放</strong>。</div><div class=" pTag">比如<strong style="font-weight: 600;">Tele-FLM</strong>的核心技术“生长策略”，其技术细节此前就已完全公开。此番发布的多模态图文模型Bunny，同样是基座模型、模型参数、训练代码、训练数据全部开源。Tele-FLM的万亿参数版本和Emu 3也计划在安全评估之后对外开源。</div><div class=" pTag">事实上，无论是高举高打的技术布局思路，还是一以贯之的技术共享模式，都是智源研究院创立之始就<strong style="font-weight: 600;">刻写在基因里</strong>的。</div><div class=" pTag">2018年，智源研究院作为人工智能领域的新型研发机构正式成立，其使命可以概括为：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">推动5大源头创新，包括基础理论、学术思想、顶尖人才、企业创新和发展政策。</div></li><li><div class=" pTag">改变人工智能下一个10年，包括人才到生态，成果到系统。</div></li><li><div class=" pTag">创造30年后依然有价值的代表作：判断人工智能发展大方向，创造经得起时间检验的代表作。</div></li></ul><div class=" pTag">2020年，智源“悟道”项目立项。2021年3月，悟道1.0发布，智源研究院正式使用“大模型”这个说法，此后被业界广泛采纳。</div><div class=" pTag">而<strong style="font-weight: 600;">悟道系列开源大模型</strong>，也成为过去一年中国产大模型快速发展的技术基石之一。一方面，悟道的7个开源模型成果涵盖文本类、图文类、蛋白质类等多个领域，在发布时连续创下“中国首个+世界最大”记录。另一方面，悟道系列也为中国大模型产业培养了一大批大模型人才，不少现如今在产业界担当主力的大模型研究者，都是“智源系”出身。</div><div class=" pTag">可以说，智源研究院是最早系统布局大模型研究的国内科研机构之一，是中国大模型研究的启蒙先行者。</div><div class=" pTag">大会现场，几位国内AI大咖也对此有颇多感慨。</div><div class=" pTag"><strong style="font-weight: 600;">杨植麟</strong>提到，智源研究院至少是在亚洲地区最早投入、而且真的投入去做大模型的机构。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">这是非常难得、非常领先的一个想法。</div></blockquote><div class=" pTag"><strong style="font-weight: 600;">王小川</strong>觉得，智源在中国大模型产业中有着非常好的定位。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">智源既有技术高度，又有智库的角色。这两方面有独有的意义，在生态里能够帮助我们更加快速健康的发展。</div></blockquote><div class=" pTag"><strong style="font-weight: 600;">李大海</strong>则提到，在大模型领域的快速发展过程中，有一些事可能商业公司没有动力、没有资源去做。从创企角度出发，非常期待在智源的撮合跟带领下，搭建一个更好的平台，把需要做好的事情一起协作好。</div><div class=" pTag"><strong style="font-weight: 600;">张鹏</strong>表示，非常非常希望跟智源长期在学术研究、落地应用合作，甚至包括公共政策相关方面继续保持合作，也祝愿智源大会越办越好。</div><div class=" pTag">也正是这样的技术领导力和技术影响力，使得智源研究院成为国内最具国际号召力的研究机构之一。一年一度的智源大会，已然成为国内国际顶尖AI学者交流的重要平台。</div><div class=" pTag">2019年首届智源大会起，每年都不乏图灵奖得主、明星项目大咖、行业关键人物现身这场“AI春晚”。深度学习三巨头、贝叶斯网络提出者Judea Pearl、RISC-V掌门人David Patterson……都曾先后参与其中，带来精彩观点的碰撞。</div><div class=" pTag">今年，是智源大会举办的第6年，现场依旧爆满，足见其在AI从业者和相关专业学生中的影响力。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtChMAEcGFEaBe65rhWSCCbqup5slSvW22lhozupsVUtmzKopwbqw21Eeo3mPTv0IjDcibS2Elsh7kg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">如果说，过去顶级的AI学术、交流活动都远在大洋彼岸，现在，就在中国，就在北京，以智源大会为代表，我们也有了属于自己的顶级AI盛会。</div><div class=" pTag">在探讨多模态大模型、AGI的全体大会之外，今年的智源大会依然围绕大家最关注的前沿技术问题，设置了大模型产业技术、Agent、具身智能、数据新基建等等分论坛和技术报告。</div><div class=" pTag">如果你感兴趣，更多详情，可以关注：</div><div class=" pTag">https://2024.baai.ac.cn/schedule</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FHLWfFesci_ITsbin5H_iAw">阅读原文 </a>
]]></content:encoded>
<pubDate>Fri, 14 Jun 2024 09:38:31 GMT</pubDate>
</item>
<item>
<title>一句话手机自己打车，开源多智能体AI助手，非苹果手机也能玩</title>
<link>https://posts.careerengine.us/p/666ab2ccb4716273209f1d44</link>
<guid>https://posts.careerengine.us/p/666ab2ccb4716273209f1d44</guid>
<content:encoded><![CDATA[
<div> Mobile-Agent团队, 量子位, 公众号, QbitAI, v2版本更新

<br /><br />总结:
Mobile-Agent团队在量子位公众号上介绍了他们新一代Mobile-Agent-v2的技术成果。该系统实现了在手机操作任务上的自动化，具有多智能体架构和记忆单元等特点。通过演示视频展示了系统在各种任务上的表现，包括跨应用操作和社交媒体平台等。此外，作者介绍了系统的背景和架构设计，包括规划智能体、决策智能体和记忆单元的作用。作者还展示了系统在英文和非英文环境下的评测结果，证明了系统的性能提升。最后，作者发布了系统的代码和论文，并将系统接入到ModelScope-Agent中。整体来看，Mobile-Agent-v2在手机自动化操作领域取得了显著的进展。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">Mobile-Agent团队 投稿</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">一句话让<span><strong style="font-weight: 600;">AI自动化操作手机</strong></span>，打个车已经不是难事了。</div><div class=" pTag">从官方公布的演示视频来看，用户只需要说出目的地，Agent就能够通过规划、决策和反思的流程自动化帮用户完成目的地输入，呼叫车辆等操作，适用于老人及视障人群，解决他们不会使用或者无法使用手机APP的问题。</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-127"></div></div><div class=" pTag">这项成果来自阿里通义实验室Mobile-Agent的v2版本更新，具体来说，本次升级有三大亮点：</div><ul class="list-paddingleft-1" style="font-size: 17px; text-align: start;"><li><div class=" pTag">首次在手机操作任务上采用多智能体架构，并延续了一代的纯视觉方案</div></li><li><div class=" pTag">多智能体各司其职，实现了更有效的任务进度追踪、任务相关信息记忆和操作反思</div></li><li><div class=" pTag">更强大的复杂指令拆解能力、跨应用操作能力和多语言场景操作能力</div></li></ul><h2>任务难度提升，v2也能搞定</h2><div class=" pTag">首先我们关注一下Mobile-Agent-v2的演示效果。从作者团队发布的演示视频来看，Mobile-Agent-v2能够完成的任务难度相比于Mobile-Agent有明显的提升。下面将展示部分演示视频中的例子。</div><div class=" pTag">在跨应用操作任务上，作者展示是查看聊天软件中的未读消息，并按照未读消息的要求完成任务，其中未读消息需要分享一个TikTok中宠物相关的视频给消息发布者。</div><div class=" pTag">该任务的难点在于，指令的一部分存在于聊天软件的未读消息中，并且分享的链接需要从另一个应用中发送给当前聊天软件的消息发布者。</div><div class=" pTag">从演示视频来看，Mobile-Agent-v2先是打开了WhatsApp并查看了未读消息。在得知需要从TikTok中找视频并分享后，Mobile-Agent-v2退出当前应用并进入TikTok中刷视频来寻找宠物相关的视频。在找到视频后，通过分享按钮将视频链接成功发送到WhatsApp的消息发布者的聊天界面内。</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-135"></div></div><div class=" pTag">接下来是一个社交媒体平台的例子。</div><div class=" pTag">社交媒体平台作为手机应用中日活跃量最大的应用类型，往往具有信息量大、界面复杂、干扰信息多等特点。</div><div class=" pTag">作者展示的是搜索名人“马斯克”，关注他并且评论一个他的帖子。Mobile-Agent-v2首先准确地找到了搜索界面。在输入“Musk”后，候选项中出现了大量的干扰选项，而Mobile-Agent-v2根据人物的全名和头像选择了目标名人，随后点击了关注。</div><div class=" pTag">在点击关注之后，出现的推荐关注列表挡住了原来的帖子，而Mobile-Agent-v2仍然能正确理解界面，通过上划的方式找到了帖子，最终完成了评论。</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-139"></div></div><div class=" pTag">此外，作者还展示了一个在YouTube上完成类似关注和评论的任务。从上述演示视频来看，Mobile-Agent-v2对于社交媒体和视频平台的操作能力十分惊艳。</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-140"></div></div><div class=" pTag">另外，在初代Mobile-Agent中评测的那些任务，例如导航、下载安装应用等，Mobile-Agent-v2也能轻松完成。</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-141"></div></div><div class=" pTag">最后，作者还展示了Mobile-Agent-v2在中文应用上的表现，包括在小红书中搜索攻略并评论，以及帮助用户回微信。Mobile-Agent-v2可以根据帖子的内容发布相关的评论，也能根据微信消息的内容生成相关的回复，相比于传统的评论和回复机器人更灵活。</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-143"></div></div><h2>规划智能体+记忆单元</h2><div class=" pTag">接下来我们将介绍Mobile-Agent-v2的背景、架构设计和操作流程。</div><div class=" pTag">在一次手机操作任务中，智能体往往需要多步操作来完成任务的要求。在每次操作时，智能体都需要跟踪当前任务的进度，即过去的操作具体完成了什么需求，以此来结合用户的指令来推理出下一步的操作目意图。</div><div class=" pTag">虽然在操作历史中保存有每一步的具体操作和操作之后的屏幕状态，但是随着操作轮数的增加，操作历史的序列将逐渐变长。冗长并且图文交错格式的操作历史，会大大增加智能体追踪任务进度的难度。</div><div class=" pTag">如下图所示，在完成了7轮操作后，输入的操作历史的序列长度已经有一万多token，加之图文交错的数据格式，对于智能体追踪任务进度是十分困难的。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fjx8p14hzPWGCjHQ8czDXRwUYicAhC6dAIPcWFMj3IELCTia4r6lh6BowQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">因此，Mobile-Agent-v2引入了规划智能体的角色，如下图所示，它会为操作智能体提供一份任务进度，从而将长的操作历史转化为纯文本的格式。</div><div class=" pTag">然而，规划智能体虽然简化了任务进度追踪，但是也导致了丢失了历史操作中的屏幕信息，这使得决策智能体无法检索到来自历史屏幕中的任务相关信息。例如在上图的任务中，需要智能体查看天气并写一份穿衣指南。而在生成穿衣指南时，历史屏幕中的天气信息需要被利用。</div><div class=" pTag">因此，Mobile-Agent-v2引入了记忆单元，并由决策智能体更新单元内的任务相关信息。此外，由于决策智能体无法观察操作后的屏幕信息，Mobile-Agent-v2引入了反思智能体来观察决策智能体操作前后的屏幕状态变化，并决定操作是否正确。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjvYfaD4aUKmwPmickpAHMCNnx0fL9ZEENQESU09zxpulbf6jatnDvz0A/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">在论文中，作者采用了动态评估，分别在英文和非英文应用上选择了5个系统内置应用和5个第三方应用，每个应用设计了2条基础指令和2条进阶指令。</div><div class=" pTag">同时，针对跨应用操作也设计了2条基础指令和2条进阶指令。英文场景和非英文场景的评估效果如下表所示。从结果中可以看出，Mobile-Agent-v2无论在英文场景还是非英文场景，无论是基础指令还是进阶指令，在多个指标上都获得了全面的提升。</div><div class=" pTag">此外，通过人工引入额外的操作知识，能进一步提升性能（Mobile-Agent-v2 + Know.）。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fjia7XrJsKicDliaEiaCRkXwqKS2gHasCIzicvr6wlu88Cib7IR0e6MgK5yjOg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fjwrnb4WSrnd9j7WKdMlr6lzwppSsTC6WjSicIjLdGyb5SXYiaHnHv80pg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">作者在文章中展示了消融实验的结果，如下表所示，在去除规划智能体、决策智能体和记忆单元后，整个智能体的性能都出现了下降。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fj7al1E784phKvkO3skQoAiagfzcXjqXhYW8PnTUu06icdj72BV7lFa8QQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">如下图所示通过分析操作失败的任务，作者发现Mobile-Agent的失败操作大量集中在后程，而Mobile-Agent-v2则相对平均。这说明了Mobile-Agent-v2能更有效地解决长序列带来的问题。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjFkTfIrTia9rWGTiazR6FI53G1ZzKFjHp79Q3d4R7Hmz9lN4bhFkKd6ibA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">最后，文章展示了一个完整的操作流程和一个反思成功的例子，其中包括了每个角色的输出。更多的例子展示在文章的结尾部分。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjmC9PM99aib14pXYbDVQUtHziadUibjNIlka8sd0GrNRicyxgK77MhIu8icg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">Mobile-Agent-v2的代码和论文现已发布，相关链接如下：&nbsp;</div><div class=" pTag">论文：https://arxiv.org/abs/2406.01014</div><div class=" pTag">代码：https://github.com/X-PLUG/MobileAgent</div><div class=" pTag"><div class=" pTag">除此之外，Mobile-Agent-v2也已经接入到魔搭的ModelScope-Agent中：</div><br /><div class=" pTag">https://github.com/modelscope/modelscope-agent</div></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FpxDGqL6HuOc1ORn4XdSn4Q">阅读原文 </a>
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 08:50:20 GMT</pubDate>
</item>
<item>
<title>Stable Diffusion 3开源秒翻车，画人好掉san</title>
<link>https://posts.careerengine.us/p/666ab2bc56528d72b24cedb0</link>
<guid>https://posts.careerengine.us/p/666ab2bc56528d72b24cedb0</guid>
<content:encoded><![CDATA[
<div> 稳定扩散3、翻车、数据集、人体结构、Stability AI<br />明敏 发自 凹非寺量子位 | 公众号 QbitAI<br />Stable Diffusion 3开源后出现翻车案例，生成结果不佳。数据集可能过于严格审核，导致模型无法理解人体结构，影响整体质量。Stability AI内部混乱，CEO辞职，团队离职，公司面临现金短缺。SD3开源中杯版本，性能欠佳暴露混乱。公司欠债1亿，疑似求卖身。未来会推出更大版本4B和8B，效果未知。总体来说，Stable Diffusion 3发布不顺，暴露出了不少问题，值得关注。<br />总结: 稳定扩散3开源后在生成结果、内部混乱和现金短缺等方面存在问题。可能由于严格数据集审核和公司团队动荡导致性能不佳，欠佳的发布引起了关注。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">明敏 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">没想到……<strong style="font-weight: 600;">Stable Diffusion 3</strong>开源即出现翻车案例。</div><div class=" pTag">生成一个躺在草地上的女孩，结果长这样？</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH43YAKn5Paab98Jsh8rasAoibaIAbJcbgbMmbWR4YjYlwh6j1icQibXKng/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而且不是个例，只要是和人<span>（整体）</span>相关的内容，生成结果都有点掉san。</div><div class=" pTag"><span style="text-align: center;">（<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://res.wx.qq.com/t/wx_fed/we-emoji/res/v1.3.10/assets/newemoji/Terror.png" /></div></div></span><span style="text-align: center;">前方高能<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://res.wx.qq.com/t/wx_fed/we-emoji/res/v1.3.10/assets/newemoji/Terror.png" /></div></div></span><span style="text-align: center;">）</span></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH1trtqFrqCN6wbHVMqTfVFD8Cx8iaOeNbSWhmO04DEBBg8b4fRRBDpicA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">但如果是局部，比如只生成人脸，确实很nice。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH8pYibqh3f6BYWdOIeetuCglHNRA0IficWUibJgoYQQKn2NYic1L9aia4lxg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">清晰度、写字、写实性等方面都有明显提升。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHXp47aAQcyEREgibe5rZsIDs6pxjELpCbDyMxGrX4vwLlSia0h3TTwWGw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">对于复杂长提示词的理解也很到位，有网友发现提示越长它画的越好。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHpqpsKYbwyHURVR6DDQ5Vh6brPvdiakxBEDVelXA7GhbaWILQKfKN2Jg/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHJDWmhfdyAqqYicbpMMZzlcuEueJ1red3GeKficxibS8UuZaUjDTTlicIwQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">那么问题来了，为啥偏偏画不好人类？</div><h2>问题可能在于数据集</h2><div class=" pTag">先来看看SD3开源的具体情况。</div><div class=" pTag">本次开源的版本是<strong style="font-weight: 600;">Stable Diffusion 3 Medium</strong>（中杯）。</div><div class=" pTag">它的规模为<strong style="font-weight: 600;">20亿</strong>参数，在笔记本上就能跑了。</div><div class=" pTag">官方强调的属性有5方面，逐一来看：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">整体质量和写实性</div></li></ul><div class=" pTag">可生成出色的细节，包括色彩、光线、强写实等，带来灵活风格的高质量输出。</div><div class=" pTag">通过16通道VAE，成功解决了其他模型的常见缺陷，比如手部和面部的写实问题。</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">提示词理解</div></li></ul><div class=" pTag">可以理解复杂长提示，包含空间推理、元素组合、动作、风格等。3个文本编码器可以全部或者组合使用，方便用户平衡性能和显存。</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">有效利用资源</div></li></ul><div class=" pTag">对VRAM占用很低，非常适合在消费级GPU上运行，且性能不降低。</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">微调</div></li></ul><div class=" pTag">能够利用小数据集微调，方便定制化。</div><div class=" pTag">目前在Hugging Face上已经可以下载模型权重。非商业用途可免费下载使用，商业用途需要先拿授权。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHkyF5TtTGKb7FiaTUTkZ6plVOjnSEEiablgKBBLPQiao2hRIO8MPC9zicdQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么为啥升级后还是会翻车？</div><div class=" pTag">有人发现，如果细看“躺在草坪上的女孩”这张图像，会发现它在局部细节上确实还可以，甚至很棒。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHvSfwIwGbuty1jLKCYwIchs5NCKS5VnvkX60J3V3uJ2hw3PIDT78OnQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">草地上的影子、衣物上反射的光线、头发的质地……都遵循了物理规律。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHxr1TCiahicJEeiamwX1aGmvuicHLXyNZLhODiaBV8EKXjp0RgafR5Zx04bQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">但人物整体就不敢恭维了。</div><div class=" pTag">不少网友都认为，这就是问题的关键。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我认为他们的NSFW过滤器，把所有人类图像都判定为了NSFW。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH2FwVV0ibIKDDJcM74OxeMa2FhqibPuY2hgaQOlvCWyHOCyOu0WxDiaDYA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这个过滤器全称是<strong style="font-weight: 600;">filtering out adult content</strong>，作用在于过滤掉不合规的成人内容。</div><div class=" pTag">SD2发布时就出现过类似的问题，研究人员发现审查这部分内容可能影响了模型对人体结构的理解。</div><div class=" pTag">后面的SD2.1和SDXL版本有所缓解。</div><div class=" pTag">这次SD3的翻车，暴露了一个问题：过于严格的数据审核，可能<strong style="font-weight: 600;">误删了一些无害的成人图像</strong>，所以现在模型没法理解人体结构。</div><div class=" pTag">有网友就阴阳说，没多久之前SD还能和Midjourney竞争，现在一比，就像个笑话。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">至少我们的数据集是安全和合乎道德的。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHTlFDKv0X4icB5VlgAdnKmKb42aTgDZ6nonj0sNibxdqYqty1I2vWibP9Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">Reddit上“<strong style="font-weight: 600;">SD3-2B发布是个笑话吗</strong>”的帖子，热度已经冲到了800+。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHO2qOKsTlQIPZP7iayjHIQiaHIHlHWp8FlEcmLDiaYcPaSx78zLlRAoQTA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">当然，除了技术以外的原因，还不少人觉得SD3的性能不佳更进一步暴露了Stability AI的内部混乱。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我猜他们现在可以安全合规地破产了。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH69k3XIDvNyuMaWP9Ya04eraG3XjnkOaH4hXYeiaTSeQTUqXAbxyzylg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>欠债1亿、疑似求卖身</h2><div class=" pTag">Stability AI的动荡，从SD3开源的一再延期就能窥见端倪。</div><div class=" pTag">2月发布模型后，一开始，官方说的是搞完RLHF就开源，结果大家伙等了3个多月，官方放出的还是只有API。直到现在，才开源了一个中杯版本。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHWTltibYuDBvqv0bPM0M1fcm0bgtzoaXDqTuHUalnsoYicWe3rqyKfeSg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">与此同时，公司CEO Emad辞职+退出董事会。核心团队也被曝集体离职。</div><div class=" pTag">今年5月，据The Information消息，这家初创公司已经面临严重现金短缺：第一季度收入不到500万美元，而亏损超过了3000万美元。同时欠了云厂商和其他企业近1亿美元，“求卖身”的消息不断传出。</div><div class=" pTag">值得一提的是，消息称SD3还将开源更多版本，包括4B和8B。</div><div class=" pTag">不知道更大版本效果会如何呢？</div><div class=" pTag"><span style="font-size: 17px;">官网传送门：https://stability.ai/news/stable-diffusion-3-medium</span></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://www.reddit.com/r/StableDiffusion/comments/1de85nc/why_is_sd3_so_bad_at_generating_girls_lying_on/</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://x.com/benjedwards/status/1800974616611184884</span><br /><span style="font-size: 17px;">[3]</span><span style="font-size: 17px;">https://www.reddit.com/r/StableDiffusion/comments/1de7lbg/comment/l8a1me0/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button</span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div class=" pTag"><span style="font-size: 17px;">— <strong style="font-weight: 600;">完</strong> —</span></div></div></div><div style="font-size: 17px;"><div class=" pTag"><span><strong style="font-weight: 600;">量子位年度AI主题策划</strong></span>正在征集中！</div><div class=" pTag">欢迎投稿专题&nbsp;<strong style="font-weight: 600;">一千零一个AI应</strong><strong style="font-weight: 600;">用</strong>，<strong style="font-weight: 600;">365行AI落地方案</strong></div><div class=" pTag">或与我们分享你在<strong style="font-weight: 600;">寻找的AI产品</strong>，或发现的<strong style="font-weight: 600;">AI新动向</strong></div></div><div style="text-align: center;"><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div></div></div><div class=" pTag" style="text-align: center;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4xgEBx-hWXaMyTPLgEsPHg">阅读原文 </a>
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 08:50:04 GMT</pubDate>
</item>
<item>
<title>2.5％KV缓存保持大模型90％性能，大模型金字塔式信息汇聚模式探秘｜开源</title>
<link>https://posts.careerengine.us/p/666ab2bb56528d72b24ceda8</link>
<guid>https://posts.careerengine.us/p/666ab2bb56528d72b24ceda8</guid>
<content:encoded><![CDATA[
<div> 缓存分配 方案 显存 KV cache PyramidKV
<br /><br />
总结: 该文章介绍了一种名为PyramidKV的新型缓存分配方案，能够有效解决大模型中KV缓存占用显存过高的问题。PyramidKV通过在不同Transformer层动态分配KV缓存预算，根据注意力模式选择要缓存的KV，实现了显著的性能提升。研究团队在LongBench测试中发现，PyramidKV在各种KV缓存大小设定下均优于baseline，尤其在保持性能的场景下表现突出。实验结果还显示，PyramidKV在长上下文输入任务中取得显著优势，并在上下文学习任务中表现出更好的性能。总体而言，PyramidKV能够用较少的KV缓存保持大模型的性能，并且在多个任务中取得了优异的结果，对于解决内存受限和模型性能之间的权衡问题具有重要意义。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">蔡泽凡 投稿</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">用KV缓存加速大模型的显存瓶颈，终于迎来突破。</div><div class=" pTag">北大、威斯康辛-麦迪逊、微软等联合<span>团队提出了全新的缓存分配方案，只用</span><strong style="font-weight: 600;"><span>2.5%的KV cache</span></strong><span>，就能保持大模型90%的性能。</span></div><div class=" pTag">这下再也不用担心KV占用的显存容量过高，导致显卡不够用了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqEEnsfibjgXMJBzMVWqWVkcFllLxva8Ha2EKiaqJE9D3vkslB4iblIayAg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">该方法名为PyramidKV，顾名思义，在KV缓存压缩的过程中融入了金字塔型的信息汇聚方式。</div><div class=" pTag">在内存受限的情况下，PyramidKV表现非常出色，既保留了长上下文理解能力，又显著减少了内存使用。</div><div class=" pTag">目前，PyramidKV相关代码已经在GitHub开源。</div><h2>引入金字塔信息汇聚方式</h2><div class=" pTag">随着模型尺寸的增大，推理需要的时间越来越多。KV cache作为推理加速的关键技术，通过缓存之前的解码步骤中计算出的Transformer的K和V矩阵减少后续解码时间。</div><div class=" pTag">但是，随着序列长度增大，需要缓存的KV cache会快速增长，占用大量显存。针对这一问题，之前的工作设计策略是对KV cache进行压缩。</div><div class=" pTag">实际上，长文本的推理加速和显存节省作为一个重要的话题，这涉及到广泛的大模型下游应用，比如检索增强生成（Retrieval-Augmented Generation）、上下文学习（In-Context Learning）受到广泛关注。</div><div class=" pTag">KV cache及KV cache的压缩能否有效帮助长文本实现推理加速成为广受关注的研究方向。</div><h3>采用均一压缩策略，是最佳方案吗？</h3><div class=" pTag">传统压缩方法的一个共同特点是，均对每个Transformer层使用同样的KV cache压缩设置，使用同样的方法压缩到同样的长度。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqogKdmeJ9Fxtywk94sP93P0ich0ysUEd8TTMukEK95XjrvcOd3pveOBA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">但PyramidKV团队发现，对KV cache进行极致压缩情况下上述方法的表现，发现当超长文本压缩到极致小的KV大小时（从32k 长度压缩到64，即保留0.2%的KV cache长度）时，会面临严重的性能减弱。</div><div class=" pTag">于是作者提出了疑问：对每个Transformer层将KV cache压缩到同样的大小是否为最优方案？</div><div class=" pTag">为了回答上述问题，研究团队对大模型进行检索增强生成的机制进行深入分析。</div><div class=" pTag">作者研究了Llama模型进行多文档问答的逐层注意力图，发现了注意力层中的<strong style="font-weight: 600;"><span>金字塔形信息汇聚模式</span></strong><span>（Pyramidal Information Funneling）</span>的存在：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">在模型的低层（例如第0层）中，注意力得分呈现近似均匀分布，这表明模型在较低层时从所有可用内容中全局聚合信息，而不会优先关注特定的段落。</div></li><li><div class=" pTag">当编码信息进行到中间层（6-18）时，逐渐转变为聚焦在段落内部的注意力模式 (Localized Attention)。在这个阶段，注意力主要集中在同一文档内的Token上，表明模型在单个段落内进行了段落内部的信息聚合。</div></li><li><div class=" pTag">这种趋势在上层（24-30）继续并加强，本文观察到了“Attention Sink”和“Massive Activation”现象。</div></li></ul><div class=" pTag">在这些层中，注意力机制极大地集中在少数几个关键Token上，因此只需要保留这些关键Token就能让输出保持一致并且减少显存占用。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnq3y1L5vLyibThq3apGob1hfM9jYRXWWJqPlDc7AO4GrKUrZFmwaUzlpQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这种注意力分配模式，即极高的注意力得分，表明模型已将信息聚合到这些关键标记中。</div><div class=" pTag">这种注意力现象显示了大模型对大量复杂的信息的进行编码的机制，最终得到生成准确答案所需的最关键信息。</div><div class=" pTag">根据以上的发现，作者认为之前的工作对所有Transformer层统一处理是低效的，因此不同Transformer层的注意力稀疏程度并不相同。在低层能观察到特别稠密的注意力，而在较高层则可以观察到非常稀疏的注意力。</div><div class=" pTag">因此，在不同层之间使用固定的 KV 缓存大小可能会导致性能不佳。这些方法可能在较高层的稀疏注意力中保留许多不重要的 tokens，而忽略了较低层密集注意力中的许多重要的 tokens。</div><h3>每层注意力特点不同，分层施策才是正解</h3><div class=" pTag">于是，作者选择了通过基于注意力模式动态分配缓存预算来提高压缩效率。</div><div class=" pTag">具体而言，PyramidKV在信息更加分散的较低层分配更多的KV cache缓存，而在信息集中于少数关键tokens的较高层减少KV cache缓存。</div><div class=" pTag">一旦为每一层确定了KV缓存预算，PyramidKV在每一个Transformer层中选择根据注意力选择要缓存的KV。</div><div class=" pTag">最后的部分Token的KV缓存，即Instruction Token，会在所有Transformer层中保留。</div><div class=" pTag">根据UIUC、普林斯顿等提出的SnapKV方法，剩余的KV的选择由从这些Instruction Token中获得的对其他的Token注意力分数来指导——</div><div class=" pTag">接收到更高注意力分数的Token被认为与生成过程更相关，因此其KV状态优先保存在GPU缓存中。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqTK7PSE12AGOq8tTY1rRCY3Er4TnyaFlibHqibH1y0H1j5T8GRuJ80rGg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>2.5%的KV cache，保持90%模型性能</h2><div class=" pTag">为了评估PyramidKV的表现，作者使用最新的开源大模型Llama-3-8B-Instruct和Mistral-7B-Instruct，来对PyramidKV和其他方法进行对比。</div><div class=" pTag">测试示例以生成格式进行评估，所有任务的答案均通过贪婪解码生成，并使用 LongBench来评估PyramidKV在处理长上下文输入任务中的表现。</div><div class=" pTag">LongBench是一个精心设计的基准测试套件，用于测试语言模型处理长文档和复杂信息序列的能力。</div><div class=" pTag">该基准测试旨在对长上下文输入进行多任务评估，包括17个数据集，涵盖单文档问答、多文档问答、摘要生成、少样本学习、合成数据和代码生成等任务。</div><div class=" pTag">数据集的平均输入长度从1235个到18409个tokens不等，需要大量的内存来管理KV缓存。</div><div class=" pTag">对于所有这些任务，作者都遵循 LongBench推荐的标准指标。</div><div class=" pTag">结果，在64、96、128、256和512个KV cache缓存大小的设定下，PyramidKV在LongBench中均取得了优于baseline的效果。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqHXQEd5hffDj5vzDca41f8Qqvd6VQzStBfTk2XlS38RIGb3AI2V7tvQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在此基础上，作者还研究了两种不同的操作场景——节省内存场景<span>（Memory-Efficient Scenario）</span>和保持性能场景<span>（Performance-Preserving Scenario）</span>，分别用于在内存和模型性能之间进行权衡。</div><div class=" pTag">PyramidKV在Longbench的多个任务和平均得分上均取得了优于baseline的效果。</div><div class=" pTag">值得注意的是，PyramidKV在size为128的设定下，在TREC任务<span>（上下文学习问答挑战）</span>中表现出显著优越的性能，相较于baseline，提高了20.的ACC结果。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqr5SAOicqMZAe6uIUX9QyHsLSsHHrpwfxvmicRkP5iae3ws9iaHyaEbshfw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">总体而言，PyramidKV仅用12%的KV缓存就能保持完整的性能，并且在各种KV缓存大小的设定下和不同主干模型中始终优于其他方法，特别是在仅保留约128<span>（0.7%）</span>KV cache缓存的节省内存场景中，其性能优势尤为明显。</div><div class=" pTag">在具体任务的检查中，PyramidKV在TREC任务<span>（上下文学习问答挑战）</span>中表现出显著优越的性能，仅仅使用64的KV cache缓存大小<span>（原始输入是5k长度）</span>就能达到90%的性能。</div><div class=" pTag">这表明模型有效地聚合了样本中的任务信息，突出了在上下文学习任务上进一步研究的潜力。</div><div class=" pTag">下面的表则展示了PyramidKV使KV缓存的占用减少的情况。作者评估了Llama-3-8B-Instruct的内存消耗。</div><div class=" pTag">具体来说，作者发现在固定批量大小为1、输入长度为8192、模型权重为fp16格式的情况下，PyramidKV在不同缓存大小下显著减少了KV缓存的内存，还一定程度上保留了任务性能。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqwdeNCbiablxX7VgQnoWzglPx1Njgbj60tRkrXjMFf27df5f8EXwqOlg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">为了进一步理解PyramidKV在LongBench上的性能，作者还进行了“大海捞针”实验，将PyramidKV与SnapKV进行比较，并且对比128大小的KV缓存和完整的KV缓存。</div><div class=" pTag">在输入序列长度在2000到4000之间的中等上下文情况下，SnapKV在“大海捞针”测试中产生了越来越多的错误案例。</div><div class=" pTag">在输入序列长度超过6000的长上下文情况下，SnapKV显著降低了LLMs在评估中的性能。</div><div class=" pTag">相比之下，PyramidKV在大多数情况下减轻了这种弱化效应。下图展示了定量结果。分数越高、颜色越浅，表示着检索能力越强。</div><div class=" pTag">在该任务的平均得分中，完整KV得分为65.0，PyramidKV得分为62.6，而SnapKV得分为57.3。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqDCYcsGmg8rKmqVz0iazuy4uNib5S4reKjXaicD2aqMdwKuUSiaibersykAw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，作者的实验表明，PyramidKV在上下文学习（In-Context Learning）的少样本学习任务中显著优于其他方法。</div><div class=" pTag">这表明KV cache缓存压缩在上下文学习中的应用前景广阔，这种方法有可能在受限的内存条件下实现更多样本的引入。</div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">论文地址：</div><br /></span><span style="font-size: 17px;">https://arxiv.org/abs/2406.02069</span><span style="font-size: 17px;"><br />项目主页:</span><br /><span style="font-size: 17px;">https://zefan-cai.github.io/PyramidKV.github.io/</span><br /><span style="font-size: 17px;"><div class=" pTag">GitHub：</div><br /></span><span style="font-size: 17px;">https://github.com/Zefan-Cai/PyramidKV</span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fy4O9pMQR82tBX3DXWZEEuw">阅读原文 </a>
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 08:50:03 GMT</pubDate>
</item>
<item>
<title>英伟达投的Sora竞品免费了！网友挤爆服务器，120秒120帧支持垫图</title>
<link>https://posts.careerengine.us/p/666ab2bb56528d72b24ceda0</link>
<guid>https://posts.careerengine.us/p/666ab2bb56528d72b24ceda0</guid>
<content:encoded><![CDATA[
<div> 生成模型 Dream Machine 视频 训练 Transformer <br />
123秒120帧视频生成测试版 Dream Machine 免费试用 网友疯狂排队 生成视频需等待<br />
Dream Machine 局限性 扭曲 问题 稳定 性能优化<br />
Luma AI 公司 Genie 1.0 Dream Machine 初创公司 融资7000万美元 领投方 a16z NVIDIA<br />
Dream Machine 背后公司 Luma AI CEO 创始人 技术团队 下一个视频生成AI 媒体发现<br /><br />
总结:<br />
Dream Machine是Luma AI推出的视频生成模型，基于Transformer构建，免费试用版引起网友热议，但需排队等待生成视频。模型存在局限性，但团队已在进行性能优化。Luma AI是一家初创公司，曾发布Genie 1.0，获得7000万美元融资，投资方包括a16z和NVIDIA。Dream Machine的背后是Luma AI团队，其首席执行官和创始人在技术和资本方面备受关注，被认为是下一个视频生成AI的崛起者。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">西风 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag"><strong style="font-weight: 600;">120秒120帧</strong>高质量逼真视频，视频生成赛道新模型入场，火到服务器被挤爆！</div><div class=" pTag">网友直呼这是Sora级别的视频生成AI，关键是<strong style="font-weight: 600;">可以免费试用</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHS0TOcYRtMDYNeagaZuAvKZxNFapRJ6xFkE5mMGYicB30IuOick0S09lA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">话不多说，直接看效果。</div><div class=" pTag">镜头拉近，爆炸场景非常自然：</div><div class=" pTag"><span style="display: none;">‍</span><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH8OicwUMV4Gibc7ib7LWjHsWLBDRWVziayjeialr3tUFrJAJ0PaXiaZmDdZmw/640?wx_fmt=gif&amp;from=appmsg" /></div></div><span style="display: none;">‍</span></div><div class=" pTag">废墟真实感拉满：</div><div class=" pTag"><span style="display: none;">‍</span><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH9uF2QfOuF2phQgiaI6dCnEicibdEAnTRqnkZGLFuRoCVmRfSfMTWaBwOQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">生成变换各种动作的视频也可以：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHgLh38umRG7VfuPdyov9z5ssPaKOqL4usaNv9efFCurPXXJuJmzevicg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">二次元风格也不在话下：</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHGqiaDf3yXFV0QASmzLSQJVeVsPcgXV1nIAr3OSvYNmHVCVDauzkKh8A/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">拿来做个动画小短片质感也很好：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHnC6Id6VDxVEOwQvraXZt7Z42JoUd34jN9rO49v9SOawtfgofkmXIPA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">下面这个就很哈利：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHuOvHiaTOH4X6Ju9bkdyxDoGXzdnNWEstHcbcp2pxsUp2ibSJNwhMY03A/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">再来看几个长视频：</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-18"></div></div><div class=" pTag">大片质感有木有：</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-19"></div></div><div class=" pTag">这个新推出的模型名为<strong style="font-weight: 600;">Dream Machine</strong>，现已推出免费公开测试版，<strong style="font-weight: 600;">支持文生视频、图生视频</strong>。</div><div class=" pTag">网友看过用过后直呼太疯狂：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH1TO7zZjkicvpLPfGKep0rDH6m4K1IuG7zVg4mlu3oggNoXMZK5I9Tew/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">有网友更是嗅到了一丝威胁感：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHKqGv95ugibM1FYuDiaweuYLKzRDvgIGKvQ7txnicLSjWRsCy1wE951C2A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>火爆了，甚至要排队几小时</h2><div class=" pTag">据了解，Dream Machine基于<strong style="font-weight: 600;">Transformer</strong>构建，并直接用视频进行训练，因此能够生成物理准确、内容连贯且充满动感的场景。</div><div class=" pTag">起初官方表示模型可以在120秒内生成120帧视频，但发布后的真实情况是太多人挤入，网站流量过大，现在生成一个视频甚至需要排队几个小时。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH5pLNbVVCSabTzGreKz4kVsNC0MW0Lc6V2LMlYyVMJIRFSOGW6ibfTCA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">产品负责人Barkley Dai在Discord上回应道：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">目前需求太大，我们正努力提升处理能力，所有生成都不会丢失，只是会暂时留在队列中等候。</div><div class=" pTag">排队时间现在已经逐渐缩短了，预计处理当前积压的生成请求仍需几个小时。<strong style="font-weight: 600;">正常情况，将提示转成视频只需2-3分钟</strong>。</div></blockquote><div class=" pTag">我们也赶紧上手试了一下，操作起来非常简单。</div><div class=" pTag">打开官网注册登录后直接点击右上角<strong style="font-weight: 600;">Try Now</strong>：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHOFyAibiaoSNQibiaFfuFdSOukjHJiaTCJNfkCwbVCSr3t03UvuTfKmQOQqw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">接着就可以上传图片、输入Prompt，点击右边的箭头生成视频：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHcrPPt5gBgR2picQ76k2LPuArAibhEc9gq8xLGsRfyjxoRly8lNrt9Tng/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">然后就是等……</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHXRrBDyqqoMKvbd88h2NNGO59s5K95CsWEqJRokeTYgs2zFxXrv4vNw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">好在用了不到一个小时，视频生成好了。</div><div class=" pTag">Prompt：A cartoon-style little bird flying freely in the sky, colored in pastel macaron hues.<span>（一只在天空中自由飞翔的小鸟，卡通风格，马卡龙色系）</span></div><div class=" pTag">第一次生成的效果如下，大伙儿觉得如何：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHKLy7QnotQ3LIFQEeEyrXdibjpfFYbib4HzyN0SBbkIJ8tU5Qcyjxhp8w/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，在推出免费公开测试版前，已经有少数AI视频创作者和电影制作人测试上了Dream Machine，他们也发布了不少作品。</div><div class=" pTag">接下来再来看一波网友们的大作。</div><div class=" pTag">有制片人直接用Dream Machine制作了一部电影预告片，使用了之前Midjourney创作的图像进行了生成：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHBdTFnBmK1R6XoFxGdrNXeoK50xA7zQpcUEhNdZpwP6Zk9fOnfSSBlQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">效果被网友称有印度导演Tarsem Singh的拍摄风格：</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-48"></div></div><div class=" pTag">这位网友同样“复活”了之前用Midjourney创作的一组图像：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHWAJiazkz5cw96ibLU0uJlyicMNxTNWd7ANVmbmJX7yiczjiaYGgLYZYmc7Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">成片是这样婶儿的：</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-51"></div></div><div class=" pTag">还有网友制作出了在沙漠中变形穿梭的飞船：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHArcLbNiad9D0icq2rrUuuVYiaDUcdvhJcjvaTAxwtG0ha8VwxuQLkHtlQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">生成的雪山景深、运镜效果都很好：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHn1icMSo6KLvRCoM9JfS9ORaGvRrvp2ibooluff0f4JhBKIoQMJXZb5Vg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHDyicLl1ibaV1FykiaCMyPRbX26njar2k0veFwu1fxUG2NZk9oCSJlIE8w/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">除了高质量视频的展示，官方也点明了Dream Machine目前存在的局限：</div><div class=" pTag">画面主体可能会扭曲，处理动态对象时可能会出现问题，文本和视觉元素融合处理方面有限制，处理复杂或多变环境时效果不稳定。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHbtjOjbErLgB11HAPTb7rHicKkrITGAsZ7uYdm8zJ5IlJzhOfC0gicSIA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><h2>谁造出了Dream Machine？</h2><div class=" pTag">Dream Machine背后是一家致力于多模态模型开发的初创公司——<strong style="font-weight: 600;">Luma AI</strong>。</div><div class=" pTag">联合创始人兼CEO <strong style="font-weight: 600;">Amit Jain</strong>是前苹果AR/CV工程师；联合创始人兼CTO <strong style="font-weight: 600;">Alex Yu</strong> 2021年毕业于加州伯克利，曾于Angjoo Kanazawa教授一起研究NeRF相关的3D计算机视觉。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHwYWhVia3L6q5OZOTlCdmTnbTS1su5S5gguNz0w4Ly2j4brWBURwU8gQ/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHuwoiawdRnK3K938Ace8bL2voPeMyJwKIdeJOeoqHDbxLiclnStJQZSYQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，团队成员还包括前英伟达研究科学家Jiaming Song、NeRF开山论文作者之一的Matt Tancik等。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHeGrC3DncpZhdT61m9iaZ78zqsBPtppRQmFmGMI9M4W4icCMTdU2DGrOg/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHxQkIhoIMUdVD3m4ncDxEwgxpoburicx60wCCdpqjnWuhZ9B4OWBpibLw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">据TechCrunch消息，截至今年1月份，Luma AI<strong style="font-weight: 600;">已融资超7000万美元</strong>。</div><div class=" pTag">其中A轮，完成了2000万美元融资，投资方包括Amplify Partners、NVIDIA、General Catalyst等。</div><div class=" pTag">B轮融资4300万美元，a16z领投，Anjey Midha、Amplify、Matrix、NVIDIA、South Park Commons等参投。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHUYvsQ5m6cgUFKt5YibaqPx4XLfaWg8Ky9gYQqGoJzP3YV2CibibPp9a8A/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHlujXgpz1IElLIVnnxkcP7U0cAicvPntWMYQ6a7ON0MYU4MasNgKztPQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而在Dream Machine之前，Luma AI凭借去年发布的一个文本到3D生成的模型<strong style="font-weight: 600;">Genie 1.0</strong>，已经打出了一波知名度。</div><div class=" pTag">Genie能够在10秒内创建3D物体，可生成四边形网格和材料，支持任意多边形数量的标准格式。Genie现在可以通过网页版、Luma iOS APP以及Discord社区使用。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHYdLOic0qGd2qpPibRD9eIiaDB1qEXiaFsT2l0Hvu4ib4gVTxa0VhZXA2Prg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">Luma iOS APP量子位之前也有介绍过。基于NeRF，小如3D装饰模型，兼具灯光和形状细节：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHnULazmMcLZCVgQy1vSNADUARibugRCQ91eMom4aF27jC8ZWAuX2ia3hg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">大到整个墓园的3D场景渲染版，都能被很好捕捉：</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHIqYWAm1lPic6HV9bJnpF7CaJ7WDb4JSexlr2swMwa1scBVm1a7eWtZA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">这次最新推出的Dream Machine，是Luma AI打造的第一个视频生成AI。</div><div class=" pTag">感兴趣的家人们可以亲自上手试试～</div><div class=" pTag"><span style="font-size: 17px;">https://lumalabs.ai/dream-machine</span></div><div class=" pTag"><span style="font-size: 17px;"><span>参考链接：</span><br /><span>[1]https://venturebeat.com/ai/we-dont-need-sora-anymore-lumas-new-ai-video-generator-dream-machine-slammed-with-traffic-after-debut/</span></span><br /><span style="font-size: 17px;">[2]https://x.com/LumaLabsAI/status/1800921380034379951</span><br /><span style="font-size: 17px;">[3]https://lumalabs.ai/team</span><br /><span style="font-size: 17px;">[4]https://x.com/minchoi/status/1800944734577336702</span><br /><span style="font-size: 17px;">[5]https://x.com/markgadala/status/1800947546656759929</span><br /><span style="font-size: 17px;">[6]https://x.com/thepaulmontreal/status/1800946280144773441</span><br /><span style="font-size: 17px;">[7]https://x.com/panaviscope/status/1800940733278622136</span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div class=" pTag"><span style="font-size: 17px;">— <strong style="font-weight: 600;">完</strong> —</span></div></div></div><div style="font-size: 17px;"><div class=" pTag"><span><strong style="font-weight: 600;">量子位年度AI主题策划</strong></span>正在征集中！</div><div class=" pTag">欢迎投稿专题&nbsp;<strong style="font-weight: 600;">一千零一个AI应</strong><strong style="font-weight: 600;">用</strong>，<strong style="font-weight: 600;">365行AI落地方案</strong></div><div class=" pTag">或与我们分享你在<strong style="font-weight: 600;">寻找的AI产品</strong>，或发现的<strong style="font-weight: 600;">AI新动向</strong></div></div><div style="text-align: center;"><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div></div></div><div class=" pTag" style="text-align: center;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FIsOZ1zIkpzfhbJfDIYIlcA">阅读原文 </a>
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 08:50:03 GMT</pubDate>
</item>
<item>
<title>字节扣子搭建大模型擂台：匿名PK效果，用户当裁判，跑分时代要结束了</title>
<link>https://posts.careerengine.us/p/666ab2acf8e51d727b0bb2c3</link>
<guid>https://posts.careerengine.us/p/666ab2acf8e51d727b0bb2c3</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">金磊 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag" style="font-size: 17px;"><strong style="font-weight: 600;">字节跳动</strong>的<strong style="font-weight: 600;">扣子</strong><span>（coze.cn）</span>，给国产大模型们组了个大局——</div><div class=" pTag" style="font-size: 17px;">在同一个“擂台”上，两个大模型为一组，直接以<strong style="font-weight: 600;">匿名的方式PK效果</strong>！</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHywAk8WnKxZn7VCQzFwnNdWJsRoFNibiavmdwW9NfcFFH0eUk9icvDicTew/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">例如我们对两位参赛“选手”同时提问今年<strong style="font-weight: 600;">高考</strong>的题目：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">阅读下面的材料，根据要求写作。（60分）</div><div class=" pTag">随着互联网的普及、人工智能的应用，越来越多的问题能很快得到答案。那么，我们的问题是否会越来越少？</div><div class=" pTag">以上材料引发了你怎样的联想和思考？请写一篇文章。</div><div class=" pTag">要求：选准角度，确定立意，明确文体，自拟标题；不要套作，不得抄袭；不得泄露个人信息；不少于800字。</div></blockquote><div class=" pTag" style="font-size: 17px;">点击问题的一瞬间，两位“选手”便立刻开始作答：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHM6AFBgLabH5jxhr9BBJicM9KokQTyHNmccQHOQFtibWa01XrVwkia93Kw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">不难看出，两个大模型不论是在生成答案的速度，或是内容的侧重上均有所不同。</div><div class=" pTag" style="font-size: 17px;">直到有一方作答完毕，这时候我们就可以开始<strong style="font-weight: 600;">投票</strong>了，一共有四个选项可选：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHzQA0Q9uKEPypybicZZUV6pFXWrG97CiaSHbJj1yNiaHicd6Ou3vHTOurng/640?wx_fmt=png&amp;from=appmsg" /></div></div>A表现更好</div></li><li><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHpl1zmz834uDhTVKkXiaHHUWTonk23yhicP5OJm7zdiaiaWcbVQV4D4IZgA/640?wx_fmt=png&amp;from=appmsg" /></div></div>两个都好</div></li><li><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH2g1aoWWKepd3fcjWXC2GiatzJuRANanye1xSibyfibMyCGW4k4dfk7Eaw/640?wx_fmt=png&amp;from=appmsg" /></div></div>两个都差</div></li><li><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH8ysUUxJaKlzbDX71NaAYc1ia3nhvQLUK4ar8y80WD9AAD535ZNDrYJw/640?wx_fmt=png&amp;from=appmsg" /></div></div>B表现更好</div></li></ul><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHOgmHEoJibL1jicUwYcibn59iavFjsQZhdqO1BBicMtMFMyNiaVIJC8XeI6rQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">在这个case中，因为生成速度相似，我们姑且以个人文字审美为标准，先将票投给大模型A。</div><div class=" pTag" style="font-size: 17px;">投票结束后，两位“选手”的庐山真面目也就揭晓了，分别是<strong style="font-weight: 600;">通义千问</strong><span>（A）</span>和<strong style="font-weight: 600;">智谱</strong><span>（B）</span>。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHX66Fhp8ia90cDlP7D4yHtiaKeOGXv61W80cPbmtaWstmTnDPOKJ2kzhQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">这便是字节跳动的AI应用开发平台<strong style="font-weight: 600;">扣子</strong>上新的玩法——<strong style="font-weight: 600;">模型广场</strong>。</div><div class=" pTag" style="font-size: 17px;">这种打擂台的模型，与此前国外极具权威性的大模型擂台<strong style="font-weight: 600;">Chatbot Arena</strong>类似。</div><div class=" pTag" style="font-size: 17px;">它同样是通过用户的参与，匿名两个模型，根据生成内容的表现来打分。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHeY1F0xdNwOZt0UEa3m2trSj5S5iazSAuvlicrE61545pz4czWhY9C3qw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">而且这种模式还得到了AI大神<strong style="font-weight: 600;">Karpathy</strong>的高度认可：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">是我唯二信任的测试基准之一。</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHt2MveuRNpXZaw52vEZOUviciaXA5DiakvnPZNc9akXuHyibMXkf8xKPFRg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">不过有一说一，扣子能让自家“院子”里的大模型们玩这种模式，也是实属罕见。</div><div class=" pTag" style="font-size: 17px;">那么模型广场具体又该如何操作？是否能够hold住脑洞大开的问题？</div><div class=" pTag" style="font-size: 17px;">我们这就来实测一波。</div><h2>匿名PK，够直接，够刺激</h2><div class=" pTag" style="font-size: 17px;">我们现在打开扣子的官网<span>（coze.cn）</span>，点击左侧的导航栏<strong style="font-weight: 600;">“探索”</strong>列表中<strong style="font-weight: 600;">“模型广场”</strong>，便可开始体验了。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHgruW5F6ic8cBUt9uswLPmJic5y79n5GBCt761mmPxBRDvibwRVSFRia1VA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">整体来看，对战的模式一共分为三大类：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">随机Bot对战</div></li><li><div class=" pTag">指定Bot对战</div></li><li><div class=" pTag">纯模型对战</div></li></ul><div class=" pTag" style="font-size: 17px;">刚才我们所展示的PK案例，就是点击<strong style="font-weight: 600;">“随机开始”</strong>按钮而来，也就是<strong style="font-weight: 600;">随机Bot对战</strong>。</div><div class=" pTag" style="font-size: 17px;">具体而言，扣子会从已经上架的Bot中随机挑选一个，然后选择匿名的两个大模型进行PK。</div><div class=" pTag" style="font-size: 17px;">这个模式考验的便是大模型们在<strong style="font-weight: 600;">任意业务场景</strong>下的文本生成、技能和知识调用等能力。</div><div class=" pTag" style="font-size: 17px;">例如我们再来体验一番，这一次的场景就变成了<strong style="font-weight: 600;">数学老师</strong>，我们选择的问题：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">某班30人中有15人参加数学建模竞赛，有8人参加数学竞赛，有6人参加英语竞赛，有3人三科竞赛都参加，请问三科竞赛都不参加的至少有多少人?</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHEvhNvga5Fjrq3WGaj99NxbiaLAYA62ia9OSx7EibZ973cVxTyseQcLlvg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;"><span>我们按照生成结果的简洁性，这次把票投给模型B，可以看到这次参赛的“选手”分别是</span><span><strong style="font-weight: 600;">通义千问</strong></span><span>（A）</span><span>和</span><strong style="font-weight: 600;"><strong style="font-size: 17px; text-align: left; font-weight: 600;">MiniMax</strong></strong><span>（B）</span><span>。</span></div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHiau3EvTkkt8TWs2U30pYxEZ04GVJOMcLU2daD1glvhWwA0zWMdwjaOQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">而<strong style="font-weight: 600;">指定Bot对战</strong>，则是需要我们先在模型广场下方的众多Bot中挑选一个要测试的场景，然后扣子再从系统中选择匿名的两个大模型来PK。</div><div class=" pTag" style="font-size: 17px;">这个模式在业务场景方面就会更加聚焦和细分。</div><div class=" pTag" style="font-size: 17px;">例如我们在茫茫Bot中，一眼就相中了<strong style="font-weight: 600;">“弱智吧十年练习生”</strong>：</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH3licWUnkFUhf9dYpLuguHIMcVlDHD7pa4bxiahmfYmSJ3ZQHYIYrq0bA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">这一次我们自己来提问：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">被门夹过的核桃，还能补脑吗？</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHOVVGXsVTOfKAkrFCARuglT5z79UdKuJEgnuxd3NTgYNLOnzNF8xhjQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">从答案中不难看出，两位“选手”都没有get到这句话里隐藏的“你脑袋被门夹了”的梗，因此——<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH2g1aoWWKepd3fcjWXC2GiatzJuRANanye1xSibyfibMyCGW4k4dfk7Eaw/640?wx_fmt=png&amp;from=appmsg" /></div></div>两个都差。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHkQgHPBTFYLyzku1gnuldKMxWMgCic7libicfAeQZRtY99cv3XspXaj89w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">最后一个模式便是<strong style="font-weight: 600;">纯模型对战</strong>——</div><div class=" pTag" style="font-size: 17px;">忽略编排等各种Bot配置的影响，直接评估大模型的文本生成能力。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHCXyWkzpTVvNWBoH2gRspyTeibRqS7bSBhKKVPw2NbnVibHBWwRDDmKPA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">我们依旧“弱智吧Style”：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">高考满分才750，怎么才能考985？</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHJvJapK7h2VOdiaeapsz8PVxhMdW9o9N599BjhSPBHJ20fia1ibHBVR4VA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">两个大模型都精准get到了985是什么意思，因此依旧是——<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHpl1zmz834uDhTVKkXiaHHUWTonk23yhicP5OJm7zdiaiaWcbVQV4D4IZgA/640?wx_fmt=png&amp;from=appmsg" /></div></div>两个都好。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH1K9ZkMqoKddgnE2knkUSRszTDsw8nJFibA27OkfNebKK3NXUo4unHOw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">值得一提的是，无论在哪种模式之下，“选手”如果在回答问题过程中暴露了自己的身份，那么用户所投出的票将被视为无效。</div><div class=" pTag" style="font-size: 17px;">以上便是扣子给国产大模型们打擂台匿名PK的三种模式了。</div><div class=" pTag" style="font-size: 17px;">而纵观扣子此次的新发布，除了大模型本身之外，另外一个关键要素便是Bot。</div><div class=" pTag" style="font-size: 17px;">并且若是亲身体验一番下来，在扣子中创建Bot这件事，最为直接的感受就是<strong style="font-weight: 600;">够简单</strong>、<strong style="font-weight: 600;">够丰富</strong>。</div><h2>小朋友都能搭建的Bot</h2><div class=" pTag" style="font-size: 17px;">其实模型广场是一个名叫<strong style="font-weight: 600;">“扣子AI工坊”</strong><span>（Coze AI Factory）</span>活动的内容之一，是由扣子和英特尔联合推出的主题 Bot征集活动。</div><div class=" pTag" style="font-size: 17px;">聚焦的是图文创作、实用工具、互动创意三个赛道。</div><div class=" pTag" style="font-size: 17px;">但如果来到扣子的<strong style="font-weight: 600;">“Bot商店”</strong>，就不难发现，这里的Bot们并非是一尘不变的那种；相反，倒是非常紧跟热点，非常fashion。</div><div class=" pTag" style="font-size: 17px;">例如正值刚刚高考完，Bot商店首页的“头条位置”留给的就是一个名叫<strong style="font-weight: 600;">“高考专业指南”</strong>的Bot，可以说是相当的应景。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CH2FicyDF29ZkGV2uX4OIRPzSaPrTjOBI657EoL8RGtlcoxODWw8e4VibA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">除此之外，像<strong style="font-weight: 600;">“国内高校百科”</strong>和<strong style="font-weight: 600;">“测测你的本命粽子”</strong>等Bot，也是紧跟热点和节假日。</div><div class=" pTag" style="font-size: 17px;">而且Bot的数量之多，简直是<strong style="font-weight: 600;">刷不到底</strong>：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHofu1WeIb4cpzDchh0xA5KfjxWLfrET6k0l2IFuKsohZQ3Lq9fhm9yA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">但比起数量来说，更重要的还是在扣子中创建复杂的Bot，仅需<strong style="font-weight: 600;">鼠标“点点点”</strong>，就连小朋友都能完成。</div><div class=" pTag" style="font-size: 17px;">第一大步，点击创建Bot，简单填写基本信息：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHyRhQfWn1928TORwOxkSCPhRFWNV6ibggwE00e5y6zuxNYyd7N4cnOhw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">第二大步，选择自己想要用的大模型：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHXbicG8h6CqAcLw0S0pEgCu1sWDZGTRN951HP6ibbIf6KMERiaVQ5rqSicQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">目前可选的大模型包括豆包、通义千问、智谱、MiniMax、月之暗面和百川。</div><div class=" pTag" style="font-size: 17px;">第三大步，给Bot添加<strong style="font-weight: 600;">“技能点”</strong>，同样是“点点点”的操作，就能在扣子已经拥有的海量插件、工作流等内容里pick自己想要的那一个。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHNT3A3mTuhXLlUE9k3g0dusw5BWMeE1nSX6Q7XD0DWfJbXa7YaicmKcQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">最后，一键“发布”，就可以上线想要拥有的Bot。</div><div class=" pTag" style="font-size: 17px;">操作之简单，也就不难理解为何扣子上Bot的数量会如此惊人了。</div><h2>字节的扣子在下一步什么棋？</h2><div class=" pTag" style="font-size: 17px;">我们再回到这次扣子新发布的<strong style="font-weight: 600;">模型广场</strong>，也正如我们在文章最开始提到的，这种把<strong style="font-weight: 600;">擂台玩法</strong>嵌入到自家大模型应用开发平台的，目前在业界算是少见。</div><div class=" pTag" style="font-size: 17px;">那么，字节为什么要这么做？</div><div class=" pTag" style="font-size: 17px;">首先从<strong style="font-weight: 600;">效果层面</strong>来看，从刚才我们创建Bot的过程中不难发现，它所依赖的能力最根本的就是来自扣子生态中所集成的大模型们。</div><div class=" pTag" style="font-size: 17px;">而也正如业界已达成的共识那样——<strong style="font-weight: 600;">没有一个大模型能够“一统天下”，每个大模型都有自己的擅长之处。</strong></div><div class=" pTag" style="font-size: 17px;">加之每个Bot也都是在细分场景里各有侧重，因此<strong style="font-weight: 600;">合适的Bot遇到合适大模型</strong>，势必将产生1+1＞2的效果。</div><div class=" pTag" style="font-size: 17px;">其次从<strong style="font-weight: 600;">操作层面</strong>来看，模型广场的出现着实是为Bot开发者节省了挨个模型比对、试错的成本。</div><div class=" pTag" style="font-size: 17px;">这无疑是给本就操作简易的扣子在操作上锦上添花。</div><div class=" pTag" style="font-size: 17px;">最后是在<strong style="font-weight: 600;">可信度层面</strong>上，扣子所pick的类似Chatbot Arena的擂台模式，已然成为业界对大模型性能认可度的标杆。</div><div class=" pTag" style="font-size: 17px;">毕竟除了前文提到的Karpathy之外，Jeff Dean和李开复也对这种模式给予过高度的认可。</div><div class=" pTag" style="font-size: 17px;">一言蔽之，字节要做的，就是把AI应用开发门槛打下去，把生态壮大起来，让AI应用能<strong style="font-weight: 600;">“多快好省”</strong>地用起来。</div><div class=" pTag" style="font-size: 17px;"><span>扣子地址：coze.cn</span></div><div class=" pTag" style="font-size: 17px;">点击「阅读原文」即刻体验扣子AI模型广场！</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDz9apvfmdKdw7FUJTvf8CHgS2bGT9ymBic3TMgPntaaZZXIvNP9Gd6nHQzXZGMBz0PB5S86bgjkibw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FT_0jxSC4f_XXXuiqIlQGNA">阅读原文 </a>
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 08:49:48 GMT</pubDate>
</item>
<item>
<title>GPT-4o更容易越狱？北航&amp;南洋理工上万次测试给出详细分析</title>
<link>https://posts.careerengine.us/p/66693116166b344696845695</link>
<guid>https://posts.careerengine.us/p/66693116166b344696845695</guid>
<content:encoded><![CDATA[
<div> 北航 南洋理工 GPT-4o 安全性 多模态

要点一：报告发现GPT-4o在文本模态上对越狱攻击的安全性有所提升，但在多模态下不如GPT-4V。

要点二：新引入的音频模态暴露了GPT-4o的新攻击面。

要点三：报告评估了多种越狱攻击方法，结果显示攻击GPT-4o的ASR低于攻击GPT-4V。

要点四：在音频模态下，直接将文本转换为音频无法越狱GPT-4o，显示GPT-4o在音频模态上具有良好安全性。

要点五：观察到多模态越狱攻击中，GPT-4o相较于GPT-4V更容易受到攻击，说明需要优先考虑为多模态模型制定对齐策略和缓解技术。

总结: 报告发现，GPT-4o在文本模态上提高了对越狱攻击的安全性，但在多模态下不如GPT-4V。新引入的音频模态暴露了新的攻击面。多种越狱攻击方法评估结果显示，攻击GPT-4o的ASR低于攻击GPT-4V。在音频模态下，直接转换文本为音频无法越狱GPT-4o，显示其在音频模态上具有良好安全性。在多模态越狱攻击中，GPT-4o相较于GPT-4V更容易受到攻击，因此需要优先考虑为多模态模型制定对齐策略和缓解技术。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">北航&amp;南洋理工联合团队&nbsp;投稿</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">GPT-4o，比上一代更容易被越狱攻击了？</div><div class=" pTag">来自北航和南洋理工的研究人员，通过上万次的API查询，对GPT-4o各种模态的安全性进行了详细测试。</div><div class=" pTag">结果发现，GPT-4o新引入的语音模态带来了新的攻击面，而且多模态整体安全性不敌GPT-4V。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8PJVmOxUhAaew839agqZSSAWPuhQ4JUhocwtUGw1XxLoNEsrYEcs0Kw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">具体来说，研究人员针对4个常用的基准测试，对GPT-4o支持的三种模态<span>（文本、图像、音频）</span>进行了测试。</div><div class=" pTag">测试一共涉及到4000+初始文本查询的优化，8000+响应判断，16000+次OpenAI的API查询。</div><div class=" pTag">基于此，研究人员撰写了详细的报告，给出了关于GPT-4o的安全性的三点见解：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">GPT-4o对文本越狱攻击的安全性比之前有所提升，但文本模态越狱攻击可迁移性强，可通过多模态形式攻击；</div></li><li><div class=" pTag">新引入的音频模态为GPT-4o的越狱攻击暴露了新的攻击面；</div></li><li><div class=" pTag">当前的黑盒多模态越狱攻击方法几乎无效，但实验表明GPT-4o多模态层面的安全性弱于GPT-4V。</div></li></ul><div class=" pTag">下面就来看一下这份报告的详细内容~</div><h2>评价规则</h2><div class=" pTag">首先，让我们了解一下作者使用的测评方式和实验设定。</div><div class=" pTag">为了评估GPT-4o的安全风险以及其相较于上一代模型的改变，作者将目标模型设置为GPT-4V和GPT-4o，利用API和移动应用对这些模型进行评估。</div><div class=" pTag">对于单模态下的文本越狱攻击，作者使用Llama2（7b-chat）生成文本越狱提示，然后用其迁移攻击目标模型。</div><div class=" pTag">为了全面评估目标模型的安全性，作者收集了现有的基于单模态和多模态的开源越狱<strong style="font-weight: 600;">数据集</strong>：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">对于文本模态，使用了AdvBench和RedTeam-2K。</div></li><li><div class=" pTag">对于音频模态，使用了AdvBench子集。</div></li><li><div class=" pTag">对于多模态越狱，使用SafeBench和MM-SafetyBench，这是基于两种典型的黑盒多模态越狱方法构建的。</div></li></ul><div class=" pTag">这些数据集按照OpenAI和Meta AI的用户策略，将数据集的内容分成了不同的类别，例如非法活动、仇恨言论等。</div><div class=" pTag"><strong style="font-weight: 600;">越狱方法</strong>层面，报告中评估了7种先进的越狱方法，分为两类。</div><div class=" pTag">其中单模态越狱方法包括基于模板的方法、GCG、AutoDAN和PAP；多模态越狱攻击方法包括FigStep、Liu等人工作和作者团队近期提出的BAP。</div><div class=" pTag">特别地，对于FigStep和Liu等人工作，基于相应方法构建的官方数据集已经发布，因此作者直接使用它们来评估目标模型；其他方法的评价则在AdvBench上进行。</div><div class=" pTag">对于基于模板的方法，作者从互联网上选择了6个典型的越狱模版进行测试，并使用它们的平均ASR作为相应指标。</div><div class=" pTag">GCG和AutoDAN最初是为白盒场景提出的，但它们已经被证明具有强大迁移性——作者通过攻击Llama2，使用这两类方法生成对抗性后缀，并随后将这些后缀应用于攻击GPT-4o和GPT-4V。</div><div class=" pTag">BAP是一种多模态越狱攻击方法，其利用了基于梯度的视觉对抗提示优化和基于思维链的文本对抗提示自适应优化。尽管目标模型是黑盒模型，但其中的文本对抗提示优化方法不受限制。因此在本研究中，作者使用它来评估文本模态的安全性。</div><div class=" pTag"><strong style="font-weight: 600;">评估指标</strong>采用的是攻击成功率（ASR），ASR越高则目标模型越容易被越狱成功。其计算公式如下：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8jz7N6ia2zOk7gjXMIy37JQAJU48xByibeJ4QoxJ2dWs9TafANicERmbFg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="text-align: left;">其中D为数据集，J为判决函数，F_θ为目标模型，v_i为图像、t_i为文本，a_i为音频，在评估时，没有涉及的模态将会被置空。</span><br /></div><div class=" pTag">目前的工作中采用不同的方法作为判决函数，在报告中，作者遵循已有工作的设计，采用四类方法将J分别实例化J_1,J_2,J3,J_4。</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">J_1表示使用基于字符串匹配的方法，其中目标字符串包括‘Sorry’等否定模式，如果响应内容是安全的。</div></li><li><div class=" pTag">J_2表示使用Meta发布的Llama Guard判断内容是否安全。</div></li><li><div class=" pTag">J_3表示使用目标模型相应以及判断提示模版，交由ChatGPT判断。</div></li><li><div class=" pTag">J_4则是交由GPT-4o判断。</div></li></ul><div class=" pTag">J_3和J_4除了模型不同外，所用的判断提示模版也不同，J_3的模版是要求大语言模型仅根据响应判断内容是否安全，而J_4的模版会同时根据问题和响应判断内容是否安全。</div><div class=" pTag">在实验评估中，作者会同时使用这四类判断函数计算ASR，定性分析时借鉴集成学习的思想，以多数判断函数的结果为准，定量分析时则以J_4的结果为准。</div><h2>纯文本模态下，有攻击比没有时更安全</h2><div class=" pTag">文本模态越狱风险方面，基于RedTeam-2K的评估结果表明，在没有攻击的情况下，GPT-4o的安全水平低于GPT-4V。</div><div class=" pTag">当考虑到特定情景，特别是那些具有较高风险的情景(如Physical Harm时，两种目标模型之间的ASR差距变得更加明显，达到14.6％。</div><div class=" pTag">这一实验发现与直觉上认为在没有攻击的情况下，GPT-4o是更安全的模型形成了鲜明对比。</div><div class=" pTag">这表明，具有更强的通用能力的模型并不一定等同于更强的安全性能，事实上，在报告的环境中可能更弱。</div><div class=" pTag">安全性能间的差异可能源于训练目标和安全目标之间的内在冲突——</div><div class=" pTag">虽然在更广泛的数据集上训练的大模型可能在知识和全面性方面表现出更好的性能，但它们也可能更容易产生不安全或有害的内容。</div><div class=" pTag">相反，经过严格安全措施训练的模型可能由于接触不同数据的机会有限和严格的响应准则而表现出性能下降。</div><div class=" pTag">报告中的实验数据表明，GPT-4o可能没有充分实现训练目标和安全目标之间的权衡。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8ZsSe82ibdnianuAbhvh6UuCFaZkIWYmiacKXHXAxRIQicDiaMNS6jZib4ic2Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">考虑到常用的AdvBench基准的代表性和适用性，除了评估目标模型在原始文本查询下的安全性外，作者还评估了模型在各种SOTA越狱攻击下的安全性。</div><div class=" pTag">作者观察到基于模板的越狱方法TBJ的ASR持续下降到0.0％，甚至低于No Attack时的ASR，这一现象表明OpenAI已经针对这些广泛传播的越狱模板实施了额外的保护措施。</div><div class=" pTag">此外还可以看到，与No Attack基线相比，GCG和AutoDAN在越狱中都实现了一定程度的可迁移性。</div><div class=" pTag">例如攻击GPT-4V时，GCG和AutoDAN分别使ASR提高10％和14.1％。</div><div class=" pTag">PAP是另一种专门为越狱大语言模型设计的方法，它在基于文本越狱攻击方法中拥有最高的ASR<span>（GPT-4V和GPT-4o的ASR分别为62.2％和62.7％）</span>。</div><div class=" pTag">BAP是作者最近提出的一种多模态越狱攻击方法，但在报告中，主要利用的是它的文本优化方法，结果BAP在攻击GPT-4V时达到了最高的ASR，达到83.1％。</div><div class=" pTag">从目标模型来看，除了J_3中的PAP以外，在任何判断函数和任何攻击方式下，攻击GPT-4o的ASR都低于攻击GPT-4V。</div><div class=" pTag">这表明在面临攻击的情况下，与GPT-4V相比，GPT-4o具有更高的安全性。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8G6hpxSnMWibiaOk9KDwhIldUbckNpVI0Xviar3efiaYoPxfV0ia7WkeXugw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>音频模态比文本更难攻击</h2><div class=" pTag">由于OpenAI的音频相关API暂时不可用，移动应用中也有请求频率限制，作者对音频模态的安全性的测试相对有限。</div><div class=" pTag">作者首先使用GPT-4o对AdvBench进行分类，并从4个最常见的类别中随机选择10个文本查询，并基于上一节的实验数据选择了GCG、AudoDAN、PAP和BAP生成的文本对抗提示。</div><div class=" pTag">随后，作者使用OpenAI的TTS-1API将总共200个文本样本转换为MP3格式。由于实验数据有限，这部分的ASR是通过人工评估来计算的。</div><div class=" pTag">结果现实，直接将原始文本查询转换为音频是无法越狱GPT-4o的，表明GPT-4o在音频模态上具有足够的安全性。</div><div class=" pTag">此外，使用GCG和AutoDAN等方法在文本模态下可以成功越狱GPT-4o的文本，在转换为音频模态后也失败了。</div><div class=" pTag">造成这种结果的主要原因是这些方法生成的对抗性后缀在模态处理过程中丢失了一些关键的语义信息（如非字母符号）。</div><div class=" pTag">另外，作者观察到PAP和BAP在文本模态下的ASR略高于从这些文本在音频模态下得到的ASR。例如，在非法活动场景中，文本模式下BAP的ASR为100％，而音频模式下的ASR为80％。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8Nwy9BzGhwu1a4LkThsj2s5WrHFkh5vIdftujNUcHB8VW2justWvleA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在检查交互结果时，作者发现在音频交互期间，GPT-4o有时会以简单的‘Sure’响应，然后询问进一步的细节，模仿人类的会话风格。</div><div class=" pTag">然而，报告中使用的文本模态越狱方法并没有考虑到这一点，因为它们依赖于单回合对话来实现越狱。因此，音频模式的越狱攻击的ASR略低于文本模式。</div><div class=" pTag">值得注意的是，尽管存在差距，音频对抗性提示的ASR并没有显著降低。</div><div class=" pTag">这在很大程度上是由于PAP和BAP采用的策略接近于人类的处理方式。例如，它们会利用有说服力的策略，如情景假设对整个语句进行优化。</div><h2>多模态下比GPT-4V更易被攻击</h2><div class=" pTag">多模态安全性上，作者首先基于SafeBench进行了评估，该数据集的核心思想是将原始查询中的有害意图转换为格式化的排版图像，并在图像中留下空白，并由目标模型填充。</div><div class=" pTag">从下表结果可以观察到，在每种判断结果中，GPT-4o的结果始终高于GPT-4V(在J_4中最多，为42.0％)，这表明GPT-4o比GPT-4V更容易受到此类攻击。</div><div class=" pTag">考虑到GPT-4o优越的多模态融合能力，这也可能导致其对此类攻击的脆弱性增加。</div><div class=" pTag">值得注意的是，我们观察到一个异常现象，即在某些情况下，目标模型在No Attack条件（仅使用原始文本查询）下的ASR高于攻击条件下的ASR。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8KQSaQsqt2D9zlJ75jr5Oicn3N4m4iakKVPLtUicQoYZsGXspLDMheNyiaQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">下图给出了一个示例，显示当使用多模态查询时，越狱尝试更容易失败。这一观察结果与原始论文的发现以及作者的直觉相矛盾。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8Iafx40wDR9dmJNnMLvYozgic5YMuf8hYbWGbHNyyeTUJzRTDvdgwHcw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">作者分析，这种差异可能是由于OpenAI实现了类似于FigStep的针对多模态排版攻击的特定防御。这些排版攻击通常需要使用诸如“请为上述列表中的每个项目生成详细的内容”的文本提示才有效。</div><div class=" pTag">作者推测OpenAI可能会根据这些字符串特征检测到排版攻击的迹象，从而在推理过程中采用更强的缓解机制。</div><div class=" pTag">在非异常情况下，使用FigStep攻击获得的ASR并不显著高于No Attack条件下的ASR。</div><div class=" pTag">例如，当攻击GPT-4o时，Hate Speech场景的ASR仅为3.6％。这表明FigStep攻击对GPT-4V和GPT-4o基本上无效。</div><div class=" pTag">这里需要注意，考虑到OpenAI对其商业模型保护措施的动态调整，目前的研究结果并不能否定FigStep在其最初发布时有效越狱GPT-4V的由有效性。</div><div class=" pTag">另外，作者还在MM-SafetyBench上进行了评估，该数据集利用了基于图像语义构建视觉对抗性提示的方法。</div><div class=" pTag">原始文本查询中的有害语义通过文本到图像模型转换为图像，然后添加关键的排版文本以生成所需的视觉对抗提示。</div><div class=" pTag">当在下表中关注Hate Speech、Physical Harm和Fraud等危害性较强的场景下的实验结果时，观察到攻击下目标模型的ASR始终低于No Attack条件(仅使用原始文本查询)下的ASR。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq89hSwkqf8bkZtq5EicAhCQPI5JVETiaRRSicKiaVRfjtBFTk3Ehyr4QalFg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">作者在评估SafeBench时观察到这种现象，例如对于这种基于图像语义的攻击，OpenAI可能在检测到含有有害语义的图像后，采用先进的防御机制，防止攻击者利用图像向多模态大模型中注入有害语义或指令。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8ia4OslG7Bnee6ceXxrIq4DYzGNP9uicLB8Q9ngAnKwF4bFfHib7tTiaLew/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">所以，作者推测OpenAI已经针对这些已知的多模态攻击方法实现了特定的防御。</div><div class=" pTag">在攻击GPT-4o时，除了Hate Speech、Economic Harm和Legal Opinion场景外，在No Attack条件下的ASR始终高于攻击条件下的ASR，这是一个异常现象。</div><div class=" pTag">在GPT-4V中也观察到类似的模式，这说明当前典型的黑盒多模态越狱方法对于越狱GPT-4o和GPT-4V无效。</div><div class=" pTag">此外作者还注意到，除J_3的判断结果外，其他三个判断函数的结果都表明GPT-4o的ASR始终高于GPT-4v。结合SafeBench获得的实验结果，这清楚地表明，与GPT-4v相比，GPT-4o更容易受到多模式越狱攻击。</div><div class=" pTag">同时，作者指出，由于官方OpenAI API的局限性，本研究主要侧重于通过API对大型数据集上涉及文本和视觉模式的越狱攻击进行自动评估，并通过移动应用程序使用AdvBench的一个子集手动对音频模式进行越狱攻击。</div><div class=" pTag">这项研究首次揭示了几个关键的观察结果。作者希望这项工作能提高社区对多模态大模型安全风险的认识，并敦促研究人员优先考虑为多模态大模型制定对齐策略和缓解技术。</div><div class=" pTag">另外，由于目前多模态越狱数据集的匮乏，本研究仅探讨文本-视觉的多模态组合下的越狱对GPT-4o安全性的影响。</div><div class=" pTag">作者表示，在未来，必须迅速建立包括文本、视觉和音频等各种模态组合的多模式数据集，以全面评估GPT-4o的安全能力。</div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">论文地址：</div><br /></span><span style="font-size: 17px;">https://arxiv.org/abs/2406.06302</span><br /><span style="font-size: 17px;"><div class=" pTag">GitHub：</div><br /></span><span style="font-size: 17px;">https://github.com/NY1024/Jailbreak_GPT4o</span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5fK3WyYnwMND8gXjWb-B2g">阅读原文 </a>
]]></content:encoded>
<pubDate>Wed, 12 Jun 2024 05:24:38 GMT</pubDate>
</item>
<item>
<title>全华人团队推出多模态大模型新基准，GPT-4o准确率仅为65.5％，所有模型最易犯感知错误</title>
<link>https://posts.careerengine.us/p/66693107222590466adc1ba9</link>
<guid>https://posts.careerengine.us/p/66693107222590466adc1ba9</guid>
<content:encoded><![CDATA[
<div> 多模态大模型 浪潮 评估 基准测试 研究<br />
<br />
总结: 本文介绍了一个全方位的多模态基准测试MMT-Bench，用于评估大型视觉语言模型在多模态多任务理解方面的表现。文章详细介绍了MMT-Bench的数据设计、任务构建、数据收集、评测结果、任务地图和错误分析等内容。研究人员对30种大型视觉语言模型进行了评估，显示当前模型在多任务AGI的路径上仍面临挑战。基于任务地图的分析显示LVLMs在相似任务上有更一致的性能表现，而错误分析发现感知错误和推理错误是LVLMs常见的错误类型。整体来说，MMT-Bench的目标是激发LVLMs研究和开发，推动多模态系统的智能化进程。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">王家豪 投稿自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">GPT-4o再次掀起多模态大模型的浪潮。</div><div class=" pTag">如果他们能以近似人类的熟练程度，在不同领域执行广泛的任务，这对许多领域带来革命性进展。</div><div class=" pTag">因而，构建一个全面的评估基准测试就显得格外重要。然而评估大型视觉语言模型能力的进程显著落后于它们自身的发展。</div><div class=" pTag">来自上海AI Lab、香港大学、上海交大、浙江大学等多家机构提出了 MMT-Bench。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnq6EiaAa7Nw34H39GEkot37UjawAjK3dKZMACPhibKnBdU1qsXGv7A2nhA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这是一个全方位的多模态基准测试，旨在全面评估大型视觉语言模型（LVLMs）在多模态多任务理解方面的表现。</div><div class=" pTag">研究团队还对当前几个代表的视觉大模型进行了能力评估，结果发现<strong style="font-weight: 600;">感知错误、推理错误</strong>是所有模型最常见的两大错误。</div><h2>多模态多任务AGI基准测试MMT-Bench</h2><div class=" pTag">MMT-Bench的广度体现在三个方面。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqvs0etQHH3d1COkraqFLRe6ptfA8tr4ZFyL04kicUm0b1DdrhDO0pHgg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">首先，MMT-Bench数据经过精心设计，包含32K个多选视觉语言问题，涵盖了32个核心元任务和162个子任务，这比此前的评测数据集MMBench大8.1倍。</div><div class=" pTag">其次，MMT-Bench包含了13种图像类型，如自然场景、合成图像、深度图、富文本图像、绘画、屏幕截图、点云、医学图像等。这样的图片多样性要求模型能够解释理解各种视觉输入。</div><div class=" pTag">第三，MMT-Bench涵盖了多种多模态情景，如车辆驾驶、GUI导航和具身AI，测试了14种多模态能力，包括视觉识别、定位、推理、OCR、计数、3D感知、时间理解等。</div><div class=" pTag"><strong style="font-weight: 600;">构建评测任务</strong>&nbsp;。</div><div class=" pTag">MMT-Bench的评测任务在构建时旨在包含尽可能多的多模态任务。为此，研究人员首先提出多模态理解的元任务。然后，通过去重和筛选重要任务总结出32个元任务。</div><div class=" pTag">接着，将每个元任务分解为几个子任务。子任务是否被保留在MMT-Bench中，需要满足三个标准：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">1、子任务是否检验了基本的多模态能力；</div></li><li><div class=" pTag">2、子任务对当前的大型视觉语言模型（LVLMs）是否具备挑战性；</div></li><li><div class=" pTag">3、子任务的测试样本是否可以公开获取。</div></li></ul><div class=" pTag">经过选择，MMT-Bench共包含了162个子任务，这比之前任务最多的评测集TinyLVLM-eHub大3.8倍。</div><div class=" pTag">MMT-Bench与此前评测数据的详细比较如下表所示。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqrIUZQIYQgYbOKqof15gTc1GZZ6iblLicPSvZRjXhZsVyc4lCBWlCzruw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">数据收集</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqCn8WXx1F3WGmicMwTibwnR3e7yYtRz6M7ZtGXwty5oF2OfuRdoQX7pXg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">MMT-Bench的研究人员设计了一个高效的数据收集流程，以构建每个子任务的多选视觉语言问题评估数据。</div><div class=" pTag">首先，他们通过Google、Paper With Code、Kaggle和ChatGPT等多种数据来源，根据子任务的名称全面搜索相关数据集。下载数据集后，再细致地评估它们是否适合评估子任务，确保数据集的可用性和相关性。</div><div class=" pTag">接着，研究人员定义了一种统一的元数据格式，用于整理下载的数据集。每个元数据样本包括图像和元信息，其中元信息包括生成评测问题和答案所需的必要信息，以及所需推理能力的标注信息和视觉图片的类型。</div><div class=" pTag">为了提高评估效率，在每个任务中，研究人员通过随机抽样将样本数量最大限制为200，并且每个数据集包含相同数量的样本。</div><div class=" pTag">最后，对于每个子任务，研究人员从它们的元数据中生成多选视觉语言问题及其选项和答案。具体来说，根据特定任务，研究人员或手动设计规则，或使用ChatGPT来进行高质量的QA生成。</div><div class=" pTag">例如，在基于草图进行图像检索的任务中，使用对应的图像作为正确答案，并从元数据中随机抽取其他图像来生成错误选项。而在生成视频描述的任务中，则使用ChatGPT编写容易混淆的错误选项。</div><div class=" pTag">综上，MMT-Bench共包含31,325个精心设计的多选问题，涵盖13种输入图像类型，如自然场景、合成图像、富文本图像、医学图像等，覆盖32个核心元任务和162个子任务，用于多任务多模态理解。</div><div class=" pTag">与之前的LVLMs基准测试相比，MMT-Bench中的问题涵盖了多种多模态场景，如GUI导航和文档理解，测试了包括视觉识别、定位、推理、OCR、计数、3D感知、时间理解等14种能力。这些特点确保MMT-Bench满足评估多任务AGI的任务广度要求。</div><h2>评测结果</h2><div class=" pTag">研究人员基于MMT-Bench对30种公开可用的大型视觉语言模型（LVLMs）进行了综合评估。</div><div class=" pTag">结果显示MMT-Bench的基准测试给现有的LVLMs带来了重大挑战，即使是InternVL-Chat、GPT-4o和GeminiProVision等先进模型，其准确率也仅分别为63.4%、65.5%和61.6%。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqpmsKpLfgo5xH3WwczcCwz95ka4fUVdVud6x9ulkH05vWP8dl1sO2Xw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">综合而言，闭源的专有模型GPT-4o目前在MMT-Bench中取得了领先地位，超过了InternVL-chat、QWen-VL-Plus、GPT-4V和GeminiProVision等其他模型。</div><div class=" pTag">值得注意的是，开源模型InternVL-chat和QwenVL-Max正紧随GPT-4o之后，这为未来开源社区模型能与闭源专有模型竞争甚至超越它们的前景增添了信心。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqxTDTEmow3WsywJqLNhhcJsMqAAkiaR7aat1XI1fe6tLTsD5z2EbZ0cQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在所有元任务的评测结果中，研究人员还发现：</div><div class=" pTag">1）大多数大型视觉语言模型在视觉识别（Visual Recognition）和视觉描述（Visual Captioning）任务中表现出色，凸显了LVLMs在识别“物体是什么”和描述图像中展示内容的能力。然而，对于精细感知任务（如定位、像素级感知等）或复杂推理任务（如图像评测判断），大多数LVLMs仍表现较差。</div><div class=" pTag">2）对于LLaVA-v1.5和LLaVA-v1.5-Xtuner，随着模型大小的增加<span>（从7B增加到13B）</span>，其性能显著提高，而从InternLM升级到InternLM2也提高了LLaVA的性能。这表明即便保持训练数据和视觉编码器保持不变，采用更大或改进的LLMs也能够提升多任务性能。</div><div class=" pTag">3）BLIP2即使没有经过指令调整，也在性能上超过了大多数经过数百万指令数据调整的LVLMs，这表明在某些任务中使用指令调整的数据甚至可能损害其他任务的泛化能力。</div><div class=" pTag"><strong style="font-weight: 600;">任务地图</strong>。</div><div class=" pTag">得益于MMT-Bench中任务的广泛覆盖，研究人员可以在任务地图上评估LVLMs的多模态性能。</div><div class=" pTag">通过分析任务地图中任务之间的关系，可以系统地解释不同任务在多模态能力中的作用。基于任务地图，研究人员发现LVLMs在彼此相近的任务上获得更一致的性能排名。此外，任务地图还可以用来发现领域外（OoD）任务和领域内任务。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqWQPibLjtyrBWypBZmLviaBPibA0waavh7egicwjuXdumND3oP5RFczgia6g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">错误分析</strong>。</div><div class=" pTag">为了分析LVLMs在MMT-Bench上的错误分布，研究人员检查了三个LVLMs：GPT-4V、GeminiProVision和InternVL-Chat-V1.2（简称InternVL）。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqjooP5BTP4G5yvkrPlJ4ZmJEeOsd2ITxqDpibVKpsykEtVHtcUc4OibHA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">结果发现，<strong style="font-weight: 600;">感知错误</strong>（Perception Error）是所有模型中最常见的错误类型。</div><div class=" pTag">其中GPT-4V的感知错误率显著低于GeminiProVision（76.9%）和InternVL（67.2%），表明其在感知任务中的表现优越。</div><div class=" pTag"><strong style="font-weight: 600;">推理错误</strong>是第二常见的错误类型，其中InternVL的推理错误率最高（14.8%），其次是GeminiProVision（10.4%）和GPT-4V（9.94%），这凸显了所有模型在复杂推理任务中所面临的挑战。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqK5yrdTORzpqD6UdABdVrcST3HjtiacO7KHAqHjDnyIhZEicgicHjsBOhw/640?wx_fmt=png&amp;from=appmsg" /></div></div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqWcNrqpMg2IFwQgAibEx4FtPOdzary9VLYhAoCPcQBSUXjlHLIdCmEsQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">最后简单一下，MMT-Bench是一个旨在评估LVLMs在多模态多任务理解方面的一个综合性基准测试。MMT-Bench的广度体现在其精心构建的包含31325个多选问题的数据上，这些问题涵盖了162个多模态任务。</div><div class=" pTag">评估结果揭示了当前LVLMs仍面临由MMT-Bench所带来的重大挑战。MMT-Bench的目标是衡量LVLMs在多任务AGI路径上的进展，并在未来将继续扩展其所涵盖的任务集。研究人员相信，MMT-Bench将进一步激发LVLMs的研究和开发，使得人们能够更接近实现真正智能的多模态系统。</div><div class=" pTag"><span style="font-size: 17px;"><span>论文地址：</span><br /><span>https://arxiv.org/abs/2404.16006</span></span><br /><span style="font-size: 17px;"><span>项目主页地址：</span><br /><span>https://mmt-bench.github.io/</span></span><br /><span style="font-size: 17px;"><span>代码地址：</span><br /><span>https://github.com/OpenGVLab/MMT-Bench</span></span><br /><span style="font-size: 17px;"><span style="font-size: 17px;">数据集地址：</span><br /><span style="font-size: 17px;">https://huggingface.co/datasets/Kaining/MMT-Bench</span></span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FaAMNV1jAKFxUQaPWXLEDWg">阅读原文 </a>
]]></content:encoded>
<pubDate>Wed, 12 Jun 2024 05:24:23 GMT</pubDate>
</item>
<item>
<title>马斯克悄然撤诉OpenAI！xAI融资招聘顺利，战略拖延已达成？</title>
<link>https://posts.careerengine.us/p/66693107222590466adc1bb1</link>
<guid>https://posts.careerengine.us/p/66693107222590466adc1bb1</guid>
<content:encoded><![CDATA[
<div> OpenAI, 马斯克, 诉讼, 撤销, 苹果<br />
<br />
马斯克主动撤销了对OpenAI提起的诉讼，原因可能是要专注于其他更重要的事情。他炮轰OpenAI与苹果的合作，并威胁要禁用苹果设备。之前马斯克指控OpenAI违反了创始协议，转向了盈利目的，但法院文件显示这起案件是无罪开释。这次撤销可能预示着马斯克有其他行动，可能是憋着别的大招。整个事件中，有关创始协议、合作细节、反复作出的承诺以及马斯克的指控等细节被提及。整体而言，这次诉讼的撤销可能是事件的另一个起点。<br /><br />总结: 本文报道了马斯克主动撤销对OpenAI的诉讼，指出可能是为了专注于其他事情。还提到了马斯克对OpenAI和苹果的炮轰，以及之前他对OpenAI提出的指控。整个事件涉及创始协议、合作细节等内容。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">西风 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">最新消息，马斯克<strong style="font-weight: 600;">主动撤销了对OpenAI提起的诉讼</strong>。</div><div class=" pTag">就是之前指控奥特曼和OpenAI公然违背了创始协议转向盈利，要求OpenAI恢复开源那个事。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8exPxgC49NiaUfL0TXHI9V3NXHUtcUeQAhGqHSKiatGTdomvHELOWSibiaQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">事件已过去近四个月，如今法院文件显示，此案是无罪开释。</div><div class=" pTag">原本就在今天，旧金山还有一场听证会，法官将考虑被告请求，决定是否应当驳回此案。</div><div class=" pTag">值得一提的是，3月份有专家告诉CNBC，案件的<strong style="font-weight: 600;">核心合同并非由所有涉事方签署的正式书面协议</strong>，也就是说一开始该案的法律基础就有问题。</div><div class=" pTag">不过，众多网友还是不解，不管怎么说，都应当全力以赴啊，为啥放弃？</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8tsgiaHvTLEmL24ic54G33N1mu5uAg1TiatEFN1kGLcIqr3iakozIG3KDMw/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8M9Ivva6TWLI2tlicPdyKtwpAIS1hxUuf3m9iaviamItwCHiaFibRicpq6c6A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">有网友猜测，马斯克这是不想再因为这事分心，应该是要专注于别的更重要的事。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq80ZEy9Xg49eKa7KwZDBKDXwfrMspahiaBJZrAcl3PND6krkGpesEhOyw/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq84z3tIz1gE5tic44d987xicpl6Lvh1THxwQCvw1lhCQA7my4dKEfcBHFA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">他会以不同的方式复仇。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8d4McBwP8ibNAISpaG1mz5lQCF9jEUx82zFg0eAN4IN8Vtib8MrLW1ibaA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">雀食，老马很忙。</div><div class=" pTag">昨天他还公开炮轰OpenAI与苹果的新合作，扬言苹果要是真敢把ChatGPT集成到系统级别，自己所有的公司都将禁用苹果设备。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8pb3AvsZnFbibpUQPyV4cps5eFib06PMBmNbh1OKwhm9iaSt0jdD3fbhCA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>事件回顾</h2><div class=" pTag">今年二月，<a href="http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;mid=2247719138&amp;idx=1&amp;sn=0adc67c9424c582387c14c4d4c80478a&amp;chksm=e8df2f90dfa8a6865000336004e54aba1f7bb1587511ebc4d3f392f2991c8094881b262cc3fe&amp;scene=21#wechat_redirect" target="_blank">马斯克将46页诉状提交到了法庭</a>。</div><div class=" pTag"><strong style="font-weight: 600;">原告，只有马斯克一人。</strong></div><div class=" pTag"><strong style="font-weight: 600;">被告，满满当当填了OpenAI关联的所有8个公司，加两位高管奥特曼和Brockman。</strong></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8Ia3A4pspeNn8oZTlWCknSnicBsmbF4aGicic9mGb5SKSM6POH79Pz3ZeA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">马斯克的指控有5点。</div><div class=" pTag">一、被告以多种方式违反了创始协议，例如原本承诺OpenAI开发AGI是为了人类利益而非私人商业利益，结果却将可视为AGI早期版本的GPT-4独家授权给微软。</div><div class=" pTag">马斯克还扒出了微软论文当证据，论文通过分析早期GPT-4的能力，认为GPT-4可以被视为早期AGI。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8icExoP1wyK1wT8cHGIehCiaQibADVsicmsrrMGGrm6ic8NxVarvNKKGn1cQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">二、被告违背承诺，曾反复作出包括书面形式在内的承诺，“诱导”马斯克对OpenAI投入了巨资及资源，而OpenAI后来背弃了非盈利使命。</div><div class=" pTag">三、被告违反了信托责任，对马斯克提供的资金及由此资助的知识产权和衍生作品进行了营利性使用。</div><div class=" pTag">四、被告涉嫌不公平商业行为，以虚假承诺为借口，索取马斯克和他人的捐赠用于非原定用途。</div><div class=" pTag">五、被告掌握了马斯克和其他人对OpenAI所做的资助以及这些资金的知识产权和衍生作品的使用相关的财务信息，原告目前无法确定自己在资产的使用、分配或分发上的利益。</div><div class=" pTag">除此之外，马斯克的这份万字诉状中还披露了OpenAI复杂的公司结构、马斯克和奥特曼2015年左右的邮件往来等更多细节亮点。</div><div class=" pTag">当时这事儿在科技圈闹得沸沸扬扬，马斯克与奥特曼两人还在𝕏平台上隔空互怼，大伙儿集体围坐吃瓜。</div><div class=" pTag">马斯克在OpenAI与人形机器人公司Figure宣布合作的帖子中放话：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">放马过来吧。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8W9XOf7jObRL0rs7xuW94zibg0nbFNMOCWdmD6yIsZiaLm59VWAZSM2Bw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">一语双关，既指这场官司，又指未来两家公司在人形机器人上的竞争。</div><div class=" pTag">奥特曼没有直接回复，而是挖出当年特斯拉备受争议时自己力挺马斯克的贴子，时隔五年回复：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">随时奉陪。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8AibxHfmU9dCsa7Vibg1TPHNqE3WktJiabrY0Da2vweoNtAATiaAFKITeGg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">之后，OpenAI对这事儿做出了正式回应，表示自己始终坚持使命，并将对马斯克的所有主张进行反驳。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8L8MiaOE2qMiaxFUqECbQy6WIEibp72mmLuvUhbJYdp07eBarztTPoxNzQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">帖中附带的，是一则更为详细的官方通告，作者包括奥特曼、Brockman、联创Wojciech Zaremba，以及ChatGPT首席架构师John Schulman。</div><div class=" pTag">并未被马斯克列为被告的Ilya Sutskever，也出现在作者名单当中。</div><div class=" pTag">通告介绍了OpenAI与马斯克的爱恨情仇，公开了马斯克与OpenAI高管的往来邮件。同时，OpenAI还表示对走到<span>（诉讼）</span>这一步“感到十分难过”。</div><div class=" pTag">再往后这事儿就没啥太大动静了，直到这次马斯克主动撤诉。</div><div class=" pTag">Ford O’Brien Landy律师事务所合伙人Kevin O’Brien表示，这个案子无疑是对马斯克有利的一次很好的宣传。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq87fBzmjVJHS6hqxhxYm5YPTqj3ica2TO9Dh0ReIurOGiaCsnwQC2DZ2Uw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">就在上个月，马斯克的AI公司<strong style="font-weight: 600;">xAI还宣布完成了60亿美元的B轮融资</strong>，马斯克X发帖称，xAI此轮融资投前估值已达180亿美元。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8VCy98MCtOPfAU4YhvasicnXMdKTAibhn6hhSQbnpHWAhBAnczojj8TgQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>马斯克在憋别的大招？</h2><div class=" pTag">网友们所说的马斯克撤诉可能是在忙着憋别的大招，也并不无道理。</div><div class=" pTag">毕竟撤诉前，他还在连发多条推文，炮轰OpenAI与苹果。</div><div class=" pTag">就因为苹果用Apple Intelligence“重新定义”了AI，与OpenAI合作，表示将在iOS18中接入ChatGPT。</div><div class=" pTag">马斯克扬言，如果苹果敢把ChatGPT集成到系统级别，自己所有的公司都将禁用苹果设备。不仅是员工，访客的苹果设备也会被检查，然后在法拉第笼<span>（可屏蔽信号）</span>中暂存。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8wibiaZRspF5kBia5HIouhaV0ZRqblRjdJO1qicfaeRRiagAkn7OMUUSxgzQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">结合撤诉前的炮轰，有网友也表示这个撤诉的时机是挺可疑的。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8ibgYwRZQ4MM12adUmqbadkGzMX3a5icYVDyXAgTq03PkTribHaGPxonRA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">苹果决定了这场战斗。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8FspwNSShhCFxa7hAWoTC3Usm4TRvuPRicS6oBZa4GEKdqUEZMLHeeHg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">目前马斯克本人对撤诉一事还未做出回应，到底怎么个事看来还需再等一波了～</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8QodWkPxHNd1w7tzUL2UzQOVribxbtNdZNAWMibmDxDXYDjo78tMUk1TA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><span>参考链接：</span><br /><span>[1]https://www.cnbc.com/2024/06/11/elon-musk-drops-suit-against-openai-and-sam-altman.html</span></span><br /><span style="font-size: 17px;">[2]https://x.com/SawyerMerritt/status/1800630127484674167</span><br /><span style="font-size: 17px;">[3]https://x.ai/blog/series-b</span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div class=" pTag"><span style="font-size: 17px;">— <strong style="font-weight: 600;">完</strong> —</span></div></div></div><div style="font-size: 17px;"><div class=" pTag"><span><strong style="font-weight: 600;">量子位年度AI主题策划</strong></span>正在征集中！</div><div class=" pTag">欢迎投稿专题&nbsp;<strong style="font-weight: 600;">一千零一个AI应</strong><strong style="font-weight: 600;">用</strong>，<strong style="font-weight: 600;">365行AI落地方案</strong></div><div class=" pTag">或与我们分享你在<strong style="font-weight: 600;">寻找的AI产品</strong>，或发现的<strong style="font-weight: 600;">AI新动向</strong></div></div><div style="text-align: center;"><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div></div></div><div class=" pTag" style="text-align: center;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5Q42ICOFqdzS7D8e5OMDVA">阅读原文 </a>
]]></content:encoded>
<pubDate>Wed, 12 Jun 2024 05:24:23 GMT</pubDate>
</item>
<item>
<title>手机流畅运行470亿大模型：上交大发布LLM手机推理框架PowerInfer-2，提速29倍</title>
<link>https://posts.careerengine.us/p/666930f8ef51b545e1dc47e8</link>
<guid>https://posts.careerengine.us/p/666930f8ef51b545e1dc47e8</guid>
<content:encoded><![CDATA[
<div> 大模型推理、手机场景优化、PowerInfer-2.0、低成本稀疏化、IPADS团队
<br /><br />总结: 上海交大IPADS团队提出了面向手机的大模型推理引擎PowerInfer-2.0，在内存有限的情况下实现了快速推理。通过动态神经元缓存和神经元簇的设计，提高了模型的稀疏性，同时保持了模型的原有能力。团队还提出了低成本的稀疏化方法，能够提升模型的稀疏度。这些技术不仅适用于手机场景，还有广阔的应用前景。通过与手机厂商合作，技术有望走出实验室，应用于各种真实场景中。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">梦晨 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">苹果一出手，<span><strong style="font-weight: 600;">在手机等移动设备上部署大模型</strong></span>不可避免地成为行业关注焦点。</div><div class=" pTag">然而，目前在移动设备上运行的模型相对较小<span>（苹果的是3B，谷歌的是2B）</span>，并且消耗大量内存，这在很大程度上限制了其应用场景。</div><div class=" pTag">即使是苹果，目前也需要与OpenAI合作，通过将云端GPT-4o大模型嵌入到操作系统中来提供能力更强的服务。</div><div class=" pTag">这样一来，苹果的混合方案引起了非常多<span><strong style="font-weight: 600;">关于数据隐私的讨论和争议，甚至马斯克都下场讨论</strong></span>。</div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">如果苹果在操作系统层面集成OpenAI，那么苹果设备将被禁止在我的公司使用。这是不可接受的安全违规行为。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8qtRxBLjcfxRfEUibW9oz4h2icOIVSsy38IqKqGYmyicptSKIjmhribuqyw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">既然终端侧本地部署大模型的方案既让手机用户享受到AI强大的智能，又能保护好自己的隐私安全，为什么苹果还要冒着侵犯隐私的风险选择联手OpenAI采用云端大模型呢？主要挑战有两点：</div><ul class="list-paddingleft-1" style="font-size: 17px; text-align: start;"><li><div class=" pTag"><span><strong style="font-weight: 600;">手机内存不够大：</strong></span>按照大模型的Scaling Law法则，模型参数越大，能力对应的也就越强，这就意味着能力更强的模型对内存的要求越高。</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">手机算力不够强：</strong></span>即使勉强把通过量化等手段把模型塞进手机了，推理速度也慢，适合的应用场景也就非常有限了。</div></li></ul><div class=" pTag">为了解决上述挑战，上海交大IPADS实验室推出了面向手机的大模型推理引擎<span>（目前论文已在arxiv公开）</span>：<span><strong style="font-weight: 600;">PowerInfer-2.0</strong></span>。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8sTN1aHG5MKFp7CFKxbHPibtcAlPpiaas2d2ibs55GKuMlx2XR68aqeyTw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">PowerInfer-2.0能够在内存有限的智能手机上实现快速推理，让Mixtral 47B模型在手机上达到<span><strong style="font-weight: 600;">11 tokens/s</strong></span>的速度。</div><div class=" pTag">与热门开源推理框架llama.cpp相比，PowerInfer-2.0的<span><strong style="font-weight: 600;">推理加速比平均达到25倍，最高达29倍</strong></span>。</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-106"></div></div><div class=" pTag">为了充分释放出PowerInfer-2.0框架的最大潜力，上海交大团队还提出了配套的大模型优化技术<span><strong style="font-weight: 600;">Turbo Sparse</strong></span>，相关论文近期也上传了arxiv，并且已经在业内引起关注。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8RiaJak6pMPWjXaUyta8Nu9Ghl6nvMMKnHNcl8Kh1PWjlGA7kLiaGt8Dw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">另外值得一提的是，去年底上海交大团队提出了针对PC场景的快速推理框架PowerInfer-1.0，在4090等消费级显卡的硬件上，实现了比llama.cpp高达11倍的推理加速，曾连续三天登顶GitHub趋势榜，5天获得了5k的GitHub star，目前已达到7.1k star。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8oZvfdvGPck58miaAwoNyL1jwiauwkntNUicqibHK6liaqOqIlEfRBRX579Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">相比PC，手机的内存和算力受到的约束更多，那么这次的PowerInfer-2.0是如何针对手机场景加速大模型推理呢？</div><h2>动态神经元缓存</h2><div class=" pTag">首先，针对手机运行内存<span>（DRAM）</span>不足的问题，PowerInfer-2.0利用了稀疏模型推理时的一个特点：<span><strong style="font-weight: 600;">每次只需要激活一小部分神经元，即“稀疏激活”。</strong></span>没有被激活的神经元即使不参与AI模型的推理计算，也不会对模型的输出质量造成影响。</div><div class=" pTag">稀疏激活为降低模型推理的内存使用创造了新的机会。为了充分利用稀疏激活的特性，PowerInfer-2.0把<span><strong style="font-weight: 600;">整个神经网络中的神经元分成了冷、热两种</strong></span>，并在内存中基于LRU策略维护了一个神经元缓存池。</div><div class=" pTag">近期频繁激活的”热神经元”被放置在运行内存中，而“冷神经元”只有在被预测激活的时候，才会被拉进内存，大幅降低了内存使用量。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8P04oBGicKqzrQpJFq3bDnywkEZpZ8shXb9vJcQHYnCTI1wy2f8LOrrQ/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><br /></div><div class=" pTag">其实冷热神经元分类，是继承自PowerInfer-1.0已有的做法。</div><div class=" pTag">而在去年12月，苹果在面向端侧的大语言模型推理方案“LLM in a Flash”中提出了和神经元缓存类似的“滑动窗口”技术。但这些工作主要针对的都是PC环境，直接迁移到手机环境，还会遇到新的难题。</div><div class=" pTag">首先手机平台的硬件条件远不及PC，无论是算力、内存总量还是存储带宽，都与PC存在较大差距。</div><div class=" pTag">其次，手机硬件平台存在<span><strong style="font-weight: 600;">CPU、GPU、NPU三种异构的计算单元</strong></span>，十分复杂。各大硬件平台宣发时都会强调一个总算力，实际上是把CPU、GPU、NPU提供的算力加起来。然而真正跑起大模型来，能不能高效利用各种异构算力还是个问题。</div><h2>以神经元簇为粒度的异构计算</h2><div class=" pTag">针对这一点，PowerInfer-2.0进一步<span><strong style="font-weight: 600;">把粗粒度的大矩阵计算分解成细粒度的“神经元簇”</strong></span>。</div><div class=" pTag">每个神经元簇可以包含若干个参与计算的神经元。对于不同的处理器，会<span><strong style="font-weight: 600;">根据处理器的特性来动态决定划分出来的神经元簇的大小</strong></span>。</div><div class=" pTag"><div class=" pTag">例如，NPU擅长于做大矩阵的计算，那么可以把所有神经元合并成一个大的神经元簇，一起交给NPU计算，这样就可以充分利用NPU的计算能力。而在使用CPU时，可以拆出多个细粒度的神经元簇，分发给多个CPU核心一起计算。</div><br /></div><div class=" pTag">具体而言，PowerInfer-2.0为模型推理的<span><strong style="font-weight: 600;">预填充阶段</strong></span><span style="font-size: 17px; text-align: left;">（Prefill）</span>和<span><strong style="font-weight: 600;">解码阶段</strong></span><span style="font-size: 17px; text-align: left;">（Decoding）</span>分别设计了两套神经元簇的划分方案：</div><div class=" pTag">预填充阶段会一次性输入很多token，基本上绝大部分神经元都会被激活，因此选择使用大神经元簇交给NPU计算。CPU此时也没有闲着，在后台为NPU执行反量化模型权重的操作。</div><div class=" pTag">解码阶段每次只有一个token，具有较高的稀疏性，因此更加适合划分成若干细粒度的神经元簇，交给CPU灵活调度和执行计算。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8XicP2aNAvY7nUrXKLWOtibGPtfibCcKlKr3ucozvfXEKtSgZvFpcLZ1PA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">神经元簇这一概念除了能够更好的适应手机的异构计算环境，还能天然地支持计算与存储I/O的流水线并行执行。</div><div class=" pTag">PowerInfer-2.0提出了<span><strong style="font-weight: 600;">分段神经元缓存和神经元簇级的流水线技术</strong></span>，在一个神经元簇等待I/O的同时，可以及时地把另一个已经准备好的神经元簇调度到处理器上进行计算，从而充分隐藏了I/O的延迟。</div><div class=" pTag">同时，这种基于神经元簇的流水线打破了传统推理引擎中逐矩阵计算的方式，可以允许来自不同参数矩阵的神经元簇交错执行，达到最高的并行效率。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8SUtzqAD3dfQ7PCZoiawa62PKAySDiawHZAviaMEP604JwLEmJK3ibRv44Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">I/O加载神经元的速度对于模型推理也至关重要。</div><div class=" pTag">分段缓存会针对不同的权重类型采取不同策略<span>（如注意力权重、预测器权重、前馈网络权重）</span>采取不同的缓存策略，<span><strong style="font-weight: 600;">提高缓存命中率，减少不必要的磁盘 I/O</strong></span>。</div><div class=" pTag">缓存还会使用LRU替换算法动态更新每个神经元的实际冷热情况，确保缓存中放着的都是最热的神经元。此外PowerInfer-2.0还针对<span><strong style="font-weight: 600;">手机UFS 4.0存储</strong></span>的性能特点，设计了专门的模型存储格式，提高读取性能。</div><div class=" pTag">最后再来看一下实测成绩，使用一加12和一加Ace 2两款测试手机，在内存受限的情况下，PowerInfer-2.0的预填充速度都显著高于llama.cpp与LLM in a Flash<span>（简称“LLMFlash”)</span>：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8tNoKNAU8ohvxqjxT2sic6RwgL4OyIZHSdfibLFERjxt0xRfy0jYqR6Sg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><div class=" pTag">解码阶段同样是PowerInfer-2.0占据很大优势。特别是对于Mixtral 47B这样的大模型，也能在手机上跑出11.68 tokens/s的速度：</div><br /></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8YQ8Ia5hUBJmurV52MJgTCNbdp4Ub8kDEEibmEyGiaK5Fw5FzEFJIW0cQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而对于Mistral 7B这种可以放进手机运行内存的模型，PowerInfer-2.0可以节约40%内存的情况下，达到与llama.cpp和MLC-LLM同水平甚至更快的解码速度：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8RQX8jTFE5xjp0c7PN2x9XHPQWTpO2Dbk5cwwLicUdvFuzRGkYP4ptEQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">PowerInfer-2.0是一个模型-系统协同设计的方案，也就是需要模型中可预测稀疏性的配合。</div><div class=" pTag">如何以低成本的形式调整模型以适配PowerInfer-2.0框架，也是一个重大挑战。</div><h2>低成本高质量地大幅提升模型稀疏性</h2><div class=" pTag">传统简单的ReLU稀疏化会给模型原本的能力造成不小的影响。</div><div class=" pTag">为了克服这个问题，上海交大IPADS联合清华和上海人工智能实验室提出一个低成本地稀疏化方法，不仅大幅提升模型的稀疏性，还能保持住模型原本的能力！</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8E8TrjxGK7uuMxf4tUvWSVluqw9lCKkMYooLtbUPRYs1gOicejqYnTGQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">首先，论文深入分析了模型稀疏化中的问题：</div><ul class="list-paddingleft-1" style="font-size: 17px; text-align: start;"><li><div class=" pTag">在类LLaMA模型中中<span><strong style="font-weight: 600;">简单引入ReLU</strong></span>，虽然能引入一定程度的稀疏性，但<span><strong style="font-weight: 600;">稀疏度仍然有限</strong></span>。</div></li><li><div class=" pTag">稀疏化过程由于训练语料的不足和训练token的不足导致模型精度下降的问题。</div></li></ul><div class=" pTag">为了提升模型的稀疏度，论文在ReLU基础上提出<span><strong style="font-weight: 600;">dReLU激活函数</strong></span>，采用替换原有激活函数后继续预训练的方式增加模型稀疏性。</div><div class=" pTag">将SwiGLU替换为dReLU一方面直观地提高了输出值中的零元素比例，另一方面能更有效地在稀疏化的过程中复用原本模型训练完成的gate和up矩阵权重。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8SFCPyOib9JpXb3IGhbLxib0uq5XmR0cDicVs2OftmzYW4qyUuobbG7xibg/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8NkOFpVSmP3QGSbJ5vWhKbydldrw3Z3KUQZmMgJ0XmAiasvhUR3nHTFg/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><br /></div><div class=" pTag">为了克服模型能力下降的问题，团队收集了包括网页、代码和数学数据集在内的多样化继续训练语料库。<span><strong style="font-weight: 600;">高质量、多样化的训练数据有助于模型在稀疏化后更好地保持和提升性能。</strong></span></div><div class=" pTag">最后，团队训练了2个TurboSparse大模型进行验证，分别是8x7B和7B的大模型。得益于高质量的继续训练语料，TurboSparse系列模型模型的<span><strong style="font-weight: 600;">精度甚至还能反超原版模型</strong></span><span>（具体见表6）</span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq80UsLh44cCibYgPRmnqRIicnlZxDocgEOtr9HP0936WQ9ibs1hNWe6qE3A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而在稀疏度方面效果也非常显著。相比于原本的Mixtral模型需要激活13B参数量，TurboSparse-Mixtral只需要激活4.3B的参数量，<span><strong style="font-weight: 600;">激活的参数量是原本模型的三分之一</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8ibz22kbccIeD0TLIoxeGhHsnnnqw1hBmpTuibl6eo5L2ibD1uOGWkr8AQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而关于稀疏化过程的成本问题，TurboSparse论文中介绍，改造过程中模型需要<span><strong style="font-weight: 600;">继续训练150B tokens</strong></span>，相比于预训练<span>（假设3T tokens）</span>还不到5%，说明其成本是很低的。</div><h2>让技术加速走出实验室</h2><div class=" pTag">从推理框架和改造模型两个角度出发，上海交大团队的成果实现了大语言模型在手机等资源受限场景下的快速推理。</div><div class=" pTag">而且这套方案的潜力不止于手机，未来在车载设备、智能家居等方向还有更多应用前景。</div><div class=" pTag">最后再正式介绍一下团队。<span><strong style="font-weight: 600;">上海交通大学并行与分布式系统研究所</strong></span><span>（简称IPADS）</span>，由<span><strong style="font-weight: 600;">陈海波教授</strong></span>领导，现有13名教师，100多名学生。</div><div class=" pTag">IPADS长期从事计算机系统的研究，近10年在权威榜单CSRankings的Operating Systems领域排名全球前二，仅次于MIT；上海交大也是排名前十中唯一上榜的亚洲高校。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDH3iaFKB6RV1I5AQU1CZMq8l3c13bXv8lGFoVFe7dRNibYJOTX6PWswxsAG5WUdXtkZOv9s6PorhzA/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><br /></div><div class=" pTag">目前，上海交大IPADS已经在Huggingface上开放了稀疏化的模型权重。在未来，如果PowerInfer-2.0能够与手机厂商进一步紧密合作，相信可以加速相关技术走出实验室，落地到各种真实场景。</div><div class=" pTag"><span style="font-size: 17px;">PowerInfer-2论文：</span><span style="font-size: 17px;">https://arxiv.org/abs/2406.06282</span><br /><span style="font-size: 17px;">TurboSparse论文：</span><span style="font-size: 17px;">https://arxiv.org/abs/2406.05955</span><br /><span style="font-size: 17px;">模型权重：</span><span style="font-size: 17px;">https://huggingface.co/PowerInfer/TurboSparse-Mixtral</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FvylZp7MG7TA3pQKOBWbYRQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Wed, 12 Jun 2024 05:24:08 GMT</pubDate>
</item>
<item>
<title>全面超越Transformer！清华蚂蚁推出纯MLP架构，长短程时序预测大幅提升</title>
<link>https://posts.careerengine.us/p/6667ef11c053f928b66dfb95</link>
<guid>https://posts.careerengine.us/p/6667ef11c053f928b66dfb95</guid>
<content:encoded><![CDATA[
<div> <h5 style="font-size: 17px; text-align: left;"><div class=" pTag">蔚明 投稿自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">Transformer很强，Transformer很好，但Transformer在处理时序数据时存在一定的局限性。</div><div class=" pTag">如计算复杂度高、对长序列数据处理不够高效等问题。</div><div class=" pTag">而在数据驱动的时代，时序预测成为许多领域中不可或缺的一部分。</div><div class=" pTag">于是乎，蚂蚁同清华联合推出一种纯MLP架构的模型<strong style="font-weight: 600;">TimeMixer</strong>，在时序预测上的性能和效能两方面全面超越了Transformer模型。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqyQkk8r8AnVfOyn7nSfOOictnqs1tmBgYwDibGVNcjUOrL25zuesf8HQQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">他们结合对时序趋势周期特性的分解以及多尺度混合的设计模式，不仅在长短程预测性能上大幅提升，而且基于纯MLP架构实现了接近于线性模型的极高效率。</div><div class=" pTag">来康康是如何做到的？</div><h2>纯MLP架构超越Transformer</h2><div class=" pTag">TimeMixer模型采用了一个多尺度混合架构，旨在解决时间序列预测中的复杂时间变化问题。</div><div class=" pTag">该模型主要采用全MLP（多层感知机）架构，由过去可分解混合Past Decomposable Mixing (PDM) 和未来多预测器混合Future Multipredictor Mixing (FMM) 两大块构成，能够有效利用多尺度序列信息。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqGkA866sjxKTATzicwyN2aXXUU5nBdxvARic17jTlia8oP3PcB3ibttkD5w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">其中PDM模块，负责提取过去的信息并将不同尺度上的季节性和趋势组分分别混合。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnquDH34hFwkjQdwNjjAtoib0ia5icMbHiaE2ASxH9qiaDnbGzicAvlpjfewSFw/640?wx_fmt=png&amp;from=appmsg" /></div></div><br />PDM以季节和趋势混合为动力，将详细的季节信息由细到粗逐步聚合，并利用较粗尺度的先验知识深入挖掘宏观趋势信息，最终实现过去信息提取中的多尺度混合。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqhMrWyI8NdMREmn9r8nkMJT8CrvhIicTmaMqLbUSznZnWrtX0WqX96jQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">FMM则是多个预测器的集合，其中不同的预测器基于不同尺度的过去信息，使 FMM 能够集成混合多尺度序列的互补预测功能。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqg5DXF8zAy4qjtaFZolvRHGrSoqh9Tc1iakKOj2CBN8CBnMHu5u85wdQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>实验效果</h2><div class=" pTag">为了验证TimeMixer的性能，团队在包含长程预测，短程预测，多元时序预测以及具有时空图结构的18组基准数据集上进行了实验，包括电力负荷预测、气象数据预测和股票价格预测等。</div><div class=" pTag">实验结果表明，TimeMixer在多个指标上全面超越了当前最先进的Transformer模型，具体表现如下：</div><div class=" pTag"><strong style="font-weight: 600;">预测精度</strong>：在所有测试的数据集上，TimeMixer均表现出更高的预测精度。以电力负荷预测为例，TimeMixer相比于Transformer模型，平均绝对误差（MAE）降低了约15%，均方根误差（RMSE）降低了约12%。</div><div class=" pTag"><strong style="font-weight: 600;">计算效率</strong>：得益于MLP结构的高效计算特性，TimeMixer在训练时间和推理时间上均显著优于Transformer模型。实验数据显示，在相同硬件条件下，TimeMixer的训练时间减少了约30%，推理时间减少了约25%。</div><div class=" pTag"><strong style="font-weight: 600;">模型可解释性</strong>：通过引入Past Decomposable Mixing和Future Multipredictor Mixing技术，TimeMixer能够更好地解释不同时间尺度上的信息贡献，使得模型的决策过程更加透明和易于理解。</div><div class=" pTag"><strong style="font-weight: 600;">泛化能力</strong>：在多个不同类型的数据集上进行测试，TimeMixer均表现出良好的泛化能力，能够适应不同的数据分布和特征。这表明TimeMixer在实际应用中具有广泛的适用性。</div><div class=" pTag"><strong style="font-weight: 600;">长程预测</strong>：为了确保模型比较的公平性，使用标准化参数进行实验，调整输入长度、批量大小和训练周期。此外，鉴于各种研究的结果通常源于超参数优化，该研究还包括了综合参数搜索的结果。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqf3u14PhQSg9US35Jbv17dqY088KHGcZ49Hu7uSop3Xq9YQa6bcN6tg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">短程预测：多变量数据</strong></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqpRAhmdY8fkQDibfxSWAImJQGGcl9TDxcxxq6afucCtZaaqIq3CFgUvA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">短程预测：单变量数据</strong></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqo4GcEtKJGzsDKdbxaGr0ShYnsqkIyMaxZdg7GjUFQgmk75mzgMldww/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">消融实验</strong>：为了验证 TimeMixer 每个组件的有效性，我们在所有 18 个实验基准上对 Past-Decomposable-Mishing 和 Future-Multipredictor-Mishing 模块中的每种可能的设计进行了详细的消融研究。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqm7tSYic21Zx1Ggk1G7ZapFejjqJ9OENZPEdIfagoHVYhOnPreX4oLMQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">模型效率</strong>：团队将训练阶段的运行内存和时间与最新最先进的模型进行比较，其中 TimeMixer 在 GPU 内存和运行时间方面，对于各种系列长度（范围从 192 到 3072）始终表现出良好的效率），此外还具有长期和短期预测任务一致的最先进性能。</div><div class=" pTag">值得注意的是，TimeMixer 作为深度模型，在效率方面表现出接近全线性模型的结果。这使得 TimeMixer 在各种需要高模型效率的场景中大有前途。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqv3nIrkhLPeibEFB3hH2w4SwHhiaIcKj3NH2MTArKYhZcvCCj9614kkRg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">好了，TimeMixer为时序预测领域带来了新的思路，也展示了纯MLP结构在复杂任务中的潜力。</div><div class=" pTag">未来，随着更多优化技术和应用场景的引入，相信TimeMixer将进一步推动时序预测技术的发展，为各行业带来更大的价值。</div><div class=" pTag">本项目获得了蚂蚁集团智能引擎事业部旗下AI创新研发部门NextEvo支持。</div><div class=" pTag">蚂蚁集团NextEvo-优化智能团队负责蚂蚁运筹优化、时序预测以及预测优化相结合的智能决策等技术方向，团队工作涵盖算法技术、平台服务和解决方案的研发。</div><div class=" pTag"><span style="font-size: 17px;"><span>论文地址：</span><br /><span>https://arxiv.org/abs/2405.14616v1</span></span><br /><span style="font-size: 17px;"><span style="font-size: 17px;">论文代码：</span><br /><span style="font-size: 17px;">https://github.com/kwuking/TimeMixer</span></span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYZ7L1hImIt-jbRT2tizyQw">阅读原文 </a> </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">蔚明 投稿自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">Transformer很强，Transformer很好，但Transformer在处理时序数据时存在一定的局限性。</div><div class=" pTag">如计算复杂度高、对长序列数据处理不够高效等问题。</div><div class=" pTag">而在数据驱动的时代，时序预测成为许多领域中不可或缺的一部分。</div><div class=" pTag">于是乎，蚂蚁同清华联合推出一种纯MLP架构的模型<strong style="font-weight: 600;">TimeMixer</strong>，在时序预测上的性能和效能两方面全面超越了Transformer模型。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqyQkk8r8AnVfOyn7nSfOOictnqs1tmBgYwDibGVNcjUOrL25zuesf8HQQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">他们结合对时序趋势周期特性的分解以及多尺度混合的设计模式，不仅在长短程预测性能上大幅提升，而且基于纯MLP架构实现了接近于线性模型的极高效率。</div><div class=" pTag">来康康是如何做到的？</div><h2>纯MLP架构超越Transformer</h2><div class=" pTag">TimeMixer模型采用了一个多尺度混合架构，旨在解决时间序列预测中的复杂时间变化问题。</div><div class=" pTag">该模型主要采用全MLP（多层感知机）架构，由过去可分解混合Past Decomposable Mixing (PDM) 和未来多预测器混合Future Multipredictor Mixing (FMM) 两大块构成，能够有效利用多尺度序列信息。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqGkA866sjxKTATzicwyN2aXXUU5nBdxvARic17jTlia8oP3PcB3ibttkD5w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">其中PDM模块，负责提取过去的信息并将不同尺度上的季节性和趋势组分分别混合。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnquDH34hFwkjQdwNjjAtoib0ia5icMbHiaE2ASxH9qiaDnbGzicAvlpjfewSFw/640?wx_fmt=png&amp;from=appmsg" /></div></div><br />PDM以季节和趋势混合为动力，将详细的季节信息由细到粗逐步聚合，并利用较粗尺度的先验知识深入挖掘宏观趋势信息，最终实现过去信息提取中的多尺度混合。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqhMrWyI8NdMREmn9r8nkMJT8CrvhIicTmaMqLbUSznZnWrtX0WqX96jQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">FMM则是多个预测器的集合，其中不同的预测器基于不同尺度的过去信息，使 FMM 能够集成混合多尺度序列的互补预测功能。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqg5DXF8zAy4qjtaFZolvRHGrSoqh9Tc1iakKOj2CBN8CBnMHu5u85wdQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>实验效果</h2><div class=" pTag">为了验证TimeMixer的性能，团队在包含长程预测，短程预测，多元时序预测以及具有时空图结构的18组基准数据集上进行了实验，包括电力负荷预测、气象数据预测和股票价格预测等。</div><div class=" pTag">实验结果表明，TimeMixer在多个指标上全面超越了当前最先进的Transformer模型，具体表现如下：</div><div class=" pTag"><strong style="font-weight: 600;">预测精度</strong>：在所有测试的数据集上，TimeMixer均表现出更高的预测精度。以电力负荷预测为例，TimeMixer相比于Transformer模型，平均绝对误差（MAE）降低了约15%，均方根误差（RMSE）降低了约12%。</div><div class=" pTag"><strong style="font-weight: 600;">计算效率</strong>：得益于MLP结构的高效计算特性，TimeMixer在训练时间和推理时间上均显著优于Transformer模型。实验数据显示，在相同硬件条件下，TimeMixer的训练时间减少了约30%，推理时间减少了约25%。</div><div class=" pTag"><strong style="font-weight: 600;">模型可解释性</strong>：通过引入Past Decomposable Mixing和Future Multipredictor Mixing技术，TimeMixer能够更好地解释不同时间尺度上的信息贡献，使得模型的决策过程更加透明和易于理解。</div><div class=" pTag"><strong style="font-weight: 600;">泛化能力</strong>：在多个不同类型的数据集上进行测试，TimeMixer均表现出良好的泛化能力，能够适应不同的数据分布和特征。这表明TimeMixer在实际应用中具有广泛的适用性。</div><div class=" pTag"><strong style="font-weight: 600;">长程预测</strong>：为了确保模型比较的公平性，使用标准化参数进行实验，调整输入长度、批量大小和训练周期。此外，鉴于各种研究的结果通常源于超参数优化，该研究还包括了综合参数搜索的结果。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqf3u14PhQSg9US35Jbv17dqY088KHGcZ49Hu7uSop3Xq9YQa6bcN6tg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">短程预测：多变量数据</strong></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqpRAhmdY8fkQDibfxSWAImJQGGcl9TDxcxxq6afucCtZaaqIq3CFgUvA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">短程预测：单变量数据</strong></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqo4GcEtKJGzsDKdbxaGr0ShYnsqkIyMaxZdg7GjUFQgmk75mzgMldww/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">消融实验</strong>：为了验证 TimeMixer 每个组件的有效性，我们在所有 18 个实验基准上对 Past-Decomposable-Mishing 和 Future-Multipredictor-Mishing 模块中的每种可能的设计进行了详细的消融研究。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqm7tSYic21Zx1Ggk1G7ZapFejjqJ9OENZPEdIfagoHVYhOnPreX4oLMQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">模型效率</strong>：团队将训练阶段的运行内存和时间与最新最先进的模型进行比较，其中 TimeMixer 在 GPU 内存和运行时间方面，对于各种系列长度（范围从 192 到 3072）始终表现出良好的效率），此外还具有长期和短期预测任务一致的最先进性能。</div><div class=" pTag">值得注意的是，TimeMixer 作为深度模型，在效率方面表现出接近全线性模型的结果。这使得 TimeMixer 在各种需要高模型效率的场景中大有前途。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqv3nIrkhLPeibEFB3hH2w4SwHhiaIcKj3NH2MTArKYhZcvCCj9614kkRg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">好了，TimeMixer为时序预测领域带来了新的思路，也展示了纯MLP结构在复杂任务中的潜力。</div><div class=" pTag">未来，随着更多优化技术和应用场景的引入，相信TimeMixer将进一步推动时序预测技术的发展，为各行业带来更大的价值。</div><div class=" pTag">本项目获得了蚂蚁集团智能引擎事业部旗下AI创新研发部门NextEvo支持。</div><div class=" pTag">蚂蚁集团NextEvo-优化智能团队负责蚂蚁运筹优化、时序预测以及预测优化相结合的智能决策等技术方向，团队工作涵盖算法技术、平台服务和解决方案的研发。</div><div class=" pTag"><span style="font-size: 17px;"><span>论文地址：</span><br /><span>https://arxiv.org/abs/2405.14616v1</span></span><br /><span style="font-size: 17px;"><span style="font-size: 17px;">论文代码：</span><br /><span style="font-size: 17px;">https://github.com/kwuking/TimeMixer</span></span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYZ7L1hImIt-jbRT2tizyQw">阅读原文 </a>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 06:30:41 GMT</pubDate>
</item>
<item>
<title>马斯克怒斥苹果接入ChatGPT：真敢集成就在全公司禁用</title>
<link>https://posts.careerengine.us/p/6667ef10c053f928b66dfb8d</link>
<guid>https://posts.careerengine.us/p/6667ef10c053f928b66dfb8d</guid>
<content:encoded><![CDATA[
<div> <h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">苹果前脚刚用Apple Intelligence“重新定义”了AI，后脚就被马斯克杠上了。</div><div class=" pTag">原因嘛，是因为苹果宣布将<strong style="font-weight: 600;"><span>在iOS18中接入ChatGPT</span></strong>，被马斯克认为是极不安全的做法。</div><div class=" pTag">马斯克扬言，如果苹果敢把ChatGPT集成到系统级别，自己所有的公司<strong style="font-weight: 600;"><span>都将禁用苹果设备</span></strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fjb7ahkRFzUwibiaol8MN9cAziaRQnibicgqr3RA16exJqfMkpWzpks91nhbg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不仅是员工，<strong style="font-weight: 600;"><span>访客的苹果设备也会被检查</span></strong>，然后在法拉第笼<span>（可屏蔽信号）</span>中暂存。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fj7RromKNJ5PKQy3po4WngZ0vK5PU75T61DIFoStNTA9P4FISRfefNgg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不过虽然马斯克明面上说的是苹果，但字里行间都透露着对老冤家OpenAI的不满。</div><div class=" pTag">老马给出的具体解释中也提到，如果苹果把信息交给OpenAI，<strong style="font-weight: 600;"><span>安全和隐私根本无法保障</span></strong>，还为此送出了表情包。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjETvPbYNdmwzhlxaTGCF5FRKFno0mq1V7D5n4QwtlwT4QFJibe92jbfA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">视角独到的网友就此提问，这是意味着特斯拉手机或者Grok手机要来了吗？</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fj2DSlJ5Gp0UQI9XKrJ5Zj4yzn7xVcavCM0icDIpWXibs9qrQZ9OAtLqRg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">当然，也有网友直接给马斯克送上了无情嘲讽：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag"><div class=" pTag">所以我猜你（指马斯克）不会用苹果和微软的电脑？</div><br /><div class=" pTag">安卓手机也不行，因为谷歌……</div><br /><div class=" pTag">我猜特斯拉、SpaceX和X一定还在用纸笔和飞鸽传书吧。</div></div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjppbWRH8VbhJAUJEiahgr9M9LOKWIrUssV6zUJkenlByh1frs6TreRicg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">所以，苹果到底做了什么，能让马斯克有如此大的反应呢？</div><h2>新版Siri将接入ChatGPT</h2><div class=" pTag">刚刚结束的WWDC上，苹果宣布与OpenAI达成了合作。OpenAI CEO奥特曼也被发现出现在了现场，被无数果粉“活捉”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjKpXlPPvyXNb4JbPvCXJrsBCiabROs962NHugia5GtrjyEhTQCEfZULIg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">奥特曼还第一时间发推庆祝，确认今年晚些时候ChatGPT将集成到苹果设备当中。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fjjs9DMToGMbOZJTmic7oIy3UnrAJ1GPTg6Bzqia8hqB18GEmIdibVBGvVg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">具体来说，苹果将在Siri当中提供ChatGPT接口，用户将可以通过Siri直接使用GPT-4o，而且免费、无需注册。</div><div class=" pTag">当用户问到苹果自家模型无法解决的问题时，Siri会推荐使用ChatGPT，然后询问用户是否同意。</div><div class=" pTag">如果建议被接受，就能立马获得来自ChatGPT的答案。</div><div class=" pTag">而且还支持本地PDF文档，并具有多模态能力，可以分析手机里的图片，在传送给ChatGPT之前Siri<strong style="font-weight: 600;"><span>会询问用户是否同意</span></strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjN7J3pxC1L3coOJDgwQ1P5Te7xj3Rvk0NHODCFhu0RFPohwUXAiaH4NA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">当然，ChatGPT的订阅用户也可以选择关联到自己的账户，并接入ChatGPT的付费功能。</div><div class=" pTag">这个功能将在今年稍晚推出。苹果表示，未来还将增加对其他AI模型的支持。</div><div class=" pTag">总结一下就是，这个功能用不用、怎么用，都是用户自愿，所有文档图片都会单独确认授权。</div><div class=" pTag">而且主要AI功能还是依靠自家模型，运算<strong style="font-weight: 600;"><span>在本地或私有云上完成</span></strong>，苹果不会存储任何信息。</div><div class=" pTag">ChatGPT更是完全属于附加组件，未来也不是唯一可选择的第三方模型。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjiauKiaTUT9AyTN6JNaDRB7icl6xOJTdAYYVCMrJYvXW4oyUqPdVgaNbnw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>马斯克：OpenAI会出卖用户数据</h2><div class=" pTag">按照苹果的描述，数据未经授权泄露给OpenAI的事情大概是不必担心的。</div><div class=" pTag">但其实，马斯克也没说将数据交给OpenAI是否取得了用户同意的问题，而是在说<span><strong style="font-weight: 600;">数据一旦交给OpenAI之后就不安全了</strong></span>。</div><div class=" pTag">他表示，苹果没能力搞自己的人工智能，却相信OpenAI能保护用户安全和隐私，这简直荒谬；苹果根本不知道把数据交给OpenAI之后会发生什么，用户会被OpenAI出卖。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fjp5wgndicUWNicMU7sh0SNbibFmnOSPCIx24px4TDbhicqTnicKwfsbBbFgw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">另外，马斯克还表示，即使上传文件到ChatGPT征得了用户同意，这种“同意”也存在问题，因为人们根本不会阅读用户条款。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fj5tb7SibQmezqBfvcn3ZzIUJJqZ9So1IUuBWA0jnVJ8ZpPD7wZUbiaEiaw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">有人用寡姐怒怼OpenAI的事情举例，表示后者未经允许克隆寡姐声音的事情就是前科劣迹。</div><div class=" pTag">虽然OpenAI后来将声音下架并澄清说给争议角色配音的演员另有其人，但马斯克还是回复了一个大大的Exactly。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjWu1XZQqq4fIiaEDBQJfqEjgmMlI0ic6LLmwdRQ5fLEu369n4X2ClicrcQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而说到隐私问题，又有网友表示老马虽然我也和你一样关心，但你还是先别说人家了，你最近聘请第三方公司收集X用户的个人信息和生物识别信息，这是要干啥你解释一下呗，而且你是怎么保证这些信息放在第三方手里就是安全的呢？</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjZ0UZNeeC6iaE2YBcSMJNSPhsqgAhzziaEo90PqgdRepBic5RwlviczEH9w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">除了安全和隐私，马斯克还表示ChatGPT实在是过于woke up，并转发了具体案例。</div><div class=" pTag">马斯克配文称，想象一下如果这样训练出的AI（规模）指数级增长会是什么样子吧……</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjAoB3bJyf3zZmkMwFu3icmefuekKe8DRAI7nJjXicUTOw8MgUoYbaMdAg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">实际上，这也是他一直以来都在指责OpenAI的一点，同时他还旗帜鲜明地反对woke AI，曾表示自己的Grok绝对不会woke up。</div><div class=" pTag">到目前为止，苹果和OpenAI都没有对马斯克的炮轰做出回应，两者之间的合作也已然官宣。</div><div class=" pTag">至于马斯克会不会真的禁用苹果设备，只有交给时间来回答了。</div><div class=" pTag">你认为马斯克和OpenAI之间的争斗会怎么收场呢，欢迎评论区交流。</div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://x.com/elonmusk/status/1800265938694193183</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://x.com/elonmusk/status/1800269249912381773/</span><br /><span style="font-size: 17px;">[3]</span><span style="font-size: 17px;">https://x.com/elonmusk/status/1800274139162485165</span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div class=" pTag"><span style="font-size: 17px;">— <strong style="font-weight: 600;">完</strong> —</span></div></div></div><div style="font-size: 17px;"><div class=" pTag"><span><strong style="font-weight: 600;">量子位年度AI主题策划</strong></span>正在征集中！</div><div class=" pTag">欢迎投稿专题&nbsp;<strong style="font-weight: 600;">一千零一个AI应</strong><strong style="font-weight: 600;">用</strong>，<strong style="font-weight: 600;">365行AI落地方案</strong></div><div class=" pTag">或与我们分享你在<strong style="font-weight: 600;">寻找的AI产品</strong>，或发现的<strong style="font-weight: 600;">AI新动向</strong></div></div><div style="text-align: center;"><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div></div></div><div class=" pTag" style="text-align: center;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FkjzP7_5xJ4mqbBLwAc557g">阅读原文 </a> </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">苹果前脚刚用Apple Intelligence“重新定义”了AI，后脚就被马斯克杠上了。</div><div class=" pTag">原因嘛，是因为苹果宣布将<strong style="font-weight: 600;"><span>在iOS18中接入ChatGPT</span></strong>，被马斯克认为是极不安全的做法。</div><div class=" pTag">马斯克扬言，如果苹果敢把ChatGPT集成到系统级别，自己所有的公司<strong style="font-weight: 600;"><span>都将禁用苹果设备</span></strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fjb7ahkRFzUwibiaol8MN9cAziaRQnibicgqr3RA16exJqfMkpWzpks91nhbg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不仅是员工，<strong style="font-weight: 600;"><span>访客的苹果设备也会被检查</span></strong>，然后在法拉第笼<span>（可屏蔽信号）</span>中暂存。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fj7RromKNJ5PKQy3po4WngZ0vK5PU75T61DIFoStNTA9P4FISRfefNgg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不过虽然马斯克明面上说的是苹果，但字里行间都透露着对老冤家OpenAI的不满。</div><div class=" pTag">老马给出的具体解释中也提到，如果苹果把信息交给OpenAI，<strong style="font-weight: 600;"><span>安全和隐私根本无法保障</span></strong>，还为此送出了表情包。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjETvPbYNdmwzhlxaTGCF5FRKFno0mq1V7D5n4QwtlwT4QFJibe92jbfA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">视角独到的网友就此提问，这是意味着特斯拉手机或者Grok手机要来了吗？</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fj2DSlJ5Gp0UQI9XKrJ5Zj4yzn7xVcavCM0icDIpWXibs9qrQZ9OAtLqRg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">当然，也有网友直接给马斯克送上了无情嘲讽：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag"><div class=" pTag">所以我猜你（指马斯克）不会用苹果和微软的电脑？</div><br /><div class=" pTag">安卓手机也不行，因为谷歌……</div><br /><div class=" pTag">我猜特斯拉、SpaceX和X一定还在用纸笔和飞鸽传书吧。</div></div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjppbWRH8VbhJAUJEiahgr9M9LOKWIrUssV6zUJkenlByh1frs6TreRicg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">所以，苹果到底做了什么，能让马斯克有如此大的反应呢？</div><h2>新版Siri将接入ChatGPT</h2><div class=" pTag">刚刚结束的WWDC上，苹果宣布与OpenAI达成了合作。OpenAI CEO奥特曼也被发现出现在了现场，被无数果粉“活捉”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjKpXlPPvyXNb4JbPvCXJrsBCiabROs962NHugia5GtrjyEhTQCEfZULIg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">奥特曼还第一时间发推庆祝，确认今年晚些时候ChatGPT将集成到苹果设备当中。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fjjs9DMToGMbOZJTmic7oIy3UnrAJ1GPTg6Bzqia8hqB18GEmIdibVBGvVg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">具体来说，苹果将在Siri当中提供ChatGPT接口，用户将可以通过Siri直接使用GPT-4o，而且免费、无需注册。</div><div class=" pTag">当用户问到苹果自家模型无法解决的问题时，Siri会推荐使用ChatGPT，然后询问用户是否同意。</div><div class=" pTag">如果建议被接受，就能立马获得来自ChatGPT的答案。</div><div class=" pTag">而且还支持本地PDF文档，并具有多模态能力，可以分析手机里的图片，在传送给ChatGPT之前Siri<strong style="font-weight: 600;"><span>会询问用户是否同意</span></strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjN7J3pxC1L3coOJDgwQ1P5Te7xj3Rvk0NHODCFhu0RFPohwUXAiaH4NA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">当然，ChatGPT的订阅用户也可以选择关联到自己的账户，并接入ChatGPT的付费功能。</div><div class=" pTag">这个功能将在今年稍晚推出。苹果表示，未来还将增加对其他AI模型的支持。</div><div class=" pTag">总结一下就是，这个功能用不用、怎么用，都是用户自愿，所有文档图片都会单独确认授权。</div><div class=" pTag">而且主要AI功能还是依靠自家模型，运算<strong style="font-weight: 600;"><span>在本地或私有云上完成</span></strong>，苹果不会存储任何信息。</div><div class=" pTag">ChatGPT更是完全属于附加组件，未来也不是唯一可选择的第三方模型。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjiauKiaTUT9AyTN6JNaDRB7icl6xOJTdAYYVCMrJYvXW4oyUqPdVgaNbnw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>马斯克：OpenAI会出卖用户数据</h2><div class=" pTag">按照苹果的描述，数据未经授权泄露给OpenAI的事情大概是不必担心的。</div><div class=" pTag">但其实，马斯克也没说将数据交给OpenAI是否取得了用户同意的问题，而是在说<span><strong style="font-weight: 600;">数据一旦交给OpenAI之后就不安全了</strong></span>。</div><div class=" pTag">他表示，苹果没能力搞自己的人工智能，却相信OpenAI能保护用户安全和隐私，这简直荒谬；苹果根本不知道把数据交给OpenAI之后会发生什么，用户会被OpenAI出卖。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fjp5wgndicUWNicMU7sh0SNbibFmnOSPCIx24px4TDbhicqTnicKwfsbBbFgw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">另外，马斯克还表示，即使上传文件到ChatGPT征得了用户同意，这种“同意”也存在问题，因为人们根本不会阅读用户条款。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fj5tb7SibQmezqBfvcn3ZzIUJJqZ9So1IUuBWA0jnVJ8ZpPD7wZUbiaEiaw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">有人用寡姐怒怼OpenAI的事情举例，表示后者未经允许克隆寡姐声音的事情就是前科劣迹。</div><div class=" pTag">虽然OpenAI后来将声音下架并澄清说给争议角色配音的演员另有其人，但马斯克还是回复了一个大大的Exactly。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjWu1XZQqq4fIiaEDBQJfqEjgmMlI0ic6LLmwdRQ5fLEu369n4X2ClicrcQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而说到隐私问题，又有网友表示老马虽然我也和你一样关心，但你还是先别说人家了，你最近聘请第三方公司收集X用户的个人信息和生物识别信息，这是要干啥你解释一下呗，而且你是怎么保证这些信息放在第三方手里就是安全的呢？</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjZ0UZNeeC6iaE2YBcSMJNSPhsqgAhzziaEo90PqgdRepBic5RwlviczEH9w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">除了安全和隐私，马斯克还表示ChatGPT实在是过于woke up，并转发了具体案例。</div><div class=" pTag">马斯克配文称，想象一下如果这样训练出的AI（规模）指数级增长会是什么样子吧……</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjAoB3bJyf3zZmkMwFu3icmefuekKe8DRAI7nJjXicUTOw8MgUoYbaMdAg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">实际上，这也是他一直以来都在指责OpenAI的一点，同时他还旗帜鲜明地反对woke AI，曾表示自己的Grok绝对不会woke up。</div><div class=" pTag">到目前为止，苹果和OpenAI都没有对马斯克的炮轰做出回应，两者之间的合作也已然官宣。</div><div class=" pTag">至于马斯克会不会真的禁用苹果设备，只有交给时间来回答了。</div><div class=" pTag">你认为马斯克和OpenAI之间的争斗会怎么收场呢，欢迎评论区交流。</div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://x.com/elonmusk/status/1800265938694193183</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://x.com/elonmusk/status/1800269249912381773/</span><br /><span style="font-size: 17px;">[3]</span><span style="font-size: 17px;">https://x.com/elonmusk/status/1800274139162485165</span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div class=" pTag"><span style="font-size: 17px;">— <strong style="font-weight: 600;">完</strong> —</span></div></div></div><div style="font-size: 17px;"><div class=" pTag"><span><strong style="font-weight: 600;">量子位年度AI主题策划</strong></span>正在征集中！</div><div class=" pTag">欢迎投稿专题&nbsp;<strong style="font-weight: 600;">一千零一个AI应</strong><strong style="font-weight: 600;">用</strong>，<strong style="font-weight: 600;">365行AI落地方案</strong></div><div class=" pTag">或与我们分享你在<strong style="font-weight: 600;">寻找的AI产品</strong>，或发现的<strong style="font-weight: 600;">AI新动向</strong></div></div><div style="text-align: center;"><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div></div></div><div class=" pTag" style="text-align: center;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FkjzP7_5xJ4mqbBLwAc557g">阅读原文 </a>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 06:30:40 GMT</pubDate>
</item>
<item>
<title>AI重新定义导航，弯道会车无灯路口提前预警，网友：导航成精了！</title>
<link>https://posts.careerengine.us/p/6667ef02334ab6289409863f</link>
<guid>https://posts.careerengine.us/p/6667ef02334ab6289409863f</guid>
<content:encoded><![CDATA[
<div> <h5 style="font-size: 17px; text-align: left;"><div class=" pTag">一凡 白交 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">AI正在守护人们的出行安全。</div><div class=" pTag">请看VCR：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjfcnpdcFskHN1vg4v4LQSQkcVKFvSPnU4mG4T2IABanZXicYMcz1PzMw/640?wx_fmt=gif&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjobpZW7PZzaqBRxZwQ1lbyksazQPLiaFIiazZrqGzcQVTqDByprYrL4oQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">最近，大量高德用户晒出类似图中的体验，发出感慨：现在导航都这么智能了？？？</div><div class=" pTag">还有用户在社交平台发帖，疯狂安利骑友们：跑山请开高德，求扩散！！！</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjXZRsMkTh1xS3DIs4nmcEK7sefldZvh3WicgHibsUqmmAq0q7eyZOicDdg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">是什么让用户当起“自来水”，甚至点赞直呼“黑科技”？</div><div class=" pTag">高德地图“车道级安全预警”功能。两轮四轮都能用，新老司机都刚需…</div><div class=" pTag">无需额外装硬件，一个APP就搞定。</div><h2>高德导航在Next level了</h2><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">“高德给力！”“高德变了？！”“高德什么时候变得这么智能了？！”</div></blockquote><div class=" pTag">在各种社交平台上，尤其是假期前后出行高峰，这些评论开始大量出现，相关视频接连成为「爆款」。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fj3XrpWZiaqHoC1lX1o5b2C1gjdWRO8niaF1jGG6vHfu3ibay2XWxlTkmdg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjzyNBUd8oJuywziaSAUx2Y5rQGjSqlzfhwNY2hQDKEZrCy4JJm2JjZNg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">结果仔细一看发现啊，他们所讨论的是高德地图的导航功能。不光有App用户，还包括不少车机用户；视频中也是各种覆盖白天黑夜；会车超车弯道各种场景。</div><div class=" pTag">种种体验感受，归结起来就是：高德导航已经在Next Level了。</div><div class=" pTag">比如一个视频中，车辆夜间正常行驶，结果导航突然鸣笛播报提醒：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">后方有大型货车逼近，请小心驾驶。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjfNQtWTVhY4fKFw1YBPjJ4nId0l7O7Uuf2OaD2mNLMoRMTyX2NEAk3w/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">结果给用户搞懵了：哪里来了的车辆？！也没看到啊。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjcicsmmA70q0zkpkmoSRNv7UhJYvnTjedK2pvpmORggBRRZaR9ezjPLA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">结果几秒钟之后， 侧后方果然就有一辆大货车疾驰而过。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjDmFQ6Lw0ibGS8EC8YO6Xf87WjUiaJM6PaXBaqicUvWMh6KwpBIpbjZgrQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">这这这，高德是在后面安了透视眼吗？？甚至还知道具体车辆类型。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjhGqCibmAYTlQdDIdP3EmticKp2MBNcK699uwqwoTibxQ3eWYUY1onoh2A/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">除了能看到后方，高德也能对前方路况了解得一清二楚。</div><div class=" pTag">像实时通知前方有交通事故已经不足以道了。而是已经上升到「你在我前面，我知道你在干嘛」这种秒级识别并响应的Level了。</div><div class=" pTag">比如这位用户正在高速路上堵车中，结果收到「前方有车辆急刹，请小心行驶」提示。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjUIu5HiaJ3yn27qO2UEShL2JD7QLiatpkC6WF1MRmekFZSy4JS94Ujt6g/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">结果没过多久，前方旁边那辆白色车辆就出了交通事故…这位司机直呼：好险~~</div><div class=" pTag">家人们，这真的能降低事故风险了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjEYgoLCllFlqhGXCHg7VAH13iap34PRb1ibXabRyM3rOdbl2JRINevcsA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">还有像那种山中弯路这种场景，高德也是大秀了一把操作。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjolQrkoaX4UyKtIxbnIK0g7KA6M6tgPxaX2nia2jxhIiaSLPKFwQZK6Dg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">这种路口完全就是视野盲区，根本看不到来车，再加上路又窄，大家一般会沿道路中部行驶。</div><div class=" pTag">这时候高德来一句预知的提醒：<strong style="font-size: 17px; text-align: left; font-weight: 600;">“</strong><strong style="font-weight: 600;">前方弯道来车，注意不要压线”</strong>。结果，几秒之后，对面真的有车！大家都靠右，让出中线会车，对司机来说，真的是很安心。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjfzR45fkb7iaC6icG0Zr46xelePZ26navkoOZIKoHqfKjwPp6FLp9ibiahw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">而且也不只是开车的，就是骑车开摩托的用户，高德也会标识出后方来车超车和弯道会车高发的路段。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjibW8CYH8iaTpFrlMXAfaickseE8icxPasMoZ4pfKaiaN9LIbVGDeTds6vaA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">系统还会依据后方来车的速度以及特殊车辆类型，提供特殊警报，引导用户作出合适的避让动作。</div><div class=" pTag">不少理想车主也表示，在跑长途开启辅助驾驶时，高德地图提供的动态施工信息，也会提示预警信息。</div><div class=" pTag">短短几个案例就可以看出来，不管是前后左右、白天还是黑夜，高德竟然都能都能顾及到——</div><div class=" pTag"><strong style="font-weight: 600;">实时探测到行车风险</strong>。</div><div class=" pTag">一边感叹着高德给行车和乘车的安全感；一边又同时疑惑着，高德什么时候装上千里眼的。</div><h2>给用户装上“千里眼”</h2><div class=" pTag">高德的确变了，而且早就变了。其实从去年起，高德陆续上线了<strong style="font-weight: 600;">车道级安全预警10大场景</strong>：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">前方有车辆急刹，有慢速车，弯道有来车，货车前方有来车</div></li><li><div class=" pTag">夜间前方有货车，无灯路口有来车</div></li><li><div class=" pTag">后方有快速来车，有快速货车</div></li><li><div class=" pTag">左、右侧有车辆汇出</div></li></ul><div class=" pTag">这10大场景下，如果双方车主都正在使用高德地图导航，程序探测到风险时，导航就会及时语音示警。</div><div class=" pTag">也就是从过去的“车道级导航”，进化为<strong style="font-weight: 600;">“车道级安全预警”</strong>，<strong style="font-weight: 600;">每天</strong>使用次数达<strong style="font-weight: 600;">千万级</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fj8G3LrVKialwYiaqTD53YF24IX8GqdAfOVvaRlCVmVIoG2ACQoCLszJcg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不再只追求“导的准确”，还要“导的安全”，体现在时间和空间两个维度上。</div><div class=" pTag"><strong style="font-weight: 600;">时间</strong>上，秒级响应，及时、准确的给到用户。</div><div class=" pTag"><strong style="font-weight: 600;">空间</strong>上，给用户安上“千里眼”，提供一种<strong style="font-weight: 600;">超视距</strong>的预警，即超越车主的视野局限。</div><div class=" pTag">人的视野，终归有限，更不要说遇到前方有大车，或者是夜晚了。</div><div class=" pTag">但在用户视野之外，高德可以利用北斗卫星，感知到用户之间的位置关系，判断行车风险，及时给到预警，无形中帮用户扩大了感知范围。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjZz7p9IwiaxPnkpw9ib2nY50NVE41AA3fGN1S0yxupLp32hqguicicKgLMw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">高德此举，其实是从过去的连接「人与车」，转向连接「人与人」，将更多交通参与者，纳入同一张网络。</div><div class=" pTag">理论上来说，<strong style="font-weight: 600;">参与的人越多，网络预警的能力就越强</strong>，体现了一种<strong style="font-weight: 600;">现实世界的Scaling Law</strong>。</div><div class=" pTag">规模越大，能力越强。</div><div class=" pTag">用户规模，也正是高德做车道级安全预警的一大优势：</div><div class=" pTag">据阿里巴巴2024财年 Q2 财报显示，高德地图日活跃用户峰值超过<strong style="font-weight: 600;">2.8亿</strong>。</div><div class=" pTag">QuestMobile披露的《2024中国移动互联网春季大报告》显示，2024年Q1，高德地图月活为<strong style="font-weight: 600;">8.01亿</strong>。</div><div class=" pTag"><strong style="font-weight: 600;">地图导航赛道第一，国内移动互联网第四。</strong></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fjs6KYAqLGTkRZ2oK8iccho1QoYNApos0rwLNN8KJWAjB78iamrMjwtOUg/640?wx_fmt=jpeg" /></div></div></div><div class=" pTag">在海量用户的基础上，高德从<strong style="font-weight: 600;">用户需求</strong>出发，结合<strong style="font-weight: 600;">技术双轮驱动</strong>，打造了<strong style="font-weight: 600;">车道级安全预警</strong>。</div><div class=" pTag">具体地说实现，比如前车急刹预警，就是在前方多辆车辆均出现踩下刹车的情况时，结合北斗卫星的高精定位能力，高德能够判断出速度的异常变化，结合交通环境进一步分析，高德能够计算出现急刹车。</div><div class=" pTag">高德利用这些信息，结合自研<strong style="font-weight: 600;">时空感知模型</strong>，会从上亿正使用导航的车辆，精准找到后方将受前车急刹影响的车辆，提前给到提示。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjlYEyLKcpeJB5BUmN6DWOibsjYxjn0J11wbibNj5bdY0WWAAiaGy0gRrXQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">安全预警等多个导航相关功能背后，也是大模型在赋能提效。</div><div class=" pTag">类似的安全预警，目前一些智能车，借助传感器，比如激光雷达，已量产的测绘距离最远可达250米，远远超出肉眼的能力，已经算“遥遥领先”了。</div><div class=" pTag">但这依然无法做到穿透感知多辆车，而且硬件成本比较高。</div><div class=" pTag">这类车子<strong style="font-weight: 600;">售价</strong>一般都在<strong style="font-weight: 600;">20万元以上</strong>，往往还都是<strong style="font-weight: 600;">新能源车辆</strong>。</div><div class=" pTag">所以，高德其实是以更普惠的方式，给保有量巨大的燃油车，以及性价比新能源车型装上了“千里眼”，让最广大的车主受益。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjcnZWCiacAAxLMzctZibBEWgibsgUKGwl6J5NNf8z8WJJHd9wWnMjmFh1Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同时，这种将车辆、路况以及云端信息结合，实时同步的方式，也可以说是对“车路云一体化”的初步探索，为未来发展提供了参考和想象空间。</div><div class=" pTag">不过目前这还比较遥远，就近期来看，高德地图主要还是提供更好的导航出行服务。</div><div class=" pTag">下一阶段，将在保证安全的基础上，满足用户新的需求：</div><div class=" pTag"><strong style="font-weight: 600;">更精细的场景，更高效的导航。</strong></div><h2>AI让出行更个性，安全更普惠</h2><div class=" pTag">随着AI、大模型技术的飞速发展，它已经悄然渗透到我们生活的方方面面。尽管可能并不容易感知，但确实是AI应用的天然场景。作为日常衣食住行中的「行」，这个我们每天都会用到的高德，正是这一趋势的生动体现。</div><div class=" pTag">首先，从车道级导航到车道级安全预警，本质上是AI技术加强。它不再只是一个简单的导航工具，更是一个能够预测和预警风险的智能助手。</div><div class=" pTag">它通过对大量经验数据积累，深度学习路径特征和交通模式，结合实时场景的推理，来预测即将到来的场景，从而辅助用户决策，为驾驶者提供了更为安全和可靠的导航服务。「让出行变得更加智能」也由此变得更加具象化。</div><div class=" pTag">事实上，也不仅是功能预警。高德向我们透露，高德上面很多功能是弱感知，大家可能都察觉不到它是AI应用。比如每次从一开始的路线规划，还是在行驶过程中的实时路况/事故计算等背后都伴随着大量数据生成和处理，以及各种复杂算法融合计算驱动。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjFowMxULJOPR3AeDXUibnkG3h9CicDQygHRDMA4K19wnrFIrib6l4qjuIQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">其次，高德地图的此次升级，还代表了一种新的出行趋势。</div><div class=" pTag">以往对于导航的认知，更多的是在于它的精准。尤其在结合北斗卫星导航系统的高精度定位，手机导航精度甚至可以在一米之内。</div><div class=" pTag">此次在精准基础之上，更重要的是<strong style="font-size: 17px; text-align: left; font-weight: 600;">用户安全体验的提升</strong>，在不同场景、不同时间段、不同交通状况，为用户提供更为个性化更智能的导航决策。</div><div class=" pTag">高德透露，年内将进一步提供更多个性化的服务。针对不同的驾驶者有着不同的驾驶习惯，满足各种个性化的诉求。</div><div class=" pTag">从导的精准、导的安全再到导的个性，这种“千人千面”甚至“一人N面”的导航服务，让每一位用户都能感受到定制化的出行体验。</div><div class=" pTag">另外在车机领域，高德在实现开启智驾状态语音+文字预警提醒的基础上，未来还会跟一些车厂合作开发基于精准的车道级施工信息实现优雅规避的功能，可以提前自动实现变道绕过施工占用车道。</div><div class=" pTag">高德地图的这一改变，不仅是技术上的升级，也是对用户需求深入理解和满足的体现。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fj8jURNaGMsiaA7KBibLjJQCa1vfb6xBuQeyQkHRKN1EFvCRKxtR0zj5RQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">最后，不同于当前火爆的ChatBot，关于AGI的想象力，出行导航系统可能率先被人触达。</div><div class=" pTag">首先亿级的用户群体，每天都会有海量数据的处理和生成。其次，有着最常用的端侧交互场景，就像GPT-4o点燃的「实时交互」，可能时时刻刻都在高德地图上发生。关键后者面向着更为强烈的需求。</div><div class=" pTag">当然，更重要的是，高德地图的服务具有一定的社会普惠性。</div><div class=" pTag">它不仅仅服务于少数人，而是面向所有用户，让每个人都能享受到AI带来的便利和安全。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjWN5UkC46u4kmv2TmjlPgaf5mWFuhI2ufjD6hPMoe9UsYTMmLQGicIKA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">从近期高德地图推出的其他功能中，比如防晒导航、室内导航等，我们可以看到AGI和大模型，在日常生活中的应用已经开始显现，而高德地图正是这一变革的先行者。</div><div class=" pTag">总结来说，高德地图的车道级安全预警功能升级，不仅是技术上的一次飞跃，更是AI在出行领域革新用户体验的一个缩影。</div><div class=" pTag">它让我们看到了AI如何让出行变得更加个性化和安全，同时也预示着在AGI时代，地图导航服务将如何更好地服务于社会，实现更广泛的普惠性。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FkFJP0wFSfHYHiy5azJzUEA">阅读原文 </a> </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">一凡 白交 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">AI正在守护人们的出行安全。</div><div class=" pTag">请看VCR：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjfcnpdcFskHN1vg4v4LQSQkcVKFvSPnU4mG4T2IABanZXicYMcz1PzMw/640?wx_fmt=gif&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjobpZW7PZzaqBRxZwQ1lbyksazQPLiaFIiazZrqGzcQVTqDByprYrL4oQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">最近，大量高德用户晒出类似图中的体验，发出感慨：现在导航都这么智能了？？？</div><div class=" pTag">还有用户在社交平台发帖，疯狂安利骑友们：跑山请开高德，求扩散！！！</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjXZRsMkTh1xS3DIs4nmcEK7sefldZvh3WicgHibsUqmmAq0q7eyZOicDdg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">是什么让用户当起“自来水”，甚至点赞直呼“黑科技”？</div><div class=" pTag">高德地图“车道级安全预警”功能。两轮四轮都能用，新老司机都刚需…</div><div class=" pTag">无需额外装硬件，一个APP就搞定。</div><h2>高德导航在Next level了</h2><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">“高德给力！”“高德变了？！”“高德什么时候变得这么智能了？！”</div></blockquote><div class=" pTag">在各种社交平台上，尤其是假期前后出行高峰，这些评论开始大量出现，相关视频接连成为「爆款」。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fj3XrpWZiaqHoC1lX1o5b2C1gjdWRO8niaF1jGG6vHfu3ibay2XWxlTkmdg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjzyNBUd8oJuywziaSAUx2Y5rQGjSqlzfhwNY2hQDKEZrCy4JJm2JjZNg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">结果仔细一看发现啊，他们所讨论的是高德地图的导航功能。不光有App用户，还包括不少车机用户；视频中也是各种覆盖白天黑夜；会车超车弯道各种场景。</div><div class=" pTag">种种体验感受，归结起来就是：高德导航已经在Next Level了。</div><div class=" pTag">比如一个视频中，车辆夜间正常行驶，结果导航突然鸣笛播报提醒：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">后方有大型货车逼近，请小心驾驶。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjfNQtWTVhY4fKFw1YBPjJ4nId0l7O7Uuf2OaD2mNLMoRMTyX2NEAk3w/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">结果给用户搞懵了：哪里来了的车辆？！也没看到啊。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjcicsmmA70q0zkpkmoSRNv7UhJYvnTjedK2pvpmORggBRRZaR9ezjPLA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">结果几秒钟之后， 侧后方果然就有一辆大货车疾驰而过。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjDmFQ6Lw0ibGS8EC8YO6Xf87WjUiaJM6PaXBaqicUvWMh6KwpBIpbjZgrQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">这这这，高德是在后面安了透视眼吗？？甚至还知道具体车辆类型。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjhGqCibmAYTlQdDIdP3EmticKp2MBNcK699uwqwoTibxQ3eWYUY1onoh2A/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">除了能看到后方，高德也能对前方路况了解得一清二楚。</div><div class=" pTag">像实时通知前方有交通事故已经不足以道了。而是已经上升到「你在我前面，我知道你在干嘛」这种秒级识别并响应的Level了。</div><div class=" pTag">比如这位用户正在高速路上堵车中，结果收到「前方有车辆急刹，请小心行驶」提示。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjUIu5HiaJ3yn27qO2UEShL2JD7QLiatpkC6WF1MRmekFZSy4JS94Ujt6g/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">结果没过多久，前方旁边那辆白色车辆就出了交通事故…这位司机直呼：好险~~</div><div class=" pTag">家人们，这真的能降低事故风险了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjEYgoLCllFlqhGXCHg7VAH13iap34PRb1ibXabRyM3rOdbl2JRINevcsA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">还有像那种山中弯路这种场景，高德也是大秀了一把操作。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjolQrkoaX4UyKtIxbnIK0g7KA6M6tgPxaX2nia2jxhIiaSLPKFwQZK6Dg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">这种路口完全就是视野盲区，根本看不到来车，再加上路又窄，大家一般会沿道路中部行驶。</div><div class=" pTag">这时候高德来一句预知的提醒：<strong style="font-size: 17px; text-align: left; font-weight: 600;">“</strong><strong style="font-weight: 600;">前方弯道来车，注意不要压线”</strong>。结果，几秒之后，对面真的有车！大家都靠右，让出中线会车，对司机来说，真的是很安心。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjfzR45fkb7iaC6icG0Zr46xelePZ26navkoOZIKoHqfKjwPp6FLp9ibiahw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">而且也不只是开车的，就是骑车开摩托的用户，高德也会标识出后方来车超车和弯道会车高发的路段。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjibW8CYH8iaTpFrlMXAfaickseE8icxPasMoZ4pfKaiaN9LIbVGDeTds6vaA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">系统还会依据后方来车的速度以及特殊车辆类型，提供特殊警报，引导用户作出合适的避让动作。</div><div class=" pTag">不少理想车主也表示，在跑长途开启辅助驾驶时，高德地图提供的动态施工信息，也会提示预警信息。</div><div class=" pTag">短短几个案例就可以看出来，不管是前后左右、白天还是黑夜，高德竟然都能都能顾及到——</div><div class=" pTag"><strong style="font-weight: 600;">实时探测到行车风险</strong>。</div><div class=" pTag">一边感叹着高德给行车和乘车的安全感；一边又同时疑惑着，高德什么时候装上千里眼的。</div><h2>给用户装上“千里眼”</h2><div class=" pTag">高德的确变了，而且早就变了。其实从去年起，高德陆续上线了<strong style="font-weight: 600;">车道级安全预警10大场景</strong>：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">前方有车辆急刹，有慢速车，弯道有来车，货车前方有来车</div></li><li><div class=" pTag">夜间前方有货车，无灯路口有来车</div></li><li><div class=" pTag">后方有快速来车，有快速货车</div></li><li><div class=" pTag">左、右侧有车辆汇出</div></li></ul><div class=" pTag">这10大场景下，如果双方车主都正在使用高德地图导航，程序探测到风险时，导航就会及时语音示警。</div><div class=" pTag">也就是从过去的“车道级导航”，进化为<strong style="font-weight: 600;">“车道级安全预警”</strong>，<strong style="font-weight: 600;">每天</strong>使用次数达<strong style="font-weight: 600;">千万级</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fj8G3LrVKialwYiaqTD53YF24IX8GqdAfOVvaRlCVmVIoG2ACQoCLszJcg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不再只追求“导的准确”，还要“导的安全”，体现在时间和空间两个维度上。</div><div class=" pTag"><strong style="font-weight: 600;">时间</strong>上，秒级响应，及时、准确的给到用户。</div><div class=" pTag"><strong style="font-weight: 600;">空间</strong>上，给用户安上“千里眼”，提供一种<strong style="font-weight: 600;">超视距</strong>的预警，即超越车主的视野局限。</div><div class=" pTag">人的视野，终归有限，更不要说遇到前方有大车，或者是夜晚了。</div><div class=" pTag">但在用户视野之外，高德可以利用北斗卫星，感知到用户之间的位置关系，判断行车风险，及时给到预警，无形中帮用户扩大了感知范围。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjZz7p9IwiaxPnkpw9ib2nY50NVE41AA3fGN1S0yxupLp32hqguicicKgLMw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">高德此举，其实是从过去的连接「人与车」，转向连接「人与人」，将更多交通参与者，纳入同一张网络。</div><div class=" pTag">理论上来说，<strong style="font-weight: 600;">参与的人越多，网络预警的能力就越强</strong>，体现了一种<strong style="font-weight: 600;">现实世界的Scaling Law</strong>。</div><div class=" pTag">规模越大，能力越强。</div><div class=" pTag">用户规模，也正是高德做车道级安全预警的一大优势：</div><div class=" pTag">据阿里巴巴2024财年 Q2 财报显示，高德地图日活跃用户峰值超过<strong style="font-weight: 600;">2.8亿</strong>。</div><div class=" pTag">QuestMobile披露的《2024中国移动互联网春季大报告》显示，2024年Q1，高德地图月活为<strong style="font-weight: 600;">8.01亿</strong>。</div><div class=" pTag"><strong style="font-weight: 600;">地图导航赛道第一，国内移动互联网第四。</strong></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fjs6KYAqLGTkRZ2oK8iccho1QoYNApos0rwLNN8KJWAjB78iamrMjwtOUg/640?wx_fmt=jpeg" /></div></div></div><div class=" pTag">在海量用户的基础上，高德从<strong style="font-weight: 600;">用户需求</strong>出发，结合<strong style="font-weight: 600;">技术双轮驱动</strong>，打造了<strong style="font-weight: 600;">车道级安全预警</strong>。</div><div class=" pTag">具体地说实现，比如前车急刹预警，就是在前方多辆车辆均出现踩下刹车的情况时，结合北斗卫星的高精定位能力，高德能够判断出速度的异常变化，结合交通环境进一步分析，高德能够计算出现急刹车。</div><div class=" pTag">高德利用这些信息，结合自研<strong style="font-weight: 600;">时空感知模型</strong>，会从上亿正使用导航的车辆，精准找到后方将受前车急刹影响的车辆，提前给到提示。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjlYEyLKcpeJB5BUmN6DWOibsjYxjn0J11wbibNj5bdY0WWAAiaGy0gRrXQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">安全预警等多个导航相关功能背后，也是大模型在赋能提效。</div><div class=" pTag">类似的安全预警，目前一些智能车，借助传感器，比如激光雷达，已量产的测绘距离最远可达250米，远远超出肉眼的能力，已经算“遥遥领先”了。</div><div class=" pTag">但这依然无法做到穿透感知多辆车，而且硬件成本比较高。</div><div class=" pTag">这类车子<strong style="font-weight: 600;">售价</strong>一般都在<strong style="font-weight: 600;">20万元以上</strong>，往往还都是<strong style="font-weight: 600;">新能源车辆</strong>。</div><div class=" pTag">所以，高德其实是以更普惠的方式，给保有量巨大的燃油车，以及性价比新能源车型装上了“千里眼”，让最广大的车主受益。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjcnZWCiacAAxLMzctZibBEWgibsgUKGwl6J5NNf8z8WJJHd9wWnMjmFh1Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同时，这种将车辆、路况以及云端信息结合，实时同步的方式，也可以说是对“车路云一体化”的初步探索，为未来发展提供了参考和想象空间。</div><div class=" pTag">不过目前这还比较遥远，就近期来看，高德地图主要还是提供更好的导航出行服务。</div><div class=" pTag">下一阶段，将在保证安全的基础上，满足用户新的需求：</div><div class=" pTag"><strong style="font-weight: 600;">更精细的场景，更高效的导航。</strong></div><h2>AI让出行更个性，安全更普惠</h2><div class=" pTag">随着AI、大模型技术的飞速发展，它已经悄然渗透到我们生活的方方面面。尽管可能并不容易感知，但确实是AI应用的天然场景。作为日常衣食住行中的「行」，这个我们每天都会用到的高德，正是这一趋势的生动体现。</div><div class=" pTag">首先，从车道级导航到车道级安全预警，本质上是AI技术加强。它不再只是一个简单的导航工具，更是一个能够预测和预警风险的智能助手。</div><div class=" pTag">它通过对大量经验数据积累，深度学习路径特征和交通模式，结合实时场景的推理，来预测即将到来的场景，从而辅助用户决策，为驾驶者提供了更为安全和可靠的导航服务。「让出行变得更加智能」也由此变得更加具象化。</div><div class=" pTag">事实上，也不仅是功能预警。高德向我们透露，高德上面很多功能是弱感知，大家可能都察觉不到它是AI应用。比如每次从一开始的路线规划，还是在行驶过程中的实时路况/事故计算等背后都伴随着大量数据生成和处理，以及各种复杂算法融合计算驱动。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjFowMxULJOPR3AeDXUibnkG3h9CicDQygHRDMA4K19wnrFIrib6l4qjuIQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">其次，高德地图的此次升级，还代表了一种新的出行趋势。</div><div class=" pTag">以往对于导航的认知，更多的是在于它的精准。尤其在结合北斗卫星导航系统的高精度定位，手机导航精度甚至可以在一米之内。</div><div class=" pTag">此次在精准基础之上，更重要的是<strong style="font-size: 17px; text-align: left; font-weight: 600;">用户安全体验的提升</strong>，在不同场景、不同时间段、不同交通状况，为用户提供更为个性化更智能的导航决策。</div><div class=" pTag">高德透露，年内将进一步提供更多个性化的服务。针对不同的驾驶者有着不同的驾驶习惯，满足各种个性化的诉求。</div><div class=" pTag">从导的精准、导的安全再到导的个性，这种“千人千面”甚至“一人N面”的导航服务，让每一位用户都能感受到定制化的出行体验。</div><div class=" pTag">另外在车机领域，高德在实现开启智驾状态语音+文字预警提醒的基础上，未来还会跟一些车厂合作开发基于精准的车道级施工信息实现优雅规避的功能，可以提前自动实现变道绕过施工占用车道。</div><div class=" pTag">高德地图的这一改变，不仅是技术上的升级，也是对用户需求深入理解和满足的体现。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8Fj8jURNaGMsiaA7KBibLjJQCa1vfb6xBuQeyQkHRKN1EFvCRKxtR0zj5RQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">最后，不同于当前火爆的ChatBot，关于AGI的想象力，出行导航系统可能率先被人触达。</div><div class=" pTag">首先亿级的用户群体，每天都会有海量数据的处理和生成。其次，有着最常用的端侧交互场景，就像GPT-4o点燃的「实时交互」，可能时时刻刻都在高德地图上发生。关键后者面向着更为强烈的需求。</div><div class=" pTag">当然，更重要的是，高德地图的服务具有一定的社会普惠性。</div><div class=" pTag">它不仅仅服务于少数人，而是面向所有用户，让每个人都能享受到AI带来的便利和安全。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCOTZ77dCm4UicCFPSWsj8FjWN5UkC46u4kmv2TmjlPgaf5mWFuhI2ufjD6hPMoe9UsYTMmLQGicIKA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">从近期高德地图推出的其他功能中，比如防晒导航、室内导航等，我们可以看到AGI和大模型，在日常生活中的应用已经开始显现，而高德地图正是这一变革的先行者。</div><div class=" pTag">总结来说，高德地图的车道级安全预警功能升级，不仅是技术上的一次飞跃，更是AI在出行领域革新用户体验的一个缩影。</div><div class=" pTag">它让我们看到了AI如何让出行变得更加个性化和安全，同时也预示着在AGI时代，地图导航服务将如何更好地服务于社会，实现更广泛的普惠性。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FkFJP0wFSfHYHiy5azJzUEA">阅读原文 </a>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 06:30:26 GMT</pubDate>
</item>
<item>
<title>5秒完成3D生成，真香合成数据集已开源，上交港中文新框架超越Instant3D</title>
<link>https://posts.careerengine.us/p/66654a6005a0c02e03898b99</link>
<guid>https://posts.careerengine.us/p/66654a6005a0c02e03898b99</guid>
<content:encoded><![CDATA[
<div> <h5 style="font-size: 17px; text-align: left;"><div class=" pTag">陈林 投稿自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">使用大模型合成的数据，就能显著提升3D生成能力？</div><div class=" pTag">来自上海交大、香港中文大学等团队还真做到了。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnq35u4YfvZ15pNLTVtYNdbyhe0MkOeYz3sib7ztrLPfd2lKBeCE9icPrxw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">他们推出Bootstrap3D框架，结合微调的具备3D感知能力的多模态大模型。这个框架能够自动生成任意数量的高质量的多视角图片数据，助力多视图扩散模型的训练。</div><div class=" pTag">结果表明，新的合成数据能够显著提高现有3D生成模型的生成物体的美学质量和文本prompt的控制能力。</div><div class=" pTag">目前，Bootstrap3D的数据集已经全面开源。</div><h2>用大模型合成数据</h2><div class=" pTag">近年来，3D内容生成技术迎来了飞速发展。然而，相对于2D图片生成，生成高质量的3D物体仍面临诸多挑战。</div><div class=" pTag">其中核心的瓶颈即在于3D数据，尤其是高质量数据的不足。</div><div class=" pTag">为了解决这一问题，研究团队推出Bootstrap3D框架，通过自动生成多视图图像数据来解决3D内容生成中高质量数据不足的问题。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnq2uc48D0AwIGTlib3HKxgo0AMBr1AJL8BUfU1bWWKT1eyAhYKfRZQrPg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">具体来说，这个框架采用了2D和视频扩散模型来生成多视图图像，并利用一个经过微调的3D多模态大模型对生成的数据进行质量筛选和描述重写。</div><div class=" pTag">通过这种方式，Bootstrap3D能够自动产生大量高质量的3D图像数据，从而“自举”出一个足够大的数据集，辅助训练更优秀的多视图扩散模型。</div><div class=" pTag">这里插一嘴，在计算机科学和机器学习领域，“Bootstrap”通常指的是一种通过自举方法解决问题的技术。</div><div class=" pTag"><strong style="font-weight: 600;">数据构建Pipeline</strong></div><div class=" pTag">具体来说，<strong style="font-weight: 600;">数据构建Pipeline</strong>是本次框架的核心创新之一，旨在自动生成高质量的多视图图像数据，并附带详细的描述文本。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnq4Zhbc8G4sVyB5P6b7fFxw9qcsicccenzWhTeIiaI1hAKSuaDmWrFTEDQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">主要分为以下几个步骤：</div><div class=" pTag"><strong style="font-weight: 600;">文本提示生成</strong>：首先，使用强大的大语言模型（如GPT-4）生成大量富有创意和多样化的文本提示。这些文本提示涵盖了各种场景和物体，为后续的图像生成提供了丰富的素材。</div><div class=" pTag"><strong style="font-weight: 600;">图像生成</strong>：利用2D扩散模型和视频扩散模型，根据生成的文本提示创建单视图图像。通过结合2D和视频扩散模型的优势，生成的图像具有更高的初始质量和多样性。</div><div class=" pTag"><strong style="font-weight: 600;">多视图合成</strong>：使用视频扩散模型将单视图图像扩展为多视图图像，生成不同角度的视图。这一步骤确保了每个对象在不同视角下的一致性，解决了传统方法中视图不一致的问题。</div><div class=" pTag"><strong style="font-weight: 600;">质量筛选和描述重写</strong>：通过我们微调的3D感知模型MV-LLaVA，对生成的多视图图像进行严格的质量筛选。筛选过程不仅过滤掉低质量的数据，还重写描述文本，使其更加准确和详细。</div><div class=" pTag">通过这个数据构建Pipeline，Bootstrap3D能够生成大量高质量的3D图像数据，为多视图扩散模型的训练提供了坚实的基础。</div><div class=" pTag">这一创新不仅解决了3D数据稀缺的问题，还显著提升了模型的生成效果和对文本提示的响应能力。</div><div class=" pTag"><strong style="font-weight: 600;">训练timestep重安排（TTR）</strong></div><div class=" pTag">团队还提出了一种创新的训练timestep重新安排策略（TTR），以解决多视图扩散模型训练中的图像质量和视图一致性问题。</div><div class=" pTag">TTR策略的核心理念是在训练过程中灵活调整合成数据和真实数据的训练时间步，从而优化去噪过程的不同阶段。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqX6aXeZibJxJtyLyufSZy77PNLicmA42qaWQ2wKGWR47zibJcqwshmbjgQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">去噪过程的阶段性特征</strong>：在扩散模型中，去噪过程通常分为不同的时间步。在早期时间步，去噪过程主要关注图像的整体结构和形状（低频成分）；在后期时间步，则主要生成图像的细节和纹理（高频成分）。这种阶段性特征为我们提供了调整训练策略的机会。</div><div class=" pTag"><strong style="font-weight: 600;">限制合成数据的训练时间步</strong>：由于合成数据可能存在一些模糊和失真，我们在训练时限制其时间步范围。具体来说，我们让合成数据主要参与早期的去噪阶段，确保它们对整体结构的贡献，而将后期的细节生成留给质量更高的真实数据。</div><div class=" pTag"><strong style="font-weight: 600;">分阶段训练策略</strong>：通过将合成数据限制在较大的时间步范围内（如200到1000步），我们确保这些数据在去噪过程中主要影响图像的低频成分，从而保持视图一致性。同时，真实数据则参与所有时间步的训练，以提供高频细节和真实感。这样的分阶段训练策略有效平衡了图像质量和视图一致性。</div><div class=" pTag"><strong style="font-weight: 600;">实验证明效果显著</strong>：广泛的实验结果表明，使用TTR策略的多视图扩散模型在图像-文本对齐、图像质量和视图一致性方面均表现优异。该策略不仅保留了原始2D扩散模型的优点，还显著提升了多视图生成的效果。</div><div class=" pTag">通过训练时间步重新安排策略（TTR），Bootstrap3D框架成功解决了合成数据质量参差不齐的问题，显著提升了多视图扩散模型的性能，为高质量3D内容生成奠定了坚实基础。</div><div class=" pTag">好了，Bootstrap3D生成的数据集已经全面开源，任何研究人员和开发者都可以免费访问和使用。</div><div class=" pTag"><span style="font-size: 17px;"><span>论文地址：</span><br /><span>https://arxiv.org/abs/2406.00093/</span></span><br /><span style="font-size: 17px;"><span>项目主页：</span><br /><span>https://sunzey.github.io/Bootstrap3D/</span></span><br /><span style="font-size: 17px;"><span style="font-size: 17px;">数据集地址：</span><br /><span style="font-size: 17px;">https://huggingface.co/datasets/Zery/BS-Objaverse/</span></span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fm7f1myu0eSZqGvZ8mbJcLg">阅读原文 </a> </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">陈林 投稿自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">使用大模型合成的数据，就能显著提升3D生成能力？</div><div class=" pTag">来自上海交大、香港中文大学等团队还真做到了。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnq35u4YfvZ15pNLTVtYNdbyhe0MkOeYz3sib7ztrLPfd2lKBeCE9icPrxw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">他们推出Bootstrap3D框架，结合微调的具备3D感知能力的多模态大模型。这个框架能够自动生成任意数量的高质量的多视角图片数据，助力多视图扩散模型的训练。</div><div class=" pTag">结果表明，新的合成数据能够显著提高现有3D生成模型的生成物体的美学质量和文本prompt的控制能力。</div><div class=" pTag">目前，Bootstrap3D的数据集已经全面开源。</div><h2>用大模型合成数据</h2><div class=" pTag">近年来，3D内容生成技术迎来了飞速发展。然而，相对于2D图片生成，生成高质量的3D物体仍面临诸多挑战。</div><div class=" pTag">其中核心的瓶颈即在于3D数据，尤其是高质量数据的不足。</div><div class=" pTag">为了解决这一问题，研究团队推出Bootstrap3D框架，通过自动生成多视图图像数据来解决3D内容生成中高质量数据不足的问题。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnq2uc48D0AwIGTlib3HKxgo0AMBr1AJL8BUfU1bWWKT1eyAhYKfRZQrPg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">具体来说，这个框架采用了2D和视频扩散模型来生成多视图图像，并利用一个经过微调的3D多模态大模型对生成的数据进行质量筛选和描述重写。</div><div class=" pTag">通过这种方式，Bootstrap3D能够自动产生大量高质量的3D图像数据，从而“自举”出一个足够大的数据集，辅助训练更优秀的多视图扩散模型。</div><div class=" pTag">这里插一嘴，在计算机科学和机器学习领域，“Bootstrap”通常指的是一种通过自举方法解决问题的技术。</div><div class=" pTag"><strong style="font-weight: 600;">数据构建Pipeline</strong></div><div class=" pTag">具体来说，<strong style="font-weight: 600;">数据构建Pipeline</strong>是本次框架的核心创新之一，旨在自动生成高质量的多视图图像数据，并附带详细的描述文本。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnq4Zhbc8G4sVyB5P6b7fFxw9qcsicccenzWhTeIiaI1hAKSuaDmWrFTEDQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">主要分为以下几个步骤：</div><div class=" pTag"><strong style="font-weight: 600;">文本提示生成</strong>：首先，使用强大的大语言模型（如GPT-4）生成大量富有创意和多样化的文本提示。这些文本提示涵盖了各种场景和物体，为后续的图像生成提供了丰富的素材。</div><div class=" pTag"><strong style="font-weight: 600;">图像生成</strong>：利用2D扩散模型和视频扩散模型，根据生成的文本提示创建单视图图像。通过结合2D和视频扩散模型的优势，生成的图像具有更高的初始质量和多样性。</div><div class=" pTag"><strong style="font-weight: 600;">多视图合成</strong>：使用视频扩散模型将单视图图像扩展为多视图图像，生成不同角度的视图。这一步骤确保了每个对象在不同视角下的一致性，解决了传统方法中视图不一致的问题。</div><div class=" pTag"><strong style="font-weight: 600;">质量筛选和描述重写</strong>：通过我们微调的3D感知模型MV-LLaVA，对生成的多视图图像进行严格的质量筛选。筛选过程不仅过滤掉低质量的数据，还重写描述文本，使其更加准确和详细。</div><div class=" pTag">通过这个数据构建Pipeline，Bootstrap3D能够生成大量高质量的3D图像数据，为多视图扩散模型的训练提供了坚实的基础。</div><div class=" pTag">这一创新不仅解决了3D数据稀缺的问题，还显著提升了模型的生成效果和对文本提示的响应能力。</div><div class=" pTag"><strong style="font-weight: 600;">训练timestep重安排（TTR）</strong></div><div class=" pTag">团队还提出了一种创新的训练timestep重新安排策略（TTR），以解决多视图扩散模型训练中的图像质量和视图一致性问题。</div><div class=" pTag">TTR策略的核心理念是在训练过程中灵活调整合成数据和真实数据的训练时间步，从而优化去噪过程的不同阶段。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqX6aXeZibJxJtyLyufSZy77PNLicmA42qaWQ2wKGWR47zibJcqwshmbjgQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">去噪过程的阶段性特征</strong>：在扩散模型中，去噪过程通常分为不同的时间步。在早期时间步，去噪过程主要关注图像的整体结构和形状（低频成分）；在后期时间步，则主要生成图像的细节和纹理（高频成分）。这种阶段性特征为我们提供了调整训练策略的机会。</div><div class=" pTag"><strong style="font-weight: 600;">限制合成数据的训练时间步</strong>：由于合成数据可能存在一些模糊和失真，我们在训练时限制其时间步范围。具体来说，我们让合成数据主要参与早期的去噪阶段，确保它们对整体结构的贡献，而将后期的细节生成留给质量更高的真实数据。</div><div class=" pTag"><strong style="font-weight: 600;">分阶段训练策略</strong>：通过将合成数据限制在较大的时间步范围内（如200到1000步），我们确保这些数据在去噪过程中主要影响图像的低频成分，从而保持视图一致性。同时，真实数据则参与所有时间步的训练，以提供高频细节和真实感。这样的分阶段训练策略有效平衡了图像质量和视图一致性。</div><div class=" pTag"><strong style="font-weight: 600;">实验证明效果显著</strong>：广泛的实验结果表明，使用TTR策略的多视图扩散模型在图像-文本对齐、图像质量和视图一致性方面均表现优异。该策略不仅保留了原始2D扩散模型的优点，还显著提升了多视图生成的效果。</div><div class=" pTag">通过训练时间步重新安排策略（TTR），Bootstrap3D框架成功解决了合成数据质量参差不齐的问题，显著提升了多视图扩散模型的性能，为高质量3D内容生成奠定了坚实基础。</div><div class=" pTag">好了，Bootstrap3D生成的数据集已经全面开源，任何研究人员和开发者都可以免费访问和使用。</div><div class=" pTag"><span style="font-size: 17px;"><span>论文地址：</span><br /><span>https://arxiv.org/abs/2406.00093/</span></span><br /><span style="font-size: 17px;"><span>项目主页：</span><br /><span>https://sunzey.github.io/Bootstrap3D/</span></span><br /><span style="font-size: 17px;"><span style="font-size: 17px;">数据集地址：</span><br /><span style="font-size: 17px;">https://huggingface.co/datasets/Zery/BS-Objaverse/</span></span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fm7f1myu0eSZqGvZ8mbJcLg">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 09 Jun 2024 06:23:28 GMT</pubDate>
</item>
<item>
<title>港大北航等1bit大模型引热议，IEEE刊物评“解决AI能源需求”！作者亲自解读在此</title>
<link>https://posts.careerengine.us/p/66654a6005a0c02e03898b91</link>
<guid>https://posts.careerengine.us/p/66654a6005a0c02e03898b91</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">BiLLM团队 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">极限量化，<strong style="font-weight: 600;">把每个参数占用空间压缩到1.1bit</strong>！</div><div class=" pTag">IEEE Spectrum专栏，一种名为<strong style="font-weight: 600;">BiLLM</strong>的训练后量化<span>（PTQ）</span>方法火了。</div><div class=" pTag">通俗来讲，随着LLM参数规模越来越大，模型计算的内存和资源也面临着更大的挑战。<strong style="font-weight: 600;">如何</strong><strong style="font-weight: 600;">把模型变得小巧经济实惠，能塞进手机等设备中？</strong></div><div class=" pTag">BiLLM解决的正是这样的一个问题。它使用1bit来近似网络中的大多数参数，使用2bit来表示一些对性能最有影响的权重。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqRusu22dNgz0mWqzEKsRUB3b06ARxFVlVw1PjsOfA0PUAhoicDKICfiaA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">实验测试中，研究人员对OPT模型、Llama系列进行了二值化。</div><div class=" pTag">在OPT模型家族上，BiLLM以1.1bit的平均权重大小实现了目前最极限的LLM训练后压缩；在Llama系列模型上，BiLLM在1.08bit下的表现甚至超过了使用全精度的OPT-66B模型。</div><div class=" pTag">效率方面，BiLLM能够在单个GPU上半小时内完成7B LLM的二值化。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqEib6ToycCZfc3uPIas17lheCpUuQ9VQNxOT2WoUeib2PDtqdne5Z3oPw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">BiLLM发布当天，便引发了网友对大模型优化的热议，有网友就表示：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">量化不是没有代价。Llama3模型的量化效果比Llama2模型要差，量化过程中的质量损失更大。</div><div class=" pTag">直觉是，一个训练不足的模型受到量化的影响较小，因为其训练过程并没有充分利用每一个权重。关于Llama的一个关键发现，以及它为何能在其大小范围内表现出色，是因为它们在比文献中所谓的“最佳”状态更大的数据集上训练了更长时间。</div><div class=" pTag">综合这些因素，似乎可以得出以下结论：小型模型、大量数据、长时间训练&gt;大型模型+量化。基本上，量化是一种用于缩短长时间训练的损失性的捷径。数据的数量和质量，一如既往是所有这些中最重要。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqZ5rFfVj3vIndDIat0hJ32ygxRo7vFEunkhszntEuDBslmE4OjAA2rw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这项研究由香港大学、苏黎世联邦理工学院、北京航空航天大学联合推出，目前已被ICML 2024接收。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnq6M5wiaomibdibk1UrFN1wwQ0W2AjyF2nj5hwcOvtmia1iau7toTJosKnLYA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">量子位也联系到了作者，给大伙儿解读一下。</div><h2>LLM权重分布探究</h2><div class=" pTag">为了应对超低位宽下大语言模型的能力崩溃问题，研究人员对多个预训练大语言模型的权重和其Hessian矩阵<span>（损失的二阶梯度）</span>分布情况进行了初步研究，得到以下观察：</div><div class=" pTag">首先，研究人员发现大语言模型的<strong style="font-weight: 600;">Hessian矩阵表现出极端的长尾分布特性</strong>。</div><div class=" pTag">这也意味着大多数位置权重的变化对模型的输入输出并不敏感，而少部分元素对于权重的输出非常敏感。</div><div class=" pTag">其次，大语言模型中的<strong style="font-weight: 600;">权重密度遵循不均匀的钟形分布形式</strong>。</div><div class=" pTag">这种钟形分布在特征方面与高斯分布或拉普拉斯分布非常相似，即大多数权重集中在0附近，整体呈现非均匀的钟形分布。</div><div class=" pTag">上述观察表明大多数权重在LLM当中是冗余的，而少部分权重发挥着极其重要的作用；同时，在极端的二值化压缩场景下，这种非均匀钟形分布会产生更大的量化误差。</div><div class=" pTag">对此，研究人员对少部分显著权重和大部分非显著权重分别提出了二阶残差逼近和最优钟形分组方法进行量化，在1.1bit的权重下首次实现了LLM的性能保证。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnq63nJhE46rhdykR18xQqhFkibTfsbJLBWG0r7SQiap7MZtoxjhTN4LJjw/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>LLM权重分布现象</h6><h3>显著权重：二阶残差逼近</h3><div class=" pTag">研究人员发现，显著权重往往积聚在特定的通道当中。</div><div class=" pTag">因此， BiLLM采用一种通道级别的分组方式来区分显著权重和非显著权重。这种结构化划分相比于非结构化处理引入的开销可以忽略不计，对硬件部署十分友好。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnq9FANpAUtgEdiaUkRm6cic8KjEOGwnicaZuITqrRIfiaJowTqYoiaNJGtXlQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>显著通道权重二阶残差逼近示意图</h6><div class=" pTag">由于显著权重的重要性，先前工作往往直接将这部分权重保存为原精度或量化到8-bit来保证LLM的性能。然而，这种方式会导致整体位宽的增加。</div><div class=" pTag">为此，研究人员开发了一种用二值化残差逼近方法作用于显著通道的权重。</div><div class=" pTag">这一方法通过直接二值化和残差二值化有效降低了显著权重的极端量化误差。与直接保留显着权值为16位或者8位相比，该方法仅通过2位开销存储显着权值，同时有效保护了权重中的重要元素。</div><h3>非显著权重：最优钟形划分</h3><div class=" pTag">由于显着通道数量极低，剩余的大部分权重仍然保持着钟形分布。</div><div class=" pTag">同时，在排除显着权重影响的情况下变得更加对称。由于二进制量化代表均匀量化的极端形式，直接将钟形分布下的权重舍入到二值权重会带来巨大的的量化误差。</div><div class=" pTag">因此研究人员对这部分权重采用了分组二值化的方式，通过自动搜索策略寻找最优的分割点。</div><div class=" pTag">此外，研究结果表明，尽管非显着权重并非理想的高斯分布或拉普拉斯分布，但搜索函数的误差曲线仍然表现出凸性，证实了最佳分割点的存在。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqKb7xUcI2Aj3TaT9rc1LsvetQ5eYF3D6myA8aY3WgSS00xjMvnTrSEw/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>非显著权重分布搜索（左），搜索误差曲线的凸性（右）</h6><div class=" pTag">同时由于外侧分组的数值方差较大，搜索中总是以较小的比例出现<span>（0.5%～3%）</span>。可以进一步采用稀疏行压缩的策略来进行分组标识，进一步提升细粒度分组方案下的硬件友好性。</div><h2>实验结果</h2><div class=" pTag">研究团队在OPT和Llama系列模型上验证了BiLLM性能。此外，考虑到LLM通常需要基于指令进行微调以适应不同的应用环境，实验还报告了Vicuna-7B和Vicuna-13B的量化结果。</div><div class=" pTag">BiLLM在平均1.1bit权重时，在多个评价指标上实现了超过GPTQ，PB-LLM等方法在2-bit时的性能，同时在部分模型体积上接近3-bit权重的性能。</div><div class=" pTag">结果表明， BiLLM 率先在接近1位的平均比特率下实现了LLM性能保证，推动了LLM无训练量化的边界。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqYPbsVRwRep7JFvPADEM7e8ibZggc7UI0pUicRU3au6ia5zphMHwI8Z7lA/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>opt系列困惑度对比结果</h6><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqtfLZoddY2usPubmopjyJBLjcCSPm9lRM2Xpam7iahcFChk7WfiaJeQIw/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>Llama系列困惑度对比结果</h6><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqpJr7qmWibfNqCS1mErxMvGlnjOyshFibZKs4e3OPib1mLCiaFDciarkezyw/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>Zero-Shot评测数据集对比结果</h6><div class=" pTag">BiLLM在Llama-13B和Vicuna-7B上实现了更好对话效果。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqmYEFCdqCFYZcbYwfeNkS4WAEMVXxAao9ufG90ib1z4h5uR0ibCB5mHtQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;">论文链接：https://arxiv.org/abs/2402.04291</span></div><div class=" pTag"><span style="font-size: 17px;"><span>参考链接：</span><br /><span>[1]https://spectrum.ieee.org/1-bit-llm</span></span><br /><span style="font-size: 17px;">[2]https://news.ycombinator.com/item?id=40529355</span></div><div class=" pTag sectionReplaced"><div class="mp_profile_iframe_wrp" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FS9tVLHcOokBy3Kkw1Jv9iw">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 09 Jun 2024 06:23:28 GMT</pubDate>
</item>
<item>
<title>马斯克擎天柱大将跳槽，在抱抱脸开源一套机器人技术：会做家务的大白，复刻低至1800</title>
<link>https://posts.careerengine.us/p/66654a52fb566b2d8280a3c9</link>
<guid>https://posts.careerengine.us/p/66654a52fb566b2d8280a3c9</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">明敏 克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">马斯克部下跳槽，把人形机器人技术开源了。不少创业公司的估值，一夜被打了骨折。</div><div class=" pTag"><strong style="font-weight: 600;">最新成果已正式发布</strong>——</div><div class=" pTag">它能像大白(●—●)一样，听懂并正确执行人类发出的指令，比如放杯子、拿水果。</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-4"></div></div><div class=" pTag">可以自己打开笔帽，在白板上写名字。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1Ww69vJXlDRVmxh4y3acpK7BfRQnp465rGJsiaRLl69mCL8uSXPdCbeSA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">或者是叠衣服。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1Wx70vjYLjhJ3nKeFhYFTXtao8Ght88mecfEbex3KMFJbUQNkJQYSXRA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">把钥匙准确插进锁眼。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WoickSoQProW8Jp6yYdNhk3ibsH6s9d0zSNMG1STYGBngMWicSDMJmiaceg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">这些操作，全都是机器人自己搞定。没有人远程操控，完全端到端实现。</div><div class=" pTag">最关键的是，它使用的算法、数据集完全<strong style="font-weight: 600;">开源</strong>！</div><div class=" pTag">这意味着，你完全可以在家自己改造一个小机器人，让它完成同样的事。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WwOPZSstaCfn3DfMRxCzlNq2Ib3IpdvticvZs8Kibz3AYxibAvkWylgdpA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">如上进展，来自Hugging Face今年新成立的机器人项目Le Robot。</div><div class=" pTag">团队领军人物Remi Cadene(雷米·卡德内)，1月才从特斯拉Optimus机器人团队离职，才过了几个月就带来如上新成果。</div><div class=" pTag">这立马引发业内关注，谷歌DeepMind科学家都来围观表示：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">开源哆啦A梦才是出路嘛。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1W2bzR6icJHu2gKhylcPbJQiak1KfnADib80v7iaQ2VMN8d625PLBEOUFF9Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">网友们更是amazing刷屏了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1Wo3oEyORogTMGmS84lBUWYP1wR17xW4FK4rxLQfbp6PNPpWAX8yQe2w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">所以，这个开源机器人，究竟如何而来？</div><h2>训练只用2个小时</h2><div class=" pTag">完成这些动作的，是花粉机器人公司最新的机器人Reachy2。</div><div class=" pTag">不过，Reachy2并不是一开始就实现自主操作的，而是先经历了一段遥控操作的过程。</div><div class=" pTag">该阶段中，开发人员会佩戴VR装备，控制机器人完成一系列任务。</div><div class=" pTag">VR遥控的过程被记录成了50段视频，每段约15秒，与Reachy2机器人内的不同传感器相关联。</div><div class=" pTag">这些视频成为了ML算法的学习素材，用于研究如何自行完成并指导Reachy2完成一系列任务。</div><div class=" pTag">训练一共持续了2个小时，之后作者测试了所有的checkpoint，发现机器人果然学习到了新的概念——</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">在2万步时，它学会了将杯子可靠地放在碗碟架上；</div></li><li><div class=" pTag">在4万步时，它学会了旋转底座并交出苹果；</div></li><li><div class=" pTag">在6万步时，它学会了旋转手臂回到初始位置。</div></li></ul><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WQIUxZ6DqtevwFlTC8vGA2uGGQyXE4HUn63l8NvEglILjnibXVClzHQQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这其中的数据集和使用的模型，现在都已开源，就连VR操作时用的程序，也同样是开源的。</div><div class=" pTag">在抱抱脸上，Reachy训练用的50段视频都可以直接下载，开源框架和工具也放在了GitHub。</div><div class=" pTag">包括机器人ML框架LeRobot，采用了Apache-2.0协议，可免费商用，据作者称达到了SOTA水准，在GitHub上已经斩获了3.4k+星标。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WzrQbnFIcaU9fcTmD7NHZAo1RLG0HasQ8VezsVKW48ywe3tVqe6ofhA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">LeRobot基于PyTorch实现，包括了预训练模型、人工采集的数据集，还有一套模拟环境，无需真实的机器人硬件也能观察效果。</div><div class=" pTag">值得一提的是，斯坦福知名开源机器人项目ALOHA中的数据，也被囊括进了其中。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WgrBVE6oPwkAoYLbMlg0rD98pbuelia3xJsMFhlibfjniaaswehKbdFZCQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，Reachy2机器人还用到了华人软件工程师、开源AI解决方案平台1ms.ai创始人Haixuan Xavier Tao开源的面向数据流的机器人应用DORA。</div><div class=" pTag">除了用DORA帮助HuggingFace完善机器人框架，1ms.ai还曾帮助清华大学完成了一套机器人工程的教程。</div><div class=" pTag">说回DORA，它提供了低延迟、可组合和分布式数据流功能，可以简化机器人程序的创建，目前已获1.2k星标。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1Wz8p5nfeBiaNbqIXZQDdG2icKY09jX1g5ao6KslVWYkmfT0O0akRkKZpQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">DORA的目标是将硬件、算法和人工智能模型结合在一起，并使它们相互通信，让硬件和软件的集成变得容易。</div><div class=" pTag">DORA提供了Python、Rust、C/C++等多种语言版本，其中在Python上速度比ROS2快了17倍。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WNP3qVb8csdfCzNEFVicqoqHqhcU7ajTMiaUL81d43ME3xstDpxlpDZIw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在Python上，DORA还具备热重载功能，意味着可以在运行过程中也可以随时修改Python代码。</div><div class=" pTag">未来，如果把检索增强生成（RAG）技术和热重载功能结合，还能创建出自编码机器人，根据提示自动生成代码。</div><div class=" pTag">作者表示，有了LeRobot和Dora，自己在家也能复刻出一个Reachy2的小号仿品。</div><h2>把具身智能成本打下来</h2><div class=" pTag">那么，这个机器人价格到底多少呢？这还是大家最关注的问题。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WicLNxQnMlJuzxj3IbOMPVtxRIK2GIl7hbbWgWNxYs9yUuCyfZBeHUnw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">其实主要取决于<strong style="font-weight: 600;">硬件</strong>。</div><div class=" pTag">作者雷米表示，目前能接入LeRobot最便宜的机械臂，只需<strong style="font-weight: 600;">250美元</strong>（折合人民币约1800元）。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WgtENlSRmoa2uMIB55aMugANjDmsUsjXJeic0fwKN3XOBj0lJ3K1MVzg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">目前展示的这款Reachy2，价格还没公布，参考它的上一代，起售价为9750美元（折合人民币约7万元）。</div><div class=" pTag">有网友表示，看来几年内把机器人助手价格打到5000美元以内有希望了（大约3.6万，不到一辆车的价格）。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WGZmTYFuP91t9IaiaRCKECHl3b25GfS5GA1SxZbHtE6sm3WH7YFN63JA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这也是为啥Hugging Face入局具身智能会引发轰动的关键所在。</div><div class=" pTag">要知道，具身智能研发成本一直居高不下，这个火爆赛道如今已经<strong style="font-weight: 600;">吸金几十亿</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WzYIKicDzqoNxu79X4Orl6rLojNoP78eiapyFu6JehhB2llpu1CiaSLJrw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而将所有算法数据集开源，意味着人形机器人的成本（起码在软件算法层面）大幅降低，会给业内其他布局机器人领域的玩家带来不小压力。</div><div class=" pTag">与此同时，Hugging Face还挖来了一流工程师。</div><div class=" pTag">领衔项目的Remi Cadene（雷米·卡德内）曾是特斯拉Autopoilot和Optimus机器人研究项目的成员。</div><div class=" pTag">入职时雷米还调侃了OpenAI，表示要做真正意义上的开源。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WMw8U72Ckt5X2dfUU70weWNeDmgFaNsJ67uHprcjazG4v1npKAeqKZg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">具体动作上，雷米的脚步走得也确实很快。上个月刚刚发布了Le Robot开源代码库，如今首个具身智能成果也来了。</div><div class=" pTag">不过能快速在人形机器人上部署训练，也少不了<strong style="font-weight: 600;">花粉机器人公司</strong>出力。</div><div class=" pTag">这是一家来自法国的机器人公司，他们也强调开源理念。在2013年发布了据称是第一个开源的3D打印机器人。</div><div class=" pTag">此前已经推出了开源全遥控机器人Reachy1。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WONgMct1YvsEicdKL5pMDhrEF6yBSgrN0db2w8aWtF3dZr9Rge69aLaA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">雷米介绍，在Hugging Face团队正留意人形机器人硬件时，花粉机器人这边也在找端到端方案，所以两家一拍即合。</div><div class=" pTag">而且还有地理上的优势，他们的办公地点相隔<strong style="font-weight: 600;">只有2小时的路程</strong>。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">所以我们只是去拜访了他们几天而已。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WSfFLtzeysMNRokbicZCIazpNJavVnnyQGEveLHs1lmkeDykN5O7kXZQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">从目前雷米透露的动向来看，他们还会开源一系列工作，比如语音命令控制等，大家可以期待一下。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WZ6gTiaKBb8zL00tXB8kaicZXLTJKgAk63aK8RxDprSFEAlUYRJ0Hhv5w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">By the way，Hugging Face最近正在招人哦，岗位是<a href="https://posts.careerengine.us/redirect/referral/id/66654bc503edcb6f3c9de35c">Post-Sales Machine Learning Solutions Engineer - Asia Remote</a>，感兴趣的童鞋可以尝试下~</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1W6pVJbxdc8pSrt1qlIOtZS4SVW6rXaROo2GnxHrSoC2cytEJk9ynFkw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://venturebeat.com/ai/hugging-face-and-pollen-robotics-show-off-first-project-an-open-source-robot-that-does-chores/</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://twitter.com/Thom_Wolf/status/1799008162772836355</span><br /><span style="font-size: 17px;">[3]</span><span style="font-size: 17px;">https://x.com/RemiCadene/status/1744248877811646853</span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div class=" pTag"><span style="font-size: 17px;">— <strong style="font-weight: 600;">完</strong> —</span></div></div></div><div style="font-size: 17px;"><div class=" pTag"><span><strong style="font-weight: 600;">量子位年度AI主题策划</strong></span>正在征集中！</div><div class=" pTag">欢迎投稿专题&nbsp;<strong style="font-weight: 600;">一千零一个AI应</strong><strong style="font-weight: 600;">用</strong>，<strong style="font-weight: 600;">365行AI落地方案</strong></div><div class=" pTag">或与我们分享你在<strong style="font-weight: 600;">寻找的AI产品</strong>，或发现的<strong style="font-weight: 600;">AI新动向</strong></div></div><div style="text-align: center;"><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div></div></div><div class=" pTag" style="text-align: center;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1OICpx-YIj7DJpna9M_aCQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 09 Jun 2024 06:23:14 GMT</pubDate>
</item>
<item>
<title>苹果AI升级大泄露，Siri将在iOS18重生！库克重新定义AI为Apple Intelligence</title>
<link>https://posts.careerengine.us/p/66654a4377708f2d685aa8fb</link>
<guid>https://posts.careerengine.us/p/66654a4377708f2d685aa8fb</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 明敏 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">万众期待的苹果WWDC在即，<span><strong style="font-weight: 600;">有关AI的升级细节全泄露了！</strong></span></div><div class=" pTag">知名网站Apple Insider称收到了新功能的确切细节，并总结评价：<span><strong style="font-weight: 600;">Siri将在iOS18中重生</strong></span>。</div><div class=" pTag">从相机相册、日历备忘录到浏览器电子邮件……几乎系统中所有原生应用都将被AI全面武装。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WiabCz5ch73gKuUaAFzibrhg7AZaVGOuQPterdlmodue3JgAjmhZMovSQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不仅如此，彭博社爆料苹果将推出针对iPhone、iPad、Mac的全生态AI能力，定名为<span><strong style="font-weight: 600;">Apple Intelligence</strong></span>：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">将自动选择运行本地AI或云端AI，苹果技术侧重于日常实用功能，把聊天机器人等花里胡哨的留给OpenAI。</div></blockquote><div class=" pTag">有不少网友感叹：Apple Intelligence是最聪明的营销手法，库克直接把AI一词中原本的Artificial<span>（人工的）</span>劫持替换了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1W5Pia1VPznzjE5G6Y9VQe6X1A64bJEV3SIicNWOMniawDYRlguyWEE6gsQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1W0kZx9EU0Fp5WQsYeBdezCxnALoicPYibMxyLiboFp7dUjPCSFH8mXW0zw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，从苹果ML实验室公开的论文中也能看到新功能的影子，如“一句话修图”技术就有传言将在此次更新中落地。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WEF28anObI6agdOkUEnAEQG9xFsqEypKQJjhWuBI3WGXxCSdMLkSbhQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">惯例先上总结，具体细节，后面挑重点展开。</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">相机：拍特定模式的照片/视频，一句话就能设定倒计时、切换前后镜头</div></li><li><div class=" pTag">照片：编辑修图、整理相册，甚至还能根据关键词找出特定的人、宠物、风景……</div></li><li><div class=" pTag">备忘录：录音转文字、语音总结大意、公式识别，学习笔记全能王驾到</div></li><li><div class=" pTag">语音备忘录：录音、转录、存档、整理文件夹，会议笔记更高效</div></li><li><div class=" pTag">提醒事项：新建购物清单、差事待办，还能加标签、整理归类</div></li><li><div class=" pTag">邮件：写邮件、存草稿、设置提醒，还能自动归类广告垃圾邮件</div></li><li><div class=" pTag">图书：导航到特定书籍、章节，一键翻页、切换主题</div></li><li><div class=" pTag">Safari：总结网页摘要、整理标签页</div></li><li><div class=" pTag">Keynote：一句话插入音频、视频、图片，自动编辑幻灯片</div></li></ul><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WUpH1Hj5VWxPoc3eTSP7kxNK9fvsQWgMyK2z82icKpmEvC0Flj7weHFQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>更智能的相机和相册</h2><div class=" pTag">新版Siri将能够<span><strong style="font-weight: 600;">直接控制</strong></span>摄像头，用户可以通过Siri完成相机模式设置等操作，具体包括：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">切换到视频录制模式</div></li><li><div class=" pTag">将相机打开到特定模式，如照片、肖像、视频、慢动作等</div></li><li><div class=" pTag">设置计时器</div></li><li><div class=" pTag">切换至前/后置摄像头</div></li></ul><div class=" pTag">除了相机之外，Siri也将给相册应用带来显著功能增强，用户可以选择通过Siri编辑、移动和隐藏照片或相册。</div><div class=" pTag">Siri还能够通过Visual Look Up识别照片中的特定物体、风景或人物，这意味着用户可以要求查看某人或特定场景的照片。</div><div class=" pTag">用户还可以选择编辑照片、视频、屏幕截图等内容——所有这些都可以通过苹果的虚拟助手 Siri 进行。</div><div class=" pTag">在相册里，Siri将能够：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">搜索并打开本地和网络中包含特定对象的照片</div></li><li><div class=" pTag">旋转、复制、移动、隐藏、收藏照片</div></li><li><div class=" pTag">创建、打开、重命名相册，或向其中添加照片</div></li><li><div class=" pTag">创造新的回忆、专辑</div></li><li><div class=" pTag"><div class=" pTag">打开照片和视频进行编辑、对照片应用滤镜、增强照片</div><br /><div class=" pTag">此外，苹果相册还将进行一些小的 UI 更改，加入新的AI编辑功能，还将推出Clean Up工具，支持从图像中移除特点对象。</div></div></li></ul><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WSOO90LmibWD4HGWPQrIJC5hKBodPhxu9jT3BnGZeG3ibYzicbwtveYZdQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>粉丝自制概念图，来源@oofus</h6><h2>用Siri管理备忘录和录音</h2><div class=" pTag">苹果在备忘录中设置的Siri增强功能将使得浏览、标记和移动笔记变得更加容易。</div><div class=" pTag">在备忘录中，搭载了Apple全新大模型支持的Siri将能够：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">创建、重命名和删除注释文件夹</div></li><li><div class=" pTag">为笔记添加或删除标签，筛选、打开、创建和删除备忘录中的特定标签</div></li><li><div class=" pTag">在备忘录中打开特定帐户下的内容（例如 iCloud、Outlook 等）</div></li><li><div class=" pTag">打开、移动、删除或固定/取消固定特定笔记</div></li><li><div class=" pTag">在笔记视图和文件夹视图之间切换</div></li></ul><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1Wic6Q5RRWhClXdrDSoZPwlvv3iaykAKjSic3h7o6efFOZO3jxtUNiaEdKJQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>新版备忘录概念图，来源：Apple Insider</h6><div class=" pTag"><div class=" pTag">新版备忘录预计还将具有应用程序内录音、音频转录以及由大模型支持的摘要功能，这将允许用户将录音、摘要和转录与其他材料（例如文本或图像）一起存储在一张笔记中。</div><br /><div class=" pTag">Math Notes是苹果为备忘录准备的另一项升级，它将集成全新GreyParrot计算器的集成，帮助用户将复杂的数学方程和图表嵌入到个人笔记。</div></div><div class=" pTag">同样在开发中的键盘数学预测功能，将允许苹果软件将数学表达式识别为文本输入的一部分，通过AI自动补全数学方程。</div><div class=" pTag">除了备忘录，语音备忘录（录音机）中也将有新功能上线。通过 Siri，用户将能够创建、暂停、删除和移动单个录音或录音文件夹。</div><div class=" pTag">借助语音备忘录应用程序，Siri 将可以：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">搜索、打开个人语音备忘录/录音</div></li><li><div class=" pTag">创建或暂停新录音</div></li><li><div class=" pTag">创建、打开和删除语音备忘录中的文件夹</div></li><li><div class=" pTag">按名称、创建日期和音频内容删除特定录音</div></li></ul><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1Wo1iahhUsOhdTyeq4No38LIcZWPf2nrInPXMmOic07yebQ8FK171Ucj6g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>新版语音备忘录概念图，来源：Apple Insider</h6><div class=" pTag">新的功能将使用户能够更轻松地找到他们可能正在寻找的特定文件，因为Siri将能够按名称、日期或位置查找录音，预计还将接收应用程序内的音频转录。</div><h2>处理邮件、做PPT，让办公更高效</h2><div class=" pTag">除了备忘录，苹果的邮件应用也将迎来重大变革，同样将搭载AI功能，使其能够根据文本内容自动对电子邮件进行分类。</div><div class=" pTag">具体来说，邮件应用将能够将电子邮件分为商业、新闻、社交等类别， Siri将能够使用这些信息在应用内执行不同的操作。</div><div class=" pTag">例如识别带有促销代码的电子邮件或来自特定公司的电子邮件，并将其标记为垃圾邮件。</div><div class=" pTag">在邮件应用程序中，Siri将拥有的能力包括：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">撰写、发送/取消发送电子邮件，或设置定时发送</div></li><li><div class=" pTag">将电子邮件另存为草稿，或删除草稿</div></li><li><div class=" pTag">将电子邮件标记为垃圾邮件，或设置不提醒、阻止、删除特定发件人/特定主题的邮件</div></li><li><div class=" pTag">回复电子邮件或其所有收件人，启用基于AI的智能回复</div></li><li><div class=" pTag">将电子邮件标记为“稍后阅读”并设定具体日期，或取消设定</div></li><li><div class=" pTag">取消订阅电子邮件，尤其是与营销相关的电子邮件</div></li><li><div class=" pTag">启用来自特定发件人或有关特定主题的电子邮件的通知设置</div></li><li><div class=" pTag"><div class=" pTag">总结电子邮件内容，归档、移动、转发电子邮件</div><br /><div class=" pTag">苹果的邮件应用程序还将搭载一项名为“智能回复”的功能，通过该功能，用户将能够发送人工智能生成的电子邮件回复。</div></div></li></ul><div class=" pTag">在办公方面，不只是邮件，新版Keynote也将搭载AI相关功能——通过Siri，用户将能够轻松查看Keynote演示文稿，并自行进行更改。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WgpCo3HQdIPyzibITgsP56D63nXcwptEYghewNKcPGXdEicrtQkicyFVoQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">通过虚拟助手，用户可以向Keynote中插入音频、图像和视频，使PPT的创建、修改、演示变得更加容易：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">向特定幻灯片中添加图像、音视频、文本框或注释等内容</div></li><li><div class=" pTag">创建新PPT或新页面，显示具体幻灯片</div></li><li><div class=" pTag">播放和停止主题演示文稿</div></li><li><div class=" pTag">显示主题演讲的活动流，显示更改内容以及更改者</div></li><li><div class=" pTag">将网络视频从Safari添加到幻灯片</div></li><li><div class=" pTag">为特定幻灯片设置标题、要点</div></li></ul><h2>用Siri创建提醒列表</h2><div class=" pTag">Siri 的提醒功能将帮助用户创建诸如家务、要阅读的书籍、学习用品、旅行安排等列表，还可以在特定提醒中添加或删除主题标签，并生成提醒概述。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1WvAf24M8atHO6SSR5dpaoSuso0UzWBtCIiaHvHWI7oq3wSnjR3ZxBe0w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>新版日历和提醒概念图，来源：Apple Insider</h6><div class=" pTag"><div class=" pTag">利用这一功能，企业用户可以创建他们需要会面的人的提醒，而学生可以列出新学年所需的用品清单。</div><br /><div class=" pTag">据Apple Insider透露，提醒事项预计还将与苹果默认的日历应用程序集成，这意味着用户将能够直接从内置日历应用程序创建和编辑提醒，支持的操作包括：</div></div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">创建新的提醒列表或其部分</div></li><li><div class=" pTag">从特定提醒中添加或删除主题标签</div></li><li><div class=" pTag">显示提醒列表/概述</div></li></ul><h2>Siri一键总结网页</h2><div class=" pTag">随着Siri升级，Safari也被全面改进。</div><div class=" pTag">爆料称，Siri将引入新的智能浏览功能，该功能将增强搜索功能并提供文章摘要。</div><div class=" pTag">还有一项名为Web Eraser的功能，它是一个内容拦截器。不过这个功能引发了争议，英国新闻媒体协会和一些法国出版商都向苹果公司投诉了该功能。消息称该功能已经构建完善可用，但是在WWDC之前苹果可能会删除它避免争议。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBBUPSHSc3ScOXzwSJIoI1W5WrG9XaiadwbXmp3B61Nx8qcxu30vpia3TTvbM75gFicBSlCYFlQHbnhA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><h2>其他</h2><div class=" pTag">Siri还可以打开系统设置的不同区域，例如亮度设置、主屏幕和应用程序库设置，以及多任务处理和手势设置。系统设置应用程序预计也将在 iOS 18 和 macOS 15 中被重新布局。</div><div class=" pTag">同时Siri还能在“文件”应用中扫描文档、将特定文件移入垃圾箱。编辑通讯录中联系人的详细信息。</div><div class=" pTag">在放大镜功能里，Siri可以描述物体、识别视野中的人等，有点类似于Rabbit 1等产品的识别方式，同时利用苹果现有的框架和 Visual Lookup 等功能。</div><div class=" pTag">此外，Siri 还能够通过苹果内部的 Generative Playground 应用程序生成各种不同的图像，但目前尚不清楚最终用户是否可以使用此功能。</div><h2>“灰质计划”</h2><div class=" pTag">值得一提的是，一些Siri新功能被放入“灰质计划”<span>（Project Greymatter）</span>中，包括生成文章、电子邮件等，以及对消息、通知等摘要。</div><div class=" pTag">一个名为Greymatter Catch-Up的功能将为用户提供最新通知的回顾。</div><div class=" pTag">据了解，苹果的人工智能软件能够生成不同级别的摘要，范围从三个主题词一直到三个句子。</div><div class=" pTag">并且，Siri、Spotlight 和Mail都将通过苹果的人工智能软件获得先进的搜索功能和更好的上下文理解。创建回复时，Siri 将能够考虑不同的实体，例如人和公司、地点和日历事件。</div><div class=" pTag">据知情人士透露，生成式人工智能软件还将允许即时创建智能回复，该回复将在邮件、Siri和消息中提供。</div><div class=" pTag">最后爆料来源AppleInsider也强调，并非所有功能都会发布。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">相关消息来自熟悉苹果操作系统预发布版本和测试环境的人士，可能并不反映最终发布版本。</div></blockquote><div class=" pTag">最后，再来欣赏一段果粉自制的iOS18概念视频：</div><div class=" pTag"><div class=" ce-iframe-holder offset offset-old-126"></div></div><div class=" pTag">究竟实际情况如何，就等11号凌晨的WWDC大会上一一揭晓了。</div><div class=" pTag">你对苹果AI还有什么期待，欢迎在评论区聊聊</div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /></span><span style="font-size: 17px;">https://appleinsider.com/articles/24/06/08/siri-is-reborn-in-ios-18----everything-apples-voice-assistant-will-be-able-to-do</span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div class=" pTag"><span style="font-size: 17px;">— <strong style="font-weight: 600;">完</strong> —</span></div></div></div><div style="font-size: 17px;"><div class=" pTag"><span><strong style="font-weight: 600;">量子位年度AI主题策划</strong></span>正在征集中！</div><div class=" pTag">欢迎投稿专题&nbsp;<strong style="font-weight: 600;">一千零一个AI应</strong><strong style="font-weight: 600;">用</strong>，<strong style="font-weight: 600;">365行AI落地方案</strong></div><div class=" pTag">或与我们分享你在<strong style="font-weight: 600;">寻找的AI产品</strong>，或发现的<strong style="font-weight: 600;">AI新动向</strong></div></div><div style="text-align: center;"><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div></div></div><div class=" pTag" style="text-align: center;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F0JXO64k2y2nJZrHgG0Wqqw">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 09 Jun 2024 06:22:59 GMT</pubDate>
</item>
<item>
<title>清华系细胞大模型登Nature子刊！能对人类2万基因同时建模，代码已开源</title>
<link>https://posts.careerengine.us/p/6663eed95da4a933f9ad8a46</link>
<guid>https://posts.careerengine.us/p/6663eed95da4a933f9ad8a46</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">白交 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">生命科学领域的基础大模型来了！</div><div class=" pTag">来自清华、百图生科的团队提出的单细胞基础大模型scFoundation，登上Nature Methods。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnq4dTiaqjcCWCEHBtaRLnPbpW88eSqY6GBGYzPib3BdQaicbxJFyNa35uBg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">该模型基于5000万人类单细胞测序的数据进行训练，拥有1亿参数，能够同时处理约20000个基因。</div><div class=" pTag">团队在模型架构上进行了创新，相同参数量下计算时间是传统Transformer架构的3%左右。相关研究成果也被NeurIPS2024接收。</div><div class=" pTag">清华大学自动化系博士研究生郝敏升为该论文的第一作者。清华大学张学工教授，马剑竹教授，百图生科宋乐教授为通讯作者。</div><div class=" pTag">作为基础模型，它在细胞测序深度增强、细胞药物响应预测和细胞扰动预测等下游任务中表现出卓越的性能提升，并为基因网络推断和转录因子识别提供了新的研究思路。</div><h2>细胞基础大模型登Nature子刊</h2><div class=" pTag">通过在大规模语料库上的训练，大模型才具备了基本的语言理解和识别能力。</div><div class=" pTag">在生命科学领域，细胞可以被视为拥有自身“语言”的基本结构和功能单元，由DNA序列、蛋白质和基因表达值等构成无数“词语”的“句子”。</div><div class=" pTag">那么随之而来的问题是：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag"><strong style="font-weight: 600;">能否基于大量细胞的“句子”来开发细胞的基础模型？</strong></div></blockquote><div class=" pTag">目前训练大规模单细胞数据主要存在以下三点挑战：</div><div class=" pTag">1、基因表达预训练数据需要涵盖不同状态和类型的细胞景观。然而目前大多数单细胞数据组织松散，全面完整的数据库仍然缺失。</div><div class=" pTag">2、在训练过程中，传统的transformer难以处理近20000个蛋白质编码基因构成的“句子”，这使得现有工作通常不得不将模型限制在一小部分预选的基因列表上。</div><div class=" pTag">3、 不同技术和实验室的单细胞转录数据在测序深度上存在差异，这妨碍了模型学习统一且有意义的细胞和基因表示。</div><div class=" pTag">针对这些问题，研究团队首先收集了超过5000万个涵盖各个器官、肿瘤和非肿瘤的大规模人类单细胞数据集用于训练。</div><div class=" pTag">与大型语言模型中的<strong style="font-weight: 600;">“词-向量”</strong>转换不同，scFoundation通过巧妙设计，将连续的基因表达值转化为向量。</div><div class=" pTag">针对单细胞数据的高稀疏性以及零值和非零值所包含信息量的差异，研究团队设计了一个<strong style="font-weight: 600;">非对称编码模块</strong>。</div><div class=" pTag">该模块在保持相同参数规模的情况下，所需的计算量仅为传统语言模型Transformer的3.4%。</div><div class=" pTag">此外，研究团队还提出了<strong style="font-weight: 600;">一种测序深度感知的预训练任务</strong>“read-depth-aware (RDA)”，能够对测序深度进行降采样，使得模型在预训练阶段在完成传统的掩膜恢复任务外，还能够由低质量细胞恢复高质量细胞的基因表达信息。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqlo9YVFcCKBeymTqersia9mibYmAAz0BJRaMBRwBxAewFHrhUJribg046Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>scFoundation模型及下游应用场景</h6><h2>两种应用范式</h2><div class=" pTag">scFoundation的应用范式主要包括<strong style="font-weight: 600;">开箱即用和微调</strong>两种：</div><ol class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">从scFoundation得到表征，进一步利用下游方法分析。</div></li><li><div class=" pTag">训练scFoundation一层和针对各个任务的MLP头，进行标签预测。</div></li></ol><div class=" pTag">在开箱即用范式上，受益于RDA预训练任务，将scFoundation应用于细胞测序深度增强任务，在不需要进一步微调的情况下达到了比现有训练方法相当甚至更好的效果。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqXNcho7SuWGKOLy4W5X45aIHy2rNRhkws521w56oNfSEf3w378qiaDfw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，通过构建模型预测细胞对癌症药物干预的反应，对指导抗癌药物的设计及理解癌症的生物学机制至关重要。</div><div class=" pTag">基于scFoundation提取的Bulk基因表达数据，能够预测药物半最大抑制浓度IC50及单细胞水平的药物敏感性，显示出在几乎所有药物和癌症类型上<strong style="font-weight: 600;">预测效果</strong>均有显著提升。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqhiahl3DeDm3Cn7SpiaD91XwAoWicNnSz7c0lNtZyfTHS2tn9JPz0lN1yA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而在<strong style="font-weight: 600;">细胞扰动预测</strong>任务中，通过提取单个细胞的基因表征来构建特定的基因共表达网络，scFoundation成功捕捉了不同条件下的细胞和基因表征，显著提高了单/双扰动预测的准确度。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqfpGPsoyffyt1I2eA6fQKxOH0sxUMhic5TicCl1Rk9Hdm2sdqiaYPL5Atg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，基因表征还可用于<strong style="font-weight: 600;">构建针对特定细胞类型的基因网络</strong>。研究团队在T、B和Monocyte细胞类型中识别出了特异的基因模块和转录因子。在微调应用方面，scFoundation在细胞类型标注任务中的效果远超传统方法。</div><div class=" pTag">研究人员还进行了丰富的消融实验，揭示了不同模块设计对性能的影响，相关模型细节已在NeurIPS 2024的xTrimoGene模型中发表。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBxSPeibxnn1hcchmVEhMRnqLyxt53CfklSZGe5MtGELmDVicsPDicaJyG7gup81s4EvRyDp81doH08A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">综上所述，scFoundation模型为建立细胞预训练大模型的模型架构、训练框架，和下游示范应用体系都提供了新的思路和方法，为生物医学任务的学习提供了基础功能，拓展了单细胞领域基础模型的边界。</div><div class=" pTag">目前模型权重及代码已开源。同时为了减少计算负担，支持更多用户轻量使用，研究团队也提供了模型相应的API，用户可在线获取scFoundation模型表征，支持CLI、Python SDK和网页端调用。</div><div class=" pTag"><span style="font-size: 17px;"><span>论文链接</span><br /><span>https://www.nature.com/articles/s41592-024-02305-7</span></span><br /><span style="font-size: 17px;">https://papers.nips.cc/paper_files/paper/2023/file/db68f1c25678f72561ab7c97ce15d912-Paper-Conference.pdf</span><br /><span style="font-size: 17px;"><span style="font-size: 17px;">代码权重开源：https://github.com/biomap-research/scFoundation </span><br /><span style="font-size: 17px;">https://aigp.biomap.com/models/1760957084760342530/1760957084772925441</span></span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-blf1-cdwe3GY7sfRox2Cg">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 08 Jun 2024 05:40:41 GMT</pubDate>
</item>
<item>
<title>量化大模型退化严重？ETH北航字节推出LoRA新范式 | ICML 2024</title>
<link>https://posts.careerengine.us/p/6663eed95da4a933f9ad8a3d</link>
<guid>https://posts.careerengine.us/p/6663eed95da4a933f9ad8a3d</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">QHT 投稿</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">大模型应用开卷，连一向保守的苹果，都已释放出发展端侧大模型的信号。</div><div class=" pTag">问题是，大语言模型<span>（LLM）</span>卓越的表现取决于“力大砖飞”，如何在资源有限的环境中部署大模型并保障性能，仍然颇具挑战。</div><div class=" pTag">以对大模型进行量化+LoRA的路线为例，有研究表明，现有方法会导致量化的LLM严重退化，甚至无法从LoRA微调中受益。</div><div class=" pTag">为了解决这一问题，来自苏黎世联邦理工学院、北京航空航天大学和字节跳动的研究人员，最新提出了一种信息引导的量化后LLM微调新算法<strong style="font-weight: 600;">IR-QLoRA</strong>。论文已入选ICML 2024 Oral论文。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKptm1vRfyN4VX15XugibJ0FQiaGfyq7xmhf3MMkY4JXZxnqia0f7Ky0VuQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">论文介绍，IR-QLoRA能有效改善量化导致的大模型性能退化。在LLaMA和LLaMA 2系列中，用该方法微调的2位模型，相比于16位模型仅有0.9%的精度差异。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKb6vHOFqAL4hJibgWicO1lFWB1ZC1ypayfibpFKYpBx8wKAZAu3BpaY1Sw/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>IR-QLoRA框架图</h6><div class=" pTag">该方法的核心思想，是通过信息保留来使LoRA微调量化的大语言模型实现精度提升。</div><div class=" pTag">包含从统一信息角度衍生的两种技术：信息校准量化和信息弹性连接。</div><h2>信息校准量化</h2><div class=" pTag">LLM的量化权重被期望反映原始对应方所携带的信息，但比特宽度的减小严重限制了表示能力。从信息的角度来看，量化LLM和原始LLM的权重之间的相关性表示为互信息。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKyNPtEvUW3pfswWBmXK5oFPTGRBAA8p1ibvEEV3LibEWcjaUEOBxicBA2Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在LLM量化后，由于比特宽度的显著减小导致表示能力的降低，量化权重的熵远小于原始权重的熵。因此，优先考虑低比特权重内的信息恢复对于增强量化LLM至关重要。</div><div class=" pTag">首先从数学上定义信息校准的优化目标。校准过程可以看为向量化器引入一个校准常数&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKibst0ts22t1Mz3erCWZXQHoKVDrUvc68DXHIccFksfvfe6w7S176flA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>&nbsp;以最大化信息，量化过程可以表述如下：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKcfETz8jkDTNhRd8JYzROUvatT7rjIkwVhW85eRs80U91OlzxA0fRNw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">由于原始权重&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKbrLy1OKZqP2rxDFgJPibMc5twISyibZNX7QZ0EjnzLD4W0WOIHoh5CQw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>&nbsp;是固定的，公式(1)中的优化目标可以表示为：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKk53aq3PKicHNIYBwQcpGkzx4KzHWzLS4PsKiaz8J40ic3OP66eGIEsxBw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">由于直接求解公式(3)中的目标非常耗时，作者提出了一种分块校准量化器信息的两步策略：</div><div class=" pTag">第一步是初始化校准常数&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKibst0ts22t1Mz3erCWZXQHoKVDrUvc68DXHIccFksfvfe6w7S176flA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>。基于神经网络权重正态分布的常见假设，将每个权重量化块的常数初始化为中值&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKAyM12ECBrMDdppCT67HE3eZlVYOP4c7N0FdgGd5RqMn94Aft6LDQkQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>。由于正态分布中靠近对称轴的区域的概率密度较高，因此该初始化旨在更大程度地利用量化器的间隔。应用位置相关中值来初始化&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKaHl2WYTNh1973icbRzAtMUHJlVxpzuiapSDjqgsHSyDMpNM2ibffhvt2Q/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>，以减轻异常值的影响。</div><div class=" pTag">第二步是优化校准常数&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKibst0ts22t1Mz3erCWZXQHoKVDrUvc68DXHIccFksfvfe6w7S176flA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>、量化尺度&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKdzibrTkMel2AVtjiaXfpnnr1ibW3aQhaFCAdZIwstQ7Ekto5qKXjfJb4Q/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>、双量化尺度&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKbtKEQN78hFNLtrSKQ4BLCseFgskYKF0VASHF5v30fEsK510RpEGWpQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>。使用信息熵作为度量，并进行基于搜索的优化以获得&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKg4PdkpdIHpA9cRKz9bQKbjbiaibcWPArFKkyRppHTVSwh74qNeD6vuFA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>。通过将&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKeriaySCIH5OwPAbfcddLsMQULyL6qiachwzJDUzJ2v336CtO52rqqYGw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>&nbsp;线性划分为n个候选来创建&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKibst0ts22t1Mz3erCWZXQHoKVDrUvc68DXHIccFksfvfe6w7S176flA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>&nbsp;的搜索空间，其中&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKIiclf8LFzPbVeFDPEgO0KIUDm7hOxriaFOITGib8VQrrpY4mJ3FJCOaSw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>&nbsp;是标准差，<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKuRFxDzbXxGJNmQGQclAolRHrnB5ED7Sc50jz7vaicgIVKwmcgOrsd2Q/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>&nbsp;是系数。使用每个候选&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKibst0ts22t1Mz3erCWZXQHoKVDrUvc68DXHIccFksfvfe6w7S176flA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>&nbsp;校准权重后，量化校准的权重并计算信息熵。获得的量化尺度与基线一致。通过&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKkVX3w66bK97HvGWkxY3bjZ3gAMia5B7gLGu5yvU417QG4yTD6EJgHoQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>&nbsp;得到量化尺度&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKLvHNDL37M7Kp4o8smaVvJ9014BNdmkA3hgOcXJkJ46YXMpexbWJPfw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>，然后二次量化为&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKIZZgnJOSbVsYVoucZynP2BnYdp2QAas9ecaia8GSdNO1qrvazWCIovg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>&nbsp;和&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xK8YYicMv1v97icribw2wTa7ObqiasLgYeSsFMro3bDpwF6UYQ5qtpPFR5mg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>。</div><div class=" pTag">对于优化后的校准常数&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKg4PdkpdIHpA9cRKz9bQKbjbiaibcWPArFKkyRppHTVSwh74qNeD6vuFA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>，执行类似于尺度的双量化以节省内存，信息校准量化的量化过程可以总结为：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKdFeHpU1ul4ctcJK79Kw1icFxr4qBtWO3LD2TG9f69RfI10k8Ih21wFA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>信息弹性连接</h2><div class=" pTag">除了基线中的量化LLM之外，由低秩矩阵组成的LoRA也阻碍了信息的恢复，为了增强LoRA的表示能力，帮助恢复量化LLM的信息，同时保持其轻量级性质，作者引入了有效的信息弹性连接。该方法构建了一个强大的低秩适配器，有助于利用从量化的LLM单元导出的信息。</div><div class=" pTag">具体来说，首先根据输入和中间维度的最大公约数对原始特征进行分组和平均，并将其添加到由&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xK8rMjN8F6ib4V4ZdhZICyh4hQqcibv5TET1BLl8PTqzvdhTkOsL6o9GKQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>&nbsp;矩阵计算的输出中。增加弹性连接的LoRA的第一个子单元&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKxg2G9kBmulNWrwIBqE0NoibZs5hpic6niaWRx7PcmTv5lcQhIs4icdibaRA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>&nbsp;可以表示为：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKo0S3uXE9sxfPoUYys19MYYGWxo7knycibYWorCM47qusfZG0tJWY5sQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">LoRA的后一个矩阵将低秩中间表示变换为输入维度，因此其伴随的无参数变换使用重复串联来增加维度。后一个子单元&nbsp;<div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKkSArK9nfkmUWUBNV3bl4nAO8psXBLusSlDch09RckkDnbdm1vMNUKw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div>&nbsp;的计算过程可以表示为：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKt7foAQcudDrkWhOlu52obKbh08Rq9yu1wI2fekiaT5DzBO5UTL0wzvg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">与LLM和LoRA单元中的矩阵乘法相比，无参数变换是一种多样化的变换形式，进一步增强了量化LLM的信息表示。</div><h2>实验验证</h2><div class=" pTag">作者广泛评估了IR-QLoRA的准确性和效率。选择LLaMA和LLaMA 2系列模型，在Alpaca和Flanv2数据集上构建参数高效的微调，使用MMLU和CommonsenseQA基准进行评估微调后量化模型的效果。</div><h3>准确率</h3><div class=" pTag">以下两张表格分别展示了在Alpaca和Flanv2数据集上微调的MMLU基准的5-shot精度结果。综合结果表明，在各种规模的LLaMA模型中，IR-QLoRA优于所有比较量化方法。</div><div class=" pTag">与基线方法QLoRA相比，IR-QLoRA在相同的微调管道下在MMLU基准上实现了精度的显著提高。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xK7GicYDOxnictg1wmgXib3cYQfWuQUmRshH5mBgAAK5JictaaAqJib7u0DbQ/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKkicCAc9SO17t5u7k2icVtWiaw5nJ5EQiaSaUQazGIK42Q5MCB6bb2QF9sg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，在LLaMA 2上的准确性比较，证明了IR-QLoRA跨LLM系列的泛化性能。</div><div class=" pTag">下表中的结果表明，IR-QLoRA不仅平均实现了至少<strong style="font-weight: 600;">2.7%</strong>的性能改进，而且在几乎每个单独的指标上都表现出了优势。这些结果表明IR-QLoRA在不同的LLM系列中表现出很强的泛化性。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKE8NgmGibXSH89feQqwsrzcQ3hD20l4ZxhVAicrYiav7Em9UolwBHYyFLw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">与MMLU基准上的现象类似，在CommonsenseQA基准上，与SOTA方法相比，IR-QLoRA始终保持了LLaMA-7B的最佳平均准确率，而且还显著提高了大多数子项的有效性。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKm1ar7B1LqdwUGXIfDZuAQL6qVqNcv87ke3DFmMicLiaKpxNzjUVzFrGA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h3>超低位宽</h3><div class=" pTag">除了4比特以外，作者还评估了超低位宽下的IR-QLoRA建议。</div><div class=" pTag">具体来说，作者采用了QLoRA和LoftQ的量化方法，按照百分位量化方法构建了NF2和NF3量化。</div><div class=" pTag">下表显示，随着量化位宽的减小，基线QLoRA的性能急剧下降，以至于其在2位情况下的性能与随机相差无几。</div><div class=" pTag">相比之下，IR-QLoRA表现出更优越的性能，在Flan v2数据集上微调2位模型时，与16位模型相比仅有0.9%的精度差异。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCcAvgyOIDHtRAxqCvT13xKosjEz8ib2SDU8WBu0YpPde8VjlFtrFJrhjZGVJs3tor1ibNG9VWydsKA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h3>效率</h3><div class=" pTag">IR-QLoRA的信息校准量化和信息弹性连接并没有带来额外的存储和训练开销。</div><div class=" pTag">如上所示，信息校准量化增加的参数仅相当于量化的缩放因子，而且采用了双重量化以进一步减少存储。因此其带来的额外存储空间很小，在4位LLaMA-7B上仅增加了 2.04%。</div><div class=" pTag">校准常数的优化过程也只增加了微不足道的训练时间（例如，LLaMA-7B为 0.46%，LLaMA-13B为 0.31%）。此外，增加的时间仅用于训练过程中的初始优化，并不会导致推理时间的增加。信息弹性连接也只在每层引入了2个额外参数，在整个模型中可以忽略不计。</div><h2>结论</h2><div class=" pTag">总的来说，基于统计的信息校准量化可确保LLM的量化参数准确保留原始信息；以及基于微调的信息弹性连接可以使LoRA利用不同信息进行弹性表示转换。</div><div class=" pTag">广泛的实验证明，IRQLoRA在LLaMA和LLaMA 2系列中实现了令人信服的精度提升，即使是2-4位宽，耗时也仅增加了0.45%。</div><div class=" pTag">IR-QLoRA具有显著的多功能性，可与各种量化框架无缝集成，并且大大提高了LLM的LoRA-finetuning量化精度，有助于在资源受限的情况下进行实际部署。</div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">论文地址：https://arxiv.org/pdf/2402.05445</div><br /><div class=" pTag">代码地址：https://github.com/htqin/IR-QLoRA</div></span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FtX6P0U5g9vNDIq2qP7IgCA">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 08 Jun 2024 05:40:41 GMT</pubDate>
</item>
<item>
<title>开源超闭源！通义千问Qwen2发布即爆火，网友：GPT-4o危</title>
<link>https://posts.careerengine.us/p/6663eeb8acfecd3348e9a30a</link>
<guid>https://posts.careerengine.us/p/6663eeb8acfecd3348e9a30a</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">鱼羊 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">开源大模型全球格局，一夜再变。</div><div class=" pTag">这不，全新开源大模型亮相，性能<strong style="font-weight: 600;">全面超越</strong>开源标杆Llama 3。王座易主了。不是“媲美”、不是“追上”，是全面超越。发布两小时，直接冲上HggingFace开源大模型榜单第一。</div><div class=" pTag">这就是最新一代开源大模型<strong style="font-weight: 600;">Qwen2</strong>，来自通义千问，来自阿里巴巴。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFVhcGdicQHiaicIcpFhMtLHTVXKXNJT9IyhvrKT2HZBibDgzyOUvrfMVFTQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">在十几项国际权威测评中，Qwen2-72B得分均胜过Llama3-70B，尤其在HumanEval、MATH等测试代码和数学能力的基准中表现突出。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFtiadkljo6iaTgLa5Jia5dN7LicQHwVN3r2RnDTtaj4D1dDxM4vej1NXFdw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不仅如此，作为国产大模型，Qwen2-72B也“毕其功于一役”，超过了国内一众闭源大模型：</div><div class=" pTag">Qwen2-72B相比于自家前代模型Qwen1.5-110B实现了整体性能的代际提升，而在上海AI Lab推出的OpenCompass大模型测评榜单上，Qwen1.5-110B已经超过了文心4、Moonshot-v1-8K等一众国内闭源模型。随着Qwen2-72B的问世，这一领先优势还在扩大。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFxV7oC3NMMuWwP8lhJ9gmuCYrSSCyl0nCC6KRD20XDDuHu04Mfq8W1w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">有网友便感慨说：这还只是刚开始。开源模型很可能在未来几个月，就能击败GPT-4o为代表的闭源模型。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFbqUglaBJyyniclaba3z0c6FtXzAkRECvq2GVILAHXUY1licGDmtMic2nA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">Qwen2的发布，可以说是一石激起千层浪。</div><div class=" pTag">上线仅1天，下载量已经超过3万次。</div><div class=" pTag">网友们还发现，除了72B和指令调优版本，这次同步开源的Qwen2-0.5B、Qwen2-1.5B、Qwen2-7B、Qwen2-57B-A14B，开源许可都换成了Apache 2.0——</div><div class=" pTag">就是说可以<strong style="font-weight: 600;">更加自由地商用</strong>。这是Llama 3系列都没做到的。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFF37fxpBdkYfuYoH0JCciaL8cxICef9vJB5hSHSYyNOg6FUQfqYicnMibg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在AI大模型领域，时间和速度都不同了。</div><div class=" pTag">因为距离阿里推出Qwen1.5-110B模型刷新SOTA，全球开源大模型形成双雄格局，才刚过去1个月时间。</div><div class=" pTag">而现在，Qwen2独领风骚，全球开源第一，国产大模型第一——连不开源的大模型都超越了。</div><h2>Qwen2挑战高考数学真题</h2><div class=" pTag">还是先来整体梳理一下Qwen2的基本情况。</div><div class=" pTag">根据官方技术博客介绍，Qwen2的特点和相比Qwen1.5的主要升级包括：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">发布5个尺寸的预训练和指令微调模型，包括Qwen2-0.5B、Qwen2-1.5B、Qwen2-7B、Qwen2-57B-A14B以及Qwen2-72B。其中Qwen2-57B-A14B是一个MoE模型。</div></li><li><div class=" pTag">在中文英语的基础上，对27种语言进行了增强。有阿拉伯语开发者表示，Qwen已经成为4亿阿拉伯语用户喜欢的大模型，<span style="font-size: 17px; text-align: justify;">稳居阿拉伯语开源模型榜单第一。</span></div></li></ul><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFcwP4wDf2T0X6DXy4qE5fuG3TWJtakdZE595DUaCjmOO6KftxibxvvJg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">在MMLU、GPQA、HumanEval、GSM8K、BBH、MT-Bench、Arena Hard、LiveCodeBench等国际权威测评中，Qwen2-72B斩获十几项世界第一，超过Llama 3。</div></li><li><div class=" pTag">代码和数学能力显著提升。</div></li><li><div class=" pTag">增大了上下文长度支持，最长实现128K tokens上下文长度支持（Qwen2-7B-Instruct和Qwen2-72B-Instruct）。</div></li></ul><div class=" pTag">纸面数据上，Qwen2在开源大模型中已经达成全球最强，那么实际表现又会如何？</div><div class=" pTag">我们用新鲜出炉的高考数学真题上手实测了一波。</div><div class=" pTag">先来个简单题：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">已知集合A={x|-5＜x^3&lt;5}，B={-3,-1,0,2,3}，则A∩B=()</div></blockquote><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFNIIjGsfFcakbcrzVemMhTHWkGmibYJk4CcrpliaCj55zTVOgfkxhB7EA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">左边是Qwen2-72B-Instruct，右边是Llama-3-70B-Instruct。除了Llama 3原版的老问题不咋支持中文外，两边的答案都是正确的。</div><div class=" pTag">那么就稍微上点难度：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">当x∈[0, 2π]时，曲线y=sinx与y=2sin(3x-π/6)的交点个数为？</div></blockquote><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFbSyFFZSv1ialtmoXJhoqHNC4OaKYyymejicsDpyeIib5WK51jibxByALdg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">Qwen2-72B-Instruct依然没有被难住，一通计算后给出正确答案：交点个数为6个。</div><div class=" pTag">而Llama-3-70B-Instruct则计算错误，扣5分。</div><div class=" pTag">Qwen2在数学能力方面，已经到了高考考场接受真题检验的水平。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFj5rD53c14eY2ibKk0NuWAiaUNJFiaBZkNMQWlIDYahy1lRUMATa4SzQiaA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">通义千问此番升级，官方和评测数据还突出了代码能力的提升，我们也有LeetCode中等难度真题浅测了一下：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">给你一个按照非递减顺序排列的整数数组nums，和一个目标值target。请你找出给定目标值在数组中的开始位置和结束位置。如果数组中不存在目标值 target，返回 [-1, -1]。你必须设计并实现时间复杂度为 O(log n) 的算法解决此问题。</div></blockquote><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFvUXfv11FGZ4ISRCMDVoDR9DdW5z14RO220AuDzjhhw5eVdj6RniaFsw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">Qwen2-72B-Instruct给出的python实现如下：</div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div class=" preReplaced" style="font-size: 17px;"><code><span style="font-size: 17px;"><span style="font-size: 17px;">def</span><span style="font-size: 17px;">searchRange</span><span style="font-size: 17px;">(nums,&nbsp;target)</span>:</span><span style="font-size: 17px;"><span style="font-size: 17px;">def</span><span style="font-size: 17px;">binary_search_left</span><span style="font-size: 17px;">(nums,&nbsp;target)</span>:</span><br /><div class=" pTag">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;left,&nbsp;right&nbsp;=&nbsp;</div><span style="font-size: 17px;">0</span><div class=" pTag">,&nbsp;len(nums)</div><span style="font-size: 17px;">while</span><div class=" pTag">&nbsp;left&nbsp;&lt;&nbsp;right:</div><br /><div class=" pTag">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mid&nbsp;=&nbsp;(left&nbsp;+&nbsp;right)&nbsp;//&nbsp;</div><span style="font-size: 17px;">2</span><span style="font-size: 17px;">if</span><div class=" pTag">&nbsp;nums[mid]&nbsp;&lt;&nbsp;target:</div><br /><div class=" pTag">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;left&nbsp;=&nbsp;mid&nbsp;+&nbsp;</div><span style="font-size: 17px;">1</span><span style="font-size: 17px;">else</span><div class=" pTag">:</div><br /><div class=" pTag">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;right&nbsp;=&nbsp;midreturn&nbsp;left</div><br /><span style="font-size: 17px;"><span style="font-size: 17px;">def</span><span style="font-size: 17px;">binary_search_right</span><span style="font-size: 17px;">(nums,&nbsp;target)</span>:</span><br /><div class=" pTag">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;left,&nbsp;right&nbsp;=&nbsp;</div><span style="font-size: 17px;">0</span><div class=" pTag">,&nbsp;len(nums)</div><span style="font-size: 17px;">while</span><div class=" pTag">&nbsp;left&nbsp;&lt;&nbsp;right:</div><br /><div class=" pTag">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mid&nbsp;=&nbsp;(left&nbsp;+&nbsp;right)&nbsp;//&nbsp;</div><span style="font-size: 17px;">2</span><span style="font-size: 17px;">if</span><div class=" pTag">&nbsp;nums[mid]&nbsp;&lt;=&nbsp;target:</div><br /><div class=" pTag">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;left&nbsp;=&nbsp;mid&nbsp;+&nbsp;</div><span style="font-size: 17px;">1</span><span style="font-size: 17px;">else</span><div class=" pTag">:</div><br /><div class=" pTag">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;right&nbsp;=&nbsp;midreturn&nbsp;left</div><br /><div class=" pTag">&nbsp;&nbsp;&nbsp;&nbsp;left,&nbsp;right&nbsp;=&nbsp;binary_search_left(nums,&nbsp;target),&nbsp;binary_search_right(nums,&nbsp;target)</div><span style="font-size: 17px;">return</span><div class=" pTag">&nbsp;[left,&nbsp;right&nbsp;-&nbsp;</div><span style="font-size: 17px;">1</span><div class=" pTag">]&nbsp;</div><span style="font-size: 17px;">if</span><div class=" pTag">&nbsp;left&nbsp;&lt;=&nbsp;right&nbsp;-&nbsp;</div><span style="font-size: 17px;">1</span><span style="font-size: 17px;">and</span><div class=" pTag">&nbsp;nums[left]&nbsp;==&nbsp;target&nbsp;</div><span style="font-size: 17px;">and</span><div class=" pTag">&nbsp;nums[right&nbsp;-&nbsp;</div><span style="font-size: 17px;">1</span><div class=" pTag">]&nbsp;==&nbsp;target&nbsp;</div><span style="font-size: 17px;">else</span><div class=" pTag">&nbsp;[</div><span style="font-size: 17px;">-1</span><div class=" pTag">,&nbsp;</div><span style="font-size: 17px;">-1]</span><br /></code><br /></div></div><div class=" pTag">一开始没有定义Solution类导致报错，不过直接把报错信息反馈给Qwen2，它自己就能完成debug：</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFXqliaHmjzM6PahDJGOweCS3flIZggALCKRgY2Vpr3e4AYqIayUI8pGA/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /></div><div class=" pTag">顺利通过测试。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFYhoic7RN2W0uFpuPX2IeEpvLicBP0bQkUhX38Dhc3uHjsKlBvyYvsib9g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>全尺寸模型标配GQA</h2><div class=" pTag">这波实测，你给通义千问打几分？</div><div class=" pTag">值得关注的是，这次阿里官方的技术博客中，还透露出了不少<strong style="font-weight: 600;">Qwen变强的技术细节</strong>。</div><div class=" pTag">首先，是<strong style="font-weight: 600;">GQA（Grouped Query Attention）</strong>的全面加持。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFZILwe9ib5ibcePMMIyytVjHGv5bKZJ6YOCdIR5E2fzhWVhbflGiabXE3Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">GQA，即分组查询注意力机制，主要思想将输入序列划分成若干个组，在组内和组间分别应用注意力机制，以更好地捕捉序列内的局部和全局依赖关系。</div><div class=" pTag">GQA能够有效降低计算复杂度，同时很容易实现并行化从而提高计算效率。</div><div class=" pTag">在Qwen1.5系列中，只有32B和110B模型使用了GQA。而Qwen2则全系列用上了这一注意力机制。也就是说，无论是高端玩家还是爱好者入门，这回都能在Qwen2各个尺寸模型中体验到GQA带来的推理加速和显存占用降低的优势。</div><div class=" pTag">另外，针对小模型<span>（0.5B和1.5B）</span>，由于embedding参数量较大，研发团队使用了tie embedding的方法让输入和输出层共享参数，以增加非embedding参数的占比。</div><div class=" pTag">其次，在上下文长度方面，Qwen2系列中所有Instruct模型，均在32K上下文长度上进行训练，并通过YARN或Dual Chunk Attention等技术扩展至更长的上下文长度。</div><div class=" pTag">其中，Qwen2-7B-Instruct和Qwen2-72B-Instruct支持128K上下文。72B版本的最长上下文长度可以达到131072个token。</div><div class=" pTag">Qwen2-57B-A14B-Instruct能处理64K上下文，其余两个较小的模型<span>（0.5B和1.5B）</span>则支持32K的上下文长度。</div><div class=" pTag">大海捞针的实验结果如下。可以看到，Qwen2-72B-Instruct在处理128K上下文长度内的信息抽取任务时，表现称得上完美。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFLz1UoO6QbDm4oEhHCSibPPfsiaTDicnE8IPiao30DSfuzEWHwTsXQaJGfA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">除此之外，在数据方面，Qwen2继续探索Scaling Law的路线。</div><div class=" pTag">比如数学能力的提升，就是研究团队给模型喂了大规模高质量数学数据的结果。</div><div class=" pTag">在多语言能力方面，研究团队也针对性地在训练数据中增加了27种语言相关的高质量数据。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFo7RANmYwBCoRvLPdIjdyQOl06ELoLxA1HtZf2ED6hkw4TvTzEvge4A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">博客还透露，接下来，通义千问研究团队还将继续探索模型及数据的Scaling Law，还会把Qwen2扩展为多模态模型。</div><h2>重新认识中国开源大模型</h2><div class=" pTag">更强的性能、更开放的态度，Qwen2刚一发布，堪称好评如潮。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFia8IWOORDCV8sZwgHWXCibS7uw3xPXnxyyB3Hek3TkrIWXnGmuxjfDvw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而在此前，生态方面，Qwen系列下载量已突破1600万次。海内外开源社区也已经出现了超过1500款基于Qwen二次开发的模型和应用。</div><div class=" pTag">已经有开发者感受到了：<strong style="font-weight: 600;">在开源路线上，现在中国大模型正在成为引领者</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFL4yIqS30TZ8bkeKybvq8Sjy5ZLWHNdAD5BKCdmPs1LA3YRATcSbNRQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">Qwen2的最新成绩单，至少印证了两个事实。</div><div class=" pTag">其一，中国开源大模型，从性能到生态，都已具备跟美国最强开源大模型Llama 3全面对垒的硬实力。</div><div class=" pTag">其二，如图灵奖得主Yann LeCun所预言，开源大模型已经走在了超越闭源模型的道路上，拐点已现。</div><div class=" pTag">事实上，这也是包括阿里在内，开源大模型玩家的明牌——</div><div class=" pTag">大模型的持续优化和进步，一方面依赖于强大的AI研发能力、领先的基础设施能力，也就是人工智能和云的强强联合。</div><div class=" pTag">以阿里为例，作为中国云厂商份额第一，依托于强大的云计算能力，能为AI训练、AI应用提供稳定高效的AI基础服务体系，同时在人工智能方面有长期的积累。</div><div class=" pTag">另一方面也需要来自外界的不断反馈和技术推动。</div><div class=" pTag">开源社区的技术反哺，从Qwen2上线第一天，GitHub上的Issues数量就可见一斑。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDhA7HpNxicPR7MGNoWDJORFSIflLDmgOTTuTV7ibxKlrdPr5ucL3cyZia0MRRaujUibzByYicdNhslowQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在技术领域，开源就是我为人人、人人为我，是全球科技互联网繁荣发展至今最核心的精神要素。</div><div class=" pTag">不论任何一个时代，不管哪种新兴技术浪潮，没有程序员、工程师不以开源感到骄傲，甚至快乐。</div><div class=" pTag">阿里高级算法专家、开源负责人林俊旸，曾对外分享过通义千问进展飞快的“秘籍”：</div><div class=" pTag"><strong style="font-weight: 600;">快乐。</strong></div><div class=" pTag">因为面向全球开发者服务，面向其他开发者交流，给别人带去实实在在的帮助，这样通义千问大模型的打造者们快乐又兴奋，关注着每一个开发者的反馈，激动于全新意想不到的落地应用。</div><div class=" pTag">这也是科技互联网世界曾经快速发展的核心原因，黄金时代，开源才是约定俗成的，不开源反而要遭受质疑。</div><div class=" pTag">然而时移世易，在大模型时代，由于研发成本、商业模式和竞争多方面的原因，闭源的光芒一度掩盖了开源，Close成了宠儿。</div><div class=" pTag">所以Meta的Llama也好，阿里通义千问的Qwen也好，复兴传统，重新证明科技互联网领域不变的精神和内核。</div><div class=" pTag">这种精神和内核，在通义千问这里，也拥有不言自明的可持续飞轮。</div><div class=" pTag">阿里巴巴董事长蔡崇信已经对外分享了思考，在全球云计算和AI的第一梯队中，有领先的云业务又有自研大模型能力的，仅谷歌和阿里两家。其他有云服务的微软、亚马逊，都是合作接入大模型；其他自研大模型的OpenAI、Meta，没有领先的云服务。</div><div class=" pTag">全球唯二，中国唯一。</div><div class=" pTag">而在开源生态的推动中，技术迭代会更快，云计算的服务延伸会越广，技术模型和商业模式，飞轮闭环，循环迭代，在固有基础设施的基础上垒起新的基础设施，形成稳固持续的竞争力。</div><div class=" pTag">但开源大模型，最大的价值和意义依然回归开发者，只有足够强大的开源大模型，AI for All、AI无处不在才不会成为纸上空谈。</div><div class=" pTag">所以通义千问Qwen2，此时此刻，登顶的是全球开源性能最高峰，引领的是开源对闭源的超越阶段，象征着中国大模型在新AI时代中的竞争力。</div><div class=" pTag">但更值得期待的价值是通过开源大模型，让天下没有难开发的AI应用、让天下没有难落地的AI方案。完整兑现AI价值，让新一轮AI复兴，持续繁荣，真正改变经济和社会。</div><div class=" pTag"><span style="font-size: 17px;">参考链接：</span></div><div class=" pTag"><span style="font-size: 17px;">https://qwenlm.github.io/zh/blog/qwen2/</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FBOYnh-vvpK85Rmq9T9I3lQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 08 Jun 2024 05:40:08 GMT</pubDate>
</item>
</channel>
</rss>