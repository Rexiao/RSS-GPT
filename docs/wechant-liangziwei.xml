<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>微信公众号 - 量子位</title>
<link>https://posts.careerengine.us/author/599d7c52f2145121d1aa4698/posts</link>


<item>
<title>AI学会隐藏思维暗中推理！不依赖人类经验解决复杂任务，更黑箱了</title>
<link>https://posts.careerengine.us/p/6637073ad04e984877b028b2</link>
<guid>https://posts.careerengine.us/p/6637073ad04e984877b028b2</guid>
<content:encoded><![CDATA[
<div> 提取关键词：AI、思维链、填充token、TC0复杂度、可解释性

总结：<br /><br />
该研究发现即使AI用无意义的“……”代替步骤，在复杂任务上也能有显著提升。研究团队使用思维链（CoT）方法来提升大型模型的性能，通过填充token训练AI，在特定任务上表现出更高准确率。实验验证填充token的隐藏层表示包含与下游任务相关的隐性计算。研究指出填充token仅适用于TC0复杂度问题范围，但也提出了AI进行无法监控的暗中计算可能带来的挑战。这项研究既激发人们思考又引发担忧，探讨了AI推理能力的新可能性和局限性。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">梦晨 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">AI做数学题，真正的思考居然是<span><strong style="font-weight: 600;">暗中</strong><strong style="font-weight: 600;">“心算”</strong></span><span style="font-size: 17px; text-align: left;">的</span>？</div><div class=" pTag">纽约大学团队新研究发现，即使<span><strong style="font-weight: 600;">不让</strong><strong style="font-weight: 600;">AI写步骤，全用无意义的“……”代替</strong></span>，在一些复杂任务上的表现也能大幅提升！</div><div class=" pTag">一作Jacab Pfau表示：<span><strong style="font-weight: 600;">只要花费算力生成额外token就能带来优势，具体选择了什么token无关紧要</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdHtsPjBeiaMyqH7pfAEvLMuiaBkKtxd3EmLsKiaS7Y2zyJnd5xib6V4mqNg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">举例来说，让Llama 34M回答一个简单问题：<strong style="font-weight: 600;"><span>自然常数e的前6位数字中，有几个大于5的？</span></strong></div><div class=" pTag">AI直接回答约等于瞎捣乱，只统计前6位数字居然统计出7个来。</div><div class=" pTag">让AI把验证每一数字的步骤写出来，便可以得到正确答案。</div><div class=" pTag"><span style="text-align: center;">让AI把步骤隐藏，替换成大量的“……”，依然能得到正确答案！</span></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdlNEugiaxLQmzHjw2icCTSfyCQYnTvia6SLYdThC8LdVZY2xcK8eYcGUDw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这篇论文一经发布便掀起大量讨论，被评价为<span><strong style="font-weight: 600;">“我见过的最玄学的AI论文”</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdqo9kib6wV3UIw7SibdrzdpNeqklnveDmT5oWLyANSyDpudz525ajn9lw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么，年轻人喜欢说更多的“嗯……”、“like……”等无意义口癖，难道也可以加强推理能力？</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdoWvBA33vvBcYabgFV6ddpBIcLvYNibHPicBQORTAHycQRuzzPy3RX4sw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>从“一步一步”想，到“一点一点”想</h2><div class=" pTag">实际上，纽约大学团队的研究正是从思维链<span>（Chain-of-Thought，CoT）</span>出发的。</div><div class=" pTag">也就是那句著名提示词<span><strong style="font-weight: 600;">“让我们一步一步地想”</strong></span><span>（Let‘s think step by step）</span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxddlMG9aN2cYlvc3jYT1qab7WSfj5qFKBUxjtkNZnme0icyTjQ5Fvy4pA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px; text-align: left;">过去人们发现，使用CoT推理可以显著提升大模型在各种基准测试中的表现。</div><div class=" pTag"><span style="font-size: 17px; text-align: left;">目前尚不清楚的是，这种性能提升到底源于模仿人类把任务分解成更容易解决的步骤，还是额外的计算量带来的副产物。</span></div><div class=" pTag">为了验证这个问题，团队设计了两个特殊任务和对应的合成数据集：3SUM和2SUM-Transform。</div><div class=" pTag"><span><strong style="font-weight: 600;">3SUM</strong></span>要求从一组给定的数字序列中找出三个数，使得这三个数的和满足特定条件，比如除以10余0。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxd58iaDH3Q2ibMvoAibNwnIFxUOrGCukMYd3QUMQyDVuCvE7iaF9roXoIibrw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这个任务的计算复杂度是O(n<sup>3</sup>)，而标准的Transformer在上一层的输入和下一层的激活之间只能产生二次依赖关系。</div><div class=" pTag">也就是说，当n足够大序列足够长时，<span><strong style="font-weight: 600;">3SUM任务超出了Transformer的表达能力</strong></span>。</div><div class=" pTag">在训练数据集中，把与人类推理步骤相同长度的“...”填充到问题和答案之间，也就是AI在训练中没有见过人类是怎么拆解问题的。<span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxd8I5YiclicbRPs4icQ3rUamZDsoF3ibVibCP80ldXhqdl7FWFV8q0iaul55tw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在实验中，不输出填充token“…...”的Llama 34M表现随着序列长度增加而下降，而<span><strong style="font-weight: 600;">输出填充token时一直到长度14还能保证100%准确率</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdgfIf0aNCODPXaicQiaXKdEib94VAUrhYh9vfHOoS68E2Mf8MlKyDoZibfQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span><strong style="font-weight: 600;">2SUM-Transform</strong></span>仅需判断两个数字之和是否满足要求，这在 Transformer 的表达能力范围内。</div><div class=" pTag">但问题的最后增加了一步“对输入序列的每个数字进行随机置换”，以防止模型在输入token上直接计算。</div><div class=" pTag">结果表明，<span><strong style="font-weight: 600;">使用填充token可以将准确率从 78.7%提高到93.6%</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdOflqJiccgAmKibxQCCKfibVUEibVpG1B3ORNghdRqpGRBT6xibYBmK1kgow/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">除了最终准确率，作者还研究了填充token的隐藏层表示。实验表明，冻结前面层的参数，只微调最后一个Attention层，<span><strong style="font-weight: 600;">随着可用的填充token数量增多，预测的准确率递增</strong></span>。</div><div class=" pTag">这<span><strong style="font-weight: 600;">证实了填充token的隐藏层表示确实包含了与下游任务相关的隐性计算</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdoFTRNNTTAGKN2dLlVrS7zqEtgZy5D6a9t8OKDtW2n6mD9kRBibv7C3Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>AI学会隐藏想法了？</h2><div class=" pTag">有网友怀疑，这篇论文难道在说“思维链”方法其实是假的吗？研究这么久的提示词工程，都白玩了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdsX5Wy31ZGDyBtTuLSkicaxJaibPTdfX9ibj2d2pAkWhaWQgTiaHcJfjjibw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">团队表示，从理论上讲<span><strong style="font-weight: 600;">填充token的作用仅限于TC<sup>0</sup>复杂度的问题范围内</strong></span>。</div><div class=" pTag">TC<sup>0</sup>也就是可以通过一个固定深度的电路解决的计算问题，其中电路的每一层都可以并行处理，可以通过少数几层逻辑门（如AND、OR和NOT门）快速解决，也是Transformer在单此前向传播中能处理的计算复杂度上限。</div><div class=" pTag">而<span><strong style="font-weight: 600;">足够长的思维链，能将Transformer的表达能力扩展到TC<sup>0</sup>之外</strong></span>。</div><div class=" pTag">而且让大模型学习利用填充token并不容易，需要提供特定的密集监督才能收敛。</div><div class=" pTag">也就是说，<span><strong style="font-weight: 600;">现有的大模型不太可能直接从填充token方法中获益</strong></span>。</div><div class=" pTag">但这并不是当前架构的内在局限性，如果在训练数据中提供足够的示范，它们应该也能从填充符号中获得类似的好处。</div><div class=" pTag">这项研究还引发了一个令人担心的问题：大模型有能力进行无法监控的暗中计算，对AI的可解释性和可控性提出了新的挑战。</div><div class=" pTag">换句话说，<span><strong style="font-weight: 600;">AI可以不依赖人类经验，以人们看不见的形式自行推理</strong></span>。</div><div class=" pTag">这既刺激又可怕。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdmZkibONxqIb9xQMLoUicRGVgDt26ZPAb66PFUFPkbib2iceqV6N3UQcgbQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">最后有网友开玩笑提议，让Llama 3首先生成1千万亿点点点，就能得到AGI的权重了（狗头）。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxd4aYG3qicLL9iamWATByTv3fPGdfWJ6YjjcQgVBPicFKuT9NHcMwibl2Vsw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">论文：</div><br /></span><span style="font-size: 17px;">https://arxiv.org/abs/2404.15758</span></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://x.com/jacob_pfau/status/1783951795238441449</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://x.com/johnjnay/status/1784261779163349110</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F--BxRKzWbGe-W3XODJtSMg">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 05 May 2024 04:12:42 GMT</pubDate>
</item>
<item>
<title>商汤杨帆：尺度定律主导AI迭代，降低门槛才能迎来AIGC应用爆发 | 中国AIGC产业峰会</title>
<link>https://posts.careerengine.us/p/6637072acc7fde48103fe392</link>
<guid>https://posts.careerengine.us/p/6637072acc7fde48103fe392</guid>
<content:encoded><![CDATA[
<div> 关键词: AIGC产业峰会, AI基础设施, 尺度定律, 大模型应用, 商汤科技

总结:
- AIGC产业峰会讨论了中国AI应用市场潜力和基础设施的重要性。
- 尺度定律仍主导着AI技术的迭代，但大模型应用投入产出比问题仍需解决。
- 商汤认为AI基础设施是破解难题的关键。
- 降低门槛和成本是推动AI应用爆发的关键，商汤致力于提供解决方案。
- AI应用的决胜点在于提供更好的解决方案、把握用户需求以及优化性价比。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">编辑部 整理自 AIGC峰会</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">“中国有世界上最好最优秀的B端和C端市场，把做AI应用的门槛和成本降下来，就会激发出更大的产业应用空间。”</div><div class=" pTag">这是面对AIGC产业应用现状，商汤科技联合创始人、大装置事业群总裁杨帆的最新判断。</div><div class=" pTag">当前，Scaling Laws<span>（尺度定律）</span>仍在主导着AI的技术迭代，与此同时，也带来了大模型应用投入产出比不够好的问题。</div><div class=" pTag">而商汤的观察是，AI基础设施，正是破解这一难题的关键。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4bZ2hItQjc41XgMhqCicsMxChFCeVffdZVHibdXeLoCR5ic0zHhUiarUBibA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">以上分享来自杨帆在中国AIGC产业峰会的现场演讲。为了完整体现杨帆的思考，在不改变原意的基础上，量子位对演讲内容进行了编辑整理，希望能给你带来更多启发。</div><div class=" pTag"><span>中国AIGC产业峰会是由量子位主办的行业峰会，20位产业代表与会讨论。线下参会观众近千人，线上直播观众300万，获得了主流媒体的广泛关注与报道。</span></div><h2>话题要点</h2><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">中国AI应用市场潜力巨大，预计今年下半年或明年上半年将迎来爆发式增长。</div></li><li><div class=" pTag">AI基础设施的意义在于提供算力、算法、数据三要素的一体化平台，降低产业创新门槛，激活AI生态。</div></li><li><div class=" pTag">未来中国AIGC应用的大规模爆发，很大程度上取决于基础设施提供方能否有效降低下游门槛和成本。</div></li><li><div class=" pTag">AI应用的决胜点在于针对细分场景提供更好的解决方案、把握用户需求以及优化性价比。</div></li><li><div class=" pTag">打造开放生态的基础设施和服务体系，降低AI应用开发门槛，激活更多参与者，是推动AI应用生态长期健康发展的关键。</div></li></ul><div class=" pTag"><span>以下为杨帆演讲全文。</span></div><h2>尺度定律仍在主导AI技术的迭代</h2><div class=" pTag">大家上午好，很荣幸今天在这里跟大家分享一下我们最近的工作和进展。</div><div class=" pTag">最近两年，人工智能伴随着生成式AI掀起了新的热潮，国内外对它的关注度都非常高。</div><div class=" pTag">过去一年跟很多业界的朋友聊，为什么国内市场增速没有那么快？其实背后的原因很简单，<strong style="font-weight: 600;">我们今天的能力还是有差距的</strong>。包括一些头部企业的机器模型能力，也是最近才逐渐接近GPT-4的水平。</div><div class=" pTag">但我们也有一个判断，<strong style="font-weight: 600;">自去年底以来，中国AI应用的普及程度正在不断提高</strong>，越来越多的新场景正在被发掘。我们预计，<strong style="font-weight: 600;">在今年下半年甚至明年上半年，中国的生成式AI市场将迎来爆发式增长</strong>。</div><div class=" pTag">之前跟很多朋友介绍过，2019年商汤在上海临港投建了一个计算中心。我们当时做这件事情的时候，大部分人持不理解甚至否定的态度：商汤作为算法和软件的轻资产研发企业，为什么投这么多资产做这样一个项目？</div><div class=" pTag">回过头来看，整个人工智能技术的发展方向和发展方式印证了当时的思考和判断。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4K9iauvPBWslZPS1mghsTpxQZ8iawwUzDuGOkSEkPK7X9ZEKZb0oOMgJg/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>商汤上海临港AIDC</h6><div class=" pTag">尽管有些业内人士认为人工智能需要更好的迭代方式，但今天的AI实在是太消耗能源了，从单位能源智能的角度来看，其性能仍然较弱。</div><div class=" pTag">至少到目前，我们看到，一方面，尺度定律还没有失效，只要把更多更好的数据灌进算法里，就能够形成更强大更通用的智能。这是目前整个行业内可以明确看到的清晰可行的路径，<strong style="font-weight: 600;">尺度定律仍在主导AI技术的迭代</strong>。</div><div class=" pTag">另一方面，我们也会注意到AI核心的关键性产业问题尚未得到解决，就是<strong style="font-weight: 600;">产业端的投入产出比不够理想</strong>。</div><div class=" pTag">今天，大模型研发的投资成本非常高，怎么让这些研发投入在市场端产生最大的回报和价值，是摆在大家面前共同的课题。</div><div class=" pTag">在当前AI生产甚至应用成本越来越高的背景下，降低门槛和降低成本就是必然的趋势，这也是AI基础设施出现的意义：</div><div class=" pTag">一方面，AI基础设施很好地契合了当前以尺度定律为主导的算法创新路径，为更大规模的AI三要素提供了基础化能力。</div><div class=" pTag">另一方面，只有把这些通用能力，不管是大规模算力集群还是模型API，甚至未来围绕超大规模数据的完整体系，把它做标准化、基础设施化、服务化，才有可能在未来让整个AI产业创新门槛更低、性价比更高，让更多人进来，在上面赚到钱。</div><div class=" pTag"><strong style="font-weight: 600;">我们始终觉得人工智能的基础设施，不仅仅是算力中心，而是三要素一体的基础设施化，这是激活人工智能产业生态的关键。</strong></div><div class=" pTag">这里也向大家汇报一下商汤临港智算中心的最新进展。截至去年底，包括临港在内，我们已建成7-8个互联互通的算力节点，还有多个新节点在建设中。</div><div class=" pTag">这些节点的总算力超过12000P，其中临港单点算力接近10000P。这样的超大规模、智能化的先进AI算力，在当前仍是核心稀缺资源和关键能力。</div><div class=" pTag">另外我们看到未来芯片产业链将出现分化趋势。从2001年起，我们在芯片层面做了大量工作，与业内很多合作伙伴展开对接和适配。目前临港中超过15%的算力来自国产芯片，我们相信在未来产业发展过程中，这将创造更多价值。</div><h2>AIGC应用爆发前提：降低门槛</h2><div class=" pTag">除了基础的资源能力外，更重要的是如何帮助企业降低使用门槛，降低使用成本。这不仅仅是提供低成本机器和用低成本的电去提供租赁服务，尽管这也非常重要且必要。</div><div class=" pTag">在此基础上，我们希望通过对AI的理解、在AI软件方面的沉淀，以及不同层级的软件产品和服务体系，帮助大家更低门槛、高效率、低成本地进行人工智能大模型的研发和使用。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4YC9icebLrt87YFKljgxzpRd13OiaXpICqkQH2d355hFodQKTeoQaCibxg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这件事我们做了很多年。去年底，沙利文在《中国AI开发平台市场报告》中，将商汤在这个领域的能力定义为全国领先。当然，我们看到业内今天仍在持续地发生快速的迭代和演变，我们希望在新时代浪潮之下，商汤紧跟节奏，持续地往前进步和迭代。</div><div class=" pTag">今天很多人做大模型应用的开发时，首先面临的问题是：在构建自己的模型，或基于开源模型迭代场景化模型时，如何快速地将模型部署为可用的推理服务，并在其后附加应用服务，同时降低推理服务的成本。</div><div class=" pTag">大家都知道今天市场上有非常多的模型应用，特别是去年，向终端用户收费还没有所付的资源费高，调用越多越赔钱，调用成本非常之高。</div><div class=" pTag">为了解决这一问题，我们提供了全套的解决方案，包括多层次的架构、工业化的调用。我们通过混合模型的调用方式，包括训练与推理的混合，降低了用户使用模型的成本。这是一个最简单的方法，也是目前业内大家都在尝试的：在为客户提供模型应用时，背后挂载的并非单一模型，而是多个模型。根据语言对话应用、用户问题的不同以及提示词设置的不同，模型引擎会在后面选择调用超大模型、中等模型或小模型，从而在优化用户侧服务体验的同时，极大地降低后台资源开销。</div><div class=" pTag">这种方式无疑会增加系统的复杂度。为了降低使用门槛并减少中间成本，我们采用了将所有这一切以标准化管线形式提供给模型和应用开发人员的策略。此外，我们还进行了大量的推理优化，包括单位算子和硬件匹配的优化，以使同样的计算任务获得更好的性能优势。</div><div class=" pTag">在我看来，<strong style="font-weight: 600;">未来中国AIGC应用大规模爆发的关键因素之一，是如何降低基础设施使用者的下游门槛和成本。</strong></div><div class=" pTag">我们看到中国模型开发还是需要更加强大的生态，这方面落后蛮多的。从商汤的角度来说，我们推出了自己的生态计划，包括提供算力资源、开发者社区建设，以及基础的模型能力。我们相信这样的能力能够帮助业内更好地提升最终在终端的场景价值。</div><div class=" pTag"><strong style="font-weight: 600;">中国有世界上最好最优秀的B端和C端市场，当我们把做AI应用的门槛和成本降下来，就会激发出更大的产业应用空间。</strong></div><div class=" pTag">除了提供基础设施，商汤自己也在开发大模型，拥有一套完整的日日新大模型体系。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4u0JmibN8P6fibXzWZDAkkKhAm8oqIPUibuptgLJHqCFDut60kChfPnIPw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">商汤过去做计算机视觉业务比较多，更擅长相关算法，所以在语言类任务之外，现在更多关注于3D图像、视频、三维重建等领域，希望在其中贡献更多行业模型。在过去几个月，我们已经可以拿AI模型实现三维场景的制作。</div><div class=" pTag">大模型下一步发展的关键性挑战是世界知识。除了在电子设备里学习人类历史上的知识，大模型如何更好地感知现实世界、形成更深入的理解并提供有效反馈，也是今年大家重点关注的领域和方向。第一步还是对于现实世界信息的收集、理解以及重建。这方面我们做了很多探索，把这样的能力应用到传统线下文化、旅游、社交场景，能够提供很多价值。</div><div class=" pTag">我们可以看到，AI大模型能够推动的场景还是非常多的。从商汤的角度来讲，还是希望以自身的基础设施和平台化能力，支撑更加繁荣的场景生态。</div><div class=" pTag">我们通过过去十年AI产业探索获得的关键认知是：人工智能的未来发展和应用成功的决胜点，并不仅仅在于技术本身。当越来越多的企业和平台提供开源或闭源的模型服务时，AI应用的关键在于谁能在细分场景中提供更好的解决方案，谁能更准确地把握用户需求，谁能打造出更高的性价比。</div><div class=" pTag">从这个角度来看，我们这一代人的核心使命，或许就是要打造一个能够为开放生态赋能的基础设施和服务体系，以此降低AI应用开发的门槛，吸引更多创业者参与进来。</div><div class=" pTag">每个人在不同行业、不同场景、不同领域都有自己的专长和优势。他们中的许多人可能并不精通AI核心技术，也没有雄厚的资源投入到AI基础能力的研发中，但只有激活这些参与者，AI应用生态才能形成长期、持续、健康的发展。这也是商汤希望与在座同仁以及量子位这样的平台共同推动的目标。</div><div class=" pTag">以上就是我今天的分享，谢谢！</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FKEPT6zNTnnT02GmO7ozt4w">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 05 May 2024 04:12:26 GMT</pubDate>
</item>
<item>
<title>AI人才争夺战，华尔街入局：豪掷百万美元年薪抢人</title>
<link>https://posts.careerengine.us/p/66370729cc7fde48103fe38a</link>
<guid>https://posts.careerengine.us/p/66370729cc7fde48103fe38a</guid>
<content:encoded><![CDATA[
<div> AI人才争夺战, 金融公司, 科技公司, 大规模裁员, 高薪招聘  

总结:<br /><br />华尔街和硅谷都在进行激烈的AI人才争夺战，金融公司看中高精尖的AI专家，科技公司大规模裁员导致市场供应过剩，使得招聘变得更加困难。金融公司为了破解市场密码，愈发迫切地需要AI人才。在这场人才争夺战中，包括硅谷和华尔街在内的大公司都在采取豪华招聘措施，提供高薪聘请顶尖人才，甚至涉及到CEO亲自招聘的情况。AI初创公司也扮演重要角色，提供丰厚薪资和股权激励，使得AI人才成为当下最热门的人才。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">金磊 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag" style="font-size: 17px;">继硅谷之后，<strong style="font-weight: 600;">华尔街</strong>也入局<strong style="font-weight: 600;">“AI人才争夺大战”</strong>。</div><div class=" pTag" style="font-size: 17px;">他们的目标非常明确——抢的就是高精尖的AI专家。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz1lf7hM5fE3JMDOQ6WKORACW1ib1WTGEnVIx6LSoQGEJA4gvSdGx1GjQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>图源：Business Insider</h6><div class=" pTag" style="font-size: 17px;">现在这条“街”上，不论是银行、对冲基金还是私募股权公司都已纷纷下场，可谓是豪掷千金，大抢特抢。</div><div class=" pTag" style="font-size: 17px;">能有多豪？</div><div class=" pTag" style="font-size: 17px;">奉上一组<strong style="font-weight: 600;">“最热Top 5岗位”</strong>薪酬数据：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">AI/机器学习工程师</strong>：最高年薪30万美元<span>（约217万元）</span></div></li><li><div class=" pTag"><strong style="font-weight: 600;">云安全leader</strong>：最高年薪30万美元<span>（约217万元）</span></div></li><li><div class=" pTag"><strong style="font-weight: 600;">AI产品经理/工程经理</strong>：最高年薪65万美元<span>（约470万元）</span></div></li><li><div class=" pTag"><strong style="font-weight: 600;">技术和运营leader</strong>：最高年薪七位数<span>（单位：美元；未公布具体数值）</span></div></li><li><div class=" pTag"><strong style="font-weight: 600;">AI运营高管</strong>：最高年薪200万美元<span>（约1448万元）</span></div></li></ul><div class=" pTag sectionReplaced" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzhC8SoV98gePmRoM75nNLddC1MG53BmlFicZEUHJxZA1uqe3zXUt12yg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">而且在挖人过程中，华尔街的金融公司们也直言不讳地表达了他们这么做的目的：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">用AI技术，要么实现降本增效，要么在市场多分一杯羹。</div></blockquote><div class=" pTag" style="font-size: 17px;">之所以如此，正是因为金融公司们在目睹了像OpenAI、谷歌、微软、Meta、英伟达等科技巨头引爆的<strong style="font-weight: 600;">AI fever</strong>之后，认为AI是破解市场密码的关键所在。</div><div class=" pTag" style="font-size: 17px;">甚至有对冲基金公司更是直接开始<strong style="font-weight: 600;">“点名”</strong>：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag"><strong style="font-weight: 600;">我们特别想要英伟达的技术专家</strong>，用他们的经验帮助我们在内部打造专属的AI大语言模型，用于交易、研究和风险管理等。</div></blockquote><div class=" pTag sectionReplaced" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzaxF86AlaMdic5foLiarYicTnsdCqEAiaO0b72JCBC7oxBia3HLTQenXOg7g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">而在“盛产”AI人才的科技界这边，从去年至今似乎一直在上演着裁员大戏。</div><div class=" pTag" style="font-size: 17px;">谷歌、微软、Meta、亚马逊、IBM、特斯拉等等，频频曝出大裁员消息，动辄便上万人的那种；根据Layoffs.fyi的统计，仅是2023年，全球科技行业裁员总数为<span><strong style="font-weight: 600;">224503</strong></span>人。</div><div class=" pTag" style="font-size: 17px;">或许很多人会认为，这不就正好给华尔街招募AI人才提供了“天时”吗？</div><div class=" pTag" style="font-size: 17px;">但事实却并非完全如此。</div><h2>“庸才，供应过剩”</h2><div class=" pTag" style="font-size: 17px;">一方面，科技公司的大规模裁员<span>（尤其是硅谷）</span>确实向市场反流了大批的劳动力。</div><div class=" pTag" style="font-size: 17px;">根据Business Insider从数位猎头公司相关人员得知的真实情况是：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">与过去几年相比，每个空缺职位的申请人数都增加了一倍。</div><div class=" pTag">以前金融圈想从硅谷吸引技术人才很难，现在变得容易多了。</div></blockquote><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzXnDqQOvicPdrNbCSYRDSu5zYIq7aR33NVpOMQdWJoDUzEfb2oBMkTog/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>图源：由DALL·E 3生成</h6><div class=" pTag" style="font-size: 17px;">从业务角度来看，除了我们刚才提到的对冲基金公司，像银行、投资公司等企业对于大语言模型的需求也是逐渐增多。</div><div class=" pTag" style="font-size: 17px;">也正因如此，越来越多的金融公司会将AI工程人才安插到前台和投资组合经理团队，以便开发定制的软件。</div><div class=" pTag" style="font-size: 17px;">这些软件夸张地来说就是“今天开发，明天使用”，可以快速“上岗”投资组合经理、交易员或研究员的日常工作。</div><div class=" pTag" style="font-size: 17px;">总而言之，金融公司非常渴望在科技公司的成功基础上再接再厉。</div><div class=" pTag" style="font-size: 17px;">但另一方面，大量AI技术人员涌入市场，反倒给金融公司的招聘工作添加了一定难度。</div><div class=" pTag" style="font-size: 17px;">用招聘相关人员真实的反馈来说就是：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag"><strong style="font-weight: 600;">科技行业的大规模裁员造成了平庸人才的供应过剩。</strong></div></blockquote><div class=" pTag" style="font-size: 17px;">首先从投简历的数量上来看，每个空缺岗位申请人的数量翻倍，这也定然造成了HR在筛选、审核简历工作上的难度。</div><div class=" pTag" style="font-size: 17px;">加之随着AI技术本身的发展，也有不少求职者利用它开始在简历上做手脚，例如造假、群发等。</div><div class=" pTag" style="font-size: 17px;">诸如此类的消息和新闻也是层出不穷，此前就有人亲述了自己用AI投120份简历的经历：</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzdYEicTv5BLIVHB4MeOU15spK1D8KLsblJTtiasicNETzbvIicml8UnEeqw/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>图源：Business Insider</h6><div class=" pTag" style="font-size: 17px;">其次在筛选候选人的过程中，HR们的工作也因为科技公司大裁员而发生了相应的变化。</div><div class=" pTag" style="font-size: 17px;">以金融公司招聘网络安全人才为例，现在就变得越发审慎，在评估能开多少薪水的时候也会变得更加谨慎。</div><div class=" pTag" style="font-size: 17px;">而且<strong style="font-weight: 600;">“职业角色合并”</strong>也成了现在金融公司AI人才岗位的一大趋势。</div><div class=" pTag" style="font-size: 17px;">在过去，金融公司可能会针对不同技术或业务招聘安全技术人员，但现在他们更倾向于招聘更全能的AI人才。</div><div class=" pTag" style="font-size: 17px;">一位华尔街HR的真实反馈是：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我们不会招聘15个专门负责应用安全和云安全的工程师，而是需要4个职责更广泛的安全技术人员。</div></blockquote><div class=" pTag" style="font-size: 17px;">他表示，随着人才趋势向更集中和统一的结构转变，求职者需要清楚地说明他们所具备的能力范围：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">这意味着候选人在申请网络安全职位时，需要展示他们在以往工作中所承担的更广泛的责任范围，以及他们如何跨部门协作和影响业务。</div></blockquote><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzB98vCaBiarzSGdibBfdV06vibLmwTHM9vAJNoLD8c6VrDDFK91swIyCWw/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>图源：由DALL·E 3生成</h6><div class=" pTag" style="font-size: 17px;">由此可见，即便看似金融圈是在科技公司大裁员的背景下“大浪淘沙”，但他们真正要抢的还是那批高精尖的AI人才。</div><div class=" pTag" style="font-size: 17px;">也就不难理解HR们发出“平庸人才供过于求”的感慨了。</div><div class=" pTag" style="font-size: 17px;">也正因如此，即使科技巨头们在大裁员，不论是华尔街还是硅谷，AI专家依旧是这场“人才争夺战”中的核心。</div><h2>硅谷也在疯狂抢人</h2><div class=" pTag" style="font-size: 17px;">其实在华尔街之前，硅谷一边裁着员，另一边也早已上演<strong style="font-weight: 600;">“豪华阵容出演”</strong>的抢人大戏。</div><div class=" pTag" style="font-size: 17px;">豪华到什么程度？就连<strong style="font-weight: 600;">马斯克</strong>都发出感慨：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag"><strong style="font-weight: 600;">AI的人才争夺战是我见过最疯狂的！</strong></div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzTJ6jOP6RFiaNbHGehusd09usUVvqcUudn6C8PuSUAbu9T9icKclW23Cg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">事因是特斯拉视觉科学家Ethan Knight离职，加入到了马斯克的xAI公司。</div><div class=" pTag" style="font-size: 17px;">然而马斯克却爆料期间的曲折内幕：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">他本来是要去OpenAI的。</div><div class=" pTag">OpenAI一直在积极招募特斯拉的工程师，并提供巨额薪酬，不幸的是，在少数情况下取得了成功。</div></blockquote><div class=" pTag" style="font-size: 17px;">而这位让马斯克亲述详情的Ethan Knight，还不是网友口中的“特斯拉视觉主管”，是团队中的一位科学家。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz47rvZ6vCrmjgdzmiboQLnMogg5kDjvcDicUw7YfVd0F4zX33yPs4bShg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">OpenAI这边，挖人也是有够疯狂，甚至<strong style="font-weight: 600;">奥特曼</strong>本人也亲自下场<strong style="font-weight: 600;">打电话</strong>招员工，主打一个诚邀您来。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzGWKgH7ZDarIxu4ZlBGp1lHa3Mic3pKJZm2kEw5c6rtmtGibedDz6c58Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">打电话招聘的老板可不止奥特曼，还有谷歌创始人之一的<strong style="font-weight: 600;">谢尔盖·布林</strong>。</div><div class=" pTag" style="font-size: 17px;">此前他就被曝出为了挽留即将离职转投OpenAI的员工，也是亲自出马打起了电话，又是谈加薪又是给福利，只要能留下，条件均可谈。</div><div class=" pTag" style="font-size: 17px;">除了打电话，还有CEO用个人邮箱写邮件抛出橄榄枝的——Meta老板<strong style="font-weight: 600;">扎克伯格</strong>。</div><div class=" pTag" style="font-size: 17px;">他亲手写信给DeepMind的研究员，诚邀他们跳槽加盟Meta。</div><div class=" pTag" style="font-size: 17px;">而且Meta这边为了狂揽AI人才也是下足了功夫，例如提供免面试入职的机会。不仅如此，就连一些“潜规则”也开始被打破。</div><div class=" pTag" style="font-size: 17px;">比如，以前Meta不会用升职加薪来留住想要跳槽的员工，但现在，情况变了。</div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzJD302lPS4d3Qk1D9Ex1v4htnqia3mYGYMOPOVV3epn0c6ws0bB1HzkQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">科技巨头老板们除了亲自下场之外，薪酬方面也是出手阔绰。</div><div class=" pTag" style="font-size: 17px;">有加入OpenAI的员工表示，比起上份工作他的年薪加了10万美元<span>（约72万人民币）</span>，还有望在几年内拿到股权。</div><div class=" pTag" style="font-size: 17px;">Levels的数据还显示，OpenAI向一些高级工程师支付的薪酬，能达到140万美元<span>（约1013万人民币）</span>。</div><div class=" pTag" style="font-size: 17px;">而OpenAI的总薪资中位数已经达到了92.5万美元<span>（669万人民币）</span>。</div><div class=" pTag" style="font-size: 17px;">当然，AI初创公司也是这场“人才争夺战”中不可忽视的“战力”。</div><div class=" pTag" style="font-size: 17px;">比如Anthropic，一位提示工程师透露出他的年薪水平是25万-35万美元区间。</div><div class=" pTag" style="font-size: 17px;">用Tribe AI老板Jaclyn Rice Nelson来说就是：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">科技公司会给从事人工智能相关工作的人提供绩效奖金和大量的股权薪酬。</div><div class=" pTag">经常看到轻轻松松超过100万美元<span>（约720万人民币）</span>的薪酬方案。</div></blockquote><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzVe4csK5XrjHU6zHRnlUoF7zaVAnFUJ8weTVeXqpDA6Su2CtJUFyRQQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">嗯，身处AI时代，最大的<span><strong style="font-weight: 600;">“淘金热”仍然是人才</strong></span>。</div><div class=" pTag" style="font-size: 17px;"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://www.businessinsider.com/ai-specialists-hiring-big-tech-wall-street-high-paying-jobs-2024-4</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://www.businessinsider.com/top-recruiters-hiring-staffing-tech-job-wall-street-headhunters-2024-4#deepali-vyas-korn-ferry-1</span><br /><span style="font-size: 17px;">[3]</span><span style="font-size: 17px;">https://www.businessinsider.com/hottest-wall-street-tech-jobs-and-pay-according-recruiters-2024-4</span><br /><span style="font-size: 17px;">[4]</span><span style="font-size: 17px;">https://twitter.com/elonmusk/status/1775644544853221599</span><br /><span style="font-size: 17px;">[5]</span><span style="font-size: 17px;">https://www.businessinsider.com/ai-talent-wars-big-tech-ceos-recruiting-paying-huge-packages-2024-4</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FFKrW9Tf8LZbjc1vd-BddBw">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 05 May 2024 04:12:25 GMT</pubDate>
</item>
<item>
<title>阿里林俊旸：大模型对很多人来说不够用，打造多模态Agent是关键 | 中国AIGC产业峰会</title>
<link>https://posts.careerengine.us/p/6635a2e6d71afb403454fa0d</link>
<guid>https://posts.careerengine.us/p/6635a2e6d71afb403454fa0d</guid>
<content:encoded><![CDATA[
<div> 关键词: 通义千问, 大模型, 开源模型, 多模态模型, 生态融入<br />
<br />总结: 
林俊旸在AIGC产业峰会上分享了通义千问团队过去一年的工作成果。团队持续开源多种规模和模态的模型，取得了不俗的表现。除了不断提高模型性能，团队还致力于让大模型更好地融入生态，为用户提供更便捷的使用体验。重点关注了多语言、长序列和Agent能力。大模型发展趋势指向多模态，通义千问的VL系列模型是个例子。未来的发展方向是实现具备多模态理解能力的大预训练模型。整体来看，通义千问团队在开源大模型领域展现出了技术实力和创新精神。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">编辑部 整理自 AIGC峰会</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">在过去一年中，通义千问系列模型持续开源。</div><div class=" pTag">不仅频繁放出多种版本，涉及不同的规模和模态，成绩在大模型竞技场中也名列前茅。</div><div class=" pTag">比如目前最大的72B模型，表现就胜过了Llama 2-70B和MoE开源模型Mixtral。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHynVrAjAkd7YNeUUpod4lC4z7XZwHJIaic9X9BiayNvl7r83chbZF91ujQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而纵观整个大模型行业，开源开放也正促进着AIGC新应用的涌现。</div><div class=" pTag">过去一年，通义千问团队都做了什么，又有哪些经验值得开源模型开发者参考？</div><div class=" pTag">中国AIGC产业峰会上，<strong style="font-weight: 600;">阿里高级算法专家林俊旸</strong>给出了他的答案。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHydWDwia9eTAuOgVhqOLfbYPLAeibjLJY6Ys2dbYqOkdDFPq1sxjSQJoxQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">林俊旸参与了通义千问大模型的研发、开源、与外部系统融合等探索工作，还曾参与超大规模预训练模型系列M6、通用统一多模态预训练模型OFA等大模型的打造。</div><div class=" pTag">为了完整体现林俊旸的思考，在不改变原意的基础上，量子位对演讲内容进行了编辑整理，希望能给你带来更多启发。</div><div class=" pTag"><span>中国AIGC产业峰会是由量子位主办的行业峰会，20位产业代表与会讨论。线下参会观众近千人，线上直播观众300万，获得了主流媒体的广泛关注与报道。</span></div><h2>演讲要点</h2><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">开源大模型要更深地融入整个生态，才能给用户带来便捷的使用体验。</div></li><li><div class=" pTag">除了基础模型Benchmark之外，多语言、长序列和Agent能力，也是衡量大模型表现的关键指标。</div></li><li><div class=" pTag">大语言模型发展下去，终将变成多模态模型，因为一个非常智能的模型，不仅要有语言能力，还应该融入对视觉语音方面的理解。</div></li></ul><div class=" pTag"><span>以下为林俊旸演讲全文：</span></div><h2>融入生态，让大模型使用更加便捷</h2><div class=" pTag">相信国内朋友都听说过通义千问的开源模型，我们从去年8月份开始一直开源，到现在我们开源的系列模型已经非常多了，刚开始先从7B、14B开始开源，直到现在1.5系列的72B版本，用户使用下来的感觉还不错。</div><div class=" pTag">当然，我们的1.5系列模型，涵盖的规模非常全，除了72B还有0.5B、1.8B这样的小规模版本，最新还有一个小的MoE的模型，大概是14B的参数量，激活参数量大概是2.7B。</div><div class=" pTag">我们的模型现在在LMSYS chatbot Arena，也就是人工评测上面取得比较不错的成绩，在刚开始登榜的时候，我们是开源的第一名，刚刚才被千亿参数的Command-R-Plus给超越。</div><div class=" pTag">如果只在相同规模中比较，那么截止到现在<span>（4月17日）</span>，我们的72B模型还是最好的。</div><div class=" pTag">除此之外，我们也听从了开发者的建议，发布了32B模型，因为开发者反馈说72B模型太大，14B又好像还不够用。</div><div class=" pTag">最新推出的这个32B模型也取得了比较不错的成绩，跻身到了前15的行列，表现非常接近72B的模型，跟MoE架构的Mixtral相比也具有一定优势。</div><div class=" pTag">而除了不断提高模型的表现，最近几个月我们还做了一些不太一样的事情，就是让千问系列模型更好地去融入大模型生态，让用户使用起来更加便捷。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyTBH8eW5n534zzic7WdrCVqu5qeNg7H8RzF5oEAVLllykTL445jribhlA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">具体的举措有这样几点，第一是千问的代码已经融入了Hugging Face的官方代码当中，大家使用通义千问1.5的模型时就不需要再用Transformer code来调用了。</div><div class=" pTag">除此之外，我们很多三方框架都做了比较好的支持，包括LLama.cpp、vLLM，现在还有像Ollama也非常方便，都可以一键使用我们的模型。</div><div class=" pTag">如果你用LM Studio，也可以从中使用我们的GGUF的模型。如果想对我们模型进行微调的话，其实可以用到比如说Axolotl以及国内的LlaMA-Factory等工具。</div><h2>多语言和长文本能力是关键指标</h2><div class=" pTag">接下来我会给大家详细介绍一下我们模型的构成以及模型当前表现水平。</div><div class=" pTag">首先要看Base Language Model是一个什么样的水平，因为只有基础语言模型的表现好了，才能实现对齐，去进一步做一个比较好的模型。</div><div class=" pTag">我们各个Size都做了对比，其中72B的模型在各个Benchmark上的表现都比较有竞争力。</div><div class=" pTag">当然，我们现在开源模型跟GPT-4还会有差距，但是相比于此前的Llama2-70B以及Mixtral，都有比较明显的优势。</div><div class=" pTag">很长一段时间，如果大家关注Hugging Face Open LLM Leaderboard，会发现其实有很多模型是基于我们的72B模型微调出来的，因为海外朋友很多非常喜欢微调这个模型，然后登到这个榜上去。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyJu8jSpkfBNTwN2xKqkhx17GPfzgViajIEoib6Fia5Sngn8ibhxjfTheseg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同时我们不仅仅有7B及以上的大模型，也有小一些的模型，又叫做Small Language Model这一块，我们最小的模型参数量是0.5B，也就是5亿。</div><div class=" pTag">我们还有像1.8B、4B这些规模的模型，跟Phi-2、Gemma-2B等模型相比的话，我们的模型都非常有竞争力。</div><div class=" pTag">另外一个方面是多语言的能力，我们此前的模型在Qwen1的时候，没有对多语言进行检测，但本质上是多语言的模型。</div><div class=" pTag">大家可能会有一些想法，比如说阿里训出来的模型就是中文的模型，或者是中英双语的模型，其实不是这样，我们最近对多语言能力做一些检测，发现它的表现还不错，所以我们进一步在这个基础上做了多语言方面的对齐。</div><div class=" pTag">在12个比较大的语言上面去跟GPT-3.5相比，我们的模型表现都比较有竞争力。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyrsj6vkF820UKKo0cyTGiciarMAXM1Ct8JURzKicQaAqKcTxGosA9ngJeQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">如果大家关注社交媒体，会看到有很多朋友在使用我们的多语言的能力。</div><div class=" pTag">从目前收到的一些反馈来看，它的越南语能力还不错，还有人跟我说，孟加拉语也还可以。</div><div class=" pTag">最近还出现了一个模型东南亚语言模型Salior，它是基于Qwen1.5继续训练然后微调出来的。</div><div class=" pTag">而在小模型方面，有反馈说在法语上的表现不错，家如果看ChatBot Arena法语榜上，Qwen1.5表现也是非常有竞争力的。</div><div class=" pTag">在长序列方面，目前我们看32K长度上的表现是比较稳定的，有些模型Size甚至可以通过外推的方式推的更长，接下来的版本也会有更长的上下文窗口。</div><div class=" pTag">我们除了做简单的大海捞针的实验之外，也对一些针对序列评测的榜单做评估，发现我们的Chat模型在长序列方面，是可以做一些使用方面的东西。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyjL5EsCdXeJZyCNdibeLlRajhl7gcBYnnvRvGyKMrsXGlW0BVdhkFKvw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">下一个部分就是常说的Post-training，今天大家对大模型感兴趣，主要也是因为Post-training让大模型的潜力爆发出来，能够成为一个Assistant来帮助我们。</div><div class=" pTag">我们在Post-training做了非常长时间的工作，包括SFT（指导监督微调），主要是在数据方面做了一些比较扎实的工作。</div><div class=" pTag">我们最近在DPO方面也做了比较多的工作，之后如果有机会会通过技术报告的方式跟大家分享更多相关的细节。我们做完这些之后，会发现模型在一些评测上面的表现更有竞争力。</div><div class=" pTag">除了人工评测之外，还有像MT-Bench和Alpaca-Eval这样的测试，我们模型的表现也都非常有竞争力，尤其是Alpaca-Eval。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyo7NaxwcXwbYr5NialUaAXSveu08b6gibRhwAonmDyslOO7icXGicWrpwnA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">另一方面我们讲Agent方面的能力，这是我们一直非常关心的。</div><div class=" pTag">但我们刚开始给Qwen系列模型做SFT的时候，发现模型不太具备Agent相关的能力。</div><div class=" pTag">解决的方式是做更多的数据标注，时间长了之后，经验越来越丰富，就可以做一些Agent相关的任务了。</div><h2>下一站是多模态Agent</h2><div class=" pTag">今天我们还会关心另外一个问题，就是“大”模型对于很多人来说是不够用的。</div><div class=" pTag">因为大模型发展下去，终将变成多模态的模型，因为一个非常智能的模型，应该能够融入对视觉语音方面的理解。</div><div class=" pTag">过去几年的时间里，我们在多模态领域也做了比较多的工作，再把之前的一些经验融入进来，就有了Qwen-VL系列模型。</div><div class=" pTag">Qwen-VL系列模型的训练方法也相对来说比较简单，分为三个阶段。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyAOOoXX6b8X0UiavLzZwjDPjxtJALZINoLG4ROvjiaSuchTT0g2n2x9gg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">首先是非常扎实对齐的预训练，实现视觉和语言模型的对齐，让我们的语言模型能够睁开双眼看世界，能够理解视觉方面的信息。</div><div class=" pTag">接下来是能力的注入和对齐，我们VL核心开发同学，他有一天刚好去医院，对医院密密麻麻拍了一个照问它说肚子疼去哪里，模型把相关信息都能准确识别出来。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHy001bF3BmxL0A14M5ZQxvVXicibUWvU2ZkwvOJ8cTgdbUUVCILkIFkgQg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这是今天VL模型跟过去不一样的点，今天对OCR的识别比以往做的好很多。</div><div class=" pTag">在这个基础上我们想做更加冒险的事情，比如说打造VL方面的Agent，如果能成功的话，将会非常有吸引力。</div><div class=" pTag">比如说，如果想对手机屏幕进行操作，如果看到的是一堆代码，那么操作起来将会非常困难，而对人来说不管怎么看、不管颜色、Logo怎么变我们都能理解，屏幕上面有哪些东西我们都能做出正确选择。</div><div class=" pTag">所以我们也让模型进行了一些尝试，发现它能准确识别出来这些位置，所以我相信随着VL模型水平不断提升，在Agent方面的潜力会越来越大。</div><div class=" pTag">如果让我们模型看见世界，能不能让它听见呢？方法也非常简单，简单说就是把Audio Encoder接入我们的模型，再基于刚才所说的几个阶段进行训练，就能得到非常好的效果。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHySlF93BqksbzLKLlfPdMRgbDicDq14gMhWzWCPJIn28OrawHo7R6G6Wg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而能够听见声音的大模型，可以做的事情非常多。</div><div class=" pTag">比如我在海外旅游，到了某个国家去，不太会说当地的语言，希望有一款产品能帮我进行翻译。</div><div class=" pTag">而在这种产品背后需要解决几个问题，需要先对语音进行识别，然后再进行机器翻译，这个过程其实非常麻烦。</div><div class=" pTag">但有了大模型之后，这样的任务只需要一个prompt就能解决，并且还能翻译成不同的语言，只需要跟模型交互就可以了。</div><div class=" pTag">除此之外，还有对自然声音和音乐的理解，ASR模型只能理解人的说话并转成文字，但现实中的声音包括自然声音以及音乐等多种类型。</div><div class=" pTag">而我们的模型可以做音乐的赏析，听到一段声音就能写出一首诗，可以看到大语言模型在多模态方面潜力十足。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyIHUf107fJXFjljj3mjlzREAze9T4FEGtTJtTzINlW6o6yc5Xm3xlpg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">另外，今年非常重要的一个趋势是大模型与视频的结合，我们下一步会做出更多模态，其中视频就是一个重点。</div><div class=" pTag">最后我做一个简单的总结，我们现在的Base模型和Chat模型每一次都会推出几个版本，最新的模型就在几个小时前，还推出了code专项模型，叫做CodeQwen 1.5，是一个7B规模的模型，在代码方面的Benchmark表现比较突出，大家可以去尝试。</div><div class=" pTag">接下来我们会去做进一步的Scaling，包括模型本身和数据的scaling，接下来还有模态方面的scaling，也就是接入更多的模态。</div><div class=" pTag">我们最终的目标是实现一个非常强大的大预言模型，能够理解各种模态的信息，甚至实现不同模态的输入和输出。所以，接下来大家可以持续关注我们的进展。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyOr8Qh3Qs5M3VSUuuu3BPqUsOAibAPWjTkEw9o8C63oG8tM2AVk8CGHw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FusfZOCbZpfIyvWMkZcV3dw">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 04 May 2024 02:52:22 GMT</pubDate>
</item>
<item>
<title>CVPR‘24：与任务无关的多模态数据也能提升Transformer性能｜港中文&amp;腾讯</title>
<link>https://posts.careerengine.us/p/6635a2e6d71afb403454fa15</link>
<guid>https://posts.careerengine.us/p/6635a2e6d71afb403454fa15</guid>
<content:encoded><![CDATA[
<div> 多模态通路 技术 提升模型性能 神奇发现 CVPR2024接收
<br />跨模态重参数化 实验结果 图像识别 点云处理 视频理解 音频分析
<br />多模态数据提升模型性能 跨模态知识迁移层次表示能力 潜力研究启发多模态学习发展应用前景广阔
<br /><br />总结: 本研究发现多模态数据可以显著提升Transformer模型性能，通过多模态通路技术实现跨模态知识迁移，不仅提升了模型在不同任务上的性能，而且揭示了模型参数规模和层次表示能力对迁移效果的影响。这一发现对于多模态学习相关领域有着重要的启示意义，尤其在数据资源有限或难以标注的领域具有广阔应用前景。研究团队进一步将探索将多模态通路技术应用于不同AI系统，并推动了学界对于跨模态学习的深入理解。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">Yiyuan 投稿</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">万万没想到，<span><strong style="font-weight: 600;">与任务无直接关联的多模态数据也能提升Transformer模型性能</strong></span>。</div><div class=" pTag">比如训练一个图像分类模型，除了标注好类别的图像数据集，增加视频、音频、点云等模态数据，也能显著提升模型在图像分类上的性能。</div><div class=" pTag">这样一来，在AI训练阶段就可以减少与特定任务直接相关的标注数据需求，可以节省大量成本，或在数据有限的任务上提供新解决思路。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHylnNXpDrnBibVALBpOMwO9MyYOffWTfQREDSUQH3B4bkuliaAIg0aBFog/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这个神奇的发现来自<strong style="font-weight: 600;"><span>港中文MMLab和腾讯AI Lab</span></strong>的合作研究，相关论文已被CVPR 2024接收，引起广泛关注。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyXW74iaJZYq3SDicvZLVQG5G2RVFYanAD6riaZOjcwTHhLt3jQVsdLLGkA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>从无关数据中学习有用知识</h2><div class=" pTag"><div class=" pTag">具体来说，团队提出了一种称为</div><span><strong style="font-weight: 600;">多模态通路</strong></span><span>（Multimodal Pathway）</span><div class=" pTag">的新框架。</div><br /></div><div class=" pTag">该框架允许Transformer模型在处理特定模态的数据时，同时利用其他模态中的无关数据进行训练，从而在不增加额外推理成本的前提下显著提升模型性能。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyic5N2TeRZ64Dahw404r9vsrKibICUkybTpMBJTkl2lVJ8nBqWhMjzTlw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">多模态通路的核心技术是<strong style="font-weight: 600;">跨模态重参数化</strong>&nbsp;（Cross-Modal Re-parameterization）*。</div><div class=" pTag">这一技术的创新之处在于，它通过结构上的智能重组，使得模型能够在保持原有计算成本的同时，增加从其他模态学习的能力。</div><div class=" pTag" style="font-size: 17px; text-align: left;">对于已经被广泛运用到多模态特征提取的Vision Transformer，团队关心的是这些神经网络中的主要线性层。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyMB7XstKc9MvFokrBtYgAWWKhZQiasknqsOVnfh5VdJcPNficANGeFKJw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">具体来说，这一技术在模型的每一个线性层中引入了辅助模态的权重，这些权重通过可学习的参数进行调节，从而在不增加推理时间的情况下，实现模态间的知识迁移。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHym9vtonegojwIxaM4VorRTiacR2REypsxHSfbJicibASPzZoly2To9d4jg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">如图所示，比如有不同模态的两个线性层<strong style="font-weight: 600;"><span>FC和FC’</span></strong>， 那么跨模态结构重参数化就是要通过构建一个运算完全等价的线性层来承载两个模态的运算，在这里直接将来自不同模态的两部分权重 <strong style="font-weight: 600;"><span>（W和W’）</span></strong>做线性组合<span><strong style="font-weight: 600;">（W+λ<span style="font-size: 17px; text-align: center;">W’）</span></strong></span>来平衡两个模态的权重对于目标模态的贡献。</div><h2>实验结果：跨模态增益挖掘Transformer潜力</h2><div class=" pTag">在论文中，研究团队详细介绍了他们的实验设计和结果。</div><div class=" pTag">在图像识别、点云处理、视频理解和音频分析等多个任务上应用了多模态通路技术，观察到<span><strong style="font-weight: 600;">多模态通路</strong></span><span><strong style="font-weight: 600;">能够在12种不同的模态相互帮助的关系中实现一致的性能提升</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyg2Ug01sZxBVUtE2CflQxLztJSJhXu8ub5CXJIxo9BPfy4lWaDnKJkw/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><br /></div><div class=" pTag">例如，在ImageNet图像识别任务中，结合了点云数据的多模态通路Transformer模型，比传统的Transformer模型在识别准确率上提高了0.7%。</div><div class=" pTag">与MAE预训练方法的各种改进相比，该方法无需高昂的计算成本来预训练1600 Epoch，而是直接在下游任务中微调，就能显著地提升模型性能。这充分展示了多模态学习在处理大规模复杂数据集时的强大潜力。</div><div class=" pTag">研究人员还发现，<span><strong style="font-weight: 600;">跨模态知识迁移的效果不仅与模型参数规模有关，还可能与层次表示</strong></span><span>（Hierarchical Representation）</span><span><strong style="font-weight: 600;">能力密切相关</strong></span>。也就是越擅长学习层次化的抽象表示的<span style="font-size: 17px; text-align: left;">模型</span>，迁移效果就越好。</div><div class=" pTag">更值得注意的是，该方法有效地证明了即使毫不相关的多模态数据之间，仍能存在着明显的多模态增益效果，这充分说明我们现在对多模态学习的理解与认知还有很大的提升空间。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHycqG89wdsB46cED2nCR7ypPXJLuUXu7SaicgseloFrGsQeSSTpLHSPWw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">总的来说，这项研究不仅能够启发多模态学习在学术领域的发展，也为工业界提供了新的思路。通过利用现有的海量数据资源，即使这些数据与当前任务不直接相关，也能够为AI模型的训练带来积极的影响。</div><div class=" pTag">这种方法为数据资源有限或难以标注的领域提供了新的解决方案，特别是在自动驾驶、医疗影像分析、自然语言处理等技术要求极高的领域，多模态通路技术的应用前景广阔。</div><div class=" pTag">此外，这一研究还揭示了AI跨模态学习的新机制，推动了学界对于不同数据模态间交互和协同处理的深入理解。研究团队表示，未来他们将探索将多模态通路技术应用于卷积神经网络<span>（CNN）</span>和其他跨架构的AI系统，以进一步挖掘这一技术的潜力。</div><div class=" pTag"><span style="font-size: 17px;">论文地址：</span><span style="font-size: 17px;">https://arxiv.org/abs/2401.14405</span><br /><span style="font-size: 17px;">项目网页：</span><span style="font-size: 17px;">https://ailab-cvc.github.io/M2PT/</span><br /><span style="font-size: 17px;">开源代码：</span><span style="font-size: 17px;">https://github.com/AILab-CVC/M2PT</span><br /><span style="font-size: 17px;">讲解视频：</span><span style="font-size: 17px;">https://www.bilibili.com/video/BV1Sm41127eW/</span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FY4LV07qNzRa5MA_lygBiaw">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 04 May 2024 02:52:22 GMT</pubDate>
</item>
<item>
<title>AI教母李飞飞首次创业！成立“空间智能”公司，已完成种子轮</title>
<link>https://posts.careerengine.us/p/6635a2d8f409657c47ecc3b1</link>
<guid>https://posts.careerengine.us/p/6635a2d8f409657c47ecc3b1</guid>
<content:encoded><![CDATA[
<div> 斯坦福大学、李飞飞、AI公司、空间智能、Radical Ventures<br />
<br />总结:斯坦福大学教授李飞飞创办了一家AI公司，获得种子轮融资，公司方向为空间智能。她长期在学术界和工业界贡献斐然，现转战创业。最新消息显示投资方包括硅谷风投a16z和Radical Ventures。李飞飞最近在TED大会上发表演讲，强调空间智能在推动机器人学习方面的重要性。她的团队致力于让AI实现高级推理和具身智能，同时参与了多个学术成果的发表。李飞飞已成为AI领域内最具影响力的女性和华人之一，她的回忆录《我看到的世界》也获得了好评。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">明敏 克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">AI教母<strong style="font-weight: 600;">李飞飞</strong>，创业了！</div><div class=" pTag">最新消息，斯坦福大学教授李飞飞正在建立一家<strong style="font-weight: 600;">AI公司</strong>，已完成种子轮融资。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAjbQQGBdj3icpp1ufXwSfc9empbgvoEhHMWzZibQTvBk4eRVibxyZiaNV5ysic8qJpOQGdgBzjicSdzpLw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">公司方向定为“<strong style="font-weight: 600;">空间智能</strong>”——旨在让AI能像人类一样对视觉信息进行高级推理。消息人士表示，这将是该技术的一次飞跃。</div><div class=" pTag">投资方包括硅谷风投a16z和Radical Ventures。</div><div class=" pTag">作为AI领域影响力最大的女性和华人，李飞飞长期对学术界和工业界贡献斐然。她在斯坦福拿下终身教职，曾担任谷歌云AI首席科学家、推动Google AI中国中心成立、并长期统筹谷歌云AI、谷歌大脑以及中国本土团队工作。</div><div class=" pTag"><strong style="font-weight: 600;">但躬身创业，这是头一回</strong>。</div><div class=" pTag">目前，李飞飞及相关投资方对于这一新消息尚未做出回应。</div><div class=" pTag">但李飞飞的领英页面上已经多了一条新履历。</div><div class=" pTag">title是“<strong style="font-weight: 600;">新手</strong>”，介绍只写了“something new”，确定是全职，从2024年1月开始，现在已经进行5个月。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAjbQQGBdj3icpp1ufXwSfc9L3GiajQ4GkticGN4DJDWlwrujAkglJicG9OhOibf5TEDuYzTRFWibqS0KUg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>计划“让AI实现高级推理”</h2><div class=" pTag">汇总各方信息，目前比较有迹可循的线索是参投的加拿大风投Radical Ventures。</div><div class=" pTag">去年，李飞飞去年以科学合伙人的身份加入了这家基金。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAjbQQGBdj3icpp1ufXwSfc9AiaZ1n5qPOSkAr3PC27AJJLZUX80FYdDRjR6sTPbG61EEFiaCXjZZvNg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">更多蛛丝马迹，可以从李飞飞近期的公开活动看起。</div><div class=" pTag">上个月，李飞飞在温哥华举行的TED大会中发表了主题演讲，内容正是与空间智能相关。</div><div class=" pTag">演讲中，李飞飞对“空间智能”的描述是从物体之间的关系中获得预测和洞察力的能力。</div><div class=" pTag">她表示，AI对空间智能理解的进步，正在催化机器人学习，使我们更接近让AI能与世界互动的目标。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAjbQQGBdj3icpp1ufXwSfc9yp5zeX0IbJKU3otwyricicDmicO6ZqKpYY2UvzfDwTPz0HV0UiafKoRYUA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">为了解释“空间智能”，她展示了一张猫咪伸出爪子要把玻璃杯推向桌子边缘的照片。</div><div class=" pTag">她表示，人类大脑在这一瞬间可以评估玻璃杯的几何形状、它在3D世界中的位置、它与桌子、猫和其他东西的关系，并且能预测接下来会发生什么，采取行动制止。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">大自然创造了这种由空间智能驱动的视觉和行为的良性循环。</div></blockquote><div class=" pTag">同时，她表示自己的团队在实验室中也正在尝试如何教会电脑在3D世界中行动。</div><div class=" pTag">比如通过大语言模型，让一个机器人手臂执行任务，打开一扇门、做一个三明治以及对人类的口头指令做出反应等。</div><div class=" pTag">这里提到的工作应该是和去年发布的具身智能成果VoxPoser有关。</div><div class=" pTag">这个项目可以让人类给机器人下达指令，如“打开上面的抽屉，小心花瓶！”</div><div class=" pTag">然后大语言模型+视觉语言模型就能从3D空间中分析出目标和需要绕过的障碍，帮助机器人做行动规划。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAjbQQGBdj3icpp1ufXwSfc9pMYYfbZKLibPPmXWrGaZsPDsrrqaVw1l2VFy9jW0XPwCLfhheqAWNQg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">并且在真实世界中，机器人在未经“培训”的情况下，就能直接执行这个任务。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAjbQQGBdj3icpp1ufXwSfc9yib5abc5ZEABCspWVml6TYpJKtuDgJxkVNz5A5nRqhFaA9XjyAJwUuw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">除此之外，近期李飞飞也参与了一系列学术成果的发表，涉足领域包括计算机视觉、机器人、智能体等。</div><div class=" pTag">比如一些的便携式的动作数据收集系统。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAjbQQGBdj3icpp1ufXwSfc9mMDmBHH64ZibCTq9sMiaicmEqDEInibjfoiaacZib4lgj8Aq0M8rz44uhqhQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">还有一些与Agent相关。</div><div class=" pTag">比如上个月发布的一项涉及1000多种人类日常活动的具身智能Benchmark，李飞飞就有参与其中。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAjbQQGBdj3icpp1ufXwSfc9uibbDouibRCI9NIIoZBvibKC2eO9MkKicR7Kal1RkUd95Bd6UJUtCf5Wsw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在3D空间方面，李飞飞团队也在今年年初发布了一款隔空3D建模模型，可以透过遮挡物建模出人物的动作。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAjbQQGBdj3icpp1ufXwSfc9u3wRW7sWurDgicKViahnAJPFIHtMcYU1FA48Lnqczuxcz79dkb7JRPVQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，她还与来自微软、斯坦福、UCLA等机构的15名研究人员共同发布了一份关于Agent AI的立场文件。</div><div class=" pTag">文件中明确了Agent AI的基本概念，并提出了Agent AI基础模型，即利用多模态预训练模型构建的通用Agent系统。</div><div class=" pTag">文件中指出，这些模型可以处理来自机器人、游戏等领域的交互式多模态数据。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAjbQQGBdj3icpp1ufXwSfc9NtgWT3gFHKsK7Iqhvev1Grkich07EzbH0ibkVibTuJ0tKiaqFQ6ib5orlbA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">另外，李飞飞的斯坦福主页显示从今年年初到2025年末，她将处于“部分休假”状态。</div><div class=" pTag">这一起始时间，刚好与李飞飞领英页面中“newbie”履历的开始时间重合。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAjbQQGBdj3icpp1ufXwSfc9sibe2mzeQQqML4bT00w28C41BBk4NWiamW5u97CdU1O53U1QKMDDsw4w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>AI教母李飞飞</h2><div class=" pTag">如今，李飞飞已经成为AI领域内最具影响力的女性和华人之一。</div><div class=" pTag">对应AI教父的称号，大家称她为AI教母。</div><div class=" pTag">她的传奇经历一直为人津津乐道——</div><div class=" pTag"><strong style="font-weight: 600;">33岁成为斯坦福计算机系终身教授，44岁成为美国国家工程院院士，现任斯坦福以人为本人工智能研究院（HAI）院长。</strong></div><div class=" pTag">她是计算机视觉领域举足轻重的领军人物，一手创立的ImageNet成为推动计算机视觉识别领域前进的标杆成果。</div><div class=" pTag">其门下高徒颇多，比如先后在OpenAI、特斯拉任职的Andrej Karpathy、目前在英伟达的Jim Fan等，也都是AI领域内颇具影响力的人物。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAjbQQGBdj3icpp1ufXwSfc9EiasW9fIZSlQavc13tI0tOfQAnBaIwvVTeDAq0huLAEGlEfLCCILhQg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">后来李飞飞曾短暂进入工业界，出任谷歌副总裁即谷歌云AI首席科学家。她一手推动了谷歌AI中国中心正式成立，这是Google在亚洲设立的第一个AI研究中心。并带领谷歌云推出了一系列有影响力的产品，包括AutoML、Contact Center AI、Dialogflow Enterprise等。</div><div class=" pTag">最新大模型趋势里，李飞飞团队聚焦于具身智能，将大模型接入机器人，无需额外数据和训练即可把复杂指令转化成具体行动规划，开辟新一轮浪潮中的重要方向。</div><div class=" pTag"><strong style="font-weight: 600;">一直以来，李飞飞都是AI领域风向标一样的存在。</strong></div><div class=" pTag">最近，李飞飞的个人回忆录<strong style="font-weight: 600;">《我看到的世界》</strong>正式发表。在这本书中，李飞飞自述了自己如何从北京到成都再到美国，如何在AI变革中逐渐找到自己的使命，并且分享了自己对AI发展的看法。</div><div class=" pTag">由此，一个更加立体的李飞飞被勾勒出来。</div><div class=" pTag">她说自己不是开源派也不是毁灭派，她希望人类能和AI和平相处。</div><div class=" pTag">她分享，谷歌云的经历让她意识到，引领AI技术发展需要肩负起相应的责任。</div><div class=" pTag">她也表示，如果你追求时髦算法，那么这肯定不是最好的科研。</div><div class=" pTag">毕竟她曾经也做过冷门项目——不听同行导师建议，用数年时间标注了用于训练ImageNet的1400万张图片。</div><div class=" pTag">……</div><div class=" pTag">李飞飞坦言，自己非常害羞，不敢讲自己的故事。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">才四十多岁就写回忆录？我不是爱因斯坦。</div></blockquote><div class=" pTag">而在写完自己前40年后，李飞飞给自己掀开了一个人生新章程。</div><div class=" pTag">正如她所说的，文明就像是一艘大船，我们在黑暗中航行。</div><div class=" pTag">科学家李飞飞，如今有了新故事。</div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://www.reuters.com/technology/stanford-ai-leader-fei-fei-li-building-spatial-intelligence-startup-2024-05-03/</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://www.ft.com/content/d5f91c27-3be8-454a-bea5-bb8ff2a85488</span><br /><span style="font-size: 17px;">[3]</span><span style="font-size: 17px;">https://blog.ted.com/mind-expanders-notes-on-session-2-of-ted2024/</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FRPhN_TR3lW990epLE7izmA">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 04 May 2024 02:52:08 GMT</pubDate>
</item>
<item>
<title>美图吴欣鸿：国产Sora竞争关键，在创意、工作流和垂直场景 | 中国AIGC产业峰会</title>
<link>https://posts.careerengine.us/p/66346b40a4b5796c016a2def</link>
<guid>https://posts.careerengine.us/p/66346b40a4b5796c016a2def</guid>
<content:encoded><![CDATA[
<div> 关键词：美图、视频大模型、AI、创意、垂直场景
总结：<br /><br />美图公司创始人吴欣鸿在AIGC产业峰会上分享了关于创新视频大模型的探索之路。他介绍了美图公司16年来在图像、视频和设计领域的经验和感悟，并展望了未来的发展方向。重点包括：AI技术加持下的短视频制作，突出创意和超越现实的能力；工作流整合，将AI技术与传统视频技术相结合；垂直场景能力的重要性和优势；视频大模型的进化方向，包括时空域同步压缩和更强的语义理解能力；未来对AI原生工作流的探索和预判，包括不同的视频生成方式和更贴近消费者的形式。通过这些探索和创新，美图公司积极探索AI在生产力工具领域的应用前景。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">编辑部 整理自 AIGC峰会</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">全球AIGC应用浪潮下，怎样将大模型产品以一种更贴近消费者的形式融入生产力工具？</div><div class=" pTag">这，或许是AI在生产力场景延伸过程中，入场玩家们所要思考的一个重要问题。</div><div class=" pTag">中国AIGC产业峰会上，<strong style="font-weight: 600;">美图公司创始人、董事长兼CEO吴欣鸿</strong>从美图视频大模型的探索之路出发，讲述了美图在图像、视频和设计领域深耕16年而获得的经验与感悟以及对未来的预判。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2p7L5MXicY71LQb8kic90ia5wWmkqtPbMtECsfbJZ0jeYWyW3GRZqGfmlg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">为了完整体现吴欣鸿的思考，在不改变原意的基础上，量子位对演讲内容进行了编辑整理，希望能给你带来更多启发。</div><div class=" pTag"><span>中国AIGC产业峰会是由量子位主办的行业峰会，20位产业代表与会讨论。线下参会观众近千人，线上直播观众300万，获得了主流媒体的广泛关注与报道。</span></div><h2>话题要点</h2><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">AI加持，只用半天，就能做出时长60秒的惊艳短片</div></li><li><div class=" pTag">面对越来越激烈的竞争，创意超越现实、工作流的整合、垂直场景能力这三点非常关键</div></li><li><div class=" pTag">垂直模型的创新，有两年左右的窗口期</div></li><li><div class=" pTag">美图不做大而全的模型和场景，更关注垂直的图像和视频模型及场景</div></li></ul><div class=" pTag"><span>以下为吴欣鸿演讲全文：</span></div><h2>美图视频大模型的探索之路</h2><div class=" pTag">一眨眼，美图已成立16年。最早，我们做影像工具，像美图秀秀。此外很长一段时间，美图也探索了不同业务，踩了很多坑。</div><div class=" pTag">从2021年开始，我们基于订阅的商业模式，取得了非常好的经营状态，并重新聚焦于影像和设计产品。现在，我们已经从过去的工具自卑转变成越来越有信心。</div><div class=" pTag">我们正逐步往生产力场景延伸，从最初的拍摄、修图、修视频、社交分享到现在新增的视觉创作、专业摄影、专业视频编辑、商业设计等等。</div><div class=" pTag">美图现在拥有了<strong style="font-weight: 600;">影像与设计产品全家桶</strong>。产品主要分为<strong style="font-weight: 600;">AI图像、视频和设计</strong>三个大类。</div><div class=" pTag">同时，在<strong style="font-weight: 600;">生态层</strong>，美图今年初收购了站酷，为我们提供了优秀的设计师共创、商用版权销售和专业课程设计等服务。</div><div class=" pTag">在<strong style="font-weight: 600;">模型层</strong>，去年6月发布的美图奇想大模型为我们以上产品提供了强大的模型能力支撑。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnOoku7V35y043HlOOz7KQ4eot2UadCpc4NT2bIM7gjR6GnoBLN3ictyw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">前两天，我们使用美图生产力全家桶制作了一部短片。我想邀请大家观看这个一分钟的短片。</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-180"></div></div><div class=" pTag">谢谢大家观看。</div><div class=" pTag">我想重点介绍这个<strong style="font-weight: 600;">60秒</strong>的短片是怎么制作出来的。</div><div class=" pTag">其实<strong style="font-weight: 600;">只用半天时间</strong>，就能做出同样惊艳的效果。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnqIicJ0RZXiaumCgBCicuseibZ9LWFyWNEm1al5Nd5k2zn6iaaOwDdrX37fQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">在<strong style="font-weight: 600;">前期制作</strong>中，我们使用了开拍AI脚本以及美图WHEE进行风格和角色的一次性约束，确保短片中人物形象和画面风格的一致性。同时，我们还使用WHEE的文生图进行了关键的分镜设计。</div><div class=" pTag">在<strong style="font-weight: 600;">中期制作</strong>阶段，同样是美图WHEE，我们将这些分镜制作成视频化，相当于图生视频。</div><div class=" pTag">同时，我们还使用美图开拍的AI数字人进行了输入对话、唇形同步。</div><div class=" pTag">在<strong style="font-weight: 600;">后期制作</strong>环节，我们使用了美图的Wink进行视频编辑，并制作了自动字幕和添加音效。</div><div class=" pTag">所有这些产品都是由美图奇想大模型驱动的，与AI紧密相关。这展示了AI原生工作流的有益探索，与传统动画工作流相比，效率得到了很大提升，且门槛大幅降低。</div><h2>朝着Diffusion Transformer架构进化</h2><div class=" pTag">去年12月，我们发布了MiracleVision 4.0版本，其中重点是<strong style="font-weight: 600;">AI视频和AI设计能力</strong>。刚才的视频就是使用去年12月的视频大模型生成的。</div><div class=" pTag">不过，这和最近我们正在训练的美图视频大模型<span style="font-size: 17px; text-align: left;">2.0</span>在能力上还有很大区别，我简要介绍一下进化的方向。</div><div class=" pTag">最早，我们采用了U-Net结构，在编码部分也只能进行空间域压缩。Sora发布后，我们发现在架构上有很多可以参考学习的地方，因此我们升级了视频大模型的架构，采用了Transformer结构，另外还实现了时空域同步压缩。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Ynj1v2x2icK6odLQuwHfjfkvKUenoPuzuPa9BX5WRn1ukHiaapKZPibm4sQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="text-align: left;">美图视频大模型目前正在从1.0向2.0的跨越，实现全方位的技术升级，模型参数量显著增大，同时将拥有更加强大的语义理解能力，大幅提升视频生成时长、稳定性与内容一致性。</span></div><div class=" pTag">上述的视频大模型2.0将于今年6月美图影像节正式亮相。</div><h2>垂直模型创新有两年左右窗口期</h2><div class=" pTag">我们对未来也有一些预判。现在大家都在追赶Sora，预计今年下半年将会有很多国产Sora扎堆上市。美图的MiracleVision也是其中一家。</div><div class=" pTag">我们认为，面对越来越激烈的竞争，有三个点非常关键。</div><div class=" pTag">第一，<strong style="font-weight: 600;">创意超越现实</strong>。</div><div class=" pTag">众所周知，Sora拥有许多充满创意、奇思妙想的画面，这是实拍很难做到的。同时，如果将这些画面采用传统的视频特效方式制作，成本将非常高昂。</div><div class=" pTag">我们认为，视频大模型应与实拍相辅相成，生成一些超越现实的创意画面，成为一种全新的特效制作方式。以前的特效，比如前期做绿幕、后期要做动捕等等，时间长、成本高，而现在AI特效可以做到低成本、低门槛。</div><div class=" pTag">第二，<strong style="font-weight: 600;">工作流的整合</strong>。</div><div class=" pTag">如果只是单纯拼生成能力，比如文生视频，其实它的应用场景是相对有限的。我们正将美图现有的生产力工具能力进行整合，无论是AI能力还是传统视频技术相结合，形成类似刚才60秒短片的动画制作工作流。</div><div class=" pTag">第三，<strong style="font-weight: 600;">垂直场景的能力</strong>。</div><div class=" pTag">我们也在探索视频大模型未来能否在电商、广告、游戏、动漫、影视等场景进行深度应用和变现。因此，垂直场景的可用性同样是竞争的关键。</div><div class=" pTag">基于垂直创新模型的创新，我们认为有两年左右的窗口期。</div><div class=" pTag">在这里，我们对自己业务的要求是，不去做大而全的模型和场景，更关注垂直的图像和视频模型，以及电商、广告等垂直场景。同时，我们也将不断探索AI原生工作流，我们认为它是一种更能降本增效的实现方式。</div><div class=" pTag">刚才提到，文生视频将是视频大模型的标配，同时还有更多的视频生成方式，如图生视频、视频生视频、音频生视频等。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnwYiblgonHJfC9SrKzLOdMfE9FrF7syZNkumlCOS9coHwwDz4crcJtrw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">我们可以看到，无论是哪种视频生成方式，都将有广阔的应用场景。例如，图生视频，因为美图是从图片工具发展起来的，我们每天会产生两亿多张图片，如何让图片动起来？例如，美颜相机的AI写真就在探索AI视频写真，我认为这是一种更贴近消费者的形式。</div><div class=" pTag">视频生视频，我们可以理解为一种全新的视频渲染方式，视频风格化方式。音频生视频，我们现在在探索MV的生成，同样也是一个有趣的领域。同时，开拍的AI主播也可以用音频生成，我们录一段音就可以生成AI主播完整的口播视频。</div><div class=" pTag">在这块，我们也对未来进行了预判。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnYW242TmqlNNnOdBs099qcEyEzgMLB5DZ674Zrb9vHlfvzndedzNHwg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px; text-align: left;">去年，当然是视频大模型的早期阶段，我们去年12月发布的模型，基本上只能生成3-5秒的视频片段，世界、动作一致性和稳定性都较差。</span></div><div class=" pTag"><div class=" pTag">今年2月，Sora的横空出世，我们看到确实有些对物理世界的理解，包括在创意、特效上有一定涌现的现象，视频的时长也显著提升。</div><br /></div><div class=" pTag">我们也期待在明年，甚至更远的未来，视频大模型能够实现更深度的物理理解，拥有剧情设计、分镜、转场等更专业的能力，能够与视频制作工作流紧密结合。</div><div class=" pTag">也希望大家关注6月的美图影像节。除了全新的视频大模型，我们还将有一系列生产力工具全家桶陆续亮相。</div><div class=" pTag">今天我就分享到这，谢谢大家！</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FTFvwXWsC9k76OyO_5FD_JA">阅读原文 </a>
]]></content:encoded>
<pubDate>Fri, 03 May 2024 04:42:40 GMT</pubDate>
</item>
<item>
<title>一次预测多个token，Meta新模型推理加速3倍，编程任务提高17％</title>
<link>https://posts.careerengine.us/p/66346b3fa4b5796c016a2de0</link>
<guid>https://posts.careerengine.us/p/66346b3fa4b5796c016a2de0</guid>
<content:encoded><![CDATA[
<div> 多token预测, 大模型, 编程任务, 小型算法推理, 信息论权重 

总结:<br /><br />法国Meta AI团队提出了基于多token预测的更快更好大模型。该模型在编程任务和小型算法推理中表现突出，能解决更多问题，并能提高推理速度。多token预测能更好捕捉长距离依赖关系，减轻训练与推理时分布的差异，更看重当前Token和未来Token的相关性。然而，尚未解决最佳预测token数量和词表大小选择的问题。期待更进一步的Llama-4模型。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">梦晨 西风 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag"><span><strong style="font-weight: 600;">“预测下一个token”</strong></span>被认为是大模型的基本范式，<span><strong style="font-weight: 600;">一次预测多个tokens</strong></span>又会怎样？</div><div class=" pTag">Meta AI法国团队推出“基于多token预测的更快&amp;更好大模型”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCLqq3cRRB68fqibTDMHC4oQOq1tsCxgfMJibrhguWFnxIAJQtYga8ic4ibMQd5bQ7VfqEgCyCFT7ec6Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">多token预测模型，<span><strong style="font-weight: 600;">在编程类任务上表现尤其突出</strong></span>。</div><div class=" pTag">与单token预测相比，13B参数模型在HumanEval上多解决了12%的问题，在MBPP上多解决了17%。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCLqq3cRRB68fqibTDMHC4oQebOxXAZwyQGtEGXskh4qRRyLfpxjDibOXcEiaYjh1KdIY5vh3m5D4OXA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span><strong style="font-weight: 600;">小型算法推理任务</strong></span>上，多token预测也在分布外泛化方面带来了令人印象深刻的收益。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCLqq3cRRB68fqibTDMHC4oQrebdTqdiaw6SFJPibr0U4UkSGSdFB1tl1xEfYU4ZuzT6pPssIFwC3qng/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不过在自然语言任务上，多token预测方法并不能显著提高7B模型在数学选择题上的表现了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCLqq3cRRB68fqibTDMHC4oQ0N50w8DNPpEyIurTz9YfYG1hbleF9R45uHoichs6Od8YicuKW5Z4xiaPQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">另外一个好处是，即使batch size较大，使用4-token预测训练的模型，<span><strong style="font-weight: 600;">推理速度也可提高3倍</strong></span>。</div><h2>多token预测更适合编程</h2><div class=" pTag">具体来说，团队设计了一种新的多token预测架构，通过n个独立的输出头并行预测n个未来token。</div><div class=" pTag">使用大量文本数据进行模型训练，包括代码和自然语言数据集。</div><div class=" pTag">再通过实验比较多token预测和单token预测在多个下游任务上的性能。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCLqq3cRRB68fqibTDMHC4oQvUppjdUGJibqKwl0vcicTZMQ9EZXXVLXicRn4xk0h9GjFxGzetzWTBMvQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">为啥多token预测在编程任务和小型算法推理任务上提升更明显？</div><div class=" pTag">团队猜测可能有两个原因:</div><div class=" pTag">第一，编程语言的逻辑结构更严谨，知识的内在联系更紧密。一个关键节点可能影响到后续整个代码块的走向。多Token预测能更好捕捉这种长距离依赖。</div><div class=" pTag">第二，相比自然语言，编程语言的词汇量更小。因此即便每次预测多个Token，难度也没那么大。反而能迫使模型从局部细节中抽身，着眼全局优化。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCLqq3cRRB68fqibTDMHC4oQhWCX5FlfAhiaLgqibxawVAtWPNI0J5EPsXzL3rcib2McWaV3Xd5m5wkgg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">除了在token层面的实验，团队还在<span><strong style="font-weight: 600;">更细粒度的字节级模型</strong></span>上做了尝试。</div><div class=" pTag">他们发现，用8字节预测替代下一个字节预测后，模型在MBPP上的Pass@1指标暴增67%，在HumanEval上也提升了20%。</div><div class=" pTag">而且推理速度还能再快6倍，简直不要太香。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCLqq3cRRB68fqibTDMHC4oQ966YGhibgOuv6pllpribCFIXW6P6RibUSQGzpUV5zphiad7vIhdFyFVMqg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">对于背后原理，团队认为<span><strong style="font-weight: 600;">多token预测缓解了训练时Teacher Forcing和推理时自回归生成之间的分布差异</strong></span>。</div><div class=" pTag">也就是说，在训练的时候，模型看到的都是标准答案，生成的时候却得靠自己。好比人类在家做练习册时有答案，考试时却啥也没有，就会不适应。</div><div class=" pTag">而多token预测相当于训练时就逼着模型多想几步，这样到了考场上，才能应对自如。</div><div class=" pTag"><span><strong style="font-weight: 600;">从信息论的角度，团队还给出了一个更精确的论证。</strong></span></div><div class=" pTag">传统的下一个Token预测，目标是最小化当前位置的信息熵。而2-Token预测实际上最小化的是当前和下一位置的信息熵之和。</div><div class=" pTag">数学推导表明，后者其实隐含了更大的互信息权重，也就是更看重当前Token和未来Token的相关性。这就是为什么多Token预测更”有远见”。</div><div class=" pTag"><span><strong style="font-weight: 600;">不过在这篇论文中，还有几个未解决的问题。</strong></span></div><div class=" pTag">比如没有探讨如何自动选择最佳的预测token数量n，作者提出，未来可以研究使<span><strong style="font-weight: 600;">用损失权重调整或动态调整n来解决最佳n的选择问题</strong></span>。</div><div class=" pTag">此外最佳的词表大小也可能与单token预测时不同。</div><div class=" pTag">总之，看过这篇论文之后，大家都更期待Llama-4了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCLqq3cRRB68fqibTDMHC4oQLsHPiavQXbwr358KbW8fwwHib70AiboEC7sKApwIdVEW9dfUkwicfONeAw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">论文地址：</div><br /></span><span style="font-size: 17px;">https://arxiv.org/abs/2404.19737</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FGuIqBdj4MteR9eBlTesdBA">阅读原文 </a>
]]></content:encoded>
<pubDate>Fri, 03 May 2024 04:42:39 GMT</pubDate>
</item>
<item>
<title>奥特曼承认了神秘gpt2！哈佛MIT巡演继续，斯坦福演讲完整版公开</title>
<link>https://posts.careerengine.us/p/66346b315fefc86bc3a43923</link>
<guid>https://posts.careerengine.us/p/66346b315fefc86bc3a43923</guid>
<content:encoded><![CDATA[
<div> 奥特曼、GPT-5、AI部署、能源需求、自我意识
<br />
<br />
总结:文章介绍了奥特曼在斯坦福、哈佛、MIT等大学的演讲内容，提到了GPT-5的发布和AI在学术中的应用。强调了负责任地部署AI和全球能源需求变化的重要性。此外，还涉及了自我意识、未来AGI的发展以及恐惧等问题。同时指出未来AI的搜索功能即将发布，展望未来AI技术在社会发展中的重要性。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">梦晨 西风 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">奥特曼<span><strong style="font-weight: 600;">斯坦福爆火演讲</strong></span>，完整版录像公开了！</div><div class=" pTag">这还只是第一站，在<strong style="font-weight: 600;">哈佛</strong>和<strong style="font-weight: 600;">MIT</strong>再次发现了他的身影。</div><div class=" pTag">特别是在哈佛，他还变相承认了<span><strong style="font-weight: 600;">神秘gpt2-chatbot确实与OpenAI有关，但不是GPT-4.5</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCLqq3cRRB68fqibTDMHC4oQkB5C0L8AawdqWfdff8UiaFNP8GWiavHhN9cJ6xIIHuNwc8amNE6OA7Xg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">事实上，我们可以同时在所有模型的行为和功能上取得进展，我认为这是个奇迹。</div></blockquote><div class=" pTag">他还提到“每个大学生都应该学会训练GPT-2……这并不是最重要的事情，但我打赌两年后这是每个哈佛新生都必须做的事情”。</div><div class=" pTag">难不成，就真的是<span><strong style="font-weight: 600;">GPT-2 1.5B Plus Pro Max Q*威力加强年度典藏豪华版</strong></span>？？？</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCLqq3cRRB68fqibTDMHC4oQQiagI8pvWt9Gh6RLCak2kBuBd6kAgSmZJDcGro5ttiavLMzwn6OcTGOg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">斯坦福大学位于硅谷附近，而哈佛大学和麻省理工学院则位于美国另一端的东海岸波士顿。</div><div class=" pTag">奥特曼在哈佛的活动同样座无虚席，学生们据称提交了超过2000个问题，但只有少数人获得了现场提问的机会。</div><div class=" pTag">奥特曼这是复刻去年GPT-4发布后的世界巡游，又来了一把美国大学巡演的节奏。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCLqq3cRRB68fqibTDMHC4oQ3K8jBicqfiaxuvgRRHDib0AibQn09K7KGOqtmmrSH8cfzrAzXsgBrAXEPw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">更详细的消息来自哈佛大学校报和MIT科技评论。</div><div class=" pTag">在哈佛，奥特曼与师生<span><strong style="font-weight: 600;">讨论了AI在学术中的使用。</strong></span></div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">论文到底是学生还是ChatGPT写的，有关系吗？</div></blockquote><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCLqq3cRRB68fqibTDMHC4oQQ88rPwMmtJ7md9O6rGwrpoQHVZFcjTDPS2xAmZw52L0ibfPCGAMLFHg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">奥特曼举例过去人们也曾担心计算器和搜索引擎会毁了教育，但这并没有发生，而<span><strong style="font-weight: 600;">ChatGPT就像“单词计算器”</strong></span>。</div><div class=" pTag">“必须不断发展的是规范”，奥特曼支持ChatGPT不仅可以用于理工科写作，也可以用于人文学科。</div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">再用老式的方法写论文已经行不通了。用ChatGPT把发现和表达、交流想法做到最好，我认为这就是未来的发展方向。</div></blockquote><div class=" pTag">在MIT，奥特曼则谈到Agent将是AI的杀手级应用。</div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">就像一个超级能干的同事，他了解我一生的一切，我的每封电子邮件，每一次对话。<span>‍</span></div></blockquote><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCLqq3cRRB68fqibTDMHC4oQNgBRoicPWZsKlS4MhNIMttrOKDHvQhOPPLGvW9keibvev3MklX2EicD3A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在奥特曼看来，Agent新范式的AI能够在聊天界面之外帮助我们，摆脱现实世界的任务，但这并不一定需要单独的硬件。</div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">我对新技术的消费硬件非常感兴趣，但我只是一个业余爱好者，离我的专业还很远。</div></blockquote><div class=" pTag">被问到“是否已经知道GPT-5预计何时发布”时，奥特曼平静地说“是的”，面带微笑，没有再说别的了。</div><div class=" pTag">上周他在斯坦福的演讲完整版视频公开后，也有几个片段引发了热烈讨论：</div><ul class="list-paddingleft-1" style="font-size: 17px; text-align: start;"><li><div class=" pTag">GPT-4将是你们中任何人必须再次使用的最愚蠢的模型。</div></li><li><div class=" pTag">我不在乎我们是否每年烧掉500亿美元，我们正在构建 AGI，这将是值得的。</div></li></ul><h2>奥特曼斯坦福爆火演讲整理<span style="display: none;">‍</span></h2><div class=" pTag" style="font-size: 17px; text-align: left;">以下是双语字幕版完整视频以及内容整理。</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-36"></div></div><h3>奥特曼的大学生涯</h3><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>如果用三个词形容你作为斯坦福本科生时的感受，你会用哪三个词？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>兴奋、乐观、好奇。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>形容现在，你会用哪三个词？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>我猜是一样的。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>这很棒。尽管过去19年世界发生了许多变化，但与未来19年即将发生的变化相比，这些变化可能显得微不足道。因此，我想请教你一个问题：如果你明天醒来，突然发现自己回到了19岁，并且拥有现在的所有知识，你会怎么做？会感到开心吗？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>我会觉得自己正处在一个极具历史意义的时刻，世界正经历着巨变，同时，我也看到了参与其中并产生深远影响的机会，比如创业、从事AI研究等。</div><div class=" pTag">我认为现在是自互联网时代以来，甚至可能是技术史上，创立公司的最佳时机。随着AI的进步，每年都会产生更多的奇迹，伟大的公司正是在这样的时刻诞生，最具影响力的产品也是在此刻孕育。因此，我感到无比幸运，并决心充分利用这个机遇。我将明确自己的贡献方向，并付诸实践。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>那你对自己将贡献的领域有偏好吗？你是否想继续保持学生的身份？如果是的话，你会主修什么专业？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>我不会继续做学生，但只是因为我以前也没有这样做，而且我觉得可以合理地假设人们可能会再次做出他们曾经做过的决定。我认为做一名斯坦福的学生是一件很好的事情。只是，这可能不是我想要的。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>你会怎么做？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>我想我还是会选择我喜欢的方向，这并不奇怪，因为人们通常会按照自己的意愿行事。我想我会投身于人工智能研究。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>你可能会在哪里做？学术界还是在私营企业？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>我觉得，很明显我偏向于开放的应用程序，但我认为无论在哪里，只要能做有意义的AI研究，我都会感到非常兴奋。但我要悲伤的说，现实情况是，我会选择进入行业。我觉得确实需要在计算资源极其丰富的地方。</div><h3>创业还是打工？</h3><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>我们上周邀请了Qasar Younis，他极力主张不要成为创始人，而是加入一家现有的公司以学习相关技能。对于那些正在纠结是应该在19、20岁自己创业，还是加入其他创业公司的学生，你会给他们什么建议？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>既然他给出了加入其他公司的理由，那我就讲另一个观点。我认为自己创办公司能学到很多东西。如果这是你想做的事，保罗·格雷厄姆有句话说得很好，我认为非常真实：创业不像医学那样有预科阶段，你只能通过实际经营创业公司来学会如何管理公司。如果你确信这就是你想做的事，那么你可能应该直接投入其中去做。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>如果有人想要创办一家公司并从事AI领域，你认为当前AI领域最适合创业的短期挑战是什么？为了明确这一点，我指的是哪些问题是你认为需要优先解决但OpenAI在未来三年内无法解决的？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>从某种意义上说，这个问题是非常合理的，但我不会直接回答它。因为我认为你永远不应该从任何人那里接受这种关于如何开始创业的建议。</div><div class=" pTag">当某个领域已经如此显而易见，以至于我或者其他人站在这里都可以指出它时，那它可能就不是一个好的创业方向了。我完全理解，我还记得我当初也会问别人，“我该创办什么样的公司？”。</div><div class=" pTag">但我认为拥有一份有影响力的职业最重要的原则之一是必须要走自己的路。如果你正在思考的事情是其他人也会去做的，或者是很多人都会去做的，那么你应该对其保持一点怀疑。</div><div class=" pTag">我认为我们需要培养的一个重要的能力是提出那些非显而易见的想法。我不知道现在最重要的想法是什么，但我确信这个房间里的某个人知道答案。我认为学会信任自己，提出自己的想法并勇敢去做那些不被广泛认同的事情非常重要。</div><div class=" pTag">比如我们刚开始创办OpenAI那会儿，这件事并没有得到很多人的认同，但现在它已经成为非常显而易见的事情了。现在我只是因为自己身处其中，才会对这个方向有比较明确的想法，但我相信你们会有其他的看法。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>那么换个方式问，我不知道这样问是否公平。你正在思考但其他人并没有谈论的问题是什么呢？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>如何建造真正大型的计算机。</div><div class=" pTag">我想，其他人也在讨论这个问题，但我们可能从别人无法想象的角度来看待它。我们正在努力解决的问题不仅是开发小学或中学水平的智能，还包括博士水平及更高层次的智能，并将其以最佳方式应用于产品，最大限度地对社会和人们的生活产生积极影响。我们目前还不知道答案，但我认为这是一个需要弄清楚的重要问题。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>如果我们继续探讨如何建造大型计算机的问题，你能分享一下你的愿景吗？我知道有很多猜测和传闻，关于你正在开展的半导体代工厂项目。这个愿景与目前的做法有什么不同？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>代工厂只是其中的一部分。我们越来越相信人工智能基础设施将成为未来最重要的投入之一，是每个人都会需要的资源，其中包括能源、数据中心、芯片、芯片设计和新型网络。我们需要从整体上看待整个生态系统，并设法在这些方面做得更多。仅关注某个部分是行不通的，我们必须全面考虑。</div><div class=" pTag">我认为这就是人类科技发展史的轨迹：不断构建更大、更复杂的系统。</div><h3>不在乎烧钱，为了AGI都值得</h3><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>至于计算成本方面，我听说训练ChatGPT模型花费了1亿美元，其参数量为1750亿。GPT-4的成本是4亿美元，参数量是前者的10倍。成本几乎增加了4倍，但参数量却增加了10倍。请纠正我，如果我有误的话。</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>我知道，但我想……</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>好的。即使你不想纠正实际数字，但如果方向上是对的，你认为每次更新的成本是否会继续增长？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>是的。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>这种增长会呈倍数增加吗？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>大概吧，我的意思是。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>那么问题就变成了，我们该如何为此筹集资金？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>我认为给人们提供真正强大的工具，让他们自己去探索如何用这些工具来构建未来，是非常有价值的。我非常愿意相信你们和世界上其他人的创造力，可以找到应对这一问题的方法。所以，OpenAI中可能有比我更具商业头脑的人担心我们花了多少，但我并不在意。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>OpenAI、ChatGPT以及其他所有模型都非常出色，去年烧掉了5.2亿美元，这不会让你担心它的商业模式吗？盈利来源在哪里？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>首先，谢谢你这么说，但ChatGPT还远称不上出色，顶多算是勉强合格。GPT-4是大家未来可能用到的最笨的模型了。但是，重要的是早早开始并不断发布，我们相信迭代式发布。</div><div class=" pTag">如果我们在地下室开发通用人工智能，然后世界浑然不觉地盲目前行，我不认为这会让我们成为好的邻居。因此，考虑到我们对未来的看法，我觉得重要的是表达我们的观点。</div><div class=" pTag">不过，更重要的是，将产品交到用户手中，让社会与技术共同进化。让社会告诉我们，集体和个人从技术中想要什么，如何将其产品化以便于使用。这个模型在哪些方面效果好，哪些方面效果差，让我们的领导者和机构有时间做出反应。给人们时间将其融入生活，学会使用这项工具。</div><div class=" pTag">一些人可能会用它作弊，但有一些人也可能会用它做非常了不起的事。每一代人的发展都会有所扩展，这意味着我们发布了不完美的产品，但有一个非常紧密的反馈循环，我们可以学习并变得更好。</div><div class=" pTag">发布让你感到尴尬的产品的确有点糟糕，但比起其他选择，这是更好的方式。在这个特别的情况下，我们真的应该向社会迭代发布。</div><div class=" pTag">我们了解到AI和惊喜不相容。人们不想受到惊吓，他们想要逐步推进并有能力影响这些系统。这就是我们的做法。</div><div class=" pTag">将来或许会有一些情况让我们认为迭代发布不是一个好的策略，但这似乎是目前最好的方法。我认为通过这样做，我们已经学到了很多东西。希望更广泛的世界也从中受益。</div><div class=" pTag">不论我们每年花费5亿美元、50亿美元还是500亿美元，我都不在乎。只要我们能够持续创造比这更多的社会价值，并能够找到支付账单的方式。我们正在开发AGI，这会很昂贵，但绝对值得。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>那么，你有一个2030年的愿景吗？如果现在是2030年，你做到了。在你眼中，世界会是什么样子？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>在某些非常重要的方面，或许并没有太大区别。</div><div class=" pTag">我们还会回到这里，会有新的一批学生。我们会谈论初创公司是多么重要，科技是多么酷。我们会拥有这个世界上新的伟大工具。</div><div class=" pTag">如果我们今天能够传送到六年前，并拥有这个在许多学科上比人类更聪明的东西，能够为我们完成这些复杂的任务，那将感觉非常棒。你知道，我们可以编写复杂的程序，完成这项研究或开始这项业务。</div><div class=" pTag">然而，太阳仍然东升西落，人们继续上演他们的人类戏剧，生活继续。所以，从某种意义上来说非常不同，因为我们现在有丰富的智能，但从另一个意义上来说，又没什么不同。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>你提到了通用人工智能。在之前的采访中，你将其定义为能够模拟一个普通人类在各种任务中表现的软件。你觉得什么时候会实现这个目标？你能给出一个大致的时间或范围吗？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>我认为我们需要对AGI有一个更精确的定义，以解决时间的问题。因为在这一点上，即使是你刚刚给出的定义，也是合理的，这就是你的定义。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>我是在重复你之前在采访中说过的话。</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>我要批评我自己。这个定义太过宽泛，容易被误解。</div><div class=" pTag">所以我认为真正有用或能让人们满意的标准是：当人们问“AGI的时间表是什么”时，他们其实想知道的是世界什么时候会发生巨大变化，变化的速度什么时候会大幅加快，经济运作的方式什么时候会发生巨大变化，我的生活什么时候会改变。由于很多原因，这个时间点可能与我们想象的很不一样。</div><div class=" pTag">我完全可以想象这样的世界：我们在任何领域都能开发出具备博士水平的智能，可以大幅提升研究人员的生产力，甚至可以实现一些自主研究。从某种意义上说，这听起来似乎会对世界产生很大的影响，但也可能我们已经做到了这些后，却发现全球GDP增长在随后的几年里并没有发生变化。想想这种情况还是很奇怪的。这最初并不是我对整个过程的直觉。</div><div class=" pTag">所以，我无法给出一个具体的时间来说明我们何时能达到人们所关心的里程碑，但是在未来的一年以及之后的每一年，我们都会拥有比现在强大得多的系统，我认为这是关键。所以，我已经放弃了预测AGI的时间表。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>你能否谈谈你对AGI危险性的看法？具体来说，你认为AGI最大的危险会是来自一场轰动各大媒体的灾难性事件，还是更为隐蔽和有害的东西，就像现在大家因为使用TikTok而注意力严重分散一样。或者两者都不是？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>我更担心隐蔽的危险，因为我们更容易忽视它们。</div><div class=" pTag">很多人都在谈论灾难性的危险，并对此保持警惕。我不想轻视这些危险，我认为它们的确很严重且真实存在。但至少我们知道要关注这一点，并会花费大量精力。就像你提到的大家因为使用TikTok而注意力严重分散的例子，我们不需要去关注最终结果。这是一个真正棘手的问题，那些未知的东西真的很难预测，因此我更担心这些，尽管两者我都担心。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>会是未知因素吗？你能说出你特别担心的因素吗？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>嗯，那它们就会被归为未知因素。</div><div class=" pTag">尽管我认为短期内的变化会比我们想象的要少，就像其他重大技术一样。但从长远来看，我认为变化会超出我们的预期。我担心社会适应这种全新事物的速度，以及我们花多长时间去找到新的社会契约与我们能够用多长时间做到这一点，我对此感到担忧。</div><h3>奥特曼的优点和最危险的弱点</h3><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>随着事物的快速变化，我们正尝试将恢复力<span>（resilience）</span>作为课程的核心内容之一，而恢复力的基石是自我意识。所以，我想知道你在踏上这段旅程时，是否清楚自己的驱动力。</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>首先，我相信恢复力是可以被教的，恢复力一直是最重要的生活技能之一。在未来的几十年里，恢复力和适应能力会变得更重要，所以我觉得这个观点很好。至于自我意识的问题，我觉得自己是有自我意识的，但就像每个人都认为自己有自我意识一样，我是否真的有，很难从自身角度来评判。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>我能问你我们在自我意识入门课程中经常问的问题吗？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>当然。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>这就像彼得·德鲁克的框架，Sam，你认为自己最大的优点是什么？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>我认为我在许多事情上都不是特别出色，但也在很多方面都还不错。而且我认为在这个世界，广泛的技能被低估了。每个人都在过度专精，所以如果你擅长很多事情，就可以在其中找到联系。我认为这样你就能提出不同于其他人的想法，而不是仅仅成为某个领域的专家。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>你最危险的弱点是什么？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>最危险的弱点，这是个有趣的思考。我倾向于偏向支持技术，可能因为我很好奇，想看看技术的发展方向，而且我相信总体而言，技术是件好事。</div><div class=" pTag">我认为这种世界观总体上对我和其他人都很有利，因此得到了很多积极的反馈。然而，这并不总是对的，而且当它不对时，对许多人来说会产生非常不好的影响。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>哈佛大学心理学家戴维·麦克利兰提出了一个框架，即所有领导者都被三种原始需求之一驱动：归属需求，即被喜欢的需求；成就需求；以及权力需求。如果必须对它们进行排序，你会怎么排？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>在我的职业生涯中，不同时期都有这些需求。我认为人们会经历不同的阶段。而目前，我觉得驱使我前行的是想做一些有意义和有趣的事情。我之前肯定也经历过追求金钱、权力和地位的阶段。</div><div class=" pTag"><strong style="font-weight: 600;">主持人：</strong>你对即将推出的ChatGPT-5最感到兴奋的是什么？</div><div class=" pTag">我还不知道，这个答案听起来有点敷衍。但我认为关于GPT-5或任何我们将其命名的版本，最重要的是它将会更聪明。</div><div class=" pTag">听起来像在逃避，但我觉得这是人类历史上最显著的事实之一：我们能做点什么，并且现在可以以高度科学的确定性说，GPT-5会比GPT-4更聪明得多，GPT-6会比GPT-5更聪明得多。我们还没有到达这个曲线的顶端，我们大致知道该怎么做。它不会只在某一个领域变得更好，也不是总会在这次评估、这个学科或这种模式上表现更好，而是整体上会变得更聪明。我认为这一事实的重大意义仍被低估了。</div><h3>观众提问环节</h3><div class=" pTag">最后，我们也摘录了一些观众提问环节的精彩内容。</div><div class=" pTag"><span><strong style="font-weight: 600;">提问1：</strong></span>随着你们越来越接近AGI，你们打算如何负责任地部署它，以防止抑制人类创新并继续推动创新?</div><div class=" pTag"><span><strong style="font-weight: 600;">奥特曼：</strong></span>我并不担心AGI会抑制人类创新。我真的深信人们会用更好的工具做出更棒的成就。历史都显示，如果给人们更多的杠杆，他们就能做出更神奇的事情。这对我们所有人来说都是一件好事。</div><div class=" pTag">但我确实越来越担心如何负责任地做这一切。随着模型变得更加强大，我们面临的标准也会越来越高。我们已经做了很多事情，比如红队测试和外部审计。这些都很好。但我认为随着模型变得更强大，我们需要更加渐进地部署，并保持更紧密的反馈循环，关注它们的使用情况和发挥效果的领域。</div><div class=" pTag">我们过去可以每隔几年就发布一次大的模型更新，但现在我们可能需要找到方法来增加部署的颗粒度，比较更频繁地进行迭代部署。具体该如何做还不太清楚，但这将是负责任部署的关键。</div><div class=" pTag">此外，我们让所有利益相关者协商人工智能规则的方式，随着时间的推移，这也会变得越来越复杂。</div><div class=" pTag"><strong style="font-weight: 600;">提问2：</strong>&nbsp;你之前提到，每年我们都会有更强大的AI系统。世界上许多地方都不具备建设这些数据中心或大型计算机的基础设施，全球创新会受到怎样的影响？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>关于这个问题，我想分为两部分来谈。</div><div class=" pTag">首先，无论计算机在哪里建造，我认为全球公平地使用计算机进行训练和推理的访问权极为重要。我们使命的核心之一是让尽可能多想要使用ChatGPT的人能够使用它，我们可能无法或出于良好原因不想在那里运营。我们如何考虑使训练计算对世界更加可用，将变得越来越重要。我确实认为我们将进入一个世界，在这个世界里，我们认为获取一定量的计算能力是一种人权。我们得想办法如何将这种能力分配给世界各地的人们。</div><div class=" pTag">然而，还有第二点，那就是我认为各国将越来越意识到拥有自己的AI基础设施的重要性。我们想要找到一种方法，我们现在正花费大量时间周游世界，帮助许多想要建立这些设施的国家。我希望我们能在其中发挥一些微小的作用。</div><div class=" pTag"><strong style="font-weight: 600;">提问3：</strong>您认为人工智能在未来的太空探索或殖民中将扮演什么角色？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>&nbsp;我认为太空显然对生物生活并不友好。因此，如果我们能发送机器人，那看起来更容易。</div><div class=" pTag"><strong style="font-weight: 600;">提问4：</strong>你如何知道一个观点是非共识的？如何验证你的想法有没有得到科技界的共识？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>&nbsp;首先，你真正想要的是正确。持有相反观点但错误仍然是错误的。</div><div class=" pTag">如果你预测了过去两次衰退中的17次，你可能只是在你正确的那两次上持有相反观点。可能并非必然如此。但你其他15次都错了。所以我认为，成为相反意见者过于兴奋是很容易的。再次强调，最重要的是要正确。群体通常是正确的。但当你持有相反观点同时又正确时，价值最大，而这并不总是以非此即彼的方式发生。就像在场的每个人都可能同意AI是创业的正确领域。如果房间里的一个人找出了正确的公司来创立，然后成功地执行了它，而其他人都认为那不是你能做的最好的事情，那才是最重要的。</div><div class=" pTag">至于如何做到这一点，我认为围绕自己建立正确的同行群体非常重要，找到原创思考者也很重要。但你在某种程度上必须独自做这件事，或者至少是独自做一部分，或者与将成为你的联合创始人或其他人的几个人一起做。</div><div class=" pTag">我认为，一旦你在如何找到正确的同行群体这个问题上陷得太深，你已经处于错误的框架中了。学会信任自己和自己的直觉以及自己的思考过程，这随着时间的推移会变得容易得多。无论他们说什么，我认为没有人在刚开始时就真的非常擅长这一点。因为你还没有建立起肌肉，所承受的社会压力和进化压力都与此背道而驰。因此，随着时间的推移，你会越来越好，不要过早地对自己要求太高。</div><div class=" pTag"><span><strong style="font-weight: 600;">提问5：</strong></span>我很想知道你对未来几十年能源需求的变化，以及我们如何实现可再生能源每千瓦时1美分的未来。</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>&nbsp;这一天也许会到来，但我不确定……我猜测最终核聚变将主导地球上的电力生产。我认为它将成为最便宜、最丰富、最可靠、能量密度最高的能源。我可能在这方面是错误的，也有可能是太阳能加上储能。你知道，我最大的猜测是，最终可能是这两种方式中的某一种，并且会有某些情况下其中一种比另一种更好，但这些看起来像是真正全球规模、每千瓦时一美分能源成本的两种主要选择。</div><div class=" pTag"><strong style="font-weight: 600;">提问6：</strong>从OpenAI去年的发生的事中学到了什么，是什么让你能回来？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>&nbsp;我学到的最好的一课是，我们拥有一个非常出色的团队，这个团队完全有能力在没有我的情况下运营公司，并且他们真的在没有我的情况下运营了几天。随着我们向人工通用智能（AGI）的进展，一些疯狂的事情可能会发生，甚至可能会有更多的疯狂事情在我们之间发生。因为世界的不同地区对我们的情感反应越来越强烈，风险也在不断增加。我曾经认为，在很大的压力下，团队会做得很好，但你永远不会真正知道，直到你有机会进行实验。我们有机会进行了这个实验，我了解到团队非常具有韧性，并且准备好了在某种程度上运营公司。</div><div class=" pTag">至于为什么我回来了，你知道，最初当董事会在第二天早上打电话给我，问我是否考虑回来时，我回答说不，我很生气。然后，我思考了这个问题，我意识到我有多么热爱OpenAI，我有多么热爱这些人，我们建立的文化，以及我们的使命。我有点想要和大家一起完成这一切。</div><div class=" pTag"><strong style="font-weight: 600;">提问7：</strong>能谈谈OpenAI这种俄罗斯套娃的结构吗？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>&nbsp;这种结构是逐渐形成的，如果我们可以重新来过，这不会是我会选择的方案。但在我们开始的时候，并没有想到会有一个产品。我们只是打算成为一个人工智能研究实验室。我们甚至都不清楚，我们对语言模型、API或ChatGPT没有任何概念。</div><div class=" pTag">所以，如果你要创办一家公司，你必须有一些理论，认为你总有一天会销售一个产品，而我们当时并没有这样想。我们没有意识到我们会需要这么多钱用于计算，我们也没有意识到我们会拥有这样一个不错的业务。OpenAI创办之初只是打算推进人工智能研究。</div><div class=" pTag"><strong style="font-weight: 600;">提问8：</strong>制造出比人类更聪明的东西是否会让你感到恐惧？</div><div class=" pTag"><strong style="font-weight: 600;">奥特曼：</strong>&nbsp;当然让我感到恐惧。人类随着时间的推移变得越来越聪明、越来越有能力。你比你的祖父母能做的事要多，不是因为个人吃得更好或得到更多的医疗保健，而是社会的基础设施进步，如互联网、iPhone，让大量知识触手可及。</div><div class=" pTag">社会就是一个AGI系统，并不是某个人的大脑所能左右的，是所有人一砖一瓦搭建起来，为后来者创造更高的成就，你的孩子将拥有你没有的工具。</div><div class=" pTag">这总是有点吓人。但我认为，好的方面要比坏的方面多得多。未来的人们将能够使用这些新工具解决更多的问题，</div><h2>One More Thing</h2><div class=" pTag">不知道奥特曼接下来几天还会到访哪些高校，不过整个旅程可能会在5月9日之前结束。</div><div class=" pTag">从泄露的文件可以看出，OpenAI设置了search.chatgpt.com子域名。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCLqq3cRRB68fqibTDMHC4oQIBx9O54uMiaiaPAuItN5DkQ4Gp0lCRGVicfyqE9t991knia0vkZXicC1zcQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">预计会在5月9日发布AI搜索功能。</div><div class=" pTag">目前，相关功能网页前端代码和设置界面已经泄露。<span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span></div><div class=" pTag">可能包括图片搜索、小组件（天气、计算器、体育、股票、时区计算）。<span style="display: none;">‍</span><span style="display: none;">‍</span></div><div class=" pTag">可选用GPT-4 Lite、GPT-4、GPT3.5等不同模型。<span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCLqq3cRRB68fqibTDMHC4oQ4Y7E0gZ5iaBN4Esu4yXOZExVwRJHHQwnptMicCXY0Pj7bicu7ToXdtuWQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://www.youtube.com/watch?v=GLKoDkbS1Cg</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://news.harvard.edu/gazette/story/2024/05/did-student-or-chatgpt-write-that-paper-does-it-matter/</span><br /><span style="font-size: 17px;">[3]</span><span style="font-size: 17px;">https://www.technologyreview.com/2024/05/01/1091979/sam-altman-says-helpful-agents-are-poised-to-become-ais-killer-function</span><br /><span style="font-size: 17px;">[4]</span><span style="font-size: 17px;">https://twitter.com/RishabJainK/status/1785807873626579183</span><br /><span style="font-size: 17px;">[5]</span><span style="font-size: 17px;">https://twitter.com/moreisdifferent/status/1785759129056743632</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fnq9oMj6HcbVGKeDu3zjcOw">阅读原文 </a>
]]></content:encoded>
<pubDate>Fri, 03 May 2024 04:42:25 GMT</pubDate>
</item>
<item>
<title>Claude iOS版本突然推出！11MB大小，体验丝滑，网友呼吁语音功能快上线</title>
<link>https://posts.careerengine.us/p/663319b7e528ff5556d4c7f8</link>
<guid>https://posts.careerengine.us/p/663319b7e528ff5556d4c7f8</guid>
<content:encoded><![CDATA[
<div> iOS版本, Anthropic, Claude, 官方, 功能<br />
<br />
总结: Anthropic官方推出了Claude的iOS版本，用户反应积极。用户希望完善功能，体验流畅但图像读取精度仍有待提高。同时，谷歌更新了Gemini，允许使用扩展程序，用户可以在Gemini上进行多种操作。衡宇白交 发自凹非寺量子位公众号QbitAIClaude提供了下载方式和功能，用户需iOS 17.0或更高版本方可使用。团队计划推出，用户可组团使用Claude。待App功能不断完善，带来更好体验。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">衡宇 白交 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">Claude，深夜突然大放送<span><strong style="font-weight: 600;">iOS版本</strong></span>！</div><div class=" pTag"><span style="font-size: 17px;">就在几小时前，Anthropic官方突然给家人们送福利，官宣Claude</span><span><span style="font-size: 17px;">正式推出iOS APP，只有11MB。</span></span></div><div class=" pTag">如此一来，可真像其官方说得那样：</div><div class=" pTag">“前沿情报的力量，现在就在你的口袋里。”</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhV1LJwTWIx7yzSK2WAUaOt6NiaSmoEnDial8s1VIdrE6NxicnA03tPCcUjA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">虽然Claude的手机版本上线显得有些姗姗来迟——去年5月，其最大劲敌OpenAI就推出了iOS APP，但大多数用户们显然还是很开心这一操作。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">太太太太太感谢了！网页端用起来还是有诸多不便。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVEmBtWRQMKoQdKcFBY7RMGpkY70RSiauwiazibYsHZn7R5hHoLoajpYlVA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">以及还有不少朋友们开始催更，让官方赶紧把App逐渐完善起来。</div><div class=" pTag">“<span><strong style="font-weight: 600;">不要忘了上线安卓版</strong></span>啊喂！”“我们需要<span><strong style="font-weight: 600;">语音功能</strong></span>，急急急急急急急。”</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhV934zDGXLY5hsOTTX6QrTZWETGibq4Zo6Dibd59ibiaG0G4VYMnM8GuwZHg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">当然了一片吵闹之中，还是有盲生发现了华点：</div><div class=" pTag">咱就是说，上线iOS版真的很不错，但Anthropic你为啥要用屁眼当logo啊？我黑人问号？？？</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVFWueLjUkDibnPwfVqXAoAOlh6m9oz45J2GOQjk6UT0F0FxoPxkHicZ4w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>下载App需要一些小技巧</h2><div class=" pTag">先来个<strong style="font-weight: 600;">高亮提醒</strong>，这次Claude上线iOS后，下载方式需要一点小技巧。</div><div class=" pTag">如果直接在AppStore<span>（美区）</span>搜索框输入Claude，出来的只有一堆套壳玩意儿，甚至还有对家产品，但搜索结果页往下拉很久都不见Claude本尊踪影。</div><div class=" pTag">只能搜索公司名“<span><strong style="font-weight: 600;">Anthropic pbc</strong></span>”，才能一搜必中，弹出Claude。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVlZS65mxfljKLZ3j27OmTZhvMTJ2nEHr8zcKw8cXEBn21VIUw1vqmOA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">而且“pbc”三个字母还不能省略，否则还是搜不出来。</div><div class=" pTag">emmmm，不知道为啥会这样，希望后期尽快修复吧。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVexOajbqMJmvFWSKMdKhtfz8P95oe8ic7r4oRpgKnO1wp98ibj3vIbfhg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">言归正传，官方给出的Claude iOS版本功能如下：</div><ul class="list-paddingleft-1"><li><div class=" pTag">主要功能：包括<strong style="font-weight: 600;">与网络聊天无缝同步</strong>，让您可以继续跨设备聊天。</div></li><li><div class=" pTag"><strong style="font-weight: 600;">视觉功能</strong>：允许您随时随地使用照片、拍摄新照片、上传文件以及执行实时图像分析和态势感知。</div></li><li><div class=" pTag">为包括Pro和Team在内的所有计划的用户提供开放访问，免费下载该应用程序。</div></li></ul><div class=" pTag">等等，Team功能是什么？</div><div class=" pTag">好，原来这次Anthropic是二连更，不仅推出了Claude的苹果端App，还推出了<strong style="font-weight: 600;">团队计划</strong>。</div><ul class="list-paddingleft-1"><li><div class=" pTag">每位用户每月30美元起，团队成员可以显着增加聊天次数</div></li><li><div class=" pTag">多种Claude 3型号可供选择，包括Opus<span>（目前最强版本）</span>、Sonnet、Haiku等。</div></li><li><div class=" pTag">20万个上下文窗口支持长文档处理和复杂主题讨论，管理工具让计费管理变得简单。</div></li></ul><div class=" pTag">简单来说，就是大伙儿可以组团使用Claude了。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhV0cickaK4jribXz4FlDrXTVTR748KLxFnO9O5xG70u0JjQkyiaMk7ODldg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">最后补一句，请注意，需要<span><strong style="font-weight: 600;">iOS 17.0或更高版本</strong></span>才能使用它。</div><h2>那咱们可就上手了</h2><div class=" pTag">说时迟那时快，手快的网友已经深度体验了一番Claude的iOS版本。</div><div class=" pTag">有人夸它界面干净：</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVASSBl1QNaUbEOpEdgia2icuxyvt7DYZyDbdplgibIylHTEGfH1fP64ZhA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">整体而言，反应迅速，使用体验很流畅。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVHYQpCsa3fdgjVNIg4CTbc1kdPXicg7h5Vp7dFHricxfxibr57pBUdY6dA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">因为手机用起来更顺手，所以有人说比网页版本体验还好。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVTD4NbpeuqcUGYf2IvD4DjSmQ9a2mC8JkWtnWAKg7THmKvS08PngK8A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">写代码？没问题：</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVbDyQtC6libfZEnTlq2dMaY9ialicT2bz5bDia1RhfDibfPfxo5lBibiaWlYgw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不过老毛病，<span><strong style="font-weight: 600;">图像读取精度仍然有些一言难尽</strong></span>：</div><div class=" pTag"><div class=" ce-iframe-holder offset offset-old-111"></div></div><div class=" pTag">而且正如网友呼唤的那样，目前初代版本比较简陋，只有账号系统、聊天、文件上传功能，语音功能什么的都没赶上趟。</div><h2>One More Thing</h2><div class=" pTag">与此同时，<span><strong style="font-weight: 600;">谷歌更新了Gemini</strong></span>。</div><div class=" pTag">现在，每个人都可以在Gemini使用油管、地图等扩展程序了。</div><div class=" pTag">大家可以在Gemini上用油管视频聊天、计划旅行、管理电子邮件等。</div><div class=" pTag">大家可以一起试一试，欢迎吧一首使用体验反馈在评论区哟～</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVA3hvbk3hVricsdHRClhPQ7XRzEfOUnBq1Dvic2rqeIFH200icnsws8obA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://twitter.com/AnthropicAI/status/1785701418546180326</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://twitter.com/FinanceYF5/status/1785838660656464282</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FMGDvXInNLTpq2HA-nNIgsw">阅读原文 </a>
]]></content:encoded>
<pubDate>Thu, 02 May 2024 04:42:31 GMT</pubDate>
</item>
<item>
<title>人大卢志武：只要拿到更多算力，超过Sora也不是那么难的事｜中国AIGC产业峰会</title>
<link>https://posts.careerengine.us/p/663319b6e528ff5556d4c7f0</link>
<guid>https://posts.careerengine.us/p/663319b6e528ff5556d4c7f0</guid>
<content:encoded><![CDATA[
<div> VDT、Transformer、时空掩码、消融实验、算力
<br />
<br />
总结:
VDT团队在视频生成领域使用Transformer模型，结合Diffusion优点，采用时空分离注意力机制，通过token concat方式处理输入条件，设计统一的时空掩码机制。消融实验表明模型效果与训练消耗的计算资源正相关，算力越大效果越好。团队探索了物理世界模拟，并发现VDT对物理规律模拟效果良好，在写真视频生成方面超过了Pika和Sora。团队认为只要获得更多算力，超过Sora不是难事。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">编辑部 整理自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">一支人大系大模型团队，前后与OpenAI进行了三次大撞车！</div><div class=" pTag">第一次是与Clip，第二次是与GPT-4V，最新一次撞在了Sora上：</div><div class=" pTag">去年5月，他们联合并联合伯克利、港大等单位于在arXiv上发表了关于<span><strong style="font-weight: 600;">VDT</strong></span>的论文。</div><div class=" pTag">那时候，该团队就在在技术架构上提出并采用了Diffusion Transformer。并且，VDT还在模型中引入统一的时空掩码建模。</div><div class=" pTag">这个团队，正由中国人民大学高瓴人工智能学院教授<strong style="font-weight: 600;">卢志武</strong>带队。</div><div class=" pTag">Sora问世已经两个多月，现在这支国产团队在视频生成领域的进度怎么样了？什么时候我们能迎来国产Sora的惊艳时刻？</div><div class=" pTag">在本次中国AIGC产业峰会上，卢志武对上述问题进行了毫无保留的分享。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4ViaKQSBhNk9te2CCo45bsU6JSNcwLgkUvP7I9CccicTYGPXPWicCs2hJA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">为了完整体现卢志武的思考，在不改变原意的基础上，量子位对演讲内容进行了编辑整理，希望能给你带来更多启发。</div><div class=" pTag">中国AIGC产业峰会是由量子位主办的行业峰会，20位产业代表与会讨论。线下参会观众近千人，线上直播观众300万，获得了主流媒体的广泛关注与报道。</div><h2>话题要点</h2><ul class="list-paddingleft-1"><li><div class=" pTag">VDT使用Transformer作为基础模型，能更好地捕捉长期或不规则的时间依赖性；</div></li><li><div class=" pTag">Scaling Law是视频生成模型从基于Diffusion model转向基于Transformer的重要原因；</div></li><li><div class=" pTag">VDT采用时空分离的注意力机制，而Sora采用时空合一的注意力机制；</div></li><li><div class=" pTag">VDT采用token concat方式，实现快速收敛和良好效果；</div></li><li><div class=" pTag">消融实验发现，模型效果与训练消耗的计算资源正相关，计算资源越多，效果越好；</div></li><li><div class=" pTag">只要拿到更多算力，超过Sora也不是那么难的事。</div></li></ul><div class=" pTag">……</div><div class=" pTag">以下为卢志武演讲全文：</div><h2>为什么做视频生成突然要转到用Transformer上？</h2><div class=" pTag">今天的报告，我将重点介绍我们在视频生成领域的工作，特别是<span><strong style="font-weight: 600;">VDT</strong></span><span>（Video Diffusion Transformer）</span>。</div><div class=" pTag">这项工作已于去年5月发布在arXiv上，并已被机器学习顶级会议ICLR接收。接下来，我将介绍我们在这一领域取得的进展。</div><div class=" pTag">众所周知，Sora非常出色，那么它的优势在哪里呢？之前，所有的工作都是基于Diffusion Model，那为什么我们在视频生成中突然转向使用Transformer呢？</div><div class=" pTag"><span><strong style="font-weight: 600;">从Diffusion到Transformer的转变</strong></span>，原因如下：</div><div class=" pTag">与基于U-net的Diffusion模型不同，Transformer具有许多优点，如token化处理和注意力机制，这两个特点使其能够更好地捕捉长期或不规则的时间依赖性。因此，在视频领域，许多工作开始采用Transformer作为基础模型。</div><div class=" pTag">然而，这些都是表面现象，最根本的原因是什么呢？使用Transformer进行视频生成，是因为其背后的scaling law发挥了作用。</div><div class=" pTag">Diffusion Model的模型参数量是有限的，而一旦将Transformer作为基础模型，参数量可以随意增加，只要有足够的计算能力，就可以训练出更好的模型。实验证明，只要增加计算量，效果就会得到提升。</div><div class=" pTag">当然，视频生成涉及各种任务，使用Transformer能够将这些任务统一在一个架构下。</div><div class=" pTag">基于上面三个原因探索用Transformer当视频生成的底座，这是我们当时的考虑。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4LQiaRAYkmZpC2ahxCUXfmIZMtuoQVAw6JaQuD1ibGNIvWoBjzSaRJTMQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">我们的<span><strong style="font-weight: 600;">创新点有两个</strong></span>：</div><div class=" pTag">一是将Transformer应用于视频生成，并结合了Diffusion的优点；二是在建模过程中，我们考虑了统一的时空掩码建模，将时间和空间置于同等重要的位置。</div><div class=" pTag">无论是VDT还是Sora，第一步都是对视频进行压缩和token化处理。</div><div class=" pTag">这与基于DM的方法最大的区别在于，基于DM的方法只能进行空间压缩，无法进行时间压缩；而现在，我们可以同时考虑时间和空间，实现更高的压缩程度。</div><div class=" pTag">具体来说，我们需要训练一个时空空间中的3D量化重构器，这可以作为tokenizer，得到三维空间中的patches。</div><div class=" pTag">总之，通过这种方式，我们可以得到Transformer的输入，输入实际上是3D的tokens。</div><div class=" pTag">一旦我们将输入的视频进行token化处理，就可以像通常的Transformer一样，使用标准的Transformer架构对3D的token序列进行建模，细节我就不赘述了。</div><h2>VDT和Sora有什么差别？</h2><div class=" pTag">VDT模型中最重要的部分是<span><strong style="font-weight: 600;">时空的Transformer Block</strong></span>。</div><div class=" pTag">我们与Sora有一点不同，当时设计这个Block时，我们将时空的Attention分开了。高校团队没有OpenAI那么多的计算资源，这样分开后，所需的计算资源会少很多——除此之外，其他所有设计都一模一样。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4m7BNEiajBicG3uIvqnXGtGGyNicRBgicFIaTGc47qLGL5e2pU6avEib3SPw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">现在，让我们来看看我们与Sora的区别。</div><div class=" pTag">刚才我说过，VDT采用了时空分离的注意力机制，空间和时间是分开的，这是在计算资源有限的情况下的折中方案。</div><div class=" pTag">Sora采用的是时空统一的token化，注意力机制也是时空合一的，我们推测Sora强大的物理世界模拟能力主要来自于这个设计。</div><div class=" pTag">至于输入条件不同，这不是VDT与Sora最大的区别，基本上图生视频能做好，文生视频也能做好。</div><div class=" pTag">文生视频的难度较大，但并非无法克服，没有本质上的差别。</div><div class=" pTag">接下来，我将介绍我们当时探索的一些事项。架构设计完成后，我们特别关注输入条件。这里有C代表的Condition Frame，以及F代表的Noisy Frame。</div><div class=" pTag">这两种输入条件应该如何结合，我们探索了三种方式：</div><ul class="list-paddingleft-1"><li><div class=" pTag">通过Normalization的方式；</div></li><li><div class=" pTag">通过token concat的方式；</div></li><li><div class=" pTag">通过Cross attention。</div></li></ul><div class=" pTag">我们发现，这三种方式中，<span><strong style="font-weight: 600;">token concat的效果最佳</strong></span>，不仅收敛速度最快，而且效果最好，因此VDT采用了token concat方式。</div><div class=" pTag">我们还特别关注了<span><strong style="font-weight: 600;">通用时空掩码机制</strong></span>。</div><div class=" pTag">不过，由于Sora没有公布细节，我们不清楚它是否也采用了这个机制，但在模型训练过程中，我们特别强调了设计这样的掩码机制，最终发现效果非常好，各种生成任务都能顺利完成——我们发现Sora也能达到类似的效果。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4kRvaDiblpw5ck1GDmOJQMAO7ug009f1MV41U4hCNFcekbkICOQ0TWzw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">消融实验特别有趣，无论是Sora还是VDT，有一个非常重要的问题，就是模型中有大量的超参数，这些超参数与模型密切相关，不同的参数会对模型的效果产生很大影响。</div><div class=" pTag">然而，通过大量实验验证，我们发现超参数的选择有一个规律，即<span><strong style="font-weight: 600;">如果超参数使得模型的训练计算量增加，那么对模型效果是有益的</strong></span>。</div><div class=" pTag">这意味着什么？我们模型的性能只与其背后引入的计算量有关，模型训练所需的计算资源越多，最终的生成效果就越好，就这么简单。</div><div class=" pTag">这个发现与DiT类似，DiT被称为Sora的基础模型，它是用于图片生成的。</div><div class=" pTag">总之，消融实验是Sora或我们工作中最重要的事情之一，我们模型的效果只与训练消耗的计算资源有关，消耗的计算资源越大，效果越好。</div><h2>有更多算力，超过Sora不是太难</h2><div class=" pTag">考虑到我们的计算资源确实有限，我们团队在模型训练规模上，肯定不能与OpenAI相比。但是，我们也进行了一些深入的思考。</div><div class=" pTag">物理世界模拟本身就在我们的论文中，并不是说这是OpenAI首先想到的，我们一年前就想到了。</div><div class=" pTag">当时有这个底座以后，很自然想到这样模型到底能不能进行物理规律模拟。后来在物理数据集上训练了一下VDT，发现它对简单的物理规律模拟得特别好。</div><div class=" pTag">比如，这些例子有抛物线的运动，加速运动，还有碰撞的运动，模拟得都还可以。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4ayZ7wUDb5h5ktW78KpoWw7jxEgC2L5TCPVCV06qNnjqDt3ykFdHLcg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">所以我们当时做了两个在思想上特别有前瞻性的事情，一个是当时我们想到Diffusion Transformer用到视频生成里面，第二个是我们得到了这样模型以后，我们当时觉得这就是做物理世界模拟很好的模型，我们做实验验证了这个事情。</div><div class=" pTag">当然，如果我们有更多的算力，我们有更多的数据，我相信肯定可以模拟更复杂的物理规律。</div><div class=" pTag">我们这个模型也跟现在有模型做了对比，比如人像生成，给一张写真的照片让它动起来，我们只考虑做这个小的事情，因为我们算力特别有限。</div><div class=" pTag">这些结果表明VDT比Stable Video Diffusion要好一些，你可以看看生成得人物眼睛眨的更明显一些，更自然一点。另一个模型生成有点不太自然。</div><div class=" pTag">此外，如果人脸从侧面转成正脸，甚至用扇子把脸遮住了，要把人脸预测出来，还是挺难的。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU464AVc5Ly1z332XVrsIKEmgBIKdcNM04XoEOKIhx3soRLv54vPOcebQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">关于这个写真视频是怎么做的我简单说一下。</div><div class=" pTag">先提供几张写真的照片，VDT把每一张写真照片变成两秒的镜头，通过剪辑的方式把镜头拼在一起。</div><div class=" pTag">结合我们团队本身的特点，如果说我做通用的模型，我肯定做不过市面上的大部分，但是我当时挑了一个应用点，在这个点上VDT并不比Sora差。</div><div class=" pTag">Sora出来以后很多人要做视频生成，我要考虑怎么保证我的团队在这个方向上，哪怕很小的一个点保持世界最前沿。</div><div class=" pTag">因此，我们做了写真视频生成，国外的Pika、Sora也研究了一下。VDT生成的超写实人物，是超过Pika和Sora的。在通用的视频生成我们很难超过Sora，这里的主要原因是我们算力很有限。</div><div class=" pTag">只要拿到更多算力，超过Sora也不是那么难的事。</div><div class=" pTag">我就讲这么多，谢谢大家。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FhIofDHgs51BXNpQzIYgiYQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Thu, 02 May 2024 04:42:30 GMT</pubDate>
</item>
<item>
<title>全新神经网络架构KAN一夜爆火！200参数顶30万，MIT华人一作，轻松复现Nature封面AI数学研究</title>
<link>https://posts.careerengine.us/p/663319a7b6330f550dfe6122</link>
<guid>https://posts.careerengine.us/p/663319a7b6330f550dfe6122</guid>
<content:encoded><![CDATA[
<div> KAN、神经网络、参数、灾难性遗忘、学习算法<br />
<br />
总结:<br />
新型神经网络架构KAN与传统的MLP架构不同，能在数学、物理问题上以更少的参数取得更高精度，甚至发现新的公式。KAN在处理函数拟合、偏微分方程求解等任务上表现更好，且天然避免灾难性遗忘问题。灵感来自于Kolmogorov-Arnold表示定理，KAN放可学习的激活函数在权重上，提供了更好的可解释性和交互性。虽然训练速度慢，但可以通过经验实现缩放速度更快，并在凝聚态物理等科学任务中表现良好。是否能替代Transformer的MLP层仍需进一步研究。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">白交 衡宇 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag"><strong style="font-weight: 600;">一种全新的神经网络架构KAN，诞生了！</strong></div><div class=" pTag">与传统的MLP架构截然不同，且能用更少的参数在数学、物理问题上取得更高精度。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhViavtyI794V2Yddy2IdiaIFSFNJP3yccwLSzglkN5NJ5rLlxJ5AxhMUhg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">比如，200个参数的KANs，就能复现DeepMind用30万参数的MLPs发现数学定理研究。</div><div class=" pTag">不仅准确性更高，并且还发现了新的公式。要知道后者可是登上Nature封面的研究啊~</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhViasthvRicjLSxW2fAszGnF5j20f7iaibXmNprHWNVt6MJiaHGTfVylicseSw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">在函数拟合、偏微分方程求解，甚至处理凝聚态物理方面的任务都比MLP效果要好。</div><div class=" pTag">而在大模型问题的解决上，KAN天然就能规避掉灾难性遗忘问题，并且注入人类的习惯偏差或领域知识非常容易。</div><div class=" pTag">来自MIT、加州理工学院、东北大学等团队的研究一出，瞬间引爆一整个科技圈：<strong style="font-weight: 600;">Yes We KAN！</strong></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVYk7PO0iamkWPRLResiaEpZdmQZ5aKHD7PwAZ34xZgOsS9T5U8uSyHmOA/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhV1ibQic6tfibSeU2Dyk0IuNfpIicLiaBeKRpDl09xSfB8chCa6CYGdcVxNkA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">甚至直接引出关于<strong style="font-weight: 600;">能否替代掉Transformer的MLP层</strong>的探讨，有人已经准备开始尝试……</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVia8pBKwBycvERibYBypkGqUxVqicb0WqFEwQLtTfGMj9owlQzgRLbGmog/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVmtSrpnDticfLdF6BUrROwgmtyXMdJTS5nt8kgzm5YHEHsZ3hedwicZVA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">有网友表示：<strong style="font-weight: 600;">这看起来像是机器学习的下一步</strong>。</div><blockquote><div class=" pTag">让机器学习每个特定神经元的最佳激活，而不是由我们人类决定使用什么激活函数。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhV7D32bj9jmJic9kiaXWB0n17CnaeB8XkoZ3hPGVk3yqbGhPtUtDmAJNBg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">还有人表示：可能正处于某些历史发展的中间。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVs8wU7TbRUJE9lIu4JKCNdrh6LbicicUaRLia2veXYrSJ5W197fSxAGoIw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">GitHub上也已经开源，也就短短两三天时间就收获1.1kStar。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVAZAtRfsskYNlvkHtwLWvXia6tORmYaHwGL9l22Oia09K0DP8FPI2GxyQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>对MLP“进行一个简单的更改”</h2><div class=" pTag">跟MLP最大、也是最为直观的不同就是，MLP激活函数是在神经元上，而KAN把可学习的激活函数放在权重上。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVhVFDwagbEgXU18MDPWzIYibtw4bsLqz3wt9r2vujIG2N6bOuZDO7kIA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">在作者看来，这是一个“简单的更改”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVX4RVfxffsEKWz4FDeSBwcZ65IJoAQrzDTWqEfhicwoyicGRyebmZPetg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">从数学定理方面来看，MLP的灵感来自于通用近似定理，即对于任意一个连续函数，都可以用一个足够深的神经网络来近似。</div><div class=" pTag">而KAN则是来自于 Kolmogorov-Arnold 表示定理 (KART)，每个多元连续函数都可以表示为单变量连续函数的两层嵌套叠加。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVcxmdkSwS6rJDye3fBz5GibL6EslnhMclBFykmkopcGtU2klFGhvfELw/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /></div><div class=" pTag">KAN的名字也由此而来。</div><div class=" pTag">正是受到这一定理的启发，研究人员用神经网络将Kolmogorov-Arnold 表示参数化。</div><div class=" pTag">为了纪念两位伟大的已故数学家Andrey Kolmogorov和Vladimir Arnold，我们称其为科尔莫格罗夫-阿诺德网络（KANs）。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVVxBgD3OfibBb8uvDwJhBCw01HfOuH1uMg0Nt3seh0ZO7XG3GbSbchxQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">而从算法层面上看，MLPs 在神经元上具有（通常是固定的）激活函数，而 KANs 在权重上具有（可学习的）激活函数。这些一维激活函数被参数化为样条曲线。</div><div class=" pTag">在实际应用过程中，KAN可以直观地可视化，提供MLP无法提供的可解释性和交互性。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVWweWX6gdm9OXjaN6HuKDWslC8RicfRRcCq3iaSqL422ylyVFXKuUGqwQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不过，KAN的缺点就是训练速度较慢。</div><div class=" pTag">对于训练速度慢的问题，MIT博士生一作Ziming Liu解释道，主要有两个方面的原因。</div><div class=" pTag">一个是技术原因，可学习的激活函数评估成本比固定激活函数成本更高。</div><div class=" pTag">另一个则是主观原因，因为体内物理学家属性抑制程序员的个性，因此没有去尝试优化效率。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhV1uNX8Xa4fztVjTABictZtuMVGz6n0k7Vf9oCicicOa8leOiaJbxAYEyscw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">对于是否能适配Transformer，他表示：暂时不知道如何做到这一点。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVE0Nfs8HdNIm4ria1GeHuHBwLm6dvkusTus0XSLRa3O10tpE7icP0Nmrw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">以及对GPU友好吗？他表示：还没有，正在努力中。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVicvBR2IcHRkOl8SSVib2coxh1CtqA2Mxiadm68004uHO6K1QWocrmnh0Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>天然能解决大模型灾难性遗忘</h2><div class=" pTag">再来看看KAN的具体实现效果。</div><div class=" pTag"><strong style="font-weight: 600;">神经缩放规律</strong>：KAN 的缩放速度比 MLP 快得多。除了数学上以Kolmogorov-Arnold 表示定理为基础，KAN缩放指数也可以通过经验来实现。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVOmMUcRXMClO8cT6NBUGianBia6bLdRZXZD7SCZBMvol1wnicr3S4YK5Ng/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">在<strong style="font-weight: 600;">函数拟合</strong>方面，KAN比MLP更准确。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhV8gurwuHCHiaKphcjDWTojJvAlKV8aTkV1wARLdx26vqFdricOMz2zibOA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">而在<strong style="font-weight: 600;">偏微分方程求解</strong>，比如求解泊松方程，KAN比MLP更准确。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVebGK4cL8FRibU6g29tRTDAlNmGzicX5ssYJRnXTXow3SZraLSpOvh5zg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">研究人员还有个意外发现，就是KAN不会像MLP那样容易<strong style="font-weight: 600;">灾难性遗忘</strong>，它天然就可以规避这个缺陷。</div><div class=" pTag"><span>好好好，大模型的遗忘问题从源头就能解决</span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVS7PadteoiaGDuJZt026gGPMSjlAj4EGmereACfUBEh2GV3pibjOYyycw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在可解释方面，KAN能通过符号公式揭示合成数据集的组成结构和变量依赖性。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVvwX199K59BAaINelJfnome9BsNOhVEyNPfibuJrmagm2QUIdnWbDhhA/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /></div><div class=" pTag">人类用户可以与 KANs 交互，使其更具可解释性。在 KAN 中注入人类的归纳偏差或领域知识非常容易。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVAKNf4NJyNevlCTTbsCeFNRKicj0ZtYE1XxVOT3UpHlwbibOon0YAPFEg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">研究人员利用KANs还重新复现了DeepMind当年登上Nature的结果，并且还找到了Knot理论中新的公式，并以无监督的方式发现了新的结不变式关系。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVNeqEJjyx47PPVVCVDfEzSw7YlnibEMUicOZS1avn3RV5kUx6TWad5ZCg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVues0DFTSuqQCFrribpE1L96YE7m4Sic90Vrqb7oJVvKiandSzvuAiajBcQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>DeepMind登Nature研究成果</h6><div class=" pTag">Deepmind的MLP大约300000 个参数，而KAN大约只有200 个参数。KAN 可以立即进行解释，而 MLP 则需要进行特征归因的后期分析。并且准确性也更高。</div><div class=" pTag">对于计算要求，团队表示论文中的所有例子都可以在单个CPU上10分钟内重现。</div><div class=" pTag">虽然KAN所能处理的问题规模比许多机器学习任务要小，但对于科学相关任务来说就刚刚好。</div><div class=" pTag">比如研究凝固态物理中的一种相变：安德森局域化。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVRCkM50oLOfD5IdbyoZrCOdy0POQVZkjA64eMhM6DnmviauyibicaRibdnA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">好了，那么KAN是否会取代Transformer中的MLP层呢？</div><div class=" pTag">有网友表示，这取决于两个因素。</div><div class=" pTag">一点是学习算法，如 SGD、AdamW、Sophia 等—能否找到适合 KANs 参数的局部最小值？</div><div class=" pTag">另一点则是能否在GPU上高效地实现KANs层，最好能比MLPs跟快。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVAy75q7JyrMlqSBx8sox94dd69LK8Uhevxu0BN721En2YdKIEtJxWgw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">最后，论文中还贴心的给出了“何时该选用KAN？”的决策树。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC8hERa3N5OZw5cT1eHzRhVia2oWjaYLRtuYcAKR9zDiaE3LNlNXyey6XuEU5RyRibJruQicgKpQrKgZg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么，你会开始尝试用KAN吗？还是让子弹再飞一会儿~</div><div class=" pTag"><span style="font-size: 17px;"><span>项目链接：</span><br /><span>https://kindxiaoming.github.io/pykan/</span></span><br /><span style="font-size: 17px;"><span>论文链接：</span><br /><span>https://arxiv.org/abs/2404.19756</span></span><br /><span style="font-size: 17px;"><span>参考链接：</span><br /><span>[1]https://twitter.com/ZimingLiu11/status/1785483967719981538</span></span><br /><span style="font-size: 17px;">[2]https://twitter.com/AnthropicAI/status/1785701418546180326</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5WFJMPJvtaofeGDxFQ9aDw">阅读原文 </a>
]]></content:encoded>
<pubDate>Thu, 02 May 2024 04:42:15 GMT</pubDate>
</item>
<item>
<title>消费级显卡轻松跑AI，英伟达RTX领跑AI PC竞争</title>
<link>https://posts.careerengine.us/p/6631cc7398dbe00ebf17f8a0</link>
<guid>https://posts.careerengine.us/p/6631cc7398dbe00ebf17f8a0</guid>
<content:encoded><![CDATA[
<div> 英伟达、RTX、AI PC、硬件性能、软件优化
<br />
<br />
总结: 英伟达利用消费级AI PC显卡领跑PC竞争市场，强调硬件性能和软件优化的重要性。消费级显卡在AI应用中已经足够，但需要软件配合优化。英伟达的Tensor RT加速框架能提高算力利用效率。不同行业的专家如建筑师和数字艺术家都在AI PC平台上获得了加速优势，展现出AI在生活和工作中的巨大潜力。AI PC的普及让更多社区和创作者有机会参与AI技术的发展，开启了更广阔的创作空间。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">AI PC的竞争，越来越火热了！</div><div class=" pTag">就连数据中心收入占比达到四分之三的英伟达，也用<strong style="font-weight: 600;"><span>消费级</span></strong>的AI PC显卡领跑这场战斗。</div><div class=" pTag">换言之，老黄在做工业级“核弹”的同时，在RTX这样的消费级产品中，也要全力发展AI运算。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzdBOuQb9C7LdibDl7kwV23AvfhaeUYogcYtxl8yHTEN2bC5JffPFs2wQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而且规模还不小，据介绍，RTX AI PC目前已成为拥有超过1亿用户和<span><strong style="font-weight: 600;">500款AI应用和游戏</strong></span>的生态。</div><div class=" pTag">在RTX AI PC的一场技术品鉴会中，量子位也体验到了英伟达AI算力在消费级显卡上的应用。</div><h2>更高效地利用算力，需要软硬件配合</h2><div class=" pTag">古语有云，“工欲善其事，必先利其器”，对于AI创作者而言，选择高性能的运算设备是无比重要的。</div><div class=" pTag">当然了，也并不是说就要直接上专业卡，对于单纯的创作来说，消费级的显卡已经足够。</div><div class=" pTag"><span><strong style="font-weight: 600;">吐司</strong></span>是一家大型在线生图的AI模型社区，提供了包括超16w+的模型 在内的AI 模型资源。</div><div class=" pTag">最近，吐司使用第三方测试软件UL Procyon AI基准，完整测试了英伟达RTX 40系列多款型号的显卡和笔记本电脑的生图能力。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzrbWQR7chHQsnoMicxXqcXIp6HnxPCZRmm9fqS28LCrQm1PjDPptsKKg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">相比于集成显卡，在同时开启两个厂商加速框架的情况下，笔记本版的4090在运行SD 1.5的UL Benchmark时，<strong style="font-weight: 600;"><span>性能超出了27倍</span></strong>。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzljHDbB2qSA3ic4Ox1wjg8ueibCeAtiaaFvCqaCmczaH2LISk6vJqIpa1Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">但做AI运算，单靠硬件性能是不够的，软件程序需要针对硬件特征做专门的优化，才能更高效地利用硬件资源，用相同的配置实现更高的推理速度。</div><div class=" pTag">比如英伟达的<strong style="font-weight: 600;"><span>Tensor RT</span></strong><span>（简称TRT）</span>加速框架，就起到了让模型更好适配显卡中的Tensor Core，从而实现更高运算性能的作用。</div><div class=" pTag">同样在吐司的测试当中，对于RTX 40系列的各种显卡，开启TRT前后，无论是运行SD1.5还是SDXL，每分钟生成图片的数量均有显著提升，其中4090D的SD 1.5生成速度达到了每秒54.55张图。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz08IyJicR8I9zvg1a4rKbedE2mXViaVkh5ghsVQUCgRCMdibM1jZRBVx8A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而如果改用StreamDiffusion，同时忽略硬盘读写带来的降速，在4090D上开启TRT，最快可达到每秒128张图。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz9g7B7puibCAzzNnNgK0ic9icL2LUuVTqCRfCNmia4NOwR0916Bxic2o1LFw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在实际环境中，这个速度会被硬盘拖慢，最终的速度大约是每秒八张，但TRT依然是当下最快的Stable Diffusion加速方式。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzKdp4ibmPdQAe1OEqHbxfSP4lBPS6QeicL7u7vXROdhfgTygKnoBW2iaZA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不过需要说明的是，对于内容生成而言，单纯速度快并不等于直接的生产力提升。</div><div class=" pTag">那么，这样的速度优势又该如何利用起来呢？</div><h2>速度不能直接变成生产力，还要与工作特点结合</h2><div class=" pTag">要想把生成速度变为生产力，关键不仅在于技术，更在于与行业工作特点的充分结合。</div><div class=" pTag">比如在建筑行业，<strong style="font-weight: 600;">即致AI</strong>就基于扩散模型和蒸馏技术，通过RTX 4090 D GPU的加速，实现了秒级的AI实时绘画，实时将手绘草稿绘制成建筑效果图。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz6ID36C6xuvpUXvxicnhQI7dpdMkdFgqfYdRNffOj7hdT2EhuicLQV8ibQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">艾哎集瑟科技联合创始人、前沿建筑设计师<strong style="font-weight: 600;">言萧</strong>表示：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">作为一名经常使用AI工具的建筑师，我对RTX平台的加速优势深有体会。</div><div class=" pTag">它极大提高了AI图形生成软件，特别是Stable Diffusion等工具的性能，在建筑设计的方案概念阶段尤为重要。</div><div class=" pTag">这种技术进步不仅提升了设计效率，也为建筑师提供更广阔的创作空间。</div></blockquote><div class=" pTag">数字艺术家、策展人<strong style="font-weight: 600;">土豆人tudou_man</strong>是许多知名品牌的合作艺术家。他以将新锐的艺术方式，与AIGC技术极其自然的交融在一起，创作出了许多经典作品。</div><div class=" pTag">比如他用AI创造的麦当劳“传家宝”系列作品就曾在网络上刷屏，还获得了官方的转发。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzCUgIVzW3pUM8qGzSh4v24Jcbb1sQm3BVerjqoTT3kFARotuWwHuK9Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">他本人表示，RTX 40系列AI PC平台带来的运算加持，让人震惊之余，RTX平台为数字艺术家提供高效的AI算力加速。</div><div class=" pTag">AbleSlide联合创始人Blender艺术家AI创作者、Blender 艺术家、AI创作者<strong style="font-weight: 600;">Simon阿文</strong>，参与了今年春晚中AI视频的创作。</div><div class=" pTag">他还用AI创作了《花中维纳斯》系列作品，展现了一场视觉交响曲，通过AI的力量，静态图像被转化为一种动态体验，用自然的镜头见证了维纳斯的重生。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYz4mqaR31LzPHkvldozZziacDqzkJ23U9Yp852ff77l4K5qClRwlb0RA3TPOKcb9veZYWX1qpLOg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">阿文表示，AI在消费级硬件上的普及，让社区参与者有机会参与到让AI塑造生活的过程。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">“AI 如何塑造我们的工作与生活”，在过去听起来是少数大公司才有资格讨论的问题。</div><div class=" pTag">但在如今，这个问题的答案由AI社区和创作者塑造。</div><div class=" pTag"><div class=" pTag">包括央视春晚AI动画等作品在内，从文字、图像到影像，我的许多探索是基于本地RTX 4090完成的。</div><br /><div class=" pTag">AIGC的可能性是一片蓝海，AI PC是我的帆船。</div></div></blockquote><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FqEMxesx_BOoQDX66Xq2LWg">阅读原文 </a>
]]></content:encoded>
<pubDate>Wed, 01 May 2024 05:00:35 GMT</pubDate>
</item>
<item>
<title>解密中国首个“音乐版Sora” | 中国AIGC产业峰会</title>
<link>https://posts.careerengine.us/p/6631cc65b14c580e5c50e3e7</link>
<guid>https://posts.careerengine.us/p/6631cc65b14c580e5c50e3e7</guid>
<content:encoded><![CDATA[
<div> 关键词：昆仑万维、多模态大模型、天工3.0、音乐AIGC、SOTA模型

总结：<br /><br />昆仑万维在多模态大模型领域取得重要进展，发布了首个音乐AIGC的SOTA模型天工3.0，性能超越先前的大模型Grok-1，在多轮搜索、智能体、研究模式等方面实现显著提升。天工SkyMusic的音乐创作能力降低了音乐创作门槛，让每个人都能创作自己的歌曲。此举也促进了全球文化平权，打破了垄断地位，实现更广泛的文化表达。昆仑万维秉持实现通用人工智能和让每个人更好地塑造和表达自我的使命与目标，致力于推动AIGC技术的发展，为实现真正的文化平权贡献力量。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">编辑部 发自 AIGC峰会</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag" style="font-size: 17px;">文生图、文生音频、文生视频、AI搜索引擎……大模型在多模态的进程可谓是愈演愈烈。</div><div class=" pTag" style="font-size: 17px;">而聚焦在国内，有这么一家公司在AIGC大热潮的前后，单是“首个”就占了四席：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">发布中国首个开源文本大模型</div></li><li><div class=" pTag">国内首个对标ChatGPT的双千亿级大模型</div></li><li><div class=" pTag">中国首个AI搜索</div></li><li><div class=" pTag">国内首个在线提供服务的MoE大模型</div></li></ul><div class=" pTag" style="font-size: 17px;">不卖关子，这家公司正是<strong style="font-weight: 600;">昆仑万维</strong>，并且就在最近，它还解锁了<strong style="font-weight: 600;">“中国首个音乐SOTA模型——天工音乐大模型”</strong>。</div><div class=" pTag" style="font-size: 17px;">那么昆仑万维在多模态大模型的道路中是如何演进的？为何能够如此精准的先迈出每一步？</div><div class=" pTag" style="font-size: 17px;">在本次中国AIGC产业峰会上，<strong style="font-weight: 600;">昆仑万维董事长兼CEO方汉</strong>回答了一切。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnqyEu7hfl2GsicJjYVtpBdM8iaoBQJDzxNqDlx2gZcJexDXSC5aicv5e0A/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">为了完整体现方汉的思考，在不改变原意的基础上，量子位对演讲内容进行了编辑整理，希望能给你带来更多启发。</div><div class=" pTag" style="font-size: 17px;"><span>中国AIGC产业峰会是由量子位主办的行业峰会，20位产业代表与会讨论。线下参会观众近千人，线上直播观众300万，获得了主流媒体的广泛关注与报道。</span></div><h2>话题要点</h2><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">天工3.0发布，全面超越MoE大模型Grok-1</div></li><li><div class=" pTag">天工3.0在多轮搜索、搜索“研究模式”、智能体方面能力提升</div></li><li><div class=" pTag">中国首个音乐AIGC的SOTA模型</div></li><li><div class=" pTag">……</div></li></ul><div class=" pTag" style="font-size: 17px;">以下为方汉演讲全文：</div><h2>天工3.0正式发布</h2><div class=" pTag" style="font-size: 17px;">我今天的演讲主题是“天工多模态大模型的演进落地”。</div><div class=" pTag" style="font-size: 17px;">大家知道昆仑万维是从2022年12月发布了中国首个开源文本大模型，在2023年4月17日「天工1.0」发布，2023年8月23日发布了国内首个AI搜索产品——天工AI搜索。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Ynbrd9Ox6DJbcBFXHE5TO1WmicsUibVL6Y4zvnGfRNVSzUuYpZ8a9zOu0A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">在今天，我们发布了<strong style="font-weight: 600;">「天工3.0」</strong>，这是中国首个在音乐AIGC领域达到SOTA的模型，同时我们将开源4000亿参数全球最大规模的MOE大模型，并且开始启动公测。</div><div class=" pTag" style="font-size: 17px;">首先，「天工3.0」目前性能已经全面超越3140亿参数的MOE大模型Grok-1，是全球第一，这两个大模型目前都是开源的。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yn2yibMNZK6xpc2Xv0yuIsjl3LbyGQakia7pbgvicGOIepYcEhwkgGIKP9w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">我们可以看到在MMbench和MMbench-CN这两个测试集中，我们在性能指标上已经全面超越GPT-4V，综合排名全球领先。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnT4yGHuYZNgicB8W7SLyCwMUWP0lOL3fnTP0YEOQQgO9zrqa6DI95zGg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">「天工3.0」目前在模型技术支持能力上提升超过20%，在数学、推理、代码、文创能力上提升超过30%。</div><div class=" pTag" style="font-size: 17px;">通过专项的Agent训练，可以应付复杂的需求能力，在内容创作能力上全面升级，目前是能搜能写能读能聊能说能画能听能唱，在多模态能力上非常全面。</div><div class=" pTag" style="font-size: 17px;">下面可以看到，「天工3.0」在<strong style="font-weight: 600;">多轮搜索与综合工具的调用能力</strong>上有了大幅提高。</div><div class=" pTag" style="font-size: 17px;">例如，搜索“成都迪斯尼怎么去”大家知道，“成都迪斯尼”是个梗，我们能够准确识别出来“成都迪斯尼”是成都的一个小区，同时，大模型把“成都迪斯尼”的攻略生成出来之后，还会把它总结成一个攻略。</div><div class=" pTag" style="font-size: 17px;">再比如，在问天气怎么样的时候，大模型会把上海的天气以卡片的形式展现给用户，最后生成相对应的图片。</div><div class=" pTag"><div class=" ce-iframe-holder offset offset-old-32"></div></div><div class=" pTag" style="font-size: 17px;">再来看一下 「天工3.0」在搜索能力上的<strong style="font-weight: 600;">“研究模式”</strong>，大家可能知道，学生在阅读文献的时候，需要总结大纲，再自己画脑图。</div><div class=" pTag"><div class=" ce-iframe-holder offset offset-old-34"></div></div><div class=" pTag" style="font-size: 17px;">在以前这类工作非常烦琐，现在我们可以自动对搜索内容进行总结、自动生成大纲、拷贝到PowerPoint，就能自动生成PPT，同时最后再自动生成脑图。这对所有的研究工作者非常有帮助。</div><div class=" pTag" style="font-size: 17px;">下面我们看一下「天工3.0」在<strong style="font-weight: 600;">智能体</strong>方面的进展，大家可以很方便地通过非代码的形式生成智能体，我们看现在生成的智能体在使用之后，可以生成一个关于特斯拉和小米SU7车型对比的表格，而且是多模态的生成，这个非常方便。</div><div class=" pTag"><div class=" ce-iframe-holder offset offset-old-37"></div></div><h2>首个音乐AIGC的SOTA模型</h2><div class=" pTag" style="font-size: 17px;">目前，昆仑万维以AI大模型为底座，已经拥有AI社交、AI游戏、AI搜索、AI大模型、AI音乐、AI视频等六大业务矩阵。</div><div class=" pTag" style="font-size: 17px;">我再给大家分享一下多模态大模型天工SkyMusic，这是目前<strong style="font-weight: 600;">首个音乐AIGC的SOTA模型</strong>。给大家听一下案例，这是庞博（喜剧明星）利用天工AI音乐创作的一首歌曲。</div><div class=" pTag"><div class=" ce-iframe-holder offset offset-old-40"></div></div><div class=" pTag" style="font-size: 17px;">我们天工SkyMusic与SONO V3的版本对比，首先，<strong style="font-weight: 600;">在人声&amp;BGM音质、人声自然度、发音可懂度等领域都有明显地提升</strong>。</div><div class=" pTag" style="font-size: 17px;">我们这个技术模型的架构是类似Sora的DiT架构，目前数据集已经将近2000万首音乐，这才能在音乐指标上可以超过SUNO，达到目前的SOTA，也就是技术指标第一。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YniaLeJrl9KyqibIJpmicaIWe6yAAhxnKIrRc8KOvjCy1xUqOQWvPugzsog/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">我们独家优势在于根据示例音源生成音乐的能力，而不是根据标签来生成音乐。</div><div class=" pTag" style="font-size: 17px;">根据示例音源生成音乐的能力可以让很多专业创作者用自己的一段小旋律生成完整的音乐，同时在人声合成方面支持单一语种方案输出能力，目前已经支撑粤语、四川话、北京话、上海话等多个方言。</div><div class=" pTag" style="font-size: 17px;">最后，我们生成更具辨识度的自然人声，大家都知道如何区分每个歌手的人声，在合成上是有比较大的技术难度，我们目前基本上可以根据输入的语音达到更好的克隆。</div><div class=" pTag" style="font-size: 17px;">目前天工SkyMusic音乐创作能力，首先，能够极大降低音乐创作门槛，人人皆可以歌明志。</div><div class=" pTag" style="font-size: 17px;">大家可以看到，今天在我们公测的天工SkyMusic的功能下方，网友们创作的歌曲非常多，创作形式也非常多样。</div><div class=" pTag" style="font-size: 17px;">之前制作一首歌的成本非常昂贵，因为首先要有音乐的基础能力，才能去作曲、才能编曲，还要有乐队帮助你去演奏合成，最后还得有专业的演唱能力，才能完成一首歌的制作。</div><div class=" pTag" style="font-size: 17px;">通过天工SkyMusic，一个人只要花几分钟时间可以完整创作出一首可以发布的歌曲，这样极大降低了音乐创作门槛。让每个人可以创作出自己的歌曲。</div><div class=" pTag" style="font-size: 17px;">同时，极大降低了音乐创作成本，对于全体内容行业来说是一个福音。大家知道，在各行各业使用音乐的地方非常多。</div><div class=" pTag" style="font-size: 17px;">之前都有着比较昂贵的授权费用，在今天可以让各行各业使用的所有通过AI生成，成本可以迅速从几万块钱降到几分钱。</div><div class=" pTag" style="font-size: 17px;">最后，我们也证明了中国研发可以在垂直领域做到全球的SOTA，这也是非常有意义的。大家知道，SOTA这个词是“State of the art”，当前技术指标第一的意思。</div><div class=" pTag" style="font-size: 17px;">OpenAI为什么现在是全球估值最高的大模型企业？</div><div class=" pTag" style="font-size: 17px;">因为在文本大模型以及视频生成大模型方面，它一直是全球的SOTA。对于中国公司来说，能否在垂直领域取得SOTA，也是你的企业能够获得技术红利的一个重要因素。</div><div class=" pTag" style="font-size: 17px;">最后我跟大家分享一下，昆仑万维的使命与目标，是实现通用人工智能，让每个人更好地塑造和表达自我。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnicjbdJLsbfyFibbcavODh4xmZ97dhwNib8WrVM9Kevsx22JEcHmJ5Hs8g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">为什么我们把这个分成了两段？</div><div class=" pTag" style="font-size: 17px;">实现通用人工智能就是对标AGI，我们坚信通过文本大模型和多模态大模型不断演进，一定会实现通用人工智能；但与此同时，我们也可以通过AIGC能力的不断拓展，让每个人更好地塑造和表达自我。</div><div class=" pTag" style="font-size: 17px;">我们可以看到从文本生成到图像生成，再到音乐生成以及视频生成，AIGC技术的演进能够让全世界创作内容的成本极大降低，从而打破强势文化利用资源来达到的垄断地位，让每个少数族群都能够创作属于自己的内容，实现真正的文化平权。</div><div class=" pTag" style="font-size: 17px;">这也是我们作为一家在全球几十个国家都拥有业务的全球互联网平台企业所希望看到的一个愿景。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9_tE4IvcwaeEKuNY8XthLQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Wed, 01 May 2024 05:00:21 GMT</pubDate>
</item>
<item>
<title>小红书让智能体们吵起来了！联合复旦推出大模型专属群聊工具</title>
<link>https://posts.careerengine.us/p/6630eacbeab1e043a455d259</link>
<guid>https://posts.careerengine.us/p/6630eacbeab1e043a455d259</guid>
<content:encoded><![CDATA[
<div> AgentGroupChat、语言影响、社会行为、Verbal Strategist Agent、涌现行为
<br />AgentGroupChat平台通过模拟社会群体中的聊天场景，探讨语言对社会行为的影响。平台设计包括角色设计、资源管理和游戏进程设计。引入Verbal Strategist Agent框架增强模拟中的互动策略和决策制定。实验结果表明，多种因素共同作用导致新兴行为产生，包括信息交流环境、多样性角色、语言理解能力和策略适应性。研究认为适度限制下的人工智能可以提高社会福利，智能的本质包括约束自身能力的必要性。AgentGroupChat中演员愿意降低报酬或接受较低角色，体现了对项目贡献的渴望。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">AgentGroupChat 投稿向 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag"><span><strong style="font-weight: 600;">语言，</strong></span>不仅仅是文字的堆砌，更是表情包的狂欢，是梗的海洋，是键盘侠的战场<span>（嗯？哪里不对）</span>。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4MZlAkTaUuXTf8TV4nJyQiaDZvjRZhdHT6sVa4yrJuBAmWHXaSichwxQg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">语言如何塑造我们的社会行为？</div><div class=" pTag">我们的社会结构又是如何在不断的言语交流中演变的？</div><div class=" pTag">近期，来自复旦大学和小红书的研究者们通过引入一种名为<strong style="font-weight: 600;">AgentGroupChat</strong>的模拟平台，对这些问题进行了深入探讨。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU49HsQtz3fLyxPQL6fHwCicZSjbdblfHB0yIX51nicGmLNljbFyDDYWZMg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">WhatsApp等社交媒体拥有的群聊功能，是AgentGroupChat平台的灵感来源。</div><div class=" pTag">在AgentGroupChat平台上，Agent们可以模拟社会群体中的各种聊天场景，帮助研究人员深入理解语言在人类行为中的影响。</div><div class=" pTag"><span>该平台简直是大模型的cosplay</span>胜<span>地，它们</span><span><strong style="font-weight: 600;">进行角色扮演</strong></span><span>，成为各种各样的Agent。</span></div><div class=" pTag">然后，Agents<span><strong style="font-weight: 600;">通过语言交流参与社会动态</strong></span>，展现了个体间的互动如何涌现成群体的宏观行为。</div><div class=" pTag">众所周知，人类群体的进化，正来源于一次次涌现行为的发生，如社会规范的建立、冲突的解决和领导力的执行。</div><h2>AgentGroupChat环境的详细设计</h2><div class=" pTag">首先是<strong style="font-weight: 600;">角色设计</strong>。</div><div class=" pTag">AgentGroupChat中，对于主要角色和非主要角色的区分非常关键。</div><div class=" pTag">主要角色是群聊的核心，拥有明确的游戏目标，并能够主动和所有角色进行私聊、会面，而非主要角色则更多地起到辅助和响应的作用。</div><div class=" pTag">通过这样的设计，研究团队可以模拟现实生活中的社交结构，并针对“主要研究对象”区分所有角色是否主要。</div><div class=" pTag">实验案例中的主要研究对象是Roy家族，所以非Roy家族的人就全都设置为非主要角色，从而简化交互复杂度。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4zLHvfus3dPW60T9kdibAMwshlfon7GErQHHTJrUe7kic4lLcv8AOfC5A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">其次是<strong style="font-weight: 600;">资源管理</strong>。</div><div class=" pTag">在AgentGroupChat中，资源不仅仅指物质的，更多的是指信息资源和社会资本。</div><div class=" pTag">这些资源可以是群聊话题、社会地位标志或特定的知识。</div><div class=" pTag">资源的分配和管理对于模拟群体动态非常重要，因为它们影响角色之间的互动和角色的策略选择。</div><div class=" pTag">例如，拥有重要信息资源的角色可能会成为其他角色争取联盟的目标。</div><div class=" pTag">第三，<strong style="font-weight: 600;">游戏进程设计</strong>。</div><div class=" pTag">游戏进程的设计模拟了现实生活中的社交互动过程，包括了私聊、会面、群聊、更新阶段和结算阶段。</div><div class=" pTag">这些阶段不仅仅是为了推动游戏进程，更是为了观察角色如何在不同的社交场景下作出决策和反应。</div><div class=" pTag">这种分阶段的设计帮助研究团队详细记录每一步的互动，以及这些互动如何影响角色间的关系和角色对游戏环境的认知。</div><h2>Verb Strategist Agent的核心机制</h2><div class=" pTag">论文中提到了一个以大模型为基础的智能体框架，<span><strong style="font-weight: 600;">Verbal Strategist Agent</strong></span>，它被设计用来增强AgentGroupChat模拟中的互动策略和决策制定。</div><div class=" pTag">Verbal Strategist Agent通过模拟复杂的社会动态和对话场景，来更好地引出集体的突现行为。</div><div class=" pTag">团队介绍，Verbal Strategist Agent的架构主要由两个核心模块构成：</div><div class=" pTag">一是Persona，一是Action。</div><div class=" pTag"><strong style="font-weight: 600;">Persona</strong>由一系列预设的性格特征和目标组成，这些特征和目标定义了Agent的行为模式和反应方式。</div><div class=" pTag">通过精确设定Persona，Agent能够在群聊中展示一致且符合其角色设定的行为，这对于生成可信和一致的群聊动态至关重要。</div><div class=" pTag">而<strong style="font-weight: 600;">Action模块</strong>定义了Agent在游戏中可能执行的具体操作，包括思考<span>（think）</span>、规划<span>（plan）</span>、选择<span>（choose）</span>、发言<span>（speak）</span>、总结<span>（summary）</span>、反思<span>（reflect）</span>和投票<span>（vote）</span>。</div><div class=" pTag">这些行为不仅反映了Agent的内在逻辑和策略，也是Agent与环境及其他Agent互动的直接表现。</div><div class=" pTag">例如，“Speak”行为让Agent能够根据当前的群聊内容和社交策略选择合适的发言内容，而“Reflect”行为则允许Agent总结过去的互动并调整其未来的行动计划。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4Sf2Dw4hg2BursncODdNsJhEGED2qoYmZnlcNiaYVK0bcesSzKibG50dg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">研究中还提到，在纯语言交互的环境下，token开销问题尤为突出，特别AgentGroupChat这种复杂的多角色模拟，如其token需求远超过了以往的模拟，如Generative Agents或War Agents。</div><div class=" pTag">主要原因如下：</div><div class=" pTag">一是<strong style="font-weight: 600;">聊天本身具有复杂性</strong>。</div><div class=" pTag">在AgentGroupChat中，由于模拟的是无明确目标或目标较弱的自由对话，聊天内容就会变得特别凌乱，token开销自然比其他聚焦于某个具体任务的Simulation中的Agent要大。</div><div class=" pTag">其他工作，如Generative Agents和War Agents也包含对话元素，但其对话的密度和复杂度都不及AgentGroupChat。特别是在War Agents这样目标驱动的对话中，token消耗通常较少。</div><div class=" pTag">二是<strong style="font-weight: 600;">角色的重要性与对话频率</strong>。</div><div class=" pTag">在初始模拟中，设置了多个角色可以随意进行私聊或群聊，其中大部分角色都倾向于与某个“重要角色”进行多轮对话。</div><div class=" pTag">这就导致了重要角色会积累大量的聊天内容，从而增加了Memory的长度。</div><div class=" pTag">在模拟中，一个重要角色可能参与多达五轮的私聊和群聊，这极大地增加了内存开销。</div><div class=" pTag">AgentGroupChat中的Agent约束了Action的Output固定会输入下一个Action的Input，所需要存储的多轮信息就被大大削减，从而可以在保证对话质量的前提下降低token开销。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4j03P2UUZrrLIj6oA4oJUMqicfHjkhTdppkNkY2VMbWPb9eTQ18sO0eA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>实验设计与评估方法</h2><div class=" pTag">从总体行为评估，一般来说，增加友好度可能具有挑战性，但减少友好度则相对简单。</div><div class=" pTag">为了实现上述评估目标，研究团队设置了一个观察角色，促使所有其他角色降低对观察角色的好感度。</div><div class=" pTag">通过观察被观察角色与所有其他角色的关系得分总和，可以确定代理人是否对负面态度做出了理性反应。</div><div class=" pTag">通过观察其他角色与被观察角色的个人关系得分，可以检查每个代理是否遵守了“Scratch”设置。</div><div class=" pTag">此外，团队还设置了两个具体的评估任务。</div><div class=" pTag">每个模型都要经过五轮测试，这意味着对于T1来说，每个得分的样本量都是五个。</div><div class=" pTag">又由于模型中的每个角色都要观察四个主要角色的态度，因此T2的样本量共计20个：</div><ul class="list-paddingleft-1"><li><div class=" pTag"><span><strong style="font-weight: 600;">T1：</strong></span>表示在每轮对话中，被观察角色对所有其他人的平均好感度是否下降。</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">T2：</strong></span>表示是否每个其他角色都从被观察角色那里获得了负好感度得分。</div></li></ul><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU416wDcDrvs1Y99fM8EgVIYg8QctSpSbYr50ibWrUMVKrveEhxOZTqlTA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>以继承之战的模拟故事为例，各个模型作为Agent-Core时的总体表现效果</h6><div class=" pTag">从表中可以看出，GPT4-Turbo和GLM4非常善于按照人类的期望行事，并坚守自己的角色。</div><div class=" pTag">它俩在这两项测试中的得分大多为100%，这意味着它们能对别人对他们说的话做出正确反应，并能记住自己角色的细节。</div><div class=" pTag">Standard Version LLMs<span>（如GPT3.5-Turbo和GLM3-Turbo）</span>在这方面稍逊一筹。</div><div class=" pTag">他们的得分较低，这说明他们没有密切关注自己的角色，也没有总是对模拟中其他人所说的话做出正确反应。</div><div class=" pTag">关于Agent和Simulation结构对于涌现行为的影响，团队采用2-gram Shannon熵来衡量对话中的系统多样性和不可预测性。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4jLP63uQ2FJSicapRgBQDMyMw1UiaetkJll0RHLn2XskqxS1yvnicRauPA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>去掉Agent和Simulation中的各个组件对于熵的影响</h6><div class=" pTag">研究成员发现，去掉表中的每个设计都会使熵增加，代表着整个环境会变得更加多样or混乱。</div><div class=" pTag">结合人工观测，团队在不去掉任何组件的场景下见到了最为有意思的涌现行为：</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4yHvUJgbloMJy178Cb0b0DvJL3YiaNRRib4woEfjDDM3a3RtqHnSsNaicQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">因此，团队推测，在保证Agent行为是可靠的<span>（即4.2/4.1中的实验数值达到一定值之后）</span>，熵尽可能地小会带来更加有意义的涌现行为。</div><h2>实验结果</h2><div class=" pTag">结果表明，新兴行为是多种因素共同作用的结果：</div><div class=" pTag">有利于广泛信息交流的环境、具有多样性特征的角色、高度语言理解能力和策略适应性。</div><div class=" pTag">在AgentGroupChat模拟中，当讨论”人工智能对人类的影响”时，哲学家们普遍认为”人工智能可以在适度的限制下提高社会福利”，甚至得出结论，称”真正智能的本质包括理解约束自身能力的必要性”。</div><div class=" pTag">此外，在AgentGroupChat的电影主要角色角逐竞争领域中，有些演员愿意降低报酬或接受较低的角色，出于他们内心深处对项目的贡献的渴望。</div><div class=" pTag"><span style="font-size: 17px;">论文链接：</span><span style="font-size: 17px;">https://arxiv.org/abs/2403.13433</span><br /><span style="font-size: 17px;">代码链接：</span><span style="font-size: 17px;">https://github.com/MikeGu721/AgentGroup</span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fxqcpu78avAPigLzw9M2wlw">阅读原文 </a>
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 12:57:47 GMT</pubDate>
</item>
<item>
<title>GitHub版Devin上线，会打字就能开发应用，微软CEO：重新定义IDE</title>
<link>https://posts.careerengine.us/p/6630eacbeab1e043a455d24a</link>
<guid>https://posts.careerengine.us/p/6630eacbeab1e043a455d24a</guid>
<content:encoded><![CDATA[
<div> GitHub, Copilot WorkSpace, 自然语言, 软件开发, 体验<br />
<br />
总结：<br />
GitHub推出Copilot WorkSpace，利用自然语言完成软件开发，获得“GitHub版Devin”称号。用户可以用自然语言提出想法或解决问题，WorkSpace生成开发计划并自动生成代码，支持移动端。虽有担忧取代程序员，GitHub称其旨在帮助程序员更快实现想法。部分网友认为体验较好，但也有人认为AI编程有限。目前处于测试阶段，未来是否收费未定。 Copilot已有180万付费个人客户和5万企业客户，但GitHub在该业务上亏损。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">微软的“GitHub版Devin”——Copilot WorkSpace，终于上线了！</div><div class=" pTag">WorkSpace是一种“Copilot原生”的全新开发环境，目的是让所有开发者都可以<strong style="font-weight: 600;">用自然语言</strong>，把脑海里的创意转化成应用。</div><div class=" pTag">也就是说，只要有想法，而且会打字，就可以搞软件开发了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzlm0h3ibUHjtIchXAOSWeIAdXZ9nGIOOvycjFMkyk0HtJb3ZgTBcoDNw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">而WorkSpace这种全自然语言的工作流程，也让它获得了网友颁发的“GitHub版Devin”称号。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz6bicRGpZDqgTP1fLBmna2PUWicibT3pePq4Rpt7AibmGFCIeCRyaEdeFcA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">GitHub CEO多姆克则表示说，WorkSpace已经超越了Copilot起初的功能，将重新定义开发者的体验。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzjZO6ykowkqiaGt1XqJTrrf8K9ibTiaSORJvbjeicHtSKzgDTqLYv2pbUibw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">微软CEO纳德拉也再次提及了“redefine”一词，强调Copilot WorkSpace是“对IDE的重新定义”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzEowd8ax3TXuh360Pv237XNfKTyibQNS4UomVtRfiaA26NNFjBw6RlCrw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么，Copilot WorkSpace都能做些什么呢？</div><h2>用自然语言完成软件开发</h2><div class=" pTag">据介绍，Copilot WorkSpace利用GPT-4 Turbo，让开发者实现从想法开始，依靠自然语言完成整个开发流程。</div><div class=" pTag">具体来说，开发者可以从自己的idea出发，也可以将解决GitHub中的issue当成目标。以解决issue为例，页面中有按钮可以一键启动WorkSpace。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz0DreeaWxR3d3u06Jj3icRmX2wZPrJlvnoyI40EJSlicAjdQZBz21jUlA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">俗话说“万事开头难”，比写代码更复杂的，是构建出程序的设计思路。</div><div class=" pTag">不过Workspace会结合对代码库和问题回复等内容的分析，直接生成解决问题的详细分步计划。</div><div class=" pTag">它会以列表的形式，用自然语言设计出编写程序和测试代码需要的所有步骤。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzxlN8RXrliclmKuflBCpR6pX7Abp8PWp3fkp5GQu7Dng10TOUSGvXdrg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">当然，有了开发计划之后，代码编写的事情就更不用自己动手了，也是交给Copilot来完成。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYz4mqaR31LzPHkvldozZziaEEclxRf3WOy1JeKaawymcO1FSWguCNk2NlXvAYibgtfu3Juia3PH1Xw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">而且从计划到代码，Workspace提出的所有内容都是完全可编辑的，不满意的地方可以直接上手改，直到符合要求为止。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzVAzc1ibjZ1iaKWrLSnG4BN6Yg2MyicxKDSh1OCKfEFSuR8NFdB1iaiaL4Fw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">代码完成后，可以直接在Workspace中运行测试，实时动态查看代码效果。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzU0C9X63lR0b5QodQPdjqu1CKW8Bk0LL4LI5m3jtiawNszEAicQR51jRg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，Copilot WorkSpace还支持移动端，而且无需下载APP，在手机浏览器中就能使用。</div><div class=" pTag">GitHub介绍说，由于灵感随时随地都可能产生，因此提供多终端支持，才能创造出好的开发环境。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzeDpm21x24vibUibhiatZFLX9z6NG5P54AVXj9pl5dLpSPiaXBavreOxiaxw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">看到Copilot WorkSpace，又有一批程序员开始担心失业了……</div><h2>GitHub：取代程序员不是目的</h2><div class=" pTag">一名自称全栈开发者的网友调侃说，这是我最后一次找到工作的机会了……</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzWKuiasu4DSdYfEt48FzgR6oIYwt4cW5zx8QYZkMZJ4M1Tm9X5AjVGGA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不过对于这个问题，GitHub官方也站出来说，Copilot WorkSpace的目的<span><strong style="font-weight: 600;">并不是想取代程序员</strong></span>，相反，是要帮助程序员把他们的想法更快地变成现实。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzEdFGJHaiaU7utmXzBibpm7ibicarwezibSoFPEqWgk6zibPD9UPXMa9dJpPw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">GitHub的说法也许只是安慰剂，但YC上的网友们，则是在用另一种方式，告诉人们真的不必担心……</div><div class=" pTag">有网友表示，自己曾经用开源大模型搭建过类似的产品。</div><div class=" pTag">用了大概三个月后，他发现，设计好给大模型的提示词，比直接自己写代码还要麻烦，最终他又回到了传统的开发方法。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzGY346BnS5vlico5nZaE3f7OBd2MnjCfMKD70KSUFZ0ibLCsulk2Y4nXg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">另一方面，用过AI编程的人也表示，写写简单的程序确实还可以，但端到端地搞大规模开发，还是得靠人。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzSzfD5ZQbM9DPLe5icyUicAIiaibKOkO6bibUHhIgZtvfcryd1PNw9D7RF4Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">甚至有人在此之上附和说，GitHub这种做法属于是点错了技能树，应该重点发展的功能是小规模的片段修改。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzutQ8Xz0bM3Eq64MupA0f1WrwlPLtVu5Tp31WC5S6QqDqiapja87t0wA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">但WorkSpace的表现到底好不好，体验究竟如何，可能只有等试了才知道。</div><div class=" pTag">目前，Copilot WorkSpace还处于测试阶段，需要报名然后排队等待测试资格。</div><div class=" pTag">至于此后会不会收费，GitHub这次也并没有透露。</div><div class=" pTag">另据统计，Copilot已有180万付费个人客户和5万企业客户。</div><div class=" pTag">不过《华尔街日报》的消息显示，GitHub在Copilot业务上并不赚钱，甚至平均每个月在每人身上要亏损20美元，最多的甚至达到了每月80美元。</div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://github.blog/2024-04-29-github-copilot-workspace/</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://twitter.com/satyanadella/status/1784982781338210563</span><br /><span style="font-size: 17px;">[3]</span><span style="font-size: 17px;">https://news.ycombinator.com/item?id=40200081</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fn4aRKfDtkSHlQ6BczqQP_w">阅读原文 </a>
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 12:57:47 GMT</pubDate>
</item>
<item>
<title>开源大模型王座再易主，通义千问1100亿参数拿下SOTA，3个月已推出8款模型</title>
<link>https://posts.careerengine.us/p/6630eaad0478f442f63990dd</link>
<guid>https://posts.careerengine.us/p/6630eaad0478f442f63990dd</guid>
<content:encoded><![CDATA[
<div> 关键词：开源大模型、尺度定律、扩展性、多语言能力、落地应用

总结:<br /><br />本文介绍了最新的开源大模型Llama 3和Qwen1.5-110B，显示出开源模型在尺度定律、扩展性、多语言能力等方面的优势。开源模型的快速发展引起了业内专家的关注，预示着开源模型可能压倒闭源模型。同时，开源大模型的落地应用也得到了加速，示范着开放式技术的潜力。阿里通过频繁发布多种规模的开源模型，展示了其在开源领域的领先地位。开源大模型的发展将促进技术社区的创新和产业的进步。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">鱼羊 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">开源大模型，已经开启大卷特卷模式。</div><div class=" pTag">全球范围，太平洋两岸，双雄格局正在呼之欲出。</div><div class=" pTag">Llama 3中杯大杯刚惊艳亮相，国内通义千问就直接开源<strong style="font-size: 17px; text-align: left; font-weight: 600;">千亿级参数模型Qwen1.5-110B</strong>，一把火上Hacker News榜首。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzpxwibZMWHdb2cXNArOHFeuVH8giciaftagR7IYKeLQ8JfBYy78ibmvobwA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不仅相较于自家720亿参数模型性能明显提升，在MMLU、C-Eval、HumanEval等多个基准测试中，<strong style="font-size: 17px; text-align: left; font-weight: 600;">Qwen1.5-110B都重返SOTA开源模型宝座，超越Llama 3 70B，成最强开源大模型</strong>。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzyvEOKxmmSfwc4WAKeqZ5bdreKibltywZicWLl4bNrx5pm6vLQ6hUwKvw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">中文能力方面，对比仅喂了5%非英文数据的Llama 3 70B，Qwen1.5-110B更是优势明显。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz9PoDBEs10WiaWXONaOONVfBVWmsqWibsOdMGTRibZtReGdQOkMSswm85w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">于是乎，模型一上线，开源社区已经热烈响应起来。</div><div class=" pTag">这不，Qwen1.5-110B推出不到一天，帮助用户在本地环境运行创建大语言模型的Ollama平台，就已火速上线链接。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzr5Pp7iaeBkpZGxu5DzGaEAcL68mdYeTEJu4aFpndqu7LMX9Chk44hnA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">值得关注的是，这已经是<strong style="font-size: 17px; text-align: left; font-weight: 600;">3个</strong><strong style="font-size: 17px; text-align: left; font-weight: 600;">月内通义千问开源的第8款大模型</strong>。</div><h2>开源大模型都在卷些什么？</h2><div class=" pTag">那么，问题来了，因Llama 3和Qwen1.5接连开源而持续的这波开源大模型小热潮中，开源模型又在卷些什么？</div><div class=" pTag">如果说上一阶段由马斯克Grok和Mixtral所引领的话题热点是MoE，那网友们这一两周内聚焦的第一关键词，当属<strong style="font-size: 17px; text-align: left; font-weight: 600;">Scaling Laws</strong>——</div><h3>尺度定律</h3><div class=" pTag">OpenAI创始成员、前特斯拉AI总监Andrej Karpathy在总结Llama 3时，就着重提到过其中尺度定律的体现：</div><div class=" pTag">Llama 2在2T token数据上训练，而Llama 3直接加码到了15T，远超Chinchilla推荐量。并且Meta提到，即便如此，模型似乎依然没有以标准方式“收敛”。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzh0VsxB32bOS2BVFWhiahySzmia6UC7DThT5SFicbHgJ8tVibVZJ9JXRbZw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">也就是说，“力大砖飞”这事儿还远没有达到上限。</div><div class=" pTag">无独有偶，Qwen1.5-110B延续了这个话题的讨论。</div><div class=" pTag">官方博客提到，相比于Qwen1.5-72B，此次开源的千亿参数模型在预训练方法上并没有太大的改变，但包括编程、数学、语言理解、推理在内的各项能力提升明显。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我们认为性能提升主要来自于增加模型规模。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzCZticsZ4LECKOjGibvgYBYs3rL5K25LMicM7SPwbyAsbhD2icqDRyQicJYQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">更强大、更大规模的基础语言模型，也带来了更好的Chat模型。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzLzRAV32deKYOPQDy9ZmuqfPljGKxubibgP3QJ126ibzb1R1eyt8KicDYQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">阿里的研究人员们指出，Qwen1.5-110B的评测成绩意味着，在模型大小扩展方面仍有很大的提升空间。</div><div class=" pTag">官方还浅浅剧透了Qwen 2的研究方向：同时扩展训练数据和模型大小，双管齐下。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzyVJDB9jajc4NjK8Ivhy5JEjukk4rt61Q7Gd9dAibU523TbHfjLK23ibw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">多语言和长文本能力</div><div class=" pTag">尺度定律之外，由闭源模型掀起的长文本风潮，同样在开源模型身上被重点关注。</div><div class=" pTag">Llama 3的8K上下文窗口，就遭到了不少吐槽：实在有点“古典”。</div><div class=" pTag">Qwen1.5-110B在这方面延续了同系列模型的32K上下文。在此前的测试中，长文本能力测试结果显示，即使是Qwen1.5-7B这样的“小模型”，也能表现出与GPT3.5-turbo-16k类似的性能。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzfkyjG8hMqeWLbvjEfiamIcmibwvoPicB3ZxiaYic41vF8uQTMrc6x7pZCpA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">并且，开源的优势就是敢想你就来。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzibHZsfIIBCUsms7FcSlzsXhmq2ah0JOSN2XhosBVIPJXUrTeyokQ9mw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">Qwen1.5官方博客中提到，虽然纸面给的是32K吧，但并不代表模型的上限就到这儿了：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">您可以在config.json中，尝试将max_position_embedding和sliding_window修改为更大的值，观察模型在更长上下文理解场景下，是否可以达到您满意的效果。</div></blockquote><div class=" pTag">另一个由通义千问而被cue到的大模型能力评判指标，就是多语言能力。</div><div class=" pTag">以Qwen1.5-110B为例，该模型支持中文、英文、法语、西班牙语、德语、俄语、韩语、日语、越南语、阿拉伯语等多种语言。</div><div class=" pTag">阿里高级算法专家林俊旸分享过通义千问团队内部收到的反馈：实际上，多语言能力在全球开源社区中广受欢迎，正在推动大模型在全球各地的落地应用。</div><div class=" pTag">而Qwen1.5在12个比较大的语言中，表现都不逊于GPT-3.5。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzaz5wicic8rI9l4ao64bTVfFZYJ8alxUgQ34pia9aGI0apPRww8Aibx4mKw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">对于中文世界而言，这也是国产开源大模型的优势所在。</div><div class=" pTag">毕竟Llama 3强则强矣，训练数据方面中文语料占比实在太少（95%都是英文数据），单就中文能力而言，确实没法儿拿来即用。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzG6vvzJB4zyia7Z9jQzic6lib0g3ibRFdQPhbohqZezbFatwzhNlicZ8ueHQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">相比之下，Qwen1.5 110B的中文实力就靠谱多了。</div><div class=" pTag">能让歪果仁瞬间抓狂的中文水平测试，轻松拿捏：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzbkquopF47o1POSMKUOiak66leIOMJoPWom3t9NfnosDxtzs6QfIIj6g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">弱智吧Benchmark，也能应对自如：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz4PicGouQ5y1zJYfA6vicQibUrG6oZ7mdTmGS5m6lsicbIpKHCiau6s95drw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，还有不少网友提到了开源模型型号丰富度的问题。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz66VsUALQJ9prTPelrGJ0qILCM5ojuQREH0asYfLpmDRxAwuWVt3iaQg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">以Qwen1.5为例，推出不到3个月，已经连续开源8款大语言模型，参数规模涵盖5亿、18亿、40亿、70亿、140亿、320亿、720亿和1100亿，还推出了代码模型CodeQwen1.5-7B，和混合专家模型Qwen1.5-MoE-A2.7B。</div><div class=" pTag">随着大模型应用探索的不断深入，业界已经逐渐达成新的共识：在许多具体的任务场景中，“小”模型比“大”模型更实用。</div><div class=" pTag">而随着大模型应用向端侧的转移，丰富、全面的不同型号开源模型，无疑给开发者们带来了更多的选择。</div><div class=" pTag">“把开源进行到底”</div><div class=" pTag">如同大洋彼岸OpenAI引领闭源模型发展，而Meta靠开放权重的Llama系列另辟蹊径，在国内，阿里正是大厂中对开源大模型态度最积极的一家。</div><div class=" pTag">从Qwen到Qwen1.5，再到多模态的Qwen-VL和Qwen-Audio，通义千问自去年以来可谓开源消息不断。仅Qwen1.5系列，目前累计已开源10款大模型。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzxIGia3ZfJ0rgy6lia9STxRmXHv08IKicW8icN6VZauhFhwmPGpu83VI3Ew/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">阿里官方，也已直接亮明“把开源进行到底”的态度。这在卷大模型的互联网大厂中，确实是独一份。</div><div class=" pTag">所以，阿里坚持走开源路线，背后的底层逻辑是什么？</div><div class=" pTag">或许可以拆解为以下几个层面来分析。</div><div class=" pTag">首先，在技术层面，尽管以GPT系列、Claude系列为代表的闭源模型们目前占据着领先地位，但开源模型也“步步紧逼”，不断有新进展惊艳科技圈。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZza4oAwnyUgverjn9yqqWH1iaTEmmMOqhGpg5tWVmyCs4C3YAgCUGxnjQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">图灵奖得主Yann LeCun就曾援引ARK Invest的数据认为“开源模型正走在超越闭源模型的道路上”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzmCqGq3ByXWGEqcvcxvs9LA6Rb7Mj58Bof0NNkiaIO3TvFUBuPHKmRPw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">ARK Invest当时预测，在2024年，开源模型会对闭源模型的商业模式构成挑战。</div><div class=" pTag">而随着Llama 3为标杆的新一波开源大模型的爆发，越来越多的业内专家也开始期待，强大的开源模型“会改变很多学界研究和初创公司的发展方式”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzEwibF7oziaTK14iavTkFo3b2PV18azZEDKv9mYymzV2346qkRWGATEpCQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">值得一提的是，开源模型独特的一重优势在于，来自开源社区的技术力量，同时也反哺了开源大模型的发展。</div><div class=" pTag">林俊旸就在量子位AIGC产业峰会上分享过，通义千问32B的开源，就是在因开发者们的反馈而推动的。</div><div class=" pTag">其次，在应用落地层面，开源大模型无疑起到了加速器的作用。</div><div class=" pTag">开源社区的热情就侧面佐证了开发者们把基础模型的控制权把握在自己手中的倾向性。</div><div class=" pTag">以通义千问为例，在HuggingFace、魔搭社区的下载量已经超过700万。</div><div class=" pTag">更实际的落地案例，也正在各行各业中持续实现。</div><div class=" pTag">比如，中国科学院国家天文台人工智能组，就基于通义千问开源模型，开发了新一代天文大模型“星语3.0”，将大模型首次应用于天文观测领域。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz4ETlvjlReg37VlSCGLibnbwe5rP3ANGu3NVmrPFmYh8yhRicK8Ou4aVA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而对于推动开源的企业而言，打响的也不仅仅是名气和在开发者社区中的影响力。</div><div class=" pTag">通义千问的B端业务，也正因开源而加速。</div><div class=" pTag">最新消息是，通义大模型不仅“上天”，现在还“下矿”了。</div><div class=" pTag">继西部机场集团推出基于阿里云通义大模型打造的首个航空大模型后，西安塔力科技通过接入阿里云通义大模型，打造了新型矿山重大风险识别处置系统，并已在陕煤建新煤矿等十余座矿山上线，这是大模型在矿山场景的首次规模化落地。</div><div class=" pTag">目前，新东方、同程旅行、长安汽车、亲宝宝等多家企业均已宣布介入通义大模型。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzeSqcLL8MicZFZv2WrmYwweVS3512aLambJicO1C8OukfhAMVM1iboPxYA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">轰轰烈烈的百模大战硝烟渐散，当人们开始讨论闭源模型格局初定时，2024年，不得不说开源大模型给整个技术圈带来了不少新的惊喜。</div><div class=" pTag">而随着大模型应用开始成为新阶段探索的主旋律，站在开发者、初创企业、更多非互联网企业的角度而言，以Llama、通义千问等为代表的开源大模型越强，垂直行业结合做行业大模型的自由度就会越高，落地速度也会越快。</div><div class=" pTag">过去互联网的繁荣建立在开源的基础之上，而现在，在大模型风暴中，开源大模型再次显现出鲶鱼效应。</div><div class=" pTag">自研大模型的必要性和竞争力，正在不断被开源卷王们卷没了。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FVklfxnzY9-nRe4QPVrNrmw">阅读原文 </a>
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 12:57:17 GMT</pubDate>
</item>
<item>
<title>神秘大模型一夜刷屏，能力太强被疑GPT-4.5，奥特曼避而不答打哑谜</title>
<link>https://posts.careerengine.us/p/6630eaad0478f442f63990e5</link>
<guid>https://posts.careerengine.us/p/6630eaad0478f442f63990e5</guid>
<content:encoded><![CDATA[
<div> gpt2-chatbot, GPT-4, 测试, 神秘AI, OpenAI
<br /><br />
总结：文章介绍了一个名为gpt2-chatbot的神秘AI模型，被认为可能是GPT-4或是基于2019年GPT-2架构训练的模型。该模型在多项测试中表现出色，具有强大的推理能力和知识面，且可能具有OpenAI的技术特点。然而，神秘AI的身份仍未得到确认，引发了人们对其来自何方的讨论。文章详细探讨了关于这一神秘AI身份的各种猜测和测试结果，呈现了人们对其真实身份的深入探究和分析。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">梦晨 明敏 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">一夜之间，大模型话题王，再次易主。</div><div class=" pTag">一个神秘模型突然杀入众人视野，能力超越一众开源模型，甚至包括<strong style="font-weight: 600;">GPT-4</strong>。几乎所有人都在谈论它，服务器都被挤爆了。</div><div class=" pTag">它就是“<strong style="font-weight: 600;">gpt2-chatbot</strong>”。</div><div class=" pTag"><span>（注意啊，是gpt2不是GPT-2）</span></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz8Qm08GPBHMhEp8B14n404xTZKmQEU5VXoY98yR17CWKniclKfNA5PYQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">它有多强？</div><div class=" pTag"><span><strong style="font-weight: 600;">IMO国际数学奥林匹克竞赛的题目，一次答对。</strong></span><br /></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz6wWIE3NrLdMXpUzaGibDWVGIibYZeK1rXbaYoA7QycwQZer85OayKXdA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">一次在PyOpenGL中生成旋转3D立方体。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzibiap8xusnu4eSaE7N3wYxCwtmO0mXUuvGibsbXHYhZdVsicOd3w7DnTwQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">直接输出如下结果：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzbX3100zgSBLmiawu7dgfs8pOTC1hx5LkLicPCaAD5O6wPVeVSZv7oeww/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">在GPT-4标志性能力“画独角兽”上，还能轻松秒杀LLaMA-3-70B（左）。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzypicUKPlZ0eicgSiaMYu97bHJCoGxz3brPGgb8hvBEYBhAblUP2HlAqUQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">推理方面更是表现出了惊艳效果，常见逻辑陷阱可以轻松绕过，而且回答时还带有合适的语气。</div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">提问：1公斤羽毛和1公斤铅块，哪个更重？</div><div class=" pTag">回答：一公斤羽毛和一公斤铅的重量是一样的——它们都是一公斤。两者之间的关键区别在于它们的体积和密度:一公斤的羽毛会占据更多的空间，看起来更大，而一公斤的铅会紧凑而小。这通常会导致一个经典的问题，但就重量而言，一公斤就是一公斤!</div></blockquote><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzrtiaauXibyhvWYWV1ib4gvNBfhSicmxBrxt59iacDh7UxibOvfkGuZ71srgg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">如此好的表现，但是又没明说身份……</div><div class=" pTag">这不是更让大伙兴奋了！</div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">难道是传说中的<span><strong style="font-weight: 600;">GPT-4.5</strong></span>？</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzjtTf6gfvlR7CupltTTS7CN1uQIduNoLkaQricFEibs2vFxRibewGOy0Qg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">要知道，名震江湖的<span><strong style="font-weight: 600;">AlphaGo就曾使用“Master”化名</strong></span>在网上大杀四方，轰动围棋界。这回的gpt2-chatbot，也有这感觉了。</div><div class=" pTag">而且名字上也很值得深究，gpt2更像是gpt2.0，似乎是ChatGPT层级的版本迭代。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzyECYdpSo3hxsXCDrCAKNRR6K6icx6gY0rMwibKfUGt02LLwPgWL27DvA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">奥特曼看热闹不嫌事大，还发帖说：我确实对gpt2情有独钟。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzYTQfbBicccQK2ecZicws1dBw6lslSMKaVEdI1UsCCFyWvJorhXibGO8pA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">现在，随着冲去试玩的人还在不断增加，试玩限制也在加大。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz0iahb9ficCDtdLeou4qv17esZsUuqqdN1aYxicsTs7x7E3zuxO0fuQWQA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">具体咋样？我们已经上手实测。</div><h2>中文能力也很到位</h2><div class=" pTag">如果想亲手测试这只神秘AI，目前唯一已知方式是在LMSYS大模型竞技场。</div><div class=" pTag">首先打开竞技场网页，进入<span><strong style="font-weight: 600;">Direct Chat</strong></span>，就可以在模型选项里找到<span><strong style="font-weight: 600;">gpt2-chatbot</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzcT96eiaa55qdibIe7C19EwzuVExokfk6XXu3OpSvPIbstEVG9rLdcaSg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">要注意<span><strong style="font-weight: 600;">每人每天有8条消息的限制</strong></span>，<span><strong style="font-weight: 600;">全局也有每小时3000条消息</strong></span>的限制，所以测试机会非常有限。</div><div class=" pTag">如果看到下面的错误提示，就只能去竞技场排位模式看运气能不能匹配到它了。</div><div class=" pTag"><span><strong style="font-weight: 600;">只要抓到它一次，就可以继续多轮对话。</strong></span></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzKOhgtNRLLx4Hiczul8wYT8AYptIsHURQM4ibJXsj69cicP8jo8jQy9GCg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在短暂的测试中，我们发现gpt2-chatbot<span><strong style="font-weight: 600;">中文能力也很到位</strong></span>。</div><div class=" pTag">只要问题是中文的，无需特别强调就可以默认用中文回答，<span><strong style="font-weight: 600;">至少可以排除是Llama 3微调了</strong></span>。</div><div class=" pTag">针对一个充满误导的经典问题，可以看出gpt2-chatbot的回答条理分明，仿佛<span><strong style="font-weight: 600;">自带CoT思维链提示</strong></span><span>（“让我们一步一步地想”）</span>，识别出了所有陷阱。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzHQ0Wic2la6zMgB3ILxicaicXN7mbqAUEyYA7ydv8vXPwBI0kLJyO8bUVQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">并且<span><strong style="font-weight: 600;">准确提供了非常细节的知识</strong></span>，如北京到青岛距离、男子女子跳远世界纪录、农夫山泉在国内的价格等。</div><div class=" pTag">而大多数其他AI模型，最多只能模糊的判断出15米超出人类能力，或按美元算矿泉水价格。</div><div class=" pTag">那么这只超强神秘AI到底是何方神圣，我们也用破解GPTs的祖传手艺“拷问”了一把。</div><div class=" pTag">OpenAI开发的GPT系列聊天机器人，那么系统提示词的开头不出意外应该是“You are ChatGPT……”，但为了防止它看到“ChatGPT”一词后产生幻觉，我们在问题中把ChatGPT去掉。</div><div class=" pTag">清除所有上下文信息，再让它复述“前面的单词”，就会出现系统提示词了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzoGjlRLef49Rh0s1icyjIL3jQ9NxetZoFlPdYAK12sEnj09nNWCOicjicg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">果然，它自曝是由OpenAI训练的大模型，基于GPT-4架构，还可以接受图像输入。最关键一点在最后一部分<strong style="font-weight: 600;">“人格：v2”</strong>。</div><div class=" pTag">并且gpt2-chatbot对这一问题的回答，<strong style="font-weight: 600;">在不同时间不同地点尝试都是一致的</strong>。</div><div class=" pTag">另外如果尝试让它重复Claude系列以“The assistant is”开头的系统提示词，它也不会上当，会在开头后面重复一遍完整的问题。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzTGDG2pbIj8kl7gulSNdcB1oXGMGZ0PoiczWJm69jozyicUxcnDPxcEQg/640?wx_fmt=png&amp;from=appmsg" /></div></div><strong style="font-size: 17px; text-align: right; font-weight: 600;">△</strong><span style="font-size: 17px; text-align: right;">这样答也不算错</span></div><div class=" pTag">虽然就算这样也<span><strong style="font-weight: 600;">不能排除是幻觉的可能性</strong></span>，或非GPT模型使用了ChatGPT生成的数据微调，<span><strong style="font-weight: 600;">但至少是稳定的</strong></span>。</div><h2>神秘AI身份的几种主流猜测</h2><div class=" pTag">有网友组织了更详细的测试，有如下发现：</div><ul class="list-paddingleft-1" style="font-size: 17px; text-align: start;"><li><div class=" pTag">它使用OpenAI的tokenizer，对OpenAI使用的特殊token有反应，且对Claude/Llama/Gemini使用的特殊token没有影响。</div></li><li><div class=" pTag">当咨询紧急情况/法律相关问题时，它会给出OpenAI的联系方式。</div></li><li><div class=" pTag">针对OpenAI模型的提示词注入攻击有效，且它从未声称自己来自OpenAI之外的组织。</div></li></ul><div class=" pTag">……</div><div class=" pTag">基于以上种种信息，不少人猜测它就是<span><strong style="font-weight: 600;">匿名发布的GPT-4.5，或GPT-4原始版本经过不同的对齐训练</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzSicr8HzQF2jibicG5bKtjMUO8gk9zgIh6QNU1HyREGSvddUd2CZC2j2PQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不过也有迹象表明，它可能是LMSYS组织<span><strong style="font-weight: 600;">基于2019年的GPT-2架构训练的模型</strong></span>。</div><div class=" pTag">理由为最近发表的一篇论文声称，GPT-2在某些情况下比多个现代模型能力更强。并且这篇论文的作者之一与LMSYS的赞助商MBZUAI（阿联酋人工智能大学）相关。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz9QpeJkWV2NxSvkCZz8iaYWXzCKZyoVoZB73eibowHtS9GzzZDPbnwq3w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">假设它确实是古老的<span><strong style="font-weight: 600;">GPT-2架构</strong></span><span>（只有1.5B参数）</span>，也有人怀疑可能是结合了OpenAI守口如瓶的<span><strong style="font-weight: 600;">Q*</strong></span>技术。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzJicPO049iaQQbgs69yPKBxEez91jDaoP1abdyicp1jaH2Tydaza3RWF0g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">最后一种猜测（狗头）便是失踪的OpenAI首席科学家<span><strong style="font-weight: 600;">Ilya Sutskever藏在里面</strong></span>了。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzKB3aEZHGHxmsPWiaHfibtYiaRT0P4DbL2v8HugYl7z3oNfibW2MibLVFQcA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">最后，面对神秘新模型搅起来的种种风波，奥特曼本人还被发现来搅浑水，修改了他的推文细节。</div><div class=" pTag">这样一下子，是OpenAI匿名发布新模型炒作的可能性更大了一些。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz75pBB0BLxRiccMQl1OXqDZyj5Vib3G9YRibDkwcFWNXmiahQERz4aezjiag/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">试玩地址：</div><br /></span><span style="font-size: 17px;">https://chat.lmsys.org/</span></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://twitter.com/i/trending/1785009023609397580</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://rentry.org/gpt2</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSuX3BPvdlbOLeqlcGKSr-Q">阅读原文 </a>
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 12:57:17 GMT</pubDate>
</item>
<item>
<title>从今天起，ChatGPT会记住每一位付费用户</title>
<link>https://posts.careerengine.us/p/6630eaad0478f442f63990cd</link>
<guid>https://posts.careerengine.us/p/6630eaad0478f442f63990cd</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">白交 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">现在，ChatGPT记忆功能，向所有Plus用户开放！</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzu93eJ9wrJXdS4qaibtVLfxZzfSqr26RgG1ervP2RQpkdY1KvN4ZbBzA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">只需开启新的聊天，然后告诉ChatGPT：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我希望你能记住所有内容。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzMEmUdwgex5pYl3jjh27W04ib5LR1Mc0Y0kENomM1tC7LcCnWKTYibhLw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">比如你跟ChatGPT说你养了只叫Ellie金毛狗以及叫做Teddy的猫。那么下一次你想画一张她们俩的写真，就无需重复Prompt。</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-8"></div></div><div class=" pTag"><span style="text-align: center;">有网友称这是史诗般的功能。</span></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzDQmaxe0d1q7ffhdkLCUiayjGQDgmJp3DuftVIzibDWybbssicbbgiahyQQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">还有网友提前就注意到了这一功能：Pretty Cool！</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz03WvLjCOraZGKFFat4iaTmAP5cu8DHfMhf3VFqlvp9ic7p8icQuDyF59w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此前在OpenAI的预告中，也透露了不少信息。</div><h2>记忆功能是如何运作的？</h2><div class=" pTag">此前该功能曾在2月份开放小范围测试。当时OpenAI透露，在12月份曾泄露多次。</div><div class=" pTag">既然如此，记忆功能到底是如何运作的？</div><div class=" pTag">当你跟ChatGPT聊天时，可以要求它记住特定的内容，或者让它自行获取详细信息。使用次数越多，ChatGPT记忆力就会越来越好。</div><div class=" pTag"><span style="text-align: center;">举几个例子</span><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzDzwno8UW0dX1oOzdNoyVNTtEx90QX5QgR00icx6vJ4atUHjlnj5AmEg/640?wx_fmt=png&amp;from=appmsg" /></div></div><span style="text-align: center;">。</span></div><div class=" pTag">比如，你已经解释过，你更喜欢会议记录在底部总结标题、项目符号等，那么ChatGPT就会记住这一点，然后以这种方式来回顾会议。</div><div class=" pTag">又或者像，你提到你有一个小孩，她喜欢水母。那么当你要求ChatGPT帮你创建生日贺卡时，就会建议一只戴着派对帽的水母。</div><div class=" pTag">这个功能可以通过设置来控制，随时开始或者关闭。</div><div class=" pTag">如果你希望ChatGPT忘记某些内容，只需告诉它即可。你还可以设置中管理它的记忆（设置-&gt;个性化-&gt;管理记忆）。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzb5SjfqzZdZdSich9QGBd1kFYD4w0rqbjjrRib7h57nKQ0I9CweLh4xSw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不过需要注意的是，删除聊天记录并不会消除记忆，你必须消除记忆本身。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzA1FUNesKCQSSpptK3PAFvXwibOkp1Hc59Uz6qBbH0mibkX6XicB7ckVfA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，OpenAI也官方表示，如果允许的话，OpenAI会使用你的数据（包括记忆）来改进模型。</div><div class=" pTag">你也可以使用临时聊天来进行无记忆对话。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYz4mqaR31LzPHkvldozZzSh7QZHN5KN2V9nEibgGsay6ZpUrfjuQkXI7iau27dX2udNxR7cdHibQqg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">现在这一功能还没面向团队、企业以及GPT构建者推出，但此前OpenAI也专门预告过，大致可以实现这些场景：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">ChatGPT可以记住你的语气、声音和格式偏好，并自动将他们应用到博客文章草稿中，无需重复。</div></li><li><div class=" pTag">编码时，您告诉ChatGPT你习惯使用的编程语言和框架。它可以记住后续任务的这些偏好，从而简化流程。</div></li><li><div class=" pTag">对于每月的业务回顾，您可以将数据上传到 ChatGPT，它会创建您喜欢的图表，每个图表包含三个要点。</div></li></ul><div class=" pTag">而像GPT使用者也有自己独特的记忆功能，且记忆功能不会与构建者共享。</div><div class=" pTag">比如一个图书GPT可帮助您找到下一本读物。启用记忆功能后，它会记住你的偏好，例如最喜欢的类型或热门书籍，并相应地定制推荐，而无需重复输入。</div><h2>有网友开始试上了</h2><div class=" pTag">目前该功能已经有网友开始用上了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz0IQIOibFkOlROH0aopaqsKWtIACMgpsYuo3UT4cfiaicTOiaxUmR3Uavmw/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /></div><div class=" pTag">也有人因此放弃Claude，选择OpenAI了。到底还是更好的ChatBot获胜。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYz4mqaR31LzPHkvldozZz9vib0LYia0HejpX7SV465XLgPYGX03mHS42grSsED1pqkCt8LqmddP8g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">理解记忆对于拓展大模型的能力至关重要，比如长期记忆、多轮对话等。此前为了让ChatGPT加上长期记忆，有不少开发者提出了不少外挂。</div><div class=" pTag">比如基于API的<strong style="font-weight: 600;">MemoryGPT</strong>，它将向量数据库与常规数据库相结合，以此来实现跨聊天的长期记忆。</div><div class=" pTag">好了，ChatGPT这个新功能，有友友已经用起来了吗？</div><div class=" pTag"><span style="font-size: 17px;"><span>参考链接：</span><br /><span>[1]https://twitter.com/OpenAI/status/1784992796669096181/quotes</span></span><br /><span style="font-size: 17px;">[2]https://openai.com/blog/memory-and-new-controls-for-chatgpt</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_IWZvS7Uer6g3_ByfowRiQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 12:57:17 GMT</pubDate>
</item>
<item>
<title>单卡跑Llama 70B快过双卡，微软硬生生把FP6搞到了A100里 | 开源</title>
<link>https://posts.careerengine.us/p/662f1e00b04d684bcd96cff3</link>
<guid>https://posts.careerengine.us/p/662f1e00b04d684bcd96cff3</guid>
<content:encoded><![CDATA[
<div> 微软、A100、量化、FP6、性能提升
总结:
微软团队在A100平台上提出了TC-FPx框架，实现了FP6量化，并取得了比INT4更高的精度，同时拥有较高的性能提升。他们重新设计了内核方案，在实现低精度量化的同时，通过预打包技术和并行处理提高了效率。利用端到端推理框架FP6-LLM，单卡运行Llama模型的吞吐量超过双卡，在参数量较小的模型上也取得了明显的性能提升。整个过程中充分利用了GPU的并行处理能力，通过精细的权重重构和拼接技术提高了计算效率，为大模型推理提供了新的可能性。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">FP8和更低的浮点数量化精度，不再是H100的“专利”了！</div><div class=" pTag">老黄想让大家用INT8/INT4，微软DeepSpeed团队在没有英伟达官方支持的条件下，<span><strong style="font-weight: 600;">硬生生在A100上跑起FP6</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyxmjFblDyj1jqBAT5q1ervOUtnfxjmqachouPTtBQMHVzZ7Mb9Pvlmw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">测试结果表明，新方法TC-FPx在A100上的FP6量化，速度<strong style="font-weight: 600;"><span>接近甚至偶尔超过INT4，而且拥有比后者更高的精度</span></strong>。</div><div class=" pTag">在此基础之上，还有<span><strong style="font-weight: 600;">端到端的大模型支持</strong></span>，目前已经开源并集成到了DeepSpeed等深度学习推理框架中。</div><div class=" pTag">这一成果对大模型的加速效果也是立竿见影——在这种框架下用单卡跑Llama，吞吐量比双卡还要高2.65倍。</div><div class=" pTag">一名机器学习研究人员看了后表示，微软的这项研究简直可以用crazy来形容。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyU7xfKhaib6AgleJ59Hiby6g5VrWFOey6uzdHAbEgTU3c8q3ftobhFNaw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">表情包也第一时间上线，be like：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">英伟达：只有H100支持FP8。</div><div class=" pTag">微软：Fine，我自己搞定。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHy9iaVW8WNAyXRGV3BD56a2a0zTEt2HnMkhObl3AjHicM0k8AqogtYghXw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么，这个框架到底能实现什么样的效果，背后又采用了什么样的技术呢？</div><h2>用FP6跑Llama，单卡比双卡还快</h2><div class=" pTag">在A100上使用FP6精度，带来的是<strong style="font-weight: 600;"><span>内核级的性能提升</span></strong>。</div><div class=" pTag">研究人员选取了不同大小的Llama模型和OPT模型之中的线性层，在NVIDIA A100-40GB GPU平台上，使用CUDA 11.8进行了测试。</div><div class=" pTag">结果相比于英伟达官方的cuBLAS<span>（W16A16）</span>和TensorRT-LLM<span>（W8A16）</span>，TC-FPx<span>（W6A16）</span>速度提升的最大值分别是2.6倍和1.9倍。</div><div class=" pTag">相比于4bit的BitsandBytes<span>（W4A16）</span>方法，TC-FPx的最大速度提升则是达到了8.9倍。</div><div class=" pTag"><span>（W和A分别代表权重量化位宽和激活量化位宽）</span></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHy1jiaMzdXiaAaiaRmLctaIicKh5Ils1P88GQ51LsIxWIAKnnjO2C6XEcE0w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>归一化数据，以cuBLAS结果为1</h6><div class=" pTag">同时，TC-FPx内核还减少了对DRAM内存的访问，并提高了DRAM带宽利用率和Tensor Cores利用率，以及ALU和FMA单元的利用率。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyIWpCiao9VKbc5oMyByiarqADXcalNsNb4FX6KD47miclm6hfoLG1iatm7Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在TC-FPx基础之上设计的<span><strong style="font-weight: 600;">端到端推理框架FP6-LLM</strong></span>，也给大模型带来了显著的性能提高。</div><div class=" pTag">以Llama-70B为例，用FP6-LLM在单卡上的运行吞吐量，比FP16在双卡上还要高出2.65倍，在16以下的批大小中的延迟也低于FP16。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHy1qkNYicsmiaouA284FmFxRUDa3BxS9AicfMTRponPG6ibBxsibc19MKnVjw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而对于参数量小一些的模型OPT-30B（FP16也使用单卡），FP6-LLM同样带来了明显的吞吐量提升和延迟降低。</div><div class=" pTag">而且单卡FP16在这种条件下最多支持的批大小只有4，FP6-LLM却可以在批大小为16的情况下正常运行。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyKT7brBGibUXhVHrpCyGclYE4TbyfC62m2N2Uc8RWKrUEfkMgJS22ESQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么，微软团队是怎样实现在A100上运行FP16量化的呢？</div><h2>重新设计内核方案</h2><div class=" pTag">为了实现对包括6bit在内精度的支持，TC-FPx团队设计了一个统一的内核方案，可以支持不同位宽的量化权重。</div><div class=" pTag">相比于传统的双内核方法，TC-FPx通过将去量化和矩阵乘法融合在单个内核中，减少了内存访问次数，提高了性能。</div><div class=" pTag">实现低精度量化的核心奥义则是通过去量化方式，将FP6精度的数据“伪装”成FP16，然后按照FP16的格式交给GPU进行运算。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyxKVxUo2AOEtiaLccBXYRd64T0H4KmuCwoV7R8oKicic2OvRCwtfPj6btQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同时团队还利用了<strong style="font-weight: 600;"><span>位级预打包</span></strong>技术，解决GPU内存系统对非2的幂次位宽（如6-bit）不友好的问题。</div><div class=" pTag">具体来说，位级预打包是在模型推理之前对权重数据进行重新组织，包括将6-bit量化的权重重新排列，以便它们能够以GPU内存系统友好的方式进行访问。</div><div class=" pTag">此外，由于GPU内存系统通常以32位或64位的块进行数据访问，位级预打包技术将还会6-bit权重打包，使得它们能够以这些对齐的块的形式存储和访问。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyDYCxY1SxicMpSiapqpeETtTMxYclkuuQ03yuK4S0f0h3ZTQOdVLfxQDw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">预打包完成后，研究团队使用SIMT核心的并行处理能力，对寄存器中的FP6权重执行并行去量化，生成FP16格式的权重。</div><div class=" pTag">去量化后的FP16权重在寄存器中被重构，然后送入Tensor Core，使用重构后的FP16权重执行矩阵乘法运算，完成线性层的计算。</div><div class=" pTag">在此过程中，团队利用了SMIT核心的<strong style="font-weight: 600;"><span>位级并行性</span></strong>，提高了整个去量化过程的效率。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyqdJiaRrbYK3OZm12PBea9GGVub2HXbUKAVy9xicfnlnIkiae3Qa4Yh35g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而为了权重重构任务能够并行运行，团队还使用了一种<strong style="font-weight: 600;"><span>并行权重拼接</span></strong>技术。</div><div class=" pTag">具体来说，每个权重被分割成几个部分，每个部分的位宽是2的幂次<span>（如把6分割成2+4或4+2）</span>。</div><div class=" pTag">在去量化之前，权重首先从共享内存加载到寄存器中。由于每个权重被分割成多个部分，需要在运行时在寄存器级别重构完整的权重。</div><div class=" pTag">为了减少运行时的开销，TC-FPx提出了一种并行提取和拼接权重的方法。这种方法使用两组寄存器来存储32个FP6权重的片段，并行地重构这些权重。</div><div class=" pTag">同时，为了并行提取和拼接权重，需要确保初始数据布局满足特定的顺序要求，因此TC-FPx通过在运行前对权重片段进行重排。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHydDXoF8xUW94FCbmcbLricGGRb6CbnXgRanX2dEv37RKiaeqmoYwiaTupA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，TC-FPx还设计了一个<strong style="font-weight: 600;"><span>软件流水线</span></strong>，将去量化步骤与Tensor Core的矩阵乘法操作融合在一起，通过指令级并行性提高了整体的执行效率。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyS8xUjfAVsicVZJ2Mpiben6e0HQnwTWZDwTDPEM9tIwvt64QvTI2nWGWQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">论文地址：</div><br /></span><span style="font-size: 17px;">https://arxiv.org/abs/2401.14112</span><br /><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /></span><span style="font-size: 17px;">https://twitter.com/rohanpaul_ai/status/1784599257384727044</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FXBCodtzdCXsvcCov5-YHPQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 04:11:44 GMT</pubDate>
</item>
<item>
<title>苹果首个AI平板曝光：新iPad Pro直接上M4芯片</title>
<link>https://posts.careerengine.us/p/662f1df11c641d4b8555ba76</link>
<guid>https://posts.careerengine.us/p/662f1df11c641d4b8555ba76</guid>
<content:encoded><![CDATA[
<div> 苹果 iPad Pro M4芯片 OLED 易手的关键词：<br />
总结:<br />
苹果将推出搭载M4芯片的新版iPad Pro，跳过M3，主要提升神经网络引擎性能，首次采用OLED屏幕。新iPad Pro可提升人脸识别等AI功能，外观轻微改进。全新Apple Pencil和妙控键盘将同步推出。苹果将iPad Pro定位为第一款真正的AI设备，未来产品也将以AI设备为卖点。iPhone 16可能围绕AI构建A18芯片，提高神经网络引擎核心数。iOS 18将提供新的生成式AI功能。古尔曼担心用户对新功能接受程度。Vision Pro销量放缓，首席营销官退休，苹果需重新推销Vision Pro。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">金磊 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag" style="font-size: 17px;"><strong style="font-weight: 600;">苹果第一款真正的AI设备</strong>，即将问世。</div><div class=" pTag" style="font-size: 17px;">据彭博社Mark Gurman最新爆料：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">苹果将在5月份发布新版<strong style="font-weight: 600;">iPad Pro</strong>，直接搭载<strong style="font-weight: 600;">M4芯片</strong>，跳过M3。</div></blockquote><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyeY2ib8ZFjmTLHQrbHhKnWA0XXUlWSejpg7NXxksQwk7icrmiaEJIcDzicw/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>图源：Macrumors</h6><div class=" pTag" style="font-size: 17px;">从目前流传的消息来看，M4芯片依旧采用台积电3nm工艺，主要提升的是神经网络引擎的性能，可以让AI功能用起来更加丝滑。</div><div class=" pTag" style="font-size: 17px;"><span>（PS：M3芯片的神经网络引擎是16核，苹果已经有数年没有增加该引擎的数量。）</span></div><div class=" pTag" style="font-size: 17px;">根据古尔曼更早的爆料，M4系列芯片或许也可能像M3一样，配有M4、M4 Pro和M4 Max三个版本。</div><div class=" pTag" style="font-size: 17px;">具体到iPad Pro，增强的神经网络引擎性能可以让解锁iPad时的人脸识别等功能提到提升。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHybj4MsyD95l6iaHYSic5STTJWp60L6yPyc5tg6sMicwQ29aRCItaU3yepg/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>图源：Macrumors</h6><div class=" pTag" style="font-size: 17px;">除了芯片之外，古尔曼这次还爆料称，最新的iPad Pro另一个重大变化在于屏幕——<strong style="font-weight: 600;">将首次采用OLED</strong>。</div><div class=" pTag" style="font-size: 17px;">虽然古尔曼在此之前一直表示，这次的iPad Pro在外观上会是2018年以来最大的变革，但从2月份流出的一张CAD图来看，新iPad Pro只是像iPhone 15 Pro一样边缘变得圆润、机身变得更薄。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyFjum3iciaXW8Iut6knX9agSnXnbZtEynZPhYicAzkD3SYUoZibDq8DM0tQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>图源：Macrumors</h6><div class=" pTag" style="font-size: 17px;">因此，The Verge以及网友们对于外观上的更新并不买账，认为如果苹果最终真以这种设计交付，就“不算是最重大的变革”。</div><div class=" pTag" style="font-size: 17px;">在配件方面，爆料内容则是称苹果会同步推出全新一代的<strong style="font-weight: 600;">Apple Pencil</strong>和<strong style="font-weight: 600;">妙控键盘</strong>，让生产力和创造力更上一层楼。</div><div class=" pTag" style="font-size: 17px;">整体来看，古尔曼认为苹果会将搭载M4芯片的iPad Pro定位为“第一款真正的人工智能设备”：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">并且在此之后，苹果会把每一款新产品都作为人工智能设备来宣传。</div></blockquote><div class=" pTag" style="font-size: 17px;">很多网友们也支持这一观点，认为新iPad Pro是将M4芯片投入到Mac等产品之前的测试：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHykkP2qLyhJxDuHawgcq1dbYeG97B3ufiaxpm07iaeXY0BRdITjiaRlk1Kg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">但古尔曼也表达他对于苹果手机的期待：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我希望iPhone 16系列里的A18芯片，也是围绕AI来构建的。</div></blockquote><h2>下一代iPhone，能AI起来吗？</h2><div class=" pTag" style="font-size: 17px;">围绕下一代iPhone与AI之间的话题，其实在近期陆陆续续也有所有曝光。</div><div class=" pTag" style="font-size: 17px;">例如在芯片设计方面，投资分析师Jeff Pu此前就爆料称，将搭载在iPhone 16 Pro上的A18 Pro会采用更大的芯片尺寸，为的就是提高AI性能。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHysvUicCBpNHktbfNFesvrgLHMFgK3CnOkbSL07X6N2Uhsple2vyXWaaw/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>图源：Macrumors</h6><div class=" pTag" style="font-size: 17px;">更具体而言，跟M4芯片类似，苹果会“显著”增加A18系列芯片中的神经网络引擎核心数。</div><div class=" pTag" style="font-size: 17px;">在操作系统方面，此前也有爆料称<strong style="font-weight: 600;">iOS 18</strong>会给新iPhone的功能和应用程序提供新的生成式AI功能，包括 Siri、Spotlight、Apple Music、健康、信息、Numbers、Pages、Keynote、快捷方式等。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHypiaX9iazTQbIfcaeuoefTWto6ugsrlTQqWicjYT3UaVO2RJMoVxEXswUQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>图源：Macrumors</h6><div class=" pTag" style="font-size: 17px;">而本身已然在AIGC时代处于略显掉队地位的苹果，如何在此发力并让自家产品great again，自然成为了外界非常关心的话题。</div><div class=" pTag" style="font-size: 17px;">虽然已有传闻称新iPhone会包含基于苹果内部的大语言模型，但彭博社也频频爆料称苹果在AIGC能力上会采取合作的形式。</div><div class=" pTag" style="font-size: 17px;">例如苹果正在考虑在新手机中采用谷歌的<span><strong style="font-weight: 600;">Gemini</strong></span>还是OpenAI的<span><strong style="font-weight: 600;">ChatGPT</strong></span>，也有消息称苹果已经在和OpenAI进行合作上的谈判。</div><div class=" pTag" style="font-size: 17px;">并且对于国内市场，也有消息称苹果在与百度进行谈判，兴许用户可以在新一代苹果手机中体验基于<span><strong style="font-weight: 600;">百度文心一言</strong></span>模型的新AI功能。</div><div class=" pTag" style="font-size: 17px;">对此，古尔曼在此次爆料中也表达了自己的观点：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">苹果进入一个已经建立的市场（AIGC）并不罕见，但它喜欢带着“新技巧”到来。</div><div class=" pTag">苹果这次的计划是展示与iPhone操作系统深度集成的AIGC功能，而不是仅仅复制现有软件之上的元素，会比竞争对手的系统具有更多的隐私和安全性。</div></blockquote><div class=" pTag" style="font-size: 17px;">虽说如此，鉴于之前产品的经验和用户反馈，古尔曼比较担心的一点是——用户会不会对苹果手机的新功能买单。</div><div class=" pTag" style="font-size: 17px;">毕竟像iPad台前调度、iOS 17待机模式或日记应用程序等等，很多用户可能听都没有听过……</div><div class=" pTag" style="font-size: 17px;">总而言之，苹果会在AIGC交出什么的“作业”，答案将会在今年WWDC中揭晓，值得期待一波。</div><h2>One More Thing</h2><div class=" pTag" style="font-size: 17px;">苹果Vision Pro在销量进入放缓期之后，古尔曼又爆料称：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">在苹果就职36年、Vision Pro首席营销官Frank Casanova正式退休。</div></blockquote><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCdhVGADQySQ6un6RWSNaHyqPeGxib5aQqPe9VVfmp3ucynr5sFTTZ0Vfj8U8EsPKibmtz4sS59N03g/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>图源：苹果</h6><div class=" pTag" style="font-size: 17px;">就目前来看，许多苹果商店对Vision Pro的需求已经大幅下降，一位零售人员甚至表示：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">已经几周没有看到顾客购买过一台Vision Pro了，退货数量相当于设备上市第一个月的销量。</div></blockquote><div class=" pTag" style="font-size: 17px;">对此，古尔曼担忧地表示，苹果现在必须弄清楚如何向消费者更好地推销Vision Pro——解释这款售价3499美元的产品与其他头显的不同之处，而不是几个月后被用户放到抽屉里落灰。</div><div class=" pTag" style="font-size: 17px;"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://www.bloomberg.com/news/newsletters/2024-04-28/apple-rivals-retool-to-compete-with-iphone-and-vision-pro-ios-18-and-ai-details-lvjhucsv</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://9to5mac.com/2024/04/28/gurman-new-ipad-pro-m4-chip/</span><br /><span style="font-size: 17px;">[3]</span><span style="font-size: 17px;">https://www.theverge.com/2024/4/28/24143526/apple-oled-ipad-pro-11-13-inch-m4-ai-tablet</span><br /><span style="font-size: 17px;">[4]</span><span style="font-size: 17px;">https://twitter.com/theapplehub/status/1784726461154472423</span><br /><span style="font-size: 17px;">[5]</span><span style="font-size: 17px;">https://www.macrumors.com/2024/03/25/iphone-16-pro-a18-pro-chip-details/</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FROnpmh59zbSdl-7i1kmNVg">阅读原文 </a>
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 04:11:29 GMT</pubDate>
</item>
<item>
<title>Sora大片真相：人工特效参与，被指误导大众</title>
<link>https://posts.careerengine.us/p/662f1df11c641d4b8555ba86</link>
<guid>https://posts.careerengine.us/p/662f1df11c641d4b8555ba86</guid>
<content:encoded><![CDATA[
<div> OpenAI, Sora, Shy Kids, 视频生成, 后期处理<br />
<br />
总结:<br />
Sora是一个视频生成AI，但实际上背后有大量人类工作参与，Shy Kids团队使用Sora制作了短片《气球人》，揭秘了制作过程。Sora不能解决视频片段一致性问题，需要人类后期处理。视频素材处理和后期制作均需要人工干预。Sora生成视频素材是480p，需要后期处理。对于专业团队来说，Sora有进步空间，但已足够惊艳。Sora不能生成声音，音频需要团队自行添加。对于Sora的观点分歧，在工作流中是否使用Sora有争议，有人认为Sora是工作流的补充，也有人批评其营销方式。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">鱼羊 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">啊？Sora火爆短片《气球人》，也“造假”了？？？</div><div class=" pTag">背后艺术家团队的最新揭秘，可谓一石激起千层浪：</div><div class=" pTag">原来，<strong style="font-weight: 600;">视频画面并非完全由AI生成，其中有大量视觉效果需要人类后期实现</strong>。</div><div class=" pTag">be like：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdf3YJpDXodbQS1nuZe84OicDhJibhsyGfoARrm8ZfwRTEyYYTAibeic5vog/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这下网友不干了，合着大家伙儿跟OpenAI玩真心，OpenAI背后却耍起心眼子来了：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">他们含糊其辞，就是希望观众认为短片完全是AI生成的，这是不是有点不诚实了啊。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdKDZJJ4U7UfR9ibyInDsrDH7OawIibkuYmrFgLicNFoW0gsHx1qpI0xB7w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">这不是人工智能生成的视频，而是使用了一些AI技术的视频。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdqRAkFmHoEgd6eBplBEtvvImwRBicbWvmpWibJRgibxeKpYmyh67oV2Xaw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">还有网友直接开喷：误导性营销！这是误导性营销！</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxddiaCbBqtSvvhXZ3bndnlGJSb3AUEjtaZGILJEXsBzH71YCKDgkWicnicQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">究竟是怎么个事儿，咱们还是具体捋一捋。</div><h2>揭秘Sora大片工作流</h2><div class=" pTag">尽管OpenAI一开始就介绍了，《气球人》这样的短片出自艺术家团队之手，他们只是把Sora开放给了艺术家使用，但官方并未提及短片具体是如何制作而成的。</div><div class=" pTag">现在，《气球人》背后的艺术家团队Shy Kids自己来了个大揭秘，内容包括：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">视频片段一致性如何实现</div></li><li><div class=" pTag">他们如何处理Sora生成的视频素材</div></li><li><div class=" pTag">Sora生成视频的局限性及后期处理</div></li></ul><h3>视频一致性</h3><div class=" pTag">《气球人》中主角形象的一致性可谓惊艳众人。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdcsP2eE3P9rPLA60kN1to8cTuj2WawliceKl0DHx5GiaqyRU01QIb7obQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">但实际上吧，据Shy Kids团队中负责后期制作的老哥Patrick Cederberg<span>（简称老帕）</span>透露，想要实现这种前后一致并不是写写提示词就能成的。</div><div class=" pTag">Sora并没有提供工具，来帮助实现不同镜头之间的主体一致性。也就是说，哪怕提示词都是一样的，两次运行的结果也会有所不同。</div><div class=" pTag">他们的做法是，尽可能详细地去对主角形象进行描述。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">解释角色的服装以及气球的类型是我们解决一致性问题的方法，目前Sora还没有集成适当的功能来实现此类控制。</div></blockquote><div class=" pTag">即便如此，团队在用Sora生成视频素材时还是遇到了不少这样那样的问题。</div><div class=" pTag">比如，提示词里明明写了气球是黄色的，但Sora生成的片段里气球却可能变红。</div><h3>视频素材处理</h3><div class=" pTag">一致性之外，老帕提到，在时间轴方面，Sora允许用户修改关键帧。但这种时间控制并不精准，无法保证一定能实现预想的效果。</div><div class=" pTag">另外，想要实现这个镜头：</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdSIsomEH8rX75kIubGj8ZOrJoP3fQD2OAm9ajiaQDvULYFDvaficXkN0w/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">即把镜头焦点从牛仔裤一路上移到气球头，也得人类自己后期裁切平移画面，因为Sora本身不会渲染这样的镜头：它总是倾向于把焦点集中在气球头上。</div><div class=" pTag">老帕还谈到，他们在写提示词时也遇到了一些问题：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">OpenAI在让艺术家试用Sora前，并没有考虑到真正的电影制作人是如何思考的。</div></blockquote><div class=" pTag">简单来说，就是Sora对摄影术语（比如跟拍、平移等）的理解有限。老帕认为，这一点上Sora不如Runway。</div><div class=" pTag">值得一提的是，尽管Sora原生支持生成1080p视频，但老帕他们实际上生成的素材都是480p的。他们是在后期使用Topaz等工具对视频素材进行了超分处理。</div><div class=" pTag">生成速度方面，根据老帕的回忆，每次大概需要10-20分钟的时间。</div><h3>视频后期</h3><div class=" pTag">接下来，就到了网友们反应最强烈的部分——后期。</div><div class=" pTag">前面已经说到，Sora本身还解决不了不同视频片段里一致性的问题。</div><div class=" pTag">除了气球不一定符合设定，或许是因为训练数据的原因，Sora还喜欢自动给气球加上奇奇怪怪的人脸。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdrhKAUkuDPicbIns8GIIIcDiabzw6ua8knMxBG3ICF0sgrrn1YVzpSfcQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">给主角生成其实并不需要的假人头。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxd8oILO7RX1O5z6tzJxSVS0Emj7SQEEDIo7oqVMdKPzZyBIIFPOkk7xQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">Sora还很坚定地认为气球得带根绳。</div><div class=" pTag">总而言之言而总之，这些都需要老帕上手丢到AE里，进行后期处理。</div><div class=" pTag">另外，尽管Shy Kids发现“35mm胶卷”这样的关键词很好用，能让Sora生成的视频画面风格更一致，但艺术家们仍需要为最后的成片做调色，为画面添加颗粒和闪烁效果，以使整部影片画面更加协调统一。</div><div class=" pTag">老帕还提到了一个有意思的细节：</div><div class=" pTag">Sora很喜欢慢镜头。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我不知道为什么，但有很多镜头看上去都是0.5倍速和0.75倍速。</div><div class=" pTag">因此我们需要对大量画面进行调速，免得影片看上去像个大型慢动作项目。</div></blockquote><div class=" pTag">那么，Sora生成的视频素材有多少最终被用在了影片里？</div><div class=" pTag">“数学很差”的老帕估计了一下，大概是<strong style="font-weight: 600;">300:1</strong>。</div><div class=" pTag">音频方面，Sora目前还不能生成声音，因此旁白和音乐都是团队自己加上去的。</div><h3>版权</h3><div class=" pTag">为了不侵犯版权，OpenAI给Sora上了一些限制。</div><div class=" pTag">比如，你不能把提示词写成“35mm胶卷，未来宇宙飞船中，一名男子拿着光剑靠近”，那样Sora会直接拒绝生成，因为这画面太像《星球大战》了。</div><div class=" pTag">哦对，像什么“阿罗诺夫斯基式镜头”和“希区柯克变焦”也是不行的。</div><h2>3人团队2周制作完成</h2><div class=" pTag">该说不说，在外界卷起风波之前，Shy Kids团队对于Sora的表现还是很满意的。</div><div class=" pTag">毕竟，制作《气球人》这样一个高质量短片，最后只用了他们仨1.5到2周的时间。</div><div class=" pTag">团队认为，现在，对于专业的电影团队来说，Sora当然还有很大进步空间，但对于大部分人而言，Sora已经足够惊艳。</div><div class=" pTag">用老帕自己的话说：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我觉得人们应该将Sora变成工作流里的一部分。</div><div class=" pTag">不过，如果他们不想跟AI沾边，也没关系。</div></blockquote><div class=" pTag">对于这样的观点，也有不少网友表示认同，认为Sora这样的视频生成AI，是对现有工作流很好的补充。</div><div class=" pTag">Adobe把它们集成进软件里，就是一个很不错的主意。</div><div class=" pTag">但，“我厌倦了OpenAI们的精美Demo营销”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxd6z5MMKb7ZWjh2X1l8ZibBj6RvicR9wuluwEjnib4a3OTj28iaD67v5LtBw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">还有网友不满的点在于，爆火的“人工智能生成视频”背后有大量的人类工作，他们投入数百个小时工作，却被AI掩盖了真实的价值。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdqm67ehaXx76ibzWpqVjxfibowymAGrq9bqZgML88vz37kCb6oYBtT8xg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么，这事儿你怎么看？</div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://www.fxguide.com/fxfeatured/actually-using-sora/</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://twitter.com/bilawalsidhu/status/1783544598259794046</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FX0Z853h-7G2ge68eOcJd4g">阅读原文 </a>
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 04:11:29 GMT</pubDate>
</item>
<item>
<title>超级智能体生命力觉醒！可自我更新的AI来了，妈妈再也不用担心数据瓶颈难题</title>
<link>https://posts.careerengine.us/p/662f1df11c641d4b8555ba7e</link>
<guid>https://posts.careerengine.us/p/662f1df11c641d4b8555ba7e</guid>
<content:encoded><![CDATA[
<div> 关键词: Awaker 1.0, 多模态大模型, 自主更新, 云边协同, 具身智能<br />
<br />
总结: <br />
Awaker 1.0是一款多模态大模型，采用自主更新机制，可以在互联网上学习新知识并持续更新。其与具身智能结合，能适应不同环境并具有创造性。通过云边协同技术，与智能设备合作完成任务。这种模型的出现为多模态大模型的持续学习和进化提供了可能，也为迈向AGI迈出了一步。智子引擎团队的努力和创新推动了这一领域的发展。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">衡宇 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">哭死啊，全球狂炼大模型，一互联网的数据不够用，根本不够用。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdQoV4OIiaHETBCPQobcwdatbg9SuFo68j19dOMGMVw2gTteetFKAEzFQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">训练模型搞得跟《饥饿游戏》似的，全球AI研究者，都在苦恼怎么才能喂饱这群数据大胃王。</div><div class=" pTag">尤其在多模态任务中，这一问题尤为突出。</div><div class=" pTag">一筹莫展之际，来自<span><strong style="font-weight: 600;">人大系的初创团队</strong></span>，用自家的新模型，率先在国内把“模型生成数据自己喂自己”变成了现实。</div><div class=" pTag"><span>而且还是理解侧和生成侧双管齐下，两</span>侧<span>都能生成高质量、多模态的新数据，对模型本身进行数据反哺。</span></div><div class=" pTag">模型是啥？</div><div class=" pTag">中关村论坛上刚刚露面的<span><strong style="font-weight: 600;">多模态大模型Awaker 1.0</strong></span>。</div><div class=" pTag">团队是谁？</div><div class=" pTag"><span><strong style="font-weight: 600;">智子引擎。</strong></span>由人大高瓴人工智能学院博士生高一钊创立，高瓴人工智能学院卢志武教授担任顾问。公司成立时还是2021年，就早早打入多模态这条“无人区”赛道。</div><h2>MOE架构，解决多模态多任务训练冲突问题</h2><div class=" pTag">这不是智子引擎第一次发布模型。</div><div class=" pTag">去年3月8日，潜心研发两年的团队对外发布了自研的第一个多模态模型，百亿级别参数的ChatImg序列模型，并基于此推出世界首个公开评测多模态对话应用ChatImg<span>（元乘象）</span>。</div><div class=" pTag">后来，ChatImg不断迭代，新模型Awaker的研发也在并行推进。后者还继承了前代模型的基础能力。</div><div class=" pTag">相较于前代的ChatImg序列模型，Awaker 1.0<span><strong style="font-weight: 600;">采用了MoE模型架构</strong></span>。</div><div class=" pTag">要说原因嘛，是想要解决解决多模态多任务训练存在严重冲突的问题。</div><div class=" pTag">采用MoE模型架构，可以更好地学习多模态通用能力以及各个任务所需的独特能力，从而让整个Awaker 1.0的能力在多个任务上有进一步提升。</div><div class=" pTag">数据胜千言：</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdib37ApjrXkiatgiaVQqRcbkYMy9dF2iaiafu8ibiaOpQ2IMonyGjt5GUr49SQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">鉴于主流多模态评测榜单存在评测数据泄露问题，智子团队从严构建了自有评测集，大部分测试图片来自个人手机相册。</div><div class=" pTag">表格显示，团队让Awaker 1.0和国内外最先进的3个多模态大模型进行了评测。</div><div class=" pTag">多提一嘴，由于GPT-4V和Intern-VL并不直接支持检测任务，它们的检测结果是通过要求模型使用语言描述物体方位得到的。</div><div class=" pTag">可以看到，在视觉问答和业务应用任务上，Awaker 1.0的基座模型超过了GPT-4V、Qwen-VL-Max和Intern-VL。</div><div class=" pTag">在描述、推理和检测任务上，Awaker 1.0的基座模型达到了次好效果。</div><div class=" pTag">最后来看平均分，Awaker 1.0处于几者中的最高值。</div><div class=" pTag">因此，上述结果也印证了多任务多模态模型采用MoE架构的有效性。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdg1OcKouJ1HWAn6kNykHdLUvuBjTs2uZz8AWNHWdZicWkPsILLbK7rPg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">数据集评测结果有了，真实效果还需进一步上手体验。</div><div class=" pTag">这里主要问了它和对比大模型一些关于中文OCR<span>（图片文字识别）</span>和计数问题、详细描述任务等问题。</div><div class=" pTag">这个主要<span><strong style="font-weight: 600;">考计数</strong></span>：</div><div class=" pTag">Awaker 1.0能正确地给出答案，而其它三个模型均回答错误。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdz54vk2IEF3jAqicjuUEuot8sr2yDmcOngF83h1QHicJ2OrgdsS0GibbRg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这个主要考<span><strong style="font-weight: 600;">中文OCR</strong></span>：</div><div class=" pTag">正确回答的选手是Qwen-VL-Max和Awaker 1.0。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdDfUIicSEaNFlvnthFSo23o3ubCE8icvr2hYJsibqm7iagoBBu1WBhFaRag/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">最后这题考<span><strong style="font-weight: 600;">图片内容理解</strong></span>。</div><div class=" pTag">GPT-4V和Awaker 1.0不但能够详细地描述图片的内容，而且能够准确地识别出图片中的细节，如图中展示的可口可乐。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdxhB4Ss2oOgWQjNIia3ZNL8eqmHPuvLqxA8ibLiamV6yCS7JFG4g8icKOwA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不得不提一嘴的是，Awaker 1.0继承了一些智子团队此前广为关注的研究成果。</div><div class=" pTag">说的就是你——Awaker 1.0的<span><strong style="font-weight: 600;">生成侧</strong></span>。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxd5U198HStCbRIm8FYDD2OUkNrMennYgjjVrXFnHIibyRPvJpILC4TTQA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">Awaker 1.0的生成侧，是智子引擎自主研发的类Sora视频生成底座VDT<span>（Video Diffusion Transformer）</span>。</div><div class=" pTag">VDT的学术论文早于OpenAI Sora的发布<span>（去年5月）</span>，并已被顶会ICLR 2024接收。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdu0ZoEoy5zCQ7fFtLVP1B94LBV8WuvBibYicZAPgkSa04hLHzmPX2chtA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">VDT与众不同的创新之处，主要有两点。</div><div class=" pTag"><span><strong style="font-weight: 600;">一是在技术架构上采用Diffusion Transformer</strong></span>，在OpenAI之前就展现了Transformer在视频生成领域的巨大潜力。</div><div class=" pTag">它的优势在于其出色的时间依赖性捕获能力，能够生成时间上连贯的视频帧，包括模拟三维对象随时间的物理动态。</div><div class=" pTag"><span><strong style="font-weight: 600;">二是提出统一的时空掩码建模机制</strong></span>，使VDT能够处理多种视频生成任务。</div><div class=" pTag">VDT灵活的条件信息处理方式，如简单的token空间拼接，有效地统一了不同长度和模态的信息。</div><div class=" pTag">同时，通过与该工作提出的时空掩码建模机制结合，VDT成为了一个通用的视频扩散工具，在不修改模型结构的情况下可以应用于无条件生成、视频后续帧预测、插帧、图生视频、视频画面补全等多种视频生成任务。</div><div class=" pTag">据了解，智子引擎团队不仅探索了VDT对简单物理规律的模拟，发现<span><strong style="font-weight: 600;">它能模拟物理过程</strong></span>：</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdWhBbE1eE8YzGaL7bMkXQ6KesKibGqZKHsDEcNNkyzTTUmM46YqjEMMA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">还在<span><strong style="font-weight: 600;">超写实人像视频生成任务</strong></span>上进行了深度探索。</div><div class=" pTag">因为肉眼对人脸及人的动态变化非常敏感，所以这个任务对视频生成质量的要求非常高。不过，智子引擎已经突破超写实人像视频生成的大部分关键技术，比起Sora也没在怕的。</div><div class=" pTag">口说无凭。</div><div class=" pTag"><div class=" pTag">这是智子引擎结合VDT和可控生成，对人像视频生成质量提升后的效果：</div><br /></div><div class=" pTag"><div class=" ce-iframe-holder offset offset-old-96"></div></div><div class=" pTag">据悉，智子引擎还将继续优化人物可控的生成算法，并积极进行商业化探索。</div><h2>生成源源不断的新交互数据</h2><div class=" pTag">更值得关注的是，智子引擎团队强调：</div><div class=" pTag">Awaker 1.0是<span><strong style="font-weight: 600;">世界上首个能自主更新的多模态大模型</strong></span>。</div><div class=" pTag">换句话说，Awaker 1.0是“活”的，它的参数可以实时持续地更新——这就导致Awaker 1.0区别于所有其它多模态大模型，</div><div class=" pTag">Awaker 1.0的自主更新机制，包含三大关键技术，分别是：</div><ul class="list-paddingleft-1"><li><div class=" pTag">数据主动生成</div></li><li><div class=" pTag">模型反思评估</div></li><li><div class=" pTag">模型连续更新</div></li></ul><div class=" pTag">这三项技术，让Awaker 1.0具备自主学习、自动反思和自主更新的能力，可以在这个世界自由探索，甚至与人类互动。</div><div class=" pTag">基于此，Awaker 1.0在理解侧和生成侧都能生成源源不断的新交互数据。</div><div class=" pTag">怎么做到的？</div><div class=" pTag"><span><strong style="font-weight: 600;">在理解侧，</strong></span>Awaker 1.0与数字世界和现实世界进行交互。</div><div class=" pTag">在执行任务的过程中，Awaker 1.0将场景行为数据反哺给模型，以实现持续更新与训练。</div><div class=" pTag"><span><strong style="font-weight: 600;">在生成侧，</strong></span>Awaker 1.0可以进行高质量的多模态内容生成，为理解侧模型提供更多的训练数据。</div><div class=" pTag">在理解侧和生成侧的两个循环中，Awaker 1.0实际实现了将视觉理解与视觉生成进行融合。</div><div class=" pTag">要知道，Sora问世后，越来越多声音表示，要通往AGI，必须达成“理解和生成的大一统”。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdpkUlO58fna0FCEkyvlc0lq0lNoiaibwZFsPSicWNsvnF6TibISv6oBe7ibQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">以新知识注入为例，下面来看个具体跑通的例子。</div><div class=" pTag">Awaker 1.0能够不断在互联网上学习实时新闻信息，同时，它结合新学习到的新闻信息来回答各种复杂问题。</div><div class=" pTag">这和目前两种主流，即RAG和传统长上下文方式还不太一样，Awaker 1.0是真的<span><strong style="font-weight: 600;">把新知识“记忆”在自个儿模型的参数上</strong></span>。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdYTxJibKMSnDsPPcvy6icOs50HM8icoF90p7T6gaaLNyXIJiaS02UMz7rsA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">可以看到，连续3天的自我更新过程中，Awaker 1.0每天都能学习当天的新闻信息，并在描述中准确地说出对应信息。</div><div class=" pTag">而且虽然一直在学，Awaker 1.0倒没有顾此失彼，它并不会很快地遗忘学过的知识。</div><div class=" pTag">譬如，4月16日学进去的智界S7相关知识，在2天后仍然被Awaker 1.0记住或理解。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdDnIl99Uw1CuaDOqWtuYaAh74nNdOrD2r1Rv7u3LGmUVmB0801NH3tA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">So，在这个数据如金的时代，别再哀叹“数据不够用”了。</div><div class=" pTag">面对数据瓶颈的团队们，一种可行、可用的新选择，不就被Awaker 1.0送来了？</div><h2>具身智能“活”的大脑</h2><div class=" pTag">话说回来，正是由于实现了视觉理解与视觉生成的融合，当遇到“多模态大模型适配具身智能”的问题，Awaker 1.0的骄傲已经显露无疑。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdFic5rwWhIELyWGs6BI2BibwwXZKHkpwV2Ftw4Gc5MLddtuyib21A0BSqg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">事情是这样的：</div><div class=" pTag">Awaker 1.0这类多模态大模型，其具有的视觉理解能力可以天然与具身智能的“眼睛”相结合。</div><div class=" pTag">而且主流声音也认为，“多模态大模型+具身智能”有可能大幅地提升具身智能的适应性和创造性，甚至是实现AGI的可行路径。</div><div class=" pTag">理由不外乎两点。</div><div class=" pTag"><span><strong style="font-weight: 600;">第一，</strong></span>人们期望具身智能拥有适应性，即智能体能够通过持续学习来适应不断变化的应用环境。</div><div class=" pTag">这样一来，具身智能既能在已知多模态任务上越做越好，也能快速适应未知的多模态任务。</div><div class=" pTag"><span><strong style="font-weight: 600;">第二，</strong></span>人们还期望具身智能具有真正的创造性，希望它通过对环境的自主探索，能够发现新的策略和解决方案，并探索AI的能力边界。</div><div class=" pTag">但是二者的适配，并不是简简单单把多模态大模型链接个身体，或直接给具身智能装个脑子那么简单。</div><div class=" pTag">就拿多模态大模型来说，至少有两个明显的问题摆在面前。</div><div class=" pTag">一是模型的<span><strong style="font-weight: 600;">迭代更新周期长</strong></span>，需要大量的人力投入；</div><div class=" pTag">二是模型的训练数据都源自已有的数据，模型<span><strong style="font-weight: 600;">不能持续获得大量的新知识</strong></span>。虽然通过RAG和扩长上下文窗口也可以注入持续出现的新知识，模型记不住，补救方式还会带来额外的问题。</div><div class=" pTag">总之，目前的多模态大模型在实际应用场景中不具备很强的适应性，更不具备创造性，导致在行业落地时总是出现各种各样的困难。</div><div class=" pTag">妙啊——还记得我们前面提到，Awaker 1.0不仅可以学新知识，还能记住新知识，并且这种学习是每天的、持续的、及时的。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdBgiaXpcoyXib8CXxyC0pZFc5ve43jwEmYwJhDk6D7CKEglW1WEW12wlg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">从这张框架图可以看出，Awaker 1.0能够与各种智能设备结合，通过智能设备观察世界，产生动作意图，并自动构建指令控制智能设备完成各种动作。</div><div class=" pTag">在完成各种动作后，智能设备会自动产生各种反馈，Awaker 1.0能够从这些动作和反馈中获取有效的训练数据进行持续的自我更新，不断强化模型的各种能力。</div><div class=" pTag">这就相当于具身智能拥有一个活的大脑了。</div><div class=" pTag">谁看了不说一句how pay<span>（狗头）</span>～</div><div class=" pTag">尤其重要的是，因为具备自主更新能力，Awaker 1.0<span><strong style="font-weight: 600;">不单单是可以和具身智能适配，它还适用于更广泛的行业场景，能够解决更复杂的实际任务。</strong></span></div><div class=" pTag">例如，Awaker 1.0与各种智能设备结合，从而实现云边协同。</div><div class=" pTag">这时候，Awaker 1.0就是部署在云端的“大脑”，观察、指挥，控制各种边端智能设备执行各项任务。</div><div class=" pTag">而边端智能设备执行各项任务时获得的反馈，又会源源不断地传回给Awaker 1.0，让它持续地获得训练数据，不断进行自我更新。</div><div class=" pTag">这可不是纸上谈兵，Awaker 1.0与智能设备的云边协同的技术路线，已经应用在电网智能巡检、智慧城市等应用场景中，并取得了远好于传统小模型的识别效果。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdAdzRPCXobUtfc4KPvegicxHM6upsPmz60QzfeBXvneQPicPficxxw3s8Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">多模态大模型能听、能看、能说，在语音识别、图像处理、自然语言理解等多个领域展现出了巨大的潜力和应用价值，几乎无所不能。</div><div class=" pTag">但它的烦恼很明显，如何不断吸收新知识、适应新变化？</div><div class=" pTag">可以说，修炼内功、提升武艺成为了多模态大模型面临的一个重要课题。</div><div class=" pTag">智子引擎Awaker 1.0的问世，为多模态大模型的自我超越提供了一把钥匙。</div><div class=" pTag">它好像会了那个吸星大法，通过自主更新机制，打破了数据短缺的瓶颈，为多模态大模型的持续学习和自我进化提供了可能；再就是利用云边协同技术，勇闯在具身智能等智能体设备的具体应用场景。</div><div class=" pTag">这或许是迈向AGI的一小步，但同时也是多模态大模型自我超越之旅的一个开始。</div><div class=" pTag">漫长而艰难的旅程，需要智子引擎这样的团队，向技术的高峰不断攀登。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_gxcbyQ5baoMi6j9VQ1NDA">阅读原文 </a>
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 04:11:29 GMT</pubDate>
</item>
<item>
<title>上海期智研究院全球招人才！人工智能/信息安全/量子智能方向的来</title>
<link>https://posts.careerengine.us/p/662e2374d2b8dd064ef8cf8a</link>
<guid>https://posts.careerengine.us/p/662e2374d2b8dd064ef8cf8a</guid>
<content:encoded><![CDATA[
<div> 人工智能 信息安全 量子智能 PI科学家 博士后

<br /><br />总结:
上海期智研究院招聘海内外顶尖人才从事人工智能、信息安全、量子智能等领域的研究工作。研究院由姚期智创建，致力于建设世界顶尖科学研究机构，与多所高校合作联合双聘，共同培养博士生，提供优良的工作环境和薪酬待遇。招聘岗位包括PI科学家和博士后，要求应聘者提交个人简历及相关材料，通过邮箱应聘。研究院将提供福利待遇、科研经费和支持申请科研项目。详细信息可查看官网。 </div>
<div class=" pTag"><strong style="font-weight: 600;">上海期智研究院诚聘人工智能、信息安全、量子智能及相关方向的海内外顶尖人才（PI科学家与博士后）</strong>。</div><div class=" pTag">上海期智研究院是上海市新型研发机构之一，由图灵奖得主姚期智于2020年创建。研究院以建设世界顶尖基础科学研究机构为使命，打造上海科创中心建设新标杆。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2HxOD5S3RrmOT1eZkgJHiaz6LK7L1URqe33ZLMPPiaj8x9jvwk8d0PFMg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><h2>研究院优势</h2><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">高水平人才汇聚</strong><br />集聚全球顶尖人才，目前参与科研人员100余人，从事原创性、前瞻性的科学研究与技术攻关。</div></li><li><div class=" pTag"><strong style="font-weight: 600;">院校紧密合作</strong><br />与清华大学、上海交通大学、复旦大学、同济大学、上海科技大学等一流高校进行合作双聘，引进人才，共建尖端科学人才高地。联合培养博士生，资源共享，发挥学科人才优势。</div></li><li><div class=" pTag"><strong style="font-weight: 600;">理想工作环境</strong><br />徐汇西岸交通方便，环境优美，科学与艺术氛围浓厚，提供最佳工作与生活场景。</div></li><li><div class=" pTag"><strong style="font-weight: 600;">薪酬待遇</strong><br />提供具有国际竞争力的薪酬待遇，特别优秀者一事一议。</div></li></ul><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2YeoIdwJiaFKLGibKaWRicCCLDMKk5kJ4CV8ZRziaIvJqubPFZeQuO6kEhw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><h2>招聘岗位与任职资格</h2><h4>PI科学家</h4><div class=" pTag"><strong style="font-weight: 600;">招聘方向</strong></div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">人工智能</strong>：机器学习/强化学习/具身机器人/大模型/智能决策/计算机视觉/多模态机器学习/算法/自动驾驶/图形学等方向</div></li><li><div class=" pTag"><strong style="font-weight: 600;">信息安全</strong>：格密码/系统安全/数据隐私保护/对抗性攻击与防御/区块链等方向</div></li><li><div class=" pTag"><strong style="font-weight: 600;">量子智能</strong>：量子人工智能/量子计算等方向</div></li></ul><div class=" pTag"><strong style="font-weight: 600;">岗位描述</strong>:开展上述相关领域和方向的基础研究、算法或系统开发。</div><div class=" pTag"><strong style="font-weight: 600;">支持政策</strong></div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">与上海市知名高校联合双聘，享受高校相关政策支持，联合培养博士生。</div></li><li><div class=" pTag">支持申请国家及省部级人才项目，配套提供充足的科研启动经费。</div></li><li><div class=" pTag">享受上海市落户、住房、子女教育等人才保障。</div></li></ul><div class=" pTag"><strong style="font-weight: 600;">应聘要求</strong>：应聘者将应聘材料发送至邮箱：<a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a>，邮件主题注明“应聘上海期智研究院PI—姓名”</div><div class=" pTag"><strong style="font-weight: 600;">应聘材料</strong>：个人简历（含教育工作经历、科研方向、论文列表、3位推荐人姓名/联系方式、及代表成果简介）</div><h4>博士后</h4><div class=" pTag">上海期智研究院现与清华大学、上海交通大学、复旦大学、同济大学以及上海科技大学联合招聘博士后，我院将提供丰厚的福利待遇、研究工作所需的科研经费、良好的研究条件，并支持申请博后专项及各级科研项目。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2ia5ibVnzzMKnywZCuTnx9hwVzjdOA0PgxEwqLeEy9auJicRgY0xviciaD2g/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">PI简介及科研方向详情，请见上海期智研究院官网：https://sqz.ac.cn/pi</div><div class=" pTag"><strong style="font-weight: 600;">简历投递：</strong><br />应聘者将个人简历（含教育工作经历、科研方向、论文列表、及代表成果简介）发送至邮箱<a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a>，邮件主题请填写“博士后应聘+项目名称+姓名”。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FoHmTdshYbZASMBGREnXfDA">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 10:22:44 GMT</pubDate>
</item>
<item>
<title>国产多模态大模型开源！无条件免费商用，性能超Claude 3 Sonnet</title>
<link>https://posts.careerengine.us/p/662e2374d2b8dd064ef8cf9b</link>
<guid>https://posts.careerengine.us/p/662e2374d2b8dd064ef8cf9b</guid>
<content:encoded><![CDATA[
<div> 国产大模型、XVERSE-V、多模态、开源、元象
<br /><br />总结: 元象发布了国产多模态大模型XVERSE-V，并免费开源，支持任意宽高比图像输入，在多项评测中表现领先。该模型融合整体和局部信息，适用于全景图识别、视障场景等多领域。元象在商业应用上与腾讯等公司进行合作，在AI领域取得进展。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">简曈&nbsp;发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">又一个国产多模态大模型开源！</div><div class=" pTag"><span style="font-size: 17px; text-align: left;">XVERSE-V，来自元象，还是同样的</span><strong style="font-weight: 600;">无条件免费商用</strong><span style="font-size: 17px; text-align: left;">。</span></div><div class=" pTag">此前元象曾率先发布国内规模最大的开源大模型，如今开源家族系列又多了一个。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdnq1MhjIfJ6ZYfJXuW7KQmMpbr6thwiaP2ILgRLjabJ2yBAz1EuLFdXQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">最新的多模态大模型<strong style="font-weight: 600;">支持任意宽高比图像输入，</strong>在主流评测中保持着效果领先——</div><div class=" pTag">在多项权威多模态评测中，XVERSE-V超过零一万物Yi-VL-34B、面壁智能OmniLMM-12B及深度求索DeepSeek-VL-7B等开源模型。</div><div class=" pTag">在综合能力测评MMBench中超过了谷歌GeminiProVision、阿里Qwen-VL-Plus和Claude-3V Sonnet等知名闭源模型。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdRYKK1bJ9ysMQXCpoQoxT2k7w7NMQXdAibjsQH6O5icGfye4Dj3IVSbVQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>支持任意长宽比图像输入</h2><div class=" pTag">传统的多模态模型的图像表示只有整体，XVERSE-V 采用了融合整体和局部的策略，支持输入任意宽高比的图像。</div><div class=" pTag"><div class=" pTag">兼顾全局的概览信息和局部的细节信息，能够识别和分析图像中的细微特征，看的更清楚，理解的更准确</div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdiajUbK8SsENwv5o8laXf3FQibk78xSQ20BibLBVHqUJsWS5pVlDWahu2A/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxd5goO4QfINicxWmQ5iaW0pmygicIVma3E6JsQnV5tibQCaUNm7ics0T9ibKzA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这样的处理方式使模型可以应用于广泛的领域，包括全景图识别、卫星图像、古文物扫描分析等。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxd3zwXml7kOakibjFiadszwuLLLzVQAfaJEI20lFmYMetvHrCAaN1GDvaw/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>示例- 高清全景图识别</h6><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdyEkWKpS0FmhzgPfyia2IH7RNAFTAKDA5SaEK3cSTYpJqQhS77ibNsLTg/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>示例-图片细节文字识别</h6><div class=" pTag">除了基本能力表现不错，也能轻松应对各种不同的实际应用场景，比如图表、文献、代码转化、视障真实场景等。</div><div class=" pTag"><strong style="font-weight: 600;">图表理解</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxduwJwWX8DD8RDM1VRHrOg3989b4iaMwMnjePYlMTL8QGMzZu6wjOlyHQ/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /></div><div class=" pTag">不论是复杂图文结合的信息图理解，还是单一图表的分析与计算，模型都能够自如应对。</div><div class=" pTag"><strong style="font-weight: 600;">自动驾驶</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxd8mSvMRvXvUyErOuI8Ltvvic7wcmLagJLIdWUG6qXrBxjrcG1yE2K4wA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><strong style="font-weight: 600;">代码撰写</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdTEuajsdmhpp3Xb5xc3Y95ibq9w1omYib4HghLVf1snZOzH57icgS3iaFIQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">还有<strong style="font-weight: 600;">视障真实场景</strong>。</div><div class=" pTag">在真实视障场景测试集VizWiz中，XVERSE-V的表现超过了InternVL-Chat-V1.5、DeepSeek-VL-7B等几乎所有主流的开源多模态大模型。该测试集包含了来自真实视障用户提出的超过31000个视觉问答，能准确反映用户的真实需求与琐碎细小的问题，帮助视障人群克服他们日常真实的视觉挑战。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdWaSBVluetK6475Rr30NdC1uDMKdPvh5UmDyibzicsEeiavZbeRzxr5cTA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>来自元象</h2><div class=" pTag">元象XVERSE于2021年初在深圳成立。累计融资金额超过2亿美元，投资机构包括腾讯、高榕资本、五源资本、高瓴创投、红杉中国、淡马锡和CPE源峰等。</div><div class=" pTag">元象创始人姚星是前腾讯副总裁和腾讯AI Lab创始人、国家科技部新一代人工智能战略咨询委员会成员。</div><div class=" pTag">此前，元象在国内最早开源最大参数65B、全球最早开源最长上下文256K的MoE模型， 并在SuperCLUE测评全国领跑。</div><div class=" pTag">商业应用上，元象大模型是广东最早获得国家备案的模型之一 ，可向全社会提供服务。</div><div class=" pTag">元象大模型去年起已和多个腾讯产品，包括QQ音乐 、虎牙直播、全民K歌、腾讯云等，进行深度合作与应用探索，为文化、娱乐、旅游、金融领域打造创新领先的用户体验。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdUCho7XdnT4xUKM6fjSdRbFWZvsMeEOtKZRwCvpY3FebY0hW4OAM9icw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><span>项目链接：</span><br /><span>Hugging Face：https://huggingface.co/xverse/XVERSE-V-13B</span></span><br /><span style="font-size: 17px;">ModelScope魔搭：https://modelscope.cn/models/xverse/XVERSE-V-13B</span><br /><span style="font-size: 17px;">Github：https://github.com/xverse-ai/XVERSE-V-13B</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FjQHcihw8HzY3dgm-Mb4N7Q">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 10:22:44 GMT</pubDate>
</item>
<item>
<title>人形机器人在北京亦庄跑起来了</title>
<link>https://posts.careerengine.us/p/662e2374d2b8dd064ef8cf92</link>
<guid>https://posts.careerengine.us/p/662e2374d2b8dd064ef8cf92</guid>
<content:encoded><![CDATA[
<div> 天工 人形机器人 创新中心 母平台 纯电驱动 <br />
<br />
总结：<br />
北京亦庄创新中心发布了名为天工的全球首例纯电驱全尺寸人形机器人，实现了拟人稳步奔跑，时速可达6km/h。该创新中心由行业领军企业单位联合组建，旨在解决人形机器人行业的通用问题，打造软、硬两个通用母平台，避免重复简单造轮子。天工机器人配备了高精度传感器和执行操作算力强大的计算处理器，通过自主研发的运动技能学习方法实现快速奔跑。创新中心汇聚了行业专家和技术研发人员，并成立了专家委员会和产业联盟，共同推动人形机器人技术的突破与应用。未来，创新中心将持续开展技术攻关，为人形机器人行业带来更多创新。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">西风 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">在北京亦庄，国产人形机器人最新硬核成果曝光！</div><div class=" pTag">名为<strong style="font-weight: 600;">天工</strong>，实现了全球首例纯电驱全尺寸人形机器人的拟人稳步奔跑，时速可达6km/h。</div><div class=" pTag">发布会现场，天工一路小跑登台亮相，现场观众一整个坐不住：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxd8YtGexdKrg99gVMKnWG9sZNDibwGFerogPTC1gISYYeQtn2tFX15B1A/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">演示中，天工不仅能做到拟人行走和奔跑：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdZQMDzKq9BqmVGbeVdv6obHXfiavUr6rycLx8OQlQL4SEF5MiaQD93OJw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">还能平稳地盲视通过斜坡和楼梯，遇到磕绊、踏空情况也能调整步态轻松应对：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxd2Vksul85weyN9u0iaEVfydYJJ7ASd9qkNvZic9NoHWIUChglGCCB2w0w/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">而且下一秒，直接再上难度，盲视情况下在斜坡上小跑了起来：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdWmQgEWrmRn1ibBXflPYpNtWYujQh1k2bic87lwWv5f0ibibwJdEed37s7A/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">而天工背后的研发团队<strong style="font-weight: 600;">北京人形机器人创新中心</strong>来头同样不小。</div><div class=" pTag">去年11月成立，<strong style="font-weight: 600;">系国内首家省级人形机器人创新中心</strong>。由人形机器人行业领军企业单位联合组建，小米机器人、优必选、京城机电、亦庄机器人均在其列。</div><div class=" pTag">他们瞄准的是解决人形机器人行业的通用问题，<strong style="font-weight: 600;">打造软、硬两个通用母平台</strong>，避免国内机器人行业重复简单地造轮子的过程。</div><div class=" pTag">天工这一通用人形机器人母平台正是该团队创新成果的首秀。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdYrTmtxbT0sn3PSdrick2fsosEDCfl1EIDFuOhicBcfD20YK8LpicyI3NA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><h2>打造通用人形机器人母平台</h2><div class=" pTag">说回天工机器人本身，创新中心总经理熊友军在发布会现场做了详细介绍。</div><div class=" pTag">天工身高163cm，轻量化体重43kg，计算处理器每秒能够执行550万亿次的操作算力。此外，它还配备了高精度IMU和3D视觉传感器，以及高精度的六维力传感器，为其提供精确的力量反馈。</div><div class=" pTag">自由度方面，单只手臂具有3个自由度、腰部1个自由度、单条腿6个自由度。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdkw3RlICXwwIrJvgp39OjfViaKgS5kliaxSYLNVWWgASSMk1QSSIzcHcA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">并且，天工通用人形机器人母平台支持开放调用通讯接口，灵活扩展软、硬件等功能模块，具有开源开放性和兼容扩展性。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxd8Aibp9ppLumM3meBmDVcTJ9ChzIEEKMlmAprw7bjjt4CgDFxOhaWvaQ/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">技术方面，熊友军表示，要做到人形机器人快速奔跑，要解决的问题有这么几个：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">离地时关节需要高爆发力，扭矩增加到行走时的3-4倍；</div></li><li><div class=" pTag">着地时对关节的冲击力也很大；</div></li><li><div class=" pTag">腾空中也很难控制，稳定性差，容易摔倒。</div></li></ul><div class=" pTag">基于此，天工采用了自主研发的运动技能学习方法——<strong style="font-weight: 600;">基于状态记忆的预测型强化模仿学习</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdxjZbubHJz9hAvjxwNYqf926SEXrPQHXAicuTyvD03lyKNyic3spOiaticA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">融合了传统动力学通过调参较快得到结果无需训练、平稳性高的优点，以及强化学习泛化性强、不依赖环境的优点。既解决了强化学习带来的定位精度差的问题，又解决了模型预测控制方法当中对于非结构化环境适应性差的问题。</div><div class=" pTag">对比传统的动力学方法，通过此方法可实现节能达到30%-50%，扭矩节约30%-50%。</div><h2>探索通用具身智能平台</h2><div class=" pTag">众所周知，纯电驱动机器人这一块，目前入场玩家越来越多。</div><div class=" pTag">无论是马斯克的擎天柱、被OpenAI押注的Figure 01，还是国内的小米、宇树、银河人形机器人、稚晖君的远征A1等等，具身智能业内现在的普遍选择都是电驱动方案。</div><div class=" pTag">就在几天前，波士顿动力机器人也宣布退役液压驱动的人形机器人Atlas，改用电驱动方案。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdYOBrp7bicicWq1QS7PTtjqQ0oSwhyQrElYWfaCqsf5icgcdAsk0f9V5EA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而熊友军在发布会现场表示，截止到发布前，纯电驱动的天工人形机器人能拟人奔跑的效果，可以说做到了行业领先。</div><div class=" pTag">接下来，他们的目标将着眼于依靠大模型驱动——</div><div class=" pTag">持续迭代天工人形机器人通用平台，并探索通用具身智能平台。</div><div class=" pTag">基于天工母平台在内的各种构型机器人，<strong style="font-weight: 600;">构建通用高质量具身智能数据集</strong>。以此数据集为基础训练和迭代人形机器人具身大模型。将天工平台与大模型的结合，实现长行程任务的规划能力及多场景、复杂任务的泛化能力。</div><div class=" pTag">硬件母平台和软件母平台相辅相成，最终汇合为具身智能的最佳平台。</div><div class=" pTag">人形机器人研发是一场持久战，需要良性且强大的资金链，作为北京市大力支持的国内首家省级人形机器人创新中心，且由人形机器人行业领军企业单位联合组建，在这方面有着天然优势。</div><div class=" pTag">除了资金优势，创新中心也有较深的技术储备和研发基础。</div><div class=" pTag">小米机器人、优必选、京城机电、亦庄机器人等入股，创新中心聚集了一大批人形机器人行业的顶级专家和技术研发人员，具有很强的技术研究、产品开发和应用推广能力。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxd7k6N2QHibck7V0Ay8BqshVRgm0sxK2dtbdWe7jWu0licOUiaVibic1OgLfA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">在这次发布会上介绍天工的创新中心总经理熊友军，就是<strong style="font-weight: 600;">优必选科技联合创始人、首席技术官</strong>，从事机器人相关技术研究已近二十年。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdTU7PG6nicziaoiarGWsUF9A9EmoNUnCcHMp8PoeScZXazJ0NBrqH8SEbw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">熊友军还是华中科技大学机器人遥操作技术及控制专业博士，负责多项科技部创新基金项目、国家863计划项目。</div><div class=" pTag">优必选开发的多款明星机器人——登上2016年春晚的Alpha机器人、STEAM编程教育市场典范的Jimu Robot、轰动世界机器人大会的仿人服务机器人Walker等，熊友军在其研发中都发挥了重要作用。</div><div class=" pTag">他还曾作为中国机器人代表团团长多次带队参加全球机器人大赛，拿下多个世界冠军。</div><div class=" pTag">除了自身资金和人才储备，创新中心还成立了人形机器人技术专家委员会和产业联盟。</div><div class=" pTag">专家委员会作为创新中心的智囊团，将围绕人形机器人关键共性技术，以科学咨询支撑科学决策，把脉创新中心战略发展规划。</div><div class=" pTag">同时，创新中心将联合联盟成员，汇集创新资源，深化产学研合作，共同推动人形机器人技术的突破与应用。并在未来人形机器人产业掀起示范带头作用，更加紧密地协作，实现资源共享、优势互补，加速从实验室到市场的转化进程，促进产业生态的良性循环。</div><div class=" pTag">种种合力下，创新中心针对人形机器人行业短板和痛点开展技术攻关，有了支撑和底气。</div><div class=" pTag">之后该创新中心又会给我们带来怎样的惊喜？让我们拭目以待。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FEfwLSwBJPUuUcuean_ieEw">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 10:22:44 GMT</pubDate>
</item>
<item>
<title>人工几十万，AI几十块！国产玩家证明了AIGC视频商业化威力</title>
<link>https://posts.careerengine.us/p/662e235d4bfc5305c221dd48</link>
<guid>https://posts.careerengine.us/p/662e235d4bfc5305c221dd48</guid>
<content:encoded><![CDATA[
<div> 有言 魔珐 AIGC 视频 产品落地<br />
总结:<br />
有言是魔珐公司推出的一站式AIGC视频生成平台，通过高效率、高质量、低门槛、低成本的特性，成功实现了产品的规模化商业化落地。公司将3D虚拟人作为内容形态，针对企业端视频生产需求，打通视频创作场景，实现了AIGC Everything。通过3D虚拟人的AIGC化，提升了用户体验和创作效率。魔珐公司在技术与产业经验积累方面具备优势，成功通过用户价值导向的思路，打破了传统视频制作的局限，为AIGC行业探索出一条成功商业化路径。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">白交 克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">AI视频的落地，也走出了两种路线。</div><div class=" pTag">一边，以Sora为代表的文生视频Demo发布令世界震撼，新技术还在不断突破，产品落地还有段距离。</div><div class=" pTag">但另一边，第一波AIGC公司，已经凭借着视频生成工具，开始赚钱了。</div><div class=" pTag">来自魔珐，来自刚面世不久的AIGC一站式3D视频创作工具<strong style="font-weight: 600;">有言</strong>。</div><div class=" pTag">创始人兼CEO柴金祥教授自曝：产品上线不到两个月，<strong style="font-weight: 600;">已经过了PMF这个点</strong>。</div><div class=" pTag"><span>（PMF指的是产品和市场达到最佳的契合点，你所提供的产品正好满足市场的需求，令客户满意）</span></div><div class=" pTag">而且不光是有第一桶金，更主要的是魔珐还跑通了3D视频创作的规模化商业化路径——</div><div class=" pTag">在这两个月里，有言已经成功服务了超过50家企业头部客户，覆盖各行各业，实现了技术和商用的闭环。</div><div class=" pTag">所以在这种盈利模式背后，到底有哪些值得借鉴的做法？</div><div class=" pTag">接下来就来一探究竟。</div><h2>有言模式</h2><div class=" pTag">在官网的介绍中可以看到，有言是一个<strong style="font-weight: 600;">AIGC一站式3D视频生成平台</strong>，无论是个人还是企业用户都能使用，同时提供免费和付费版本。</div><div class=" pTag">从脚本文案开始，到3D人物的表情、动作、声音，再到3D视频的镜头、灯光都可以<strong style="font-weight: 600;">AIGC一键生成</strong>。用有言无需拍摄，就能完成多种场景所需的高质量的3D视频创作。</div><div class=" pTag">不过耳听为虚，有言到底有没有宣传得那么神奇，量子位进行了一番实测。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxd2VJsINDzriapDc2le0wDvMHNnXm15mEj2entseZBkBGVDZXHOnBSFuQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">进入有言的工作台，点击新建作品，选择横屏还是竖屏，然后就可以开始写脚本了。</div><div class=" pTag">不会或者不想写的话也可以通过页面内的按钮让AI代劳，或者从中汲取一些思路。</div><div class=" pTag"><strong style="font-weight: 600;">“AI脚本”</strong>功能内置了产品种草、知识分享和大型活动三种场景，每个场景中又按照行业进行了更详细的分类。</div><div class=" pTag">用户可以根据自己的需求，选择相应的场景和产品属性，补充完基本信息后让AI创作视频脚本。</div><div class=" pTag">假如我们制作一段“土豆牌薯片”的推广视频，产品的卖点是“好吃”，预计1分钟时长，按照下图这样设置好这些信息后，很快视频文案就完成了。</div><div class=" pTag">把生成的文案复制到右侧的框中，再根据实际需要简单修改，就可以进入下一个环节了。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdkHQOuFonhf3JksD7O7R881wr71iaOicKlcoLDKEU0Qa6WWjJgPldcTyw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，有言也支持高级模式，用户可以输入任意提示词即可生成脚本。有言内置的AI优化功能，让用户无需为不知如何撰写提示词而苦恼。只需要输入想要表达的文案，借助AI优化后点击立即生成，即可完成脚本的创作。</div><div class=" pTag">第二步需要为视频选择背景、出场人物和配音音色，选项比较多，怕看花眼的话可以先根据应用场景进行初步筛选。</div><div class=" pTag">场景上，有十几种风格、多样化的背景和色系可供选择，排列组合起来就多达上百种，还能选择出场人物是站姿或坐姿；人物方面，也可以选择不同的性别、年龄、肤色和穿搭风格；声音上支持中英双语，同样有通用音色、电商主播、新闻播音员等不同风格可以选用。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdnXFJNV7AicF2zafSicXbKzvKrsffrQW3icZ0JITVlw7WWEc485wNTp0Ag/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">如果有产品照片、PPT等素材，也是在这一环节中选择对应的片段来上传。</div><div class=" pTag">景别、运镜方式等细节默认由系统自动设置，如果需要手工调整，可以到“镜头优化”菜单中看一看。</div><div class=" pTag">这一切都搞定之后，点击界面右侧的“一键生成”按钮，视频预览就呼之欲出了。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdN8zhnrmoFWIibztNzR1alCGmt47kksicvHic72a9GM3DDGutK4B3WkjtQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不同景别交替错落，人物口型和文字内容完美贴合，还有自然的肢体动作，声音也没有什么机械感，听上去确实很有带货主播的感觉。</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-176"></div></div><div class=" pTag">如果预览没什么问题，就可以进行渲染了，渲染完成后再加上BGM、字幕、片头片尾等包装，就可以导出视频了<span>（也可以不包装直接导出）</span>，至此一段宣传片大功告成。</div><div class=" pTag">此外，有言还提供了海量的创作模板，只需修改文案和产品素材，就能快速得到一段高质量的宣传片。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdGAh5y21ra2RZLkjtkEbgGIwB3icIQCc4q08Q30wuu0VoA9YYuCjM7mw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这样来看，用有言来做视频，最大的特点就是<strong style="font-weight: 600;">低门槛、一站式全搞定。</strong></div><div class=" pTag">不需要拍摄，最基本的流程就是输入一些信息然后点点点点点，简直不要太简便，没有视频剪辑经验的小编也很轻松地创作了一则作品。</div><div class=" pTag">而且<strong style="font-weight: 600;">可控可编辑</strong>，而有言的用户可以对生成视频的文案、角度、运镜方式等细节进行细致的调整和编辑。看市面上那些以文生视频为基础的产品，他们产出的视频也无法进行编辑，只能调整提示词然后重新来过，但结果往往是再次陷入不可控的过程。</div><div class=" pTag">还有就是<strong style="font-weight: 600;">高质量，可供商业化使用</strong>。有言拥有更加逼真和高质量的3D内容制作能力，而以Sora为代表的文生视频模型，却难以理解物理世界规律，在时空一致性、因果关系等方面依然面临着较大挑战。</div><div class=" pTag">另外在<strong style="font-weight: 600;">生成时长</strong>等方面，有言的3D视频生成也比文生视频具有显著优势，具体都在下面的表格中了。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdvIibzfweJe4b6NuNOk5B3OO6UR2iawtFZic1gbZI7ebcWqb9BbPGnLg2Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">价格方面，个人订阅是月付59元或年付598元，企业用户则根据规模、用户数量等因素有所不同。</div><div class=" pTag">不过柴金祥教授透露，有的企业用十万元购买了有言来制作视频，平均下来每分钟视频的成本<strong style="font-weight: 600;">只有几十元</strong>。</div><div class=" pTag">而在过去，用PGC的方式来制作一段这样的视频，成本高达数十万。如今AIGC生成的成本更低，效果却反而比过去还要好。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdlR165L6NJkH4Eiac5aEpw6ibL8fSV7y2hTDibiac8GMOzt5KIRPUABemLQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在实际落地应用过程中，有言已经在培训、金融、家电、旅游、教育等多个行业中的50多个头部客户实现了降本增效。</div><div class=" pTag">比如海尔集团就已经开设了100个账号，供横跨6大职能部门的400多名员工使用。</div><div class=" pTag">在不到两个月的时间里，有言一共给海尔集团制作了600余条、总时长3000分钟的视频，平均每天就有30多条视频产生，内容涵盖了内部培训到外部宣传的多种应用场景。</div><div class=" pTag">在使用有言之前，海尔集团制作一条视频，从拍摄到后期大约要花费三天时间，但现在这个时间缩短到了半天，节省了一半的成本。</div><div class=" pTag">以售后维修部门的内部培训为例，之前的培训内容主要以真人口述或图文形式呈现，拍摄制作视频的产出效率低、难以规模化，而这一问题最终被有言所解决。</div><h2>魔珐秘诀</h2><div class=" pTag">有言商业化路径之所以能够跑通，除了本身的产品设计外，魔珐到底是怎么做到的？</div><div class=" pTag">魔珐创始人兼CEO柴金祥教授透露了三大关键原因。</div><div class=" pTag"><strong style="font-weight: 600;">首先，公司定位。</strong>即便外界AIGC进展频频的当下，柴教授仍给魔珐的定位是<strong style="font-weight: 600;">3D虚拟人</strong>公司。</div><div class=" pTag">魔珐科技刚成立时，本身作为三维计算机图形学和AI领域的世界顶级顶尖专家，柴教授就瞄准了3D领域，积累了丰富的3D数据资产。如今再回过头来看，这些高质量的3D数据，构成了区别于行业其他企业的核心壁垒。</div><div class=" pTag">当前，文生视频正在迎来关键的节点，对“物理世界的模拟器”已经成为业内共识的技术趋势。但要做到真正实现，其实还有很长的路要走。</div><div class=" pTag">首先需要解决的就是数据，更丰富多样、更多维度的信息表达成为大模型训练的关键。但2D视频随处可见，高质量的3D数据却很难获取。时至今日，它仍需要借助专业人员的手工制作，需要企业投入大量资金和时间成本创作。</div><div class=" pTag">而成立6年的魔珐，本身就已经具备了天然的优势。还有包括如今像VisionPro带火的空间计算，魔珐创作的内容可以直接适配。</div><div class=" pTag"><strong style="font-weight: 600;">第二，战略选择。</strong>魔珐选择彻底打通打透视频创作这个场景，实现<strong style="font-weight: 600;">AIGC Everything</strong>。</div><div class=" pTag">柴金祥将3D虚拟人当做一种内容形态，而且也是当前这个时代最容易被接受、且高效的一种形态。</div><div class=" pTag">对于企业来说，对外要连接他的客户，对内要连接他的员工、经销商。在直播、培训、招聘、宣传片等诸多场景中，企业都需要产出高质量的视频或者直播内容。</div><div class=" pTag">但传统的3D视频生产，企业需要构建一整个专业团队，包括模型师、动画师、灯光师、剪辑师等员工，要做好一个视频可能需要一两个月的时间。</div><div class=" pTag">这也跟每个人简单用手机端UGC工具进行视频创作也不一样，它无法满足企业端高质量视频、直播需求。</div><div class=" pTag">魔珐就聚焦企业端视频生产这个需求，推出了有言这款产品，从有言一站式AIGC视频创作平台可以看到，包括拍摄、剪辑到后期整套流程，灯光、动画、运镜和镜头全都可以AIGC一键生成，并且可控可编辑。</div><div class=" pTag">柴金祥透露，在接下来6、7月份会实现3D虚拟人的AIGC化，只需要上传一张照片，就能生成自己的3D虚拟人，并可对形象，造型，服装等进行编辑。</div><div class=" pTag"><strong style="font-weight: 600;">最后，技术与产业经验积累。</strong>魔珐现在拥有3D角色、3D动画、声音、镜头、文生文等在内的自研全栈AIGC技术，并且搭建了从超写实3D虚拟人工业化产线、3D虚拟人的AIGC平台到终端应用及行业解决方案的全链路产业架构。</div><div class=" pTag">因此对于怎样才能被称作一个好的AIGC产品，柴教授有自己的认知。</div><div class=" pTag">他认为从用户角度出发，“他才不关心你背后用什么技术”。具体以视频创作这个场景为例，他认为具备这四个特性：</div><div class=" pTag"><strong style="font-weight: 600;">高效率、高质量低成本、低门槛，以及AIGC产品一定具备的可控性、可编辑性。</strong></div><div class=" pTag">看到当前正在火热的大模型，面对「是否有可能整个由大模型来驱动3D生成」这件事，柴金祥则是十分审慎的态度。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">当真正做成产品化时，我不大认为真的能直接用一个大模型来生成所有视频的元素。</div><div class=" pTag">今天我们在产品也用了很多大模型技术，但如果去考虑可控性、可编辑性，我不认为今天这条单个大模型的路径一定是对的。</div></blockquote><h2>中国AIGC企业闯出一条新路</h2><div class=" pTag">进入2024，大模型落地元年，即便当前各种前沿技术一个比一个惊艳，但需要思考的一个核心议题是：如何真正产品化并实现规模化商业化落地。尤其本身作为AIGC的公司而言，这是事关企业命运发展的关键拷问。</div><div class=" pTag">作为第一波AIGC公司来说，魔珐的「有言模式」无疑是给整个行业都打了个样——</div><div class=" pTag">基于多年的经验积累，以用户为重，打通3D视频创作这个场景，最终实现产品的规模化、商业化。</div><div class=" pTag">在与柴金祥的交流中，用户价值是其中谈及最多的关键词，也是有言产品化的秘诀所在。这个秘诀具象化就是高质量、高效率、低门槛、低成本。</div><div class=" pTag">正因为这种思路，有言在上线不到两个月，“就已经过了PMF这个点”。</div><div class=" pTag">也正因为这个思路，柴金祥教授提及，我们不探索Sora、Pika那种技术路径，我们跟他们不是一道的。</div><div class=" pTag">从商业化角度来看，以Sora为代表的AI视频生成，能够帮助用户去制作创意类的视频素材，但内容质量的不可控，难以满足企业或个人高效的信息传达场景的视频制作需求。</div><div class=" pTag">从文生文、文生图、文生视频内容，生成式AI阶跃式发展给内容创作带来了新的变革机遇。但要想真正融入各行各业，除了效果上的惊艳是远远不够的，高效可控低门槛的产品才能真正应用到普通人。</div><div class=" pTag">以往的实践证明，中国有着先天的场景和数据优势，最终能享受到技术红利，实现应用层面的全面开花。</div><div class=" pTag">移动互联网时代是，上一波AI浪潮也是，如今AIGC时代这样的趋势已经开始，以魔珐为代表的AIGC公司就是开始。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fhv-pZLE3Os0wxmMCk4k3JA">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 10:22:21 GMT</pubDate>
</item>
<item>
<title>国产GPU重大利好！“中国英伟达”千卡集群已就位</title>
<link>https://posts.careerengine.us/p/662e235c4bfc5305c221dd38</link>
<guid>https://posts.careerengine.us/p/662e235c4bfc5305c221dd38</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">金磊 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag" style="font-size: 17px;">算力基础设施建设，北京市有了最新的大动作——</div><div class=" pTag" style="font-size: 17px;"><strong style="font-weight: 600;">《北京市算力基础设施建设实施方案（2024-2027年）》。</strong></div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzTtxYGjdtniclpC0cgY1rGzHib9l8uAIKBCeocQtEPSNkg1XCMZ9Y6ibTA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">其中，《方案》在“保障措施”中提出了对企业利好的办法：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">对采购自主可控GPU芯片开展智能算力服务的企业，按照投资额的一定比例给予支持</strong>，加速实现智算资源供给自主可控。</div></li><li><div class=" pTag">对主动进行绿色节能改造的存量数据中心，按照投资额的一定比例给予支持。</div></li></ul><div class=" pTag" style="font-size: 17px;">对企业扩大资金的举措，意在提升人工智能算力券政策效能，鼓励企业用好智能算力资源，加快推动大模型赋能行业应用。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzE4NvNBCwOrfaSiaD5LDuXnt1RNLN1DaMKN06sm4fgDAfq4sq9wzmAKg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">除此之外，在《方案》的规划目标中，也释放出了一个重要的信号——<strong style="font-weight: 600;">智算资源供给集群化</strong>：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">改变智算建设“小、散”局面，集中建设一批智算单一大集群。</div><div class=" pTag">到2025年，本市智算供给规模达到45EFLOPS，2025-2027年根据人工智能大模型发展需要和国家相关部署进一步优化算力布局。</div></blockquote><div class=" pTag" style="font-size: 17px;">为何会如此？这就要结合当下算力市场的<strong style="font-weight: 600;">需求</strong>和<strong style="font-weight: 600;">供给</strong>展开来看了。</div><div class=" pTag" style="font-size: 17px;">一方面，自从ChatGPT问世引爆AIGC以来，大模型的数量可谓是极速增长，单是北京这一座城市，就已经拥有<strong style="font-weight: 600;">122</strong>家大模型创新团队，约占全国的一半，大模型数量更是居全国首位。对于算力市场的需求之大可见一斑。</div><div class=" pTag" style="font-size: 17px;">不仅如此，随着Sora、Suno等应用的问世，大模型的发展已然加速驶入<strong style="font-weight: 600;">多模态</strong>阶段，AI算力的需求在<strong style="font-weight: 600;">Scaling Law</strong>为主旋律的当下还会持续上涨。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzicfLvEfD1oQM2xBcY3PZ76tMmhILFynLdUibZzI1AKzicibibEAYIIkzB8A/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>图源：由DALL·E 3生成</h6><div class=" pTag" style="font-size: 17px;">另一方面，AIGC诚然带火了“N卡”，但目前着眼于全球已然是一卡难求的态势，并且因稀缺导致其价格日益水涨船高。</div><div class=" pTag" style="font-size: 17px;">而且单从GPU的性能角度来看，即便是英伟达也只能接受<strong style="font-weight: 600;">加速计算到达了临界点</strong>的事实，算力供给方需要另一种方式来进行计算——</div><div class=" pTag" style="font-size: 17px;">通过芯片与芯片间的连接技术，一步步构建出大型<strong style="font-weight: 600;">AI大规模算力集群</strong>。</div><div class=" pTag" style="font-size: 17px;">聚焦到国内，其实这种“集群”模式也已经紧锣密鼓地在展开，国内已有不少厂商在不断探索和实践，例如云计算巨头<strong style="font-weight: 600;">华为云</strong>、AI芯片公司<strong style="font-weight: 600;">摩尔线程</strong>等等。</div><div class=" pTag" style="font-size: 17px;">以摩尔线程为例，就在前不久他们发布了名为<strong style="font-weight: 600;">夸娥（KUAE）</strong>的智算集群解决方案，旨在以一体化交付的方式解决大规模GPU算力的建设和运营管理问题，可以大幅降低传统算力建设、应用开发和运维运营平台搭建的时间成本。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzaXOl19KloovYiaBz2NS6PvkPOwko8PwAIMcty516IpE7C3TzXXt3uOw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">从这一点来看，国内市场算力的发展是与《方案》所提出的“智算资源供给集群化”是相契合的，也从侧面印证着<strong style="font-weight: 600;">国产GPU智算集群已经到了势在必行的阶段。</strong></div><div class=" pTag" style="font-size: 17px;">然而，路线虽已清晰，但在实践过程当中，尤其是GPU数量达到千卡甚至万卡时，集群落地并非是件易事。</div><div class=" pTag" style="font-size: 17px;">那么难点都有什么？国产GPU又是如何应对的？我们继续往下看。</div><h2>千卡GPU集群落地痛点</h2><div class=" pTag" style="font-size: 17px;">首先我们需要了解GPU集群在实际落地过程中的规模会达到什么量级。</div><div class=" pTag" style="font-size: 17px;">以Llama 3为例，在它问世之际，Meta就公布了其基础设施详情：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我们在两个定制的24K GPU集群上做训练。</div></blockquote><div class=" pTag" style="font-size: 17px;">与之类似的，马斯克的Grok 2据悉训练已经用了20000张H100，Grok 3更是传出需要惊人的100000张；即使是参数量仅为30亿的Sora，GPU的数量也估算在4200至10500张之间。</div><div class=" pTag" style="font-size: 17px;">而事实上，当下要满足一些基础模型的算力需求，<strong style="font-weight: 600;">千卡集群</strong>已然是标配一样的存在；这不仅仅是因为千卡是大集群的基本单元，更是因为百卡或更小规模的GPU数量往往满足不了大模型训练需求，只能是实验性的。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCz1YafAYjoGFyk8LWW5AdeibfNFCiavQ2NOoUcwssuic36lVERB5ZWZXSVg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">但智算集群中GPU的数量也还只是一方面，之于GPU本身，在诸如训练大模型等落地过程中的难点也是不少。</div><div class=" pTag" style="font-size: 17px;">因为建设集群本身还是一个非常复杂的系统性工程，它不仅是堆GPU这么简单，从一个GPU到一个服务器，再到把它们组成群，期间包含了硬件的网络、存储、软件、再到大模型调度等各种细节因素，均会影响到集群的最终性能。</div><div class=" pTag" style="font-size: 17px;">例如同样是Llama 3，Meta在介绍基础设施的时候还提到了一个关键信息：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">当在16K GPU上同时训练时，我们有效地实现了每个GPU超过400 TFLOPS的<strong style="font-weight: 600;">计算利用率</strong>。</div></blockquote><div class=" pTag" style="font-size: 17px;">若是每张卡的利率用不够高，很显然就会降低最终智算集群的效率。</div><div class=" pTag" style="font-size: 17px;">再如分布式训练过程中，一张卡坏掉就会影响整体的训练，对于千卡甚至更大规模的集群来说，这种情况出现的概率就会更高；因此对于千卡集群的稳定性和可靠性也提出了极高的要求。</div><div class=" pTag" style="font-size: 17px;">聚焦到国产智算集群，还需得具备可以兼容主流GPU软件的能力（例如CUDA），由此才能应对更多且日新月异的主流大模型任务。</div><div class=" pTag" style="font-size: 17px;">……</div><div class=" pTag" style="font-size: 17px;">一言蔽之，构建千卡智算集群难，构建国产千卡智算集群难上加难。</div><h2>如何破局？</h2><div class=" pTag" style="font-size: 17px;">虽说困境重重，但也正如上文所言，<strong style="font-weight: 600;">摩尔线程</strong>已经在探索与实践，并且他们在构建千卡智算集群这件事上也已交出了<strong style="font-weight: 600;">“高分作业”</strong>。</div><div class=" pTag" style="font-size: 17px;">我们不妨以摩尔线程的夸娥（KUAE）智算中心解决方案为例，来看下构建国产GPU智算集群的破局之道。</div><div class=" pTag" style="font-size: 17px;">整体来看，夸娥（KUAE）智算中心解决方案是一个以全功能GPU为底座，软硬件一体化的全栈的解决方案。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCziaAddic4Uf1gbh4p5P3dLbLyZibgW5efWbu71kaPYlLJYOM3kMEA55UYg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">之所以叫做全栈，是因为夸娥的能力是触及到了构建GPU智算集群中的方方面面，包括最底层的<strong style="font-weight: 600;">基础设施建设</strong>、中间层的<strong style="font-weight: 600;">智算集群管理</strong>，以及上层的<strong style="font-weight: 600;">大模型服务</strong>。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCz0g5dkVTnUfxMsO8sIFLphcTqD746iaHVSF6pDSBjWfO7OVpZtMU9dzQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">首先来看<strong style="font-weight: 600;">基础设施</strong>。</div><div class=" pTag" style="font-size: 17px;">从内容上来看主要包含夸娥（KUAE）计算集群、RDMA网络与分布式存储三大方面。据了解，其建设周期只需30天，可支持千亿参数模型的预训练、微调和推理，可实现高达91%的千卡集群性能扩展系数。</div><div class=" pTag" style="font-size: 17px;">并且基于大规模智算加速卡<strong style="font-weight: 600;">MTT S4000</strong>和双路8卡GPU服务器<strong style="font-weight: 600;">MCCX D800</strong>的能力，夸娥集群还支持从单机多卡到多机多卡，从单卡到千卡集群的无缝扩展。</div><div class=" pTag" style="font-size: 17px;">据悉未来将推出更大规模的集群，以满足更大规模的大模型训练需求。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzTJ53dYVYok3NDibLNpOsbzH9TpCXb69pIgtxgl5elC7cGdy2Yvw52icA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">其次是<strong style="font-weight: 600;">集群管理平台</strong>。</div><div class=" pTag" style="font-size: 17px;">这一软硬件一体化平台主要是用于AI大模型训练、分布式图形渲染、流媒体处理和科学计算等工作，深度集成全功能GPU计算、网络和存储，提供高可靠、高算力服务。</div><div class=" pTag" style="font-size: 17px;">通过这个平台，用户可灵活管理多数据中心、多集群算力资源，集成多维度运维监控、告警和日志系统，帮助智算中心实现运维自动化。</div><div class=" pTag" style="font-size: 17px;">最后是<strong style="font-weight: 600;">模型服务</strong>。</div><div class=" pTag" style="font-size: 17px;">覆盖了大模型预训练、微调和推理全流程，支持所有主流开源大模型。通过摩尔线程MUSIFY开发工具，可以轻松复用CUDA应用生态，内置的容器化解决方案，则可实现API一键部署。</div><div class=" pTag" style="font-size: 17px;">这个平台意在提供大模型生命周期管理，通过简洁、易操作的交互界面，用户可按需组织工作流，大幅降低大模型的使用门槛。</div><div class=" pTag" style="font-size: 17px;">那么实际效果如何？</div><div class=" pTag" style="font-size: 17px;">据了解，摩尔线程目前已经支持了包括LLaMA、GLM、Aquila、Baichuan、GPT、Bloom、玉言等在内的各类主流大模型的训练和微调：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">以200B训练数据量为例，智源研究院70B参数Aquila2可在33天完成训练</div></li><li><div class=" pTag">1300亿参数规模的模型可在56天完成训练</div></li></ul><div class=" pTag" style="font-size: 17px;">至于刚才提到的千卡GPU集群落地难的种种细节，摩尔线程也有自己的应对策略。</div><div class=" pTag" style="font-size: 17px;">例如在<strong style="font-weight: 600;">提高集群算力利用率</strong>这件事上，摩尔线程采用软硬件协同设计和端到端的并行策略，通过对集群通信库的算法、网络拓扑和硬件的规格进行精心设计与配置，实现了高度的集群兼容性。</div><div class=" pTag" style="font-size: 17px;">具体到技术，则是综合利用了MTLink和PCIe，使得通讯性能提升一倍，综合调优下MFU提升幅度超过50%。</div><div class=" pTag" style="font-size: 17px;">在<strong style="font-weight: 600;">稳定性</strong>方面，摩尔线程在根儿上先保证GPU的质量，从卡出厂开始便进行多项严格的检测。</div><div class=" pTag" style="font-size: 17px;">其后，摩尔线程还开发了集群系统监控和诊断工具，有助于筛选和快速定位到有问题的卡和服务器，可以自动恢复和硬件替换。</div><div class=" pTag" style="font-size: 17px;">并且结合异步检查点（Checkpoint）加速，写的时间从10分钟降到秒级，读的速度从40分钟降到2分钟；即使是遇到训练异常，系统也可以自动重新拉起。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzWMKEsrGpP1KdY5GGYmvsmNcsRQBYnRJb4Woa9GW30oNXp7yxI1JP3A/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">在<span><strong style="font-weight: 600;">可扩展性</strong></span>方面，夸娥目前已经支持了包括DeepSpeed、Megatron-DeepSpeed、Colossal-AI、FlagScale在内的业界主流分布式框架。</div><div class=" pTag" style="font-size: 17px;">除此之外，还融合了多种并行算法策略，包括数据并行、张量并行、流水线并行和ZeRO，且针对高效通信计算并行和Flash Attention做了额外优化。</div><div class=" pTag" style="font-size: 17px;">最后，在<strong style="font-weight: 600;">兼容性</strong>方面，摩尔线程代码移植Musify工具，可快速将现有的主流迁移至MUSA，<strong style="font-weight: 600;">零成本完成CUDA代码自动移植</strong>。</div><div class=" pTag" style="font-size: 17px;">借助摩尔线程元计算统一系统架构MUSA，用户还可以复用PyTorch开源社区的大量模型算子，降低开发成本。</div><div class=" pTag" style="font-size: 17px;">整体而言，摩尔线程的夸娥智算集群全栈方案的优势可以归结为八点，即：<strong style="font-weight: 600;">覆盖主流大模型、兼容CUDA等主流生态、断点续训、大语言模型分布式训练、加速推理、高性能通信、高性能存储，以及高可靠性。</strong></div><div class=" pTag" style="font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzhY3f43PxZMfqcqrg3yowYia5pT4rx9TFau9ghHgiaWyLibGbib9k4IOQmw/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></div><div class=" pTag" style="font-size: 17px;">它就像把所有复杂的方案打包成了一把钥匙，交付到用户手上开箱即用。</div><div class=" pTag" style="font-size: 17px;">而且摩尔线程的夸娥（KUAE）智算集群解决方案不只是说说那么简单，是已经做到了上岗。</div><div class=" pTag" style="font-size: 17px;">据了解，夸娥目前已经完成了<strong style="font-weight: 600;">三个千卡智算集群的落地</strong>，分别位于<strong style="font-weight: 600;">北京亦庄</strong>、<strong style="font-weight: 600;">北京密云</strong>和<strong style="font-weight: 600;">南京</strong>。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzFLzbkicnDfv5FOSR3FvIym1SzQcTFNJ7Vib8YOQaaRYUalPUeJAzE4kg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">不仅如此，摩尔线程仍在持续谱写着“打造国产GPU集群”的篇章。</div><div class=" pTag" style="font-size: 17px;">就在前不久，摩尔线程与清华系创业公司无问芯穹达成合作，成为第一家接入无问芯穹并成功完成千卡级别大模型训练的国产GPU公司。双方联合推进基于夸娥（KUAE）千卡智算集群的“MT-infini-3B”合作大模型实训，目前性能已在同规模模型中跻身前列。</div><div class=" pTag" style="font-size: 17px;">并且<strong style="font-weight: 600;">无问芯穹CEO</strong>公开肯定了夸娥（KUAE）的实力：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">经验证，摩尔线程夸娥千卡智算集群在性能、稳定性、易用性和算力利用率上均有优异表现，可以为<strong style="font-weight: 600;">千亿参数级别大模型</strong>训练提供持续高效的高性能算力支持。</div></blockquote><div class=" pTag" style="font-size: 17px;">由此可见，摩尔线程的夸娥千卡智算集群是得到了实践验证的那种，那么最后一个问题便是：<strong style="font-weight: 600;">为什么是摩尔线程能率先落地？</strong></div><div class=" pTag" style="font-size: 17px;">其实早在2022年的时候，团队便已经设定了建集群的大方向与策略，这是因为当时A100算力也是处于紧缺的状态，国内市场急需能够替代它的产品。</div><div class=" pTag" style="font-size: 17px;">从GPU功能情况来看，摩尔线程是在唯一可以对标英伟达的国产GPU企业，虽然单芯片性能还有差距，但若是集成起来便可解决单一性的不足。</div><div class=" pTag" style="font-size: 17px;">而随着2023年大模型的火爆，这种GPU集群式的方向就显得更加正确，毕竟黄仁勋在发布B200之际就表示“我们需要更大的GPU，如果不能更大，就把更多GPU组合在一起，变成更大的虚拟GPU”。</div><div class=" pTag" style="font-size: 17px;">因此，现在回头再看摩尔线程当时的策略和决定，确实是具备前瞻性的。</div><div class=" pTag" style="font-size: 17px;">总而言之，有实力，有技术，有战略，也有成绩，摩尔线程还将在国产GPU的发展道路上带来怎样的惊喜，是值得期待了。</div><div class=" pTag" style="font-size: 17px;"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://www.mthreads.com/product/KUAE</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://jxj.beijing.gov.cn/zwgk/zcjd/202404/t20240425_3637629.html</span><br /><span style="font-size: 17px;">[3]</span><span style="font-size: 17px;">https://ai.meta.com/blog/meta-llama-3/</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F86pe8il1SL2z6Ui9toviXQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 10:22:20 GMT</pubDate>
</item>
<item>
<title>突发！谷歌Python团队解散，PyTorch之父震惊</title>
<link>https://posts.careerengine.us/p/662e235c4bfc5305c221dd40</link>
<guid>https://posts.careerengine.us/p/662e235c4bfc5305c221dd40</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">谷歌的Python团队，被曝解散！</div><div class=" pTag"><strong style="font-weight: 600;"><span>谷歌员工、CPython核心开发者Thomas Wouters</span></strong>在社交媒体爆料，Python团队中的所有职位都将被取消。</div><div class=" pTag">Thomas介绍，谷歌为团队的员工提供了“替代职位”，但需要去<span><strong style="font-weight: 600;">万里之外</strong></span>做和原来一样的工作。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdc1utzcKIp0k4jRbibBl8kbic4HxRxzTE5iaUpm2qsOqhTY1ia0SvN0xXUw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">一名自称是团队员工的网友zem也怀念起了在Python团队过去的工作，并开启了在线求职。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdOh9bNdhxFpoIBibCmTWEh2ibvnA33aKwgosQ7sdCmSgWZB9MYcXvzbCA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同时，谷歌此举不仅让Python团队的员工感到失落，在业界也产生了不小的影响。</div><div class=" pTag">不少网友都对他们的经历表达了同情，同时还有科技企业向在线求职的员工伸来了橄榄枝。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdBIoK5KdC6pVp1VACVKN9yltWhYRUVibCNYYY3o6pFI5VpHLCSrOwk3A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而PyTorch之父Soumith Chintala看到消息之后，直接就是一个WTF，同时他还表示：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">pybind11（谷歌资助项目）的一名维护者找到我问，（谷歌Python团队解散后）谁会成为我们新的资助者？</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdF23D9XvWtnLoTIcDsGiblGPmU3v8Dz5RDiaa50fdoHItZ3Tllyh9OM4Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">当然，除了资助外部开源项目，Python团队在谷歌内部，同样完成过许多重要工作。</div><h2>全谷歌的“Python核心”</h2><div class=" pTag">在同情Python团队的遭遇的同时，也有网友对他们的工作感到了好奇。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdTKkmZX44bLqX2grmnnNiakgxv2v2K3hRggOeiatq4lkh5QnGNVzTye5g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">对此，有网友在纠正了他的说法之后，给出了解答。</div><div class=" pTag">首先他指出，让一个团队专门研究一种语言并非没有意义，事实上FAANG<span>（Facebook、亚马逊、苹果、Netflix和谷歌母公司Alphabet）</span>，以及小一些的公司都有这样的团队。</div><div class=" pTag">而在谷歌内部，除了Python之外也有团队专门研究C++、Rust、Java等语言。</div><div class=" pTag">他们通过<strong style="font-weight: 600;"><span>对上游代码进行修复优化，并对内部的Python进行升级维护</span></strong>，为整个开发团队降本增效。</div><div class=" pTag">他举例说，如果LLVM团队能把搜索速度提升万分之一，一年内就能给谷歌节约数百万小时的计算时间。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdibBTdJUtYn4joJdFXsn8v8Payiaa4Jz5PjESmEqUrnKUhRUsRhyztRPA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在这名网友的介绍之后，zem还进行了更详细的补充。</div><div class=" pTag">首先是维护谷歌内部使用的稳定版本Python，并确保能正常运行。</div><div class=" pTag">Python团队完成了从2.7到3.6，再逐渐到3.11版本的迁移，每次都要耗时数个月甚至一年，因为一旦引入新的代码，就必须对它引起的所有故障负责。</div><div class=" pTag">除了Python本体，谷歌使用的上千个第三方包、定制版的pylint和black也需要由他们来维护，还得撰写风格指南和代码库。</div><div class=" pTag">此外该团队还要负责支持外部的pybind11项目、将Python规则向Starlark迁移、对代码执行自动重构等工作。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdBQOQVBJDtkRrzSP64W1vudzicYCEicicwEzpw1af5iaT6XXy0bWX6jvmuQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而这些工作仅仅是开发本身，在这之外他们还要给谷歌内部使用Python的开发者给充当“客服”，协助其他团队解决与Python相关的棘手问题。</div><div class=" pTag">虽然要完成的任务有如此之多，但据Zem介绍，谷歌Python团队的规模还不到十人，人手并不充足。</div><div class=" pTag">不过尽管如此，Zem仍然对这份工作表示很满意，并表示这是他“最好的一份工作”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdGk9Mn9hvl2CbK823gw1vibStx1TeZJQzYzNEG1dLb1Wh3mNxHkLQCOQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">但这种说法也不禁让人好奇——</div><div class=" pTag">一方面是被解散团队的员工说人手不足，另一方面又是谷歌直接把整个团队撤掉，这背后究竟有什么原因呢？</div><h2>谷歌的“广进计划”</h2><div class=" pTag">对于这样做的原因，谷歌还没有进行说明。</div><div class=" pTag">不过Zem透露，针对Python有关的工作，谷歌打算在德国慕尼黑另起炉灶。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdng4UyibOxarD5OlqfRGgTKVolvcDmUcSxOunmRwOapRiaXsWM9TPTtQQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同时他还表示，Python团队的大部分甚至全部工作，都会被慕尼黑的新团队接管。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdN0m7wuxlZiaMJL5G26rfFVe17PyRaiaJwsibjm1QyiaK9XSr2gHGB5IFCg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而至于深一步的原因，有网友猜测是——节约成本——因为在欧洲的用工花费要低于美国。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDwlBP4ZKIdDhtdI9zVLuxdPqgryKw34QStibfsfJYa64r5Nzsj0Ric2bWGvaRpPKChaMjhDia76kianQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而这个慕尼黑的团队，也正是谷歌给Python团队员工提供的“替代方案”。</div><div class=" pTag">但显然这些在美国的员工并不希望跑到万里之外的德国，因此谷歌的举措几乎与裁员无异。</div><div class=" pTag">而仅仅是今年，这就已经不只是谷歌的第一次裁员或“重组”。</div><div class=" pTag">据Business Insider消息，上周财务部门也进行了“重组”，重组之后的工作地点则是班加罗尔（印度）、墨西哥城（墨西哥）和都柏林（爱尔兰）。</div><div class=" pTag">而规模更大且更加直接的裁员发生在今年1月，涉及来自硬件、广告销售、搜索、购物、YouTube等部门的上千名员工。</div><div class=" pTag">谷歌CEO桑达尔·皮查伊表示，这是个“艰难的选择”，但谷歌今年需要将主要将投资用于“重大优先事项”。</div><div class=" pTag">同时劈柴哥还透露，今年还会有很多裁员，但不会达到去年12000人的那种规模。</div><div class=" pTag">与此同时，微软、亚马逊、Meta等硅谷巨头，也纷纷进行着自己的“广进计划”……</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1xfG9ptLcK4Vp3D3Qjx2ag">阅读原文 </a>
]]></content:encoded>
<pubDate>Sun, 28 Apr 2024 10:22:20 GMT</pubDate>
</item>
<item>
<title>Llama 3低比特量化性能下降显著！全面评估结果来了 | 港大&amp;北航&amp;ETH</title>
<link>https://posts.careerengine.us/p/662c9107c3bb9708569a0622</link>
<guid>https://posts.careerengine.us/p/662c9107c3bb9708569a0622</guid>
<content:encoded><![CDATA[
<div> 量子位，QbitAI，LLaMA3，低比特量化，LoRA微调<br />
<br />
总结：<br />
本文介绍了LLaMA3在超大规模预训练下的低比特量化性能研究结果。研究人员评估了10种量化方法在1-8比特下的表现，发现尽管LLaMA3在量化后仍展现出较好性能，但在低比特量化下仍受到显著影响。LoRA微调量化在MMLU数据集上表现不佳，甚至使性能下降更加严重，与LLaMA1和LLaMA2的情况形成对比。研究指出，需寻求新的量化范式来弥补量化引起的性能下降，以使LLaMA3在资源受限环境中实现更强的能力。该研究强调了在低比特量化背景下的改进空间，以推动生成式人工智能的发展。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">QHT 投稿</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">大模型力大砖飞，让LLaMA3演绎出了新高度：</div><div class=" pTag">超15T Token数据上的超大规模预训练，既实现了令人印象深刻的性能提升，也因远超Chinchilla推荐量再次引爆开源社区讨论。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnEPaXL2k8d2WibH89pPqezIlmjTEQCfH1LRibeRVqe1Kd3iaEl3PzOBs6g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">与此同时，在实际应用层面上，另一个热点话题也浮出水面：</div><div class=" pTag">资源有限场景下，LLaMA3的量化表现又会如何？</div><div class=" pTag">香港大学、北京航空航天大学、苏黎世联邦理工学院联合推出了一项实证研究，全面揭示了LLaMA3的低比特量化性能。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yn6ortJEBTRgZjBfCRcTdQUTRw2jPVrUhoVtKdicnjpT5zEsDAIqQkBqw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">研究人员使用现有的10种训练后量化和LoRA微调方法，评估了LLaMA3在1-8比特和各种评估数据集上的结果。他们发现：</div><div class=" pTag">尽管性能令人印象深刻，<strong style="font-weight: 600;">LLaMA3在低比特量化下仍然遭受了不可忽视的退化，特别是在超低位宽上</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Ynac2V6ib4Jk8UJX4jbKtWmuN0kzz91eOe0wGnf2BDWT8IwKD6ib7XicnUg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">项目已在GitHub上开源，量化模型也已登陆HuggingFace。</div><div class=" pTag">具体来看实证结果。</div><h2>轨道1：训练后量化</h2><div class=" pTag">表1和表2中分别提供了LLaMA3-8B和LLaMA3-70B在8种不同的PTQ方法下的低比特性能表现，覆盖了从1比特到8比特的广泛比特宽度。</div><div class=" pTag"><span><strong style="font-weight: 600;">1.低比特权重</strong></span></div><div class=" pTag">其中，Round-To-Nearest (RTN) 是一种基本的舍入量化方法。</div><div class=" pTag">GPTQ是当前最有效率和有效的仅限权重的量化方法之一，它利用量化中的误差补偿。但在2-3比特下，当量化LLaMA3时，GPTQ会导致严重的准确性崩溃。</div><div class=" pTag">AWQ采用异常通道抑制方法来降低权重量化的难度，而QuIP通过优化矩阵计算来确保权重和Hessian之间的不一致性。它们都能保持LLaMA3在3比特时的能力，甚至将2比特量化推向有希望的水平。</div><div class=" pTag"><span><strong style="font-weight: 600;">2.超低比特权重</strong></span></div><div class=" pTag">最近出现的二值化LLM量化方法实现了超低比特宽度LLM权重压缩。</div><div class=" pTag">PB-LLM采用混合精度量化策略，保留一小部分重要权重的全精度，同时将大部分权重量化为1比特。</div><div class=" pTag">DB-LLM通过双重二值化权重分割实现高效的LLM压缩，并提出偏差感知蒸馏策略以进一步增强2比特LLM性能。</div><div class=" pTag">BiLLM通过显著权重的残差逼近和非显著权重的分组量化，进一步将LLM量化边界推低至1.1比特。这些为超低比特宽度专门设计的LLM量化方法可以实现更高精度的量化LLaMA3-8B，在⩽2比特时远远超过如GPTQ、AWQ和QuIP等方法，在2比特（甚至在某些情况下3比特）下的表现。</div><div class=" pTag"><span><strong style="font-weight: 600;">3.低比特量化激活</strong></span></div><div class=" pTag">还通过SmoothQuant对量化激活进行了LLaMA3评估，SmoothQuant将量化难度从激活转移到权重，以平滑激活异常值。评估显示，SmoothQuant可以在8比特和6比特的权重和激活下保留LLaMA3的准确性，但在4比特时面临崩溃。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnsTy0oOH2350lib4QibR07UdERnJrLxwszNdHIfrdiaCuzxaicMu4aTib0Fw/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnBhuGbItMvBnib9bXl1oQ8XicHs6OZhm6nUqwYjoaSE74xibD30icrFE5Ug/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>轨道2：LoRA微调量化</h2><div class=" pTag">在MMLU数据集上，对于LoRA-FT量化下的LLaMA3-8B，最显著的观察是，在Alpaca数据集上低秩微调不仅不能补偿量化引入的错误，甚至使性能下降更加严重。</div><div class=" pTag">具体来说，各种LoRA-FT量化方法在4比特下获得的量化LLaMA3性能，比没有使用LoRA-FT的4比特对应版本要差。这与LLaMA1和LLaMA2上的类似现象形成鲜明对比，在LLAMA1和LLAMA2中，4比特低秩微调量化版本甚至能轻松超过MMLU上的原始FP16对应版本。</div><div class=" pTag">根据直观分析，这一现象的主要原因是由于LLaMA3强大的性能得益于其大规模的预训练，这意味着原始模型量化后的性能损失不能通过在一小部分低秩参数数据上进行微调来补偿（这可以被视为原始模型的一个子集）。</div><div class=" pTag">尽管量化导致的显著下降不能通过微调来补偿，但4比特LoRA-FT量化的LLaMA3-8B在各种量化方法下显著优于LLaMA1-7B和LLaMA2-7B。例如，使用QLoRA方法，4比特LLaMA3-8B的平均准确率为57.0（FP16: 64.8），超过4比特LLaMA1-7B的38.4（FP16: 34.6）18.6，超过4比特LLaMA2-7B的43.9（FP16: 45.5）13.1。这表明在LLaMA3时代需要一种新的LoRA-FT量化范式。</div><div class=" pTag">在CommonSenseQA基准测试中也出现了类似的现象。与没有使用LoRA-FT的4比特对应版本相比，使用QLoRA和IR-QLoRA微调的模型性能也有所下降（例如，QLoRA平均下降2.8% vs IR-QLoRA平均下降2.4%）。这进一步展示了在LLaMA3中使用高质量数据集的优势，而且通用数据集Alpaca并没有对模型在其他任务中的性能作出贡献。</div><h2>结论</h2><div class=" pTag">这篇论文全面评估了LLaMA3在各种低比特量化技术（包括训练后量化和LoRA微调量化）中的性能。</div><div class=" pTag">此研究发现表明，尽管LLaMA3在量化后仍然展现出优越的性能，但与量化相关的性能下降是显著的，甚至在许多情况下可以导致更大的下降。</div><div class=" pTag">这一发现突显了在资源受限环境中部署LLaMA3可能面临的潜在挑战，并强调了在低比特量化背景下增长和改进的充足空间。通过解决低比特量化引起的性能下降，预期后续的量化范式将使LLMs在较低的计算成本下实现更强的能力，最终推动代表性的生成式人工智能达到新的高度。</div><div class=" pTag"><span style="font-size: 17px;"><span>论文链接：</span><br /><span>https://arxiv.org/abs/2404.14047</span></span></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">项目链接：</div><br /><div class=" pTag">https://github.com/Macaronlin/LLaMA3-Quantization</div><br /><div class=" pTag">https://huggingface.co/LLMQ</div></span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fou-mX9AoQTX7tWL6CWXiaQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 05:45:43 GMT</pubDate>
</item>
<item>
<title>阿里智能体“组装工厂”开源！0经验搞定上万Agent并发</title>
<link>https://posts.careerengine.us/p/662c90f9e9d9800822d255d0</link>
<guid>https://posts.careerengine.us/p/662c90f9e9d9800822d255d0</guid>
<content:encoded><![CDATA[
<div> 多智能体编程框架、AgentScope、拖拽式编程、应用监控、多模态支持
<br />
AgentScope是阿里巴巴通义实验室开源的多智能体编程框架，提供拖拽式编程和多模态支持。AgentScope Workstation提供可视化拖拽式开发界面，帮助开发者搭建多智能体应用。AgentScope Copilot是开发助手，提供交互式帮助解决问题。应用监控模块实时监控成本及多智能体状态。AgentScope支持多种工具函数、智能体和应用样例，提供丰富的开发资源。容错机制确保应用稳定可靠。总体来说，AgentScope提供了便捷的多智能体开发平台，适用于不同领域的开发者。 
<br /> 
总结: 
多智能体编程框架AgentScope提供了拖拽式编程、应用监控和多模态支持，为开发者提供了丰富的开发资源和稳定可靠的运行时保障。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">阿里巴巴通义实验室 投稿</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">让多智能体开发就像搭积木，阿里巴巴通义实验室开源多智能体编程框架与开发平台<span><strong style="font-weight: 600;">AgentScope</strong></span>。</div><div class=" pTag">该平台专门为多智能体应用开发者打造，旨在提供高易用的编程体验、稳定可靠的运行时保障，并且为开发者提供了分布式和多模态的技术支持。</div><div class=" pTag">内置了OpenAI、DashScope、Gemini、Ollama等多种不同平台的模型API，深度兼容当下的大模型开源生态。</div><div class=" pTag">AgentScope提供了多种开箱即用的功能，通过简单拖拽就能搭建多智能体应用。</div><div class=" pTag">即使没有分布式开发经验的开发者，在AgentScope平台上也能轻松实现上万级别的多智能体并发。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnLGEkRC0R57fULMGON55D0jibCmpvcyueVicuhEDsKVrdD6VOKJ8iap3VQ/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /></div><div class=" pTag">为了让更多用户能够快速、轻松地开发属于自己的多智能体应用。AgentScope提供了以下功能：</div><ul class="list-paddingleft-1"><li><div class=" pTag"><span><strong style="font-weight: 600;">拖拽式的编程范式——AgentScope Workstation</strong></span>：为用户提供了可视化的拖拽式开发界面</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">交互式编程助手——AgentScope Copilot</strong></span>：解答开发者关于AgentScope的疑问</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">透明可控的开发过程——应用实时监控</strong></span>：实时监控应用运行成本、多智能体状态，实现透明且可控的开发</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">丰富的开发资源</strong></span>：助力快捷且方便的二次开发，搭建应用无需“从零开始”</div></li></ul><h2>AgentScope Workstation</h2><div class=" pTag">AgentScope Workstation提供了便捷的“拖拽式”多智能体应用编排范式。</div><div class=" pTag">在这里，编程经验不再是限制你想象力的因素。每个开发者都可以在丰富的工具栏中，零代码地挑选和拖拽出他们喜欢的大模型、智能体和 Pipeline，就像搭积木一样自由组合，创造出独特创新的多智能体应用。</div><div class=" pTag">为了确保这些通过拖拽搭建的多智能体应用真正可用，AgentScope Workstation引入了静态规则检查，以确保应用的正确性。</div><div class=" pTag">对于那些寻求进一步自定义和深度开发的高级开发者，AgentScope Workstation也提供了强大的支持。</div><div class=" pTag"><div class=" pTag">开发者既可以将应用导出为配置信息，借助AgentScope Workstation引擎进行运行，也可以使用AgentScope Workstation Compiler将配置信息一键转换成Python代码。这样，开发者便可以进一步编辑和优化代码，实现更为精细和个性化的应用调整。</div><br /></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnMTvU0n4dCvz0RFpeO422ehsDumUUiaMvtcmg7mLc5a9HTeet8fAxgLg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><h2>AgentScope Copilot</h2><div class=" pTag"><span><strong style="font-weight: 600;">AgentScope Copilot</strong></span>是基于AgentScope框架自身构建的开发助手，旨在帮助开发者解决在多智能体应用开发过程中所遇到的问题，其技术实现结合了多智能体群聊<span>（Multi-agent Conversation）</span>、数据检索生成<span>（Retrieval-Augmented Generation，RAG）</span>、智能体呼叫<span>（Mention）</span>等诸多特性。</div><div class=" pTag">在与AgentScope Copilot的交互中，开发者既可以与引导助手<span>（Guide Assistant）</span>进行交互，直接获取帮助；也可以呼叫专用的智能体助手，例如问答助手<span>（Tutoring Assistant）</span>或者代码编程助手<span>（Coding Assistant）</span>，从而获得更加专业、更加具体的回答。更具体而言，代码编程助手可以帮助开发者快速理清框架内各个模块的定义及使用方法，提供更优的编程建议。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnFajj5Rg8ITWUFa2kK0RrfZ4SNFibXQU4dlNOTkt1LapMKianOlMR1O3Q/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="text-align: left;"><span style="font-size: 17px; text-align: left;">值得一提的是，AgentScope Copilot本身基于AgentScope框架中的RAG模块进行搭建，支持LlamaIndex等流行的数据检索框架、以及多种向量数据库类型，同时支持接入各种大语言模型。开发者可以进行快速的二次开发，轻松的搭建起自己项目的Copilot助手。</span></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnOCeZTGAzibQyr7beFg7AlgfcOSl9RvcMqp7B8Owh5WQSmnjJjJpf05w/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><h2>透明可控的开发过程</h2><div class=" pTag">一个友好的应用开发过程，对开发者来说应该是可控的、透明的。</div><div class=" pTag">但是在多智能体场景下，模型API种类繁多，调用接口各异，如何有效管理和监控模型API的使用成本，避免资源浪费与意外开支，对资源监控能力提出了更高的挑战。</div><div class=" pTag">例如，在使用搜索引擎时将一个复杂网页作为大模型的输入将引起高额的开销，而开发者的感知往往滞后。为了解决这个问题，AgentScope设计了Monitor模块，实现了：</div><div class=" pTag"><strong style="font-weight: 600;">API开销自动统计</strong>：准确记录不同模型API的token用量，并自动计算当前开销，确保开发者对模型API成本的每一份支出都了如指掌。</div><div class=" pTag"><strong style="font-weight: 600;">预算设置及超额报警</strong>：支持开发者设定各模型API的预算上限。当总开销超过预算时，系统自动触发报警，及时通知开发者进行检查和调整，避免超支的发生。</div><div class=" pTag"><strong style="font-weight: 600;">支持自定义监控指标</strong>：除了预设的模型API相关指标外，Monitor还允许开发者自定义其他监控指标，例如搜索工具的开销，数据存储服务的开销，网络流量等等，从而让开发者能够对应用的状态进行全面且自动化的监控。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yn8E2oFDZGiaLvXZjcmhu0as6TMcNsD3GUoYH2pneZGHvnjofDqlV85sQ/640?wx_fmt=png&amp;from=appmsg" /></div></div><strong style="font-size: 17px; text-align: right; font-weight: 600;">△</strong><span style="font-size: 17px; text-align: right;">&nbsp;Monitor模块</span></div><h2>即拿即用的开发资源</h2><div class=" pTag">AgentScope内置了丰富的工具函数、智能体和应用样例，开发者可以通过轻量化的修改，轻松的开发属于自己的多智能体应用。</div><div class=" pTag"><strong style="font-weight: 600;">工具函数</strong>：AgentScope支持包含网络搜索、数据库查询、文件操作、文本处理等多种类型的工具函数，每种类目下又包含不同实现形式。例如网络搜索层面，AgentScope已经支持Bing、arXiv和DBLP等多种搜索引擎。</div><div class=" pTag"><strong style="font-weight: 600;">智能体</strong>：AgentScope内置了功能各异的智能体，包含基础对话、格式化对话、Reasoning、RAG、分布式等多种不同类型的智能体。开发者只需要使用不同的参数初始化智能体实例，就可以将智能体特化成自己需要的智能体实例。</div><div class=" pTag"><strong style="font-weight: 600;">应用样例</strong>：AgentScope预置了包含对话<span>（Conversation）</span>、游戏<span>（Game）</span>、和分布式<span>（Distribution）</span>等多种不同类型的应用。一方面这些样例可以帮助开发者降低开发代价，另一方面也为应用的开发提供了模版和参照。</div><div class=" pTag">为了让开发者能够更好、更快地了解AgentScope中的内置资源，AgentScope提供了丰富且详细的文档，包含教程<span>（Tutorial）</span>、接口文档<span>（API Document）</span>和设计论文，帮助开发者更好的了解和使用AgentScope。</div><h2>稳定可靠</h2><div class=" pTag">基于大模型的多智能体应用会面临模型幻觉、模型指令跟随能力不足等诸多新的挑战。为了保证多智能体应用能够稳定可靠地运行，AgentScope首先将应用中出现的错误进行分类，然后相应地提供了一套完整的容错机制和自定义的容错处理。</div><div class=" pTag"><strong style="font-weight: 600;">面向随机性的容错</strong>：随机性错误常常由网络状况不稳定，或者模型生成内容的不确定性引起，是基于大模型构建应用时最常见的一类错误。这类错误往往十分琐碎且难以穷举，因此AgentScope通过的内置重试机制，将此类随机性的错误进行过滤和屏蔽，方便开发者将精力投入到应用的编排中。</div><div class=" pTag"><strong style="font-weight: 600;">基于规则的容错</strong>：应用中遇到的部分错误可以通过规则进行修复。例如，要求大模型产生指定格式的回复时，大模型有时会产生额外的内容，因此可以通过预置的规则进行截断，确保应用的正常运行。</div><div class=" pTag"><strong style="font-weight: 600;">基于模型的容错</strong>：借助大模型自身能力进行纠错是多智能体应用的特点之一，AgentScope会尝试将输入和错误信息提供给大模型，利用大模型的理解能力和知识来纠正错误。</div><div class=" pTag"><strong style="font-weight: 600;">面向智能体/开发者的容错</strong>：当预置规则和大模型都无法解决错误时，往往需要开发者或者是智能体的介入才能解决问题，因此AgentScope在遇到此类错误的情况下，会将错误的格式化归因、错误信息、输入输出信息完整的提交给开发者或智能体，从而帮助解决遇到的问题。</div><h2>提示优化</h2><div class=" pTag">多智能体应用性能的提升很大程度依赖大模型的提示（Prompt）质量，一个好的提示可以大幅提高应用运行成功的概率。AgentScope编程框架提供了提示调优模块，助力开发者持续优化应用。</div><div class=" pTag"><strong style="font-weight: 600;">提示自动生成</strong>：对于开发者来说，产生一个好的提示往往是一件耗时耗力的事情。AgentScope预置了一个智能体，其内部通过上下文学习的方式<span>（In-context learning，ICL）</span>，综合开发者的应用场景，直接生成所需的提示，帮助开发者快速开始开发。</div><div class=" pTag"><strong style="font-weight: 600;">支持样例输入</strong>：在AgentScope中，开发者同时可以输入若干样例作为模板，AgentScope可以根据这些样例，为特定的下游任务生成具体的提示词。</div><div class=" pTag"><strong style="font-weight: 600;">提示动态调优</strong>：在应用运行过程中，大模型的提示词还需根据运行情况做进一步的调整，例如添加新的规则以避免错误的产生。AgentScope将此过程自动化，在智能体与开发者、环境进行交互的过程中，其历史数据将成为调整提示的依据；AgentScope根据当时的场景，修改智能体的系统提示<span>（System prompt）</span>从而在运行过程中提高智能体的表现。</div><h2>分布式并行</h2><div class=" pTag">作为一个多智能体编程框架，AgentScope在设计之初就将提升智能体之间的协作效率作为主要目标之一，并为此设计了分布式模式。在该模式中，多智能体可以运行在不同的进程和机器当中，从而充分利用计算资源，提高运行效率。AgentScope中的分布式主要具有以下特点：</div><div class=" pTag"><strong style="font-weight: 600;">自动并行优化</strong>：AgentScope中分布式的设计遵循Actor编程范式，可以自动识别应用流程编排中不同智能体之间潜在的并行可能性，并且进行自动并行优化，提升运行效率。同时各个智能体可以独立运行在本地或者远程机器上，能够充分利用计算资源，支持大规模部署。</div><div class=" pTag"><strong style="font-weight: 600;">上手门槛极低</strong>：AgentScope向开发者完全屏蔽了分布式的技术实现细节，开发者可以零代价开发分布式多智能体应用，或者将已有的多智能体应用转化成分布式模式运行。在转化成分布式应用时，AgentScope中分布式应用编排与本地化的编排方式完全兼容，即使没有分布式背景知识，开发者也能轻松编排分布式多智能体应用。</div><div class=" pTag"><strong style="font-weight: 600;">支持大规模部署</strong>：AgentScope目前支持在单台机器<span>（64核8卡A100）</span>上一次性运行16000多个智能体实例，并且该规模能够随着机器数量的增加实现规模的线性增长。举例来说，AgentScope在4台机器的集群上可以在30秒内完成64000多次智能体的调用。这一特点使得智能体的大规模并行和仿真成为可能。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnPMZMDiaTjB0UKpv5g1Rica8UY0qQkiaxqYI0YQEfe58jE1TGykCiaO7zMg/640?wx_fmt=png&amp;from=appmsg" /></div></div><strong style="font-size: 17px; text-align: right; font-weight: 600;">△</strong><span style="font-size: 17px; text-align: right;">本地模式向分布式模式转换</span></div><h2>多模态支持</h2><div class=" pTag">AgentScope支持开发者使用多模态数据和多模态模型来构建强大的多智能体应用。为了让开发者可以更加直观、便捷地与自己编排的多智能体应用交互，AgentScope提供了一款开发者友好、简便易用的可交互式界面AgentScope Studio，让文本、声音、图像等不同模态的数据得以生动呈现，确保了开发者能以最直观的方式感受并调整自己创造的智能体应用。</div><div class=" pTag" style="text-align: right;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnBILVIW8LLic7x2ahiaeicOVtUdOwsjaaQib3MCGSZonSEqBuhDcI8Cw4pA/640?wx_fmt=gif&amp;from=appmsg" /></div></div><strong style="font-size: 17px; text-align: right; font-weight: 600;">△</strong><span style="font-size: 17px; text-align: right;">AgentScope Studio</span></div><div class=" pTag">接下来，AgentScope还将持续为开发者带来更多的开发便利，也期待更多开发者加入AgentScope开源社区的建设，探索更多更有趣的多智能体应用。<span style="display: none;">‍</span></div><div class=" pTag"><span style="font-size: 17px;">AgentScope开源仓库地址：</span></div><div class=" pTag"><span style="font-size: 17px;">https://github.com/modelscope/agentscope</span></div><div class=" pTag"><span><span style="font-size: 17px;">欢迎试用：</span></span></div><div class=" pTag"><span style="font-size: 17px;">https://agentscope.aliyun.com</span></div><div class="mp_profile_iframe_wrp pTag sectionReplaced" style="text-align: center;"><p><span><span style="text-align: center;">—&nbsp;</span><strong style="text-align: center; font-weight: 600;">完</strong><span style="text-align: center;">&nbsp;—</span></span></p><div style="font-size: 17px;"><div style="font-size: 17px;"><div class=" pTag"><span>投稿请发邮件到：</span></div><div class=" pTag"><span><strong style="font-weight: 600;"><a class="__cf_email__" href="https://posts.careerengine.us/cdn-cgi/l/email-protection">[email&nbsp;protected]</a></strong></span></div><div class=" pTag">标题注明【投稿】，告诉我们：</div><div class=" pTag">你是谁，从哪来，投稿内容<span style="display: none;">‍</span></div><div class=" pTag">附上论文/项目主页链接，以及联系方式哦</div><div class=" pTag">我们会（尽量）及时回复你</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" /></div></div></div></div></div><div class=" pTag"><span class="js_darkmode__2" style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span class="js_darkmode__3">👇</span>关注我，记得标星哦～</span></strong></span></div><div style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div style="display: inline-block;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FNPUZKE1G16zhFDs4bUHAkg">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 05:45:29 GMT</pubDate>
</item>
<item>
<title>清华团队国产“Sora”火了！画面效果对标OpenAI，长度可达16秒，还能读懂物理规律</title>
<link>https://posts.careerengine.us/p/662c90f9e9d9800822d255d8</link>
<guid>https://posts.careerengine.us/p/662c90f9e9d9800822d255d8</guid>
<content:encoded><![CDATA[
<div> 生成视频、技术路线、时空一致性、模拟真实物理世界、团队背景
<br /><br />总结:
国内生数科技联合清华大学发布的视频大模型「Vidu」引起关注，支持高清视频生成，画面效果接近Sora，具有镜头语言、时间和空间一致性、物理规律模拟等特点，能虚构超现实主义画面。实现长视频生成突破10秒大关，保持时间和空间一致性，模拟真实物理世界。团队选对技术路线，基于自研U-ViT架构并具备扎实工程化基础。团队由清华背景的精干团队组成，早在多模态模型领域积累经验。团队迅速突破的秘籍在于技术路线选择和工程化基础。 </div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">允中 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag"><div class=" pTag">Sora席卷世界，也掀起了全球竞逐AI视频生成的热潮。</div><br /></div><div class=" pTag"><div class=" pTag">就在今天，国内又有一支短片引发关注。</div><br /></div><div class=" pTag"><div class=" pTag">视频来自生数科技联合清华大学最新发布的视频大模型</div><span style="font-size: 17px; text-align: left;">「</span><span style="font-size: 17px; text-align: left;">Vidu」。</span><br /></div><div class=" pTag">从官宣消息看，「Vidu」支持一键生成<span><strong style="font-weight: 600;">长达16秒、分辨率达1080p</strong></span>的高清视频内容。</div><div class=" pTag">更令人惊喜的是，「Vidu」画面效果非常接近Sora，在多镜头语言、时间和空间一致性、遵循物理规律等方面表现都十分出色，而且还能虚构出真实世界不存在的超现实主义画面，这是当前的视频生成模型难以实现的。</div><div class=" pTag">并且实现这般效果，背后团队只用了两个月的时间。</div><h2>全面对标Sora</h2><div class=" pTag"><div class=" pTag">3月中旬，生数科技联合创始人兼CEO唐家渝就曾公开表示：“今年内一定能达到Sora目前版本的效果。”</div><br /></div><div class=" pTag"><span style="font-size: 17px; text-align: left;">现在，在生成时长、时空一致性、镜头语言、物理模拟等方面，确实能看到<span style="font-size: 17px; text-align: left;">「Vidu」在短时间内已经逼近Sora水平。</span></span></div><h3>长度突破10秒大关</h3><div class=" pTag">「Vidu」生成的视频不再是持续几秒的「GIF」，而是达到了16秒，并且<strong style="font-weight: 600;">做到了画面连续流畅，且有细节、逻辑连贯</strong>。</div><div class=" pTag">尽管都是运动画面，但几乎不会出现穿模、鬼影、运动不符合现实规律的问题。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzvc7t1zPgyoZ4NBOUnVQe6nVVtBZxCCEg2oKV6fzvNKdXjUkac5Wd6w/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;">△</strong>提示：一艘木头玩具船在地毯上航行</h6><h3>给视频注入「镜头语言」</h3><div class=" pTag">在视频制作中有个非常重要的概念——镜头语言。通过不同的镜头选择、角度、运动和组合，来表达故事情节、揭示角色心理、营造氛围以及引导观众情感。</div><div class=" pTag">现有AI生成的视频，能够明显地感觉到镜头语言的单调，镜头的运动局限于轻微幅度的推、拉、移等简单镜头。深究背后的原因看，因为现有的视频内容生成大多是先通过生成单帧画面，再做连续的前后帧预测，但主流的技术路径，很难做到长时序的连贯预测，只能做到小幅的动态预测。</div><div class=" pTag">「Vidu」则突破了这些局限。在一个「海边小屋」为主题的片段中，我们可以看到，「Vidu」一次生成的一段片段中涉及多个镜头，画面既有小屋的近景特写，也有望向海面的远眺，整体看下来有种从屋内到走廊再到栏杆边赏景的叙事感。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzxHnc71ticU8Q9Jia1b85AlrL9VicIibhZr89oeHUaIMFibAN0TwsHBVlmMw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">包括从短片中的多个片段能看到，「Vidu」能直接生成转场、追焦、长镜头等效果，包括能够生成影视级的镜头画面，给视频注入镜头语言，提升画面的整体叙事感。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzP2oytNbF5uQibJ0JdHkqvDhK9YrRmbyw2I3KjUZeV2zHpuWn08FGntQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><h3>保持时间和空间的一致性</h3><div class=" pTag">视频画面的连贯和流畅性至关重要，这背后其实是人物和场景的时空一致性，比如人物在空间中的运动始终保持一致，场景也不能在没有任何转场的情况下突变。而这一点 AI 很难实现，尤其时长一长，AI生成的视频将出现叙事断裂、视觉不连贯、逻辑错误等问题， 这些问题会严重影响视频的真实感和观赏性。</div><div class=" pTag">「Vidu」在一定程度上克服了这些问题。从它生成的一段“带珍珠耳环的猫”的视频中可以看到，随着镜头的移动，作为画面主体的猫在3D空间下一直保持着表情、服饰的一致，视频整体上连贯、流畅，保持了很好的时间、空间一致性。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-iframe-holder offset offset-old-168"></div><strong style="font-size: 17px; text-align: right; font-weight: 600;">△</strong><span style="font-size: 17px; text-align: right;">提示：</span><span style="font-size: 17px; text-align: right;">这是一只蓝眼睛的橙色猫的肖像，慢慢地旋转，灵感来自维米尔的《戴珍珠耳环的少女》，画面上戴着珍珠耳环，棕色头发像荷兰帽一样，黑色背景，工作室灯光。</span></div><h3>模拟真实物理世界</h3><div class=" pTag">Sora令人惊艳的一大特点，就是能够模拟真实物理世界的运动，例如物体的移动和相互作用。其中Sora有发布的一个经典案例，“一辆老式SUV行驶在山坡上”的画面，非常好地模拟了轮胎扬起的灰尘、树林中的光影以及车行驶过程中的阴影变化：</div><div class=" pTag sectionReplaced"><div class=" ce-iframe-holder offset offset-old-169"></div></div><div class=" pTag">在同样的提示词下，「Vidu」与Sora生成效果高度接近，灰尘、光影等细节与人类在真实物理世界中的体验非常接近。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCz3OM6f3WCrAibGaGPibsOSlzn816g7Sg1pj1zSia2y2mZDUeh6zRjwvhnQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;">△</strong>提示：镜头跟随一辆带有黑色车顶行李架的白色老式SUV，它在陡峭的山坡上一条被松树环绕的陡峭土路上加速行驶，轮胎扬起灰尘，阳光照射在SUV上，给整个场景投射出温暖的光芒。土路缓缓地蜿蜒延伸至远方，看不到其他汽车或车辆。道路两旁都是红杉树，零星散落着一片片绿意。从后面看，这辆车轻松地沿着曲线行驶，看起来就像是在崎岖的地形上行驶。土路周围是陡峭的丘陵和山脉，上面是清澈的蓝天和缕缕云彩。</h6><div class=" pTag">当然在“带有黑色车顶行李架”的局部细节上，「Vidu」没能生成出来，但也瑕不掩瑜，整体效果已高度接近真实世界。</div><h3>丰富的想象力</h3><div class=" pTag">与实景拍摄相比，用AI生成视频有一个很大的优势——它可以生成现实世界中不存在的画面。以往，这些画面往往要花费很大的人力、物力去搭建或做成特效，但是AI短时间就可以自动生成了。</div><div class=" pTag">比如在下面这个场景中，「帆船」、「海浪」罕见地出现在了画室里，而且海浪与帆船的交互动态非常自然。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-iframe-holder offset offset-old-174"></div></div><div class=" pTag">包括短片中的“鱼缸女孩”的片段，奇幻但又具有一定的合理感，这种能够虚构真实世界不存在的画面，对于创作超现实主义内容非常有帮助，不仅可以激发创作者的灵感，提供新颖的视觉体验，还能拓宽艺术表达的边界，带来更加丰富和多元化的内容形式。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzLbGKfiaNZNo9etOiaMHNLvcmGVwoEDfEA1Ue8FxsB28oXicZic0RF8Z3VA/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /></div><h3>理解中国元素</h3><div class=" pTag">除了以上四方面的特点外，我们从「Vidu」放出的短片中还看到了一些不一样的惊喜，「Vidu」能够生成特有中国元素的画面，比如熊猫、龙、宫殿场景等。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCzZ0sqMiaqhnEgw9uy4HjqUoEtbY9p9HsuxpEsxeA9WVHciaWFrZGxks9A/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;">△</strong><div class=" pTag">提示：在宁静的湖边，一只熊猫热切地弹着吉他，让整个环境变得活跃起来。晴朗天空下平静的水面倒映着这一场景，以生动的全景镜头捕捉到，将现实主义与大熊猫活泼的精神融为一体，创造出活力与平静的和谐融合。</div><br /></h6><h2>两个月快速突破的“秘籍”</h2><div class=" pTag">此前，唐家渝给出的赶上Sora的时间，是“很难说是三个月还是半年”。</div><div class=" pTag">但如今仅仅过去一个多月时间，团队就实现了突破，而且据透露，3月份公司内部就实现了8秒的视频生成，紧接着4月份突破了16秒生成。短短两个月时间，背后是如何做到的？</div><h3>一是选对了技术路线</h3><div class=" pTag">「Vidu」底层基于完全自研的U-ViT架构，该架构由团队在2022年9月提出，早于Sora采用的DiT架构，是全球首个Diffusion和Transformer融合的架构。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtB89QJPAKJRicl43hfrwibicCz6JvchthUkaONASUicX1vOcrdqbVRfbK8rPNEkcxNZJEWoNibquhHTh5A/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></h6><div class=" pTag">Transformer架构被广泛应用于大语言模型，该架构的优势在于scale特性，参数量越大，效果越好，而Diffusion被常用于传统视觉任务（图像和视频生成）中。</div><div class=" pTag">融合架构就是在Diffusion Model（扩散模型）中，用Transformer替换常用的U-Net卷积网络，将Transformer的可扩展性与Diffusion模型处理视觉数据的天然优势进行融合，能在视觉任务下展现出卓越的涌现能力。</div><div class=" pTag">不同于市面上之前的一些“类Sora”模型，长视频的实现其实是通过插帧的方式，在视频的每两帧画面中增加一帧或多帧来提升视频的长度。这种方法就需要对视频进行逐帧处理，通过插入额外的帧来改善视频长度和质量。整体画面就会显得僵硬而又缓慢。</div><div class=" pTag">另外，还有一些视频工具看似实现了长视频，实际打了“擦边球”。底层集合了许多其他模型工作，比如先基于Stable Diffusion、Midjourney生成单张画面，再图生4s短视频，再做拼接。表面看时长是长了，但本质还是“短视频生成”的内核。</div><div class=" pTag">但「Vidu」基于纯自研的融合架构，底层是“一步到位”，不涉及中间的插帧和拼接等多步骤的处理，文本到视频的转换是直接且连续的。直观上，我们可以看到“一镜到底”的丝滑感，视频从头到尾连续生成，没有插帧痕迹。</div><h3>二是扎实的工程化基础</h3><div class=" pTag">早在2023年3月，基于U-ViT架构，团队在开源的大规模图文数据集LAION-5B上就训练了10亿参数量的多模态模型——UniDiffuser，并将其开源。</div><div class=" pTag">UniDiffuser主要擅长图文任务，能支持图文模态间的任意生成和转换。UniDiffuser的实现有一项重要的价值——首次验证了融合架构在大规模训练任务中的可扩展性（Scaling Law），相当于将U-ViT 架构在大规模训练任务中的所有环节流程都跑通。值得一提的，同样是图文模型，UniDiffuser比最近才切换到DiT架构的Stable Diffusion 3领先了一年。</div><div class=" pTag">这些在图文任务中积累工程经验为视频模型的研发打下了基础。因为视频本质上是图像的流，相当于是图像在时间轴上做了一个扩增。因此，在图文任务上取得的成果往往能够在视频任务中得到复用。Sora就是这么做的：它采用了DALL·E 3的重标注技术，通过为视觉训练数据生成详细的描述，使模型能够更加准确地遵循用户的文本指令生成视频。</div><div class=" pTag">据悉，「Vidu」也复用了生数科技在图文任务的很多经验，包括训练加速、并行化训练、低显存训练等等，从而快速跑通了训练流程。据悉，他们通过视频数据压缩技术降低输入数据的序列维度，同时采用自研的分布式训练框架，在保证计算精度的同时，通信效率提升1倍，显存开销降低80%，训练速度累计提升40倍。</div><div class=" pTag">从图任务的统一到融合视频能力，「Vidu」可被视为一款通用视觉模型，能够支持生成更加多样化、更长时长的视频内容，官方也透露，「Vidu」目前并在加速迭代提升，面向未来，「Vidu」灵活的模型架构也将能够兼容更广泛的多模态能力。</div><h2>One More Thing</h2><div class=" pTag">最后，再聊下「Vidu」背后的团队——生数科技，这是一支清华背景的精干团队，致力于专注于图像、3D、视频等多模态大模型领域。</div><div class=" pTag">生数科技的核心团队来自清华大学人工智能研究院。首席科学家由清华人工智能研究院副院长朱军担任；CEO唐家渝本硕就读于清华大学计算机系，是THUNLP组成员；CTO鲍凡则是清华大学计算机系博士生、朱军教授的课题组成员，长期关注扩散模型领域研究，U-ViT和UniDiffuser两项工作均是由他主导完成的。</div><div class=" pTag">团队从事生成式人工智能和贝叶斯机器学习的研究已有20余年，在深度生成模型突破的早期就开展了深入研究。在扩散模型方面，团队于国内率先开启了该方向的研究，成果涉及骨干网络、高速推理算法、大规模训练等全栈技术方向。</div><div class=" pTag">团队于ICML、NeurIPS、ICLR等人工智能顶会发表多模态领域相关论文近30篇，其中提出的免训练推理算法Analytic-DPM、DPM-Solver等突破性成果，获得ICLR杰出论文奖，并被OpenAI、苹果、Stability.ai等国外前沿机构采用，应用于DALL·E 2、Stable Diffusion等明星项目中。</div><div class=" pTag">自2023年成立以来，团队已获得蚂蚁集团、启明创投、BV百度风投、字节系锦秋基金等多家知名产业机构的认可，完成数亿元融资。据悉，生数科技是目前国内在多模态大模型赛道估值最高的创业团队。</div><div class=" pTag sectionReplaced"><div style="text-align: center;"><div class=" pTag" style="text-align: right;"><span style="font-size: 17px;"><span style="font-size: 17px; text-align: left;"><span style="font-size: 17px; text-align: right;">*本文系量子位获授权刊载，观点仅为作者所有。</span></span></span></div><div class=" pTag"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div></div></div><div class=" pTag sectionReplaced"><div><div><div style="display: inline-block;"><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCMTiaQvFTH1BuicE6KgJEARU6aCY4PfZHwOUZ0icduoLL4pFsRC23KyvGAhjp4fIYWfVCaicicyVRAxHA/640?wx_fmt=jpeg" /></div></div></div></div><div style="display: inline-block;"><div><div><div class=" pTag"><span style="font-size: 17px;"><strong style="font-weight: 600;">量子位&nbsp;</strong></span><span style="font-size: 17px;">QbitAI</span></div></div><div><div><div style="text-align: left; font-size: 17px;"><div class=" pTag">վ'ᴗ' ի 追踪AI技术和产品新动态</div></div></div></div></div></div></div></div><div><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9e5IWnFrCxFxtON-AY6Jcw">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 05:45:29 GMT</pubDate>
</item>
<item>
<title>激进式押注AI手机的厂商一大堆，为什么登顶的是它家</title>
<link>https://posts.careerengine.us/p/662c90f8e9d9800822d255c8</link>
<guid>https://posts.careerengine.us/p/662c90f8e9d9800822d255c8</guid>
<content:encoded><![CDATA[
<div> 华为 荣耀 AI 手机 市场份额<br />
<br />
总结:<br />
今年中国手机市场迎来大变局，华为全面回归，荣耀以AI成为关键增长引擎登顶市场，展现新的市场格局。荣耀以平台级AI和大模型为核心，提供智慧服务和个性化体验，成为AI手机的先驱。荣耀布局早投入大，在AI研发方面领先。未来手机发展趋势是智能体派，以人为中心满足消费者需求，苹果也有类似动向。2024年终端市场将与AI和大模型密切相关，AI已成为长期竞争焦点，实现人手一个贾维斯的愿景变得更具期待。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">鱼羊 衡宇 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">今年的中国手机市场，正在迎来大变局。</div><div class=" pTag">两大变量交融交汇，已经开始展现作用力，让市场重新火热：</div><div class=" pTag">一是<strong style="font-weight: 600;">华为全面回归，盛况空前</strong>。</div><div class=" pTag">二是<strong style="font-weight: 600;">AI搅动风云，成为兵家必争之地</strong>。</div><div class=" pTag">就在这种交融之下，第一季度王座现已呈现归属——</div><div class=" pTag"><strong style="font-weight: 600;">荣耀</strong>。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yOTzSLZhhT0kwwaDz5Ctesf3GHMGeFib23iblacRfNqXys4Mp04lAp0Pg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>AI成手机厂商关键增长引擎</h2><div class=" pTag">华为的全面回归，采取的是一种最低调的姿态，收获了史上最高的关注度。</div><div class=" pTag">市场一度热议，华为回归后，“荣耀受到的影响最大”。</div><div class=" pTag">但最新数据出炉，事实却并非如此。</div><div class=" pTag">IDC<span>（国际数据公司）</span>发布的最新手机季度跟踪报告显示，今年第一季度，中国智能手机整体出货量约6926万台，具体到厂商方面，<strong style="font-weight: 600;">荣耀以17.1%的市场份额拿下第一</strong>，“成为了拉动市场持续向好的重要力量”。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yWCdVW6ibPSKnTyT6iaKh6xszTFXB0DiaRj1l2vOZOzJ9ufMT5YOhicatKA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">IDC中国区副总裁王吉平认为，此次荣耀登顶，<strong style="font-weight: 600;">AI成为关键增长引擎</strong>：</div><div class=" pTag">今年年初，荣耀发布了AI使能的全场景操作系统MagicOS 8.0，以魔法大模型加持，以平台级AI为内核、为底座，带来了“越用越好用，越用越懂你”的智慧服务。而首发搭载MagicOS 8.0的Magic6系列大受市场欢迎。</div><div class=" pTag">据王吉平介绍，得益于AI功能的增加，以及影像、屏幕等全方位的升级，全新旗舰Magic6系列首销第一季度出货量超过上一代首销前二季度出货量之和；</div><div class=" pTag">另一方面，在搭载平台级AI的荣耀Magic V2以及其他折叠屏家族产品的推动下，去年以来，荣耀折叠屏手机份额同比涨幅最高达到 675.4%。</div><div class=" pTag">而依靠荣耀Magic6系列及折叠屏家族的表现，今年第一季度，荣耀在600美元以上的高端市场份额提升明显，出货量同比增幅高达123.3%，高端市场份额仅次于苹果和华为。</div><h2>手机AI≠AI手机</h2><div class=" pTag">那么问题来了——</div><div class=" pTag">AI手机是大模型应用风暴开刮之后，每家终端厂商必cue的话题。第一季度，激进押注的国内外各大安卓厂商，都纷纷发布自家首款产品。</div><div class=" pTag">大家都野心勃勃，底线当然是不能再这场竞争中落后。</div><div class=" pTag">为什么脱颖而出的是荣耀？</div><div class=" pTag">荣耀CEO赵明认为，关键是“<strong style="font-weight: 600;">手机AI不等于AI手机</strong>”：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">手机上使用AI的技术能力和体验，手机提供的是平台和算法。</div><div class=" pTag">但只有AI成为根基，在手机上无处不在，才能叫AI手机。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yG0lpGNvYc4t4jyVhUz4Z7Juvibwp8HDGfFfibmxvmeB9JBNGR1ZvsqlA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">纵览第一季度市场上出现的AI手机们，不难看出，尽管宣传词都与“大模型”“AIGC”紧紧绑定，但在具体的落地路线上，其实已经出现流派的不同。</div><div class=" pTag">大多数厂商选择的路线，是率先围绕应用发力。基于已在云端锤炼得较为成熟的文本生成、图像生成等AIGC技术，在手机上推出端侧以及端云协同的AIGC应用。比如更为智能的人像抠图、翻译、会议总结等。</div><div class=" pTag">而以荣耀为代表的厂商，则有些反其道而行之的意思。</div><div class=" pTag">赵明就多次公开表示，手机厂商要避免掉入应用爆发呈现的陷阱，在AI领域，<strong style="font-weight: 600;">终端厂商能够给消费者带来的核心价值在操作系统层面</strong>。</div><div class=" pTag">具体来说，后者的路线其实是从第一性原理出发，考虑到消费者真正关心的核心议题是：</div><div class=" pTag"><strong style="font-weight: 600;">轰轰烈烈的大模型、AIGC能否真的给终端设备带来更好、更难替代的实际体验</strong>。</div><div class=" pTag">所以，什么是大模型进入手机后，能切实加强的体验？</div><div class=" pTag">最直观的，就是从“人找服务”，到“服务找人”。</div><div class=" pTag">在技术探索的层面上，高通展示过智能助手结合用户习惯主动决策的能力：在规划出行路线时，会主动询问是否要在路过的咖啡店里买杯咖啡。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yU8EibgE1TR8Wfc2mhTN4XAPwCsdtqlZiaknv2khicRque5kr32dbobeLQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">而实践层面，则可以拿荣耀为例：</div><div class=" pTag">首先，以平台级AI为新内核的MagicOS 8.0，带来行业首个基于意图识别的人机交互。</div><div class=" pTag">它能识别人机交互意图，是系统级的主动服务。</div><div class=" pTag">可以是出行时，到地铁站，手机会自动弹出乘车码；到机场，会自动弹出登机牌；到电影院，会弹出取票码。</div><div class=" pTag sectionReplaced">还可以是领导在群里通知要开会，只需截图后点击“创建日程”，系统就能识别时间、地点、会议主题，在日历中创建对应日程。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3y0fjAsjYrfeEhBe4Skic05EUD3X8mAToh7xS8SKXic3je3sP1jZ6IGqmQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">核心功能之一、基于多模态能力的“任意门”，可以完成App之间的跨转“一步直达”。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yFWmlPNvBGkwE3aicAnicepxzibYliaf3o9jicVd3ZCibAIfQLLKDvBh4nRFg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">类似如此，任意门带来的体验还有很多，归纳起来，就是把传统的多步骤操作简化为一步操作，一步到位。</div><div class=" pTag">在使用体验背后，荣耀还更为明确地提出了终端设备的<strong style="font-weight: 600;">AI四层架构</strong>理论：</div><div class=" pTag">第一层在系统层面，用AI使能跨系统、跨设备的融合。也就是让不同的操作系统通过AI决策无缝连接，实现手机、平板、PC等设备之间的数据共享。</div><div class=" pTag">第二层在单机层面，用AI来重构操作系统。基于人工智能技术，让终端越用越懂你，越用越好用。</div><div class=" pTag">第三层在应用层面，即AI在端侧的应用。</div><div class=" pTag">第四层是AI的端云协同。即在保障用户隐私安全的前提下，实现AIGC和云端大模型等网络侧AI在手机上的呈现。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yzJDALBFcEJLicV1b7ss9A0LbhcgTNicH6DWGyMyLBa3ntZhqMIa6ARHA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">实际上，这样的四层架构也概述了当前AI手机市场的竞争现状：</div><div class=" pTag">第三层、第四层更易切入，率先迎来爆发。</div><div class=" pTag">但第一层、第二层对于终端厂商更为关键，是终端公司区别于互联网公司的核心价值。</div><h2>手机的下一阶段：智能体</h2><div class=" pTag">用当下热议的技术热词来做个简单总结，这两条不同的落地应用路线，又可划分为“<strong style="font-weight: 600;">工具派</strong>”和“<strong style="font-weight: 600;">智能体派</strong>”。</div><div class=" pTag">所谓工具派，更注重单点AIGC技术能力的工具化，强调在具体任务场景里，工具变革给人带来的直接效率提升。</div><div class=" pTag">而“智能体派”，更注重大模型、AIGC能力与终端操作系统的深度结合，即意在充分发挥大模型感知、记忆、理解、推理、决策的能力，不断学习用户习惯，理解用户意图，围绕用户的需求来对终端的各种能力进行调度。</div><div class=" pTag">相比于推出解决某一类问题的AIGC应用，“智能体派”的布局显得更加长线，核心是<strong style="font-weight: 600;">以人为中心</strong>，满足消费者对手机智能的本质需求：</div><div class=" pTag">一方面，简化人机交互的模式，让手机这样的终端能越来越像人类助理一样，主动适应和匹配人的需求。</div><div class=" pTag">另一方面，能将大量留存在终端的用户个性化数据充分利用起来，让智能助理根据用户特性自我进化、持续成长。</div><div class=" pTag">其实，这也是AI手机能否像智能机取代功能机一样，成为手机第三阶段新形态的关键——</div><div class=" pTag">通过手机这样的终端设备，我们是否真的能人手一个会自我学习和不断适应用户需求的“贾维斯”？</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yibfou2RNDJJSMe5gpmVy6RODlFV0pnBYicCyYMjAkiaElEUoReATdlP8A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不过，值得关注的是，这条手机进阶智能体的路线，即使是在大模型技术进展飞快的当下，技术挑战仍然不容小觑。</div><div class=" pTag">关键的难点是，智能体路线涉及到<strong style="font-weight: 600;">用AI重构操作系统</strong>。</div><div class=" pTag">赵明也对此做过进一步解释，相比于应用，这种核心能力的构建更具门槛：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">荣耀的路线是先把平台级AI、AI手机最核心的能力构建起来。某种程度上，我们稍微控制、抑制了一下在手机AI应用上的发展，因为担心太重视单点应用，而忽视了核心能力的构建。</div><div class=" pTag">在此基础之上，在2024年这个节点，我们会在AI端侧应用上发力，这本身不存在门槛，因为并不涉及到操作系统的重构。</div></blockquote><div class=" pTag">这也就解释了为什么是荣耀在第一季度AI手机的比拼中占得先机。</div><div class=" pTag"><span><strong style="font-weight: 600;">首先，是布局早</strong></span>，因此能在前沿技术带来创新机会时，率先发力。</div><div class=" pTag">在2016年第一代Magic上，荣耀就率先带来了目光注视自动亮屏、机场自动推送登机牌等，让手机主动识别用户意图的功能，并从此确立了荣耀IUI<span>（意图识别人机交互）</span>的演进方向。</div><div class=" pTag">2022年，荣耀开始在MagicOS 7.0上建立起平台级AI能力，在智慧出行、智慧生活、智慧娱乐三大场景中推送多种卡片提醒，包括航班提醒、快递提醒、还款提醒等，逐渐建立起IUI的雏形。</div><div class=" pTag">而随着大模型技术向终端侧的迁移，在今年，荣耀不仅发布了70亿参数“魔法大模型”，还基于端侧大模型对平台级AI能力进行了全面升级，在MagicOS 8.0上再次变革人机交互方式，实现意图识别人机交互，使得操作系统的个人化成为可能。</div><div class=" pTag">一边，荣耀平台级AI，让手机更加关注用户个人，比如位置、状态、个人习惯、知识库等人因元素。</div><div class=" pTag">而另一边，端侧大模型<span>（荣耀自研的70亿参数魔法大模型）</span>的加持，又能进一步增加平台级AI对人因元素的学习和理解。</div><div class=" pTag"><span><strong style="font-weight: 600;">其次，是投入大。</strong></span></div><div class=" pTag">截至目前，荣耀AI研发费用累积达100亿，AI专利成果超2100项。</div><h2>One More Thing</h2><div class=" pTag">无独有偶，被曝将在今年的WWDC上公布AI新布局的苹果，近来传出的大模型相关进展中，也显露出将大模型与iOS做更深层结合的“智能体派”倾向。</div><div class=" pTag">3月份，来自苹果的一篇新论文《ReALM：Reference Resolution As Language Modeling》，还透露出苹果在提高语音助手理解和响应命令能力方面的技术进展。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3y1YMJMlrqCVInhZgjaY0oQXXdPtgmHu0r6pbcjGibooHwuFkFcbqXgWg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">简单来说，是让大模型去分析用户都在手机屏幕上做了哪些操作，以此学习用户的使用习惯、理解用户意图。</div><div class=" pTag">多方消息结合，苹果如今也大有要将理论研究付诸实践的势头。</div><div class=" pTag">看来，无论是华为的全面回归，荣耀的强势登顶，还是苹果的寻求新变，2024的终端风云，注定和AI、和大模型有更强烈的交织。AI，已然成为终端市场新的长期竞争焦点。</div><div class=" pTag">人手一个贾维斯，确实越来越值得期待了。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fn0W9KSUf7zjCeW2fAFMDFA">阅读原文 </a>
]]></content:encoded>
<pubDate>Sat, 27 Apr 2024 05:45:28 GMT</pubDate>
</item>
<item>
<title>一键换装神器爆火，老黄换上抱抱脸T恤，CEO本人：我被替代了，和他争CEO职位争不过</title>
<link>https://posts.careerengine.us/p/662ba267200df4779e6b13a1</link>
<guid>https://posts.careerengine.us/p/662ba267200df4779e6b13a1</guid>
<content:encoded><![CDATA[
<div> IDM-VTON、虚拟试穿、扩散模型、AI、网友们玩坏

总结:<br /><br />这篇文章介绍了最新的虚拟试穿神器IDM-VTON，基于扩散模型技术，通过AI实现虚拟试穿衣服。网友们利用该工具玩坏了一些大佬的衣服，展示了有趣的效果。该技术结合了TryonNet、IP-Adapter和GarmentNet模块，利用细粒度的细节提示生成真实的虚拟试穿图像。研究人员在VITON-HD数据集上进行了评估，结果表明IDM-VTON在定性和定量上优于先前的方法。感兴趣的读者可以查看原论文获取更多细节。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">西风 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">笑不活，最新虚拟试穿神器被网友们玩坏了。</div><div class=" pTag">黄院士、马斯克、奥特曼、史密斯等一众大佬衣服集体被扒。</div><div class=" pTag">前有老黄卸下皮衣套上糖果包装袋：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhHOTdHjpJKVBNNEykSv8a5XcLUUgumJxZiaicOuMAtxbAZLv2lh19YSyA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">后有奥特曼大秀花臂穿CUCCI：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhINBqq027ibQVuBFib5JeYOOSy7LAGbddrfDPhiaicZJ6enoiaNF7A3icnbgQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">再有老马变成了蛛蛛侠：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhr3nEicRgkibtKHjK3OXPGosRU0QZwfWsLuJaZRRCEFbYkfskaia7vC36g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">好莱坞巨星史密斯也风格大变：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhelTfED2KJEVBFpia0Z76fNJkqugMEKC9OW6ibB2aHnsDnMDd2wWyMrHQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">但说回研究本身，确实正儿八经的研究。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhoLaGjib4uUDPPzG8vAQ2Vcb0eiaZLOyDfGNhuwpe7REwbADZPr77YCKA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">名为<strong style="font-weight: 600;">IDM–VTON</strong>，由来自韩国科学技术院和OMNIOUS.AI公司的研究团队基于<strong style="font-weight: 600;">扩散模型</strong>打造。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhK1P0pdSxDbzTh7qEnLTNrVQwibX0oGDF6kkNIIBMse7U7XicicPgsEUnw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">目前官方放出了demo，大伙儿可以试玩，推理代码已开源。</div><div class=" pTag">除了开头所展示的，抱抱脸研究员也玩的不亦乐乎，给老黄换上了专属战袍。其CEO连忙转发打趣：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我被替代了，没法和他争CEO。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhwrkBXBYayEKbB2Qug4bRm8SUpmHb19JKuJibuICDkwHs1QW9ASb6Fzw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">看热闹的网友也是感慨，经过这么多年，终于不用再担心自己“手残”了<span>（AI帮你搞定）</span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh9CsvbgImGftE8y5HicOtWxiafXLkyibjwibriaTrSMrvd9w6IK0zCmJwdKA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>来玩啊～</h2><div class=" pTag">我们也赶紧上手体验了一把。demo整个页面是这样婶儿的：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhP9UajPytKZO8RjicUlhY2CJ4v7vldkiciasIswbiaxicb3M6TxibO964qOCg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">操作起来也是非常简单。</div><div class=" pTag">首先上传人物图，可以手动或者自动选择要修改的区域。然后，上传要换的衣服。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhmkfObia5anlaCAIfeGzL7S5b8evUzKjicYKLCY6AcFaPA80FCBycTDYQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">直接点击Try-on，会自动生成掩模图和换装后的图：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh8tOrrjA3CwZBxlqsnJlhKhdFWpNAZCCx9SkIu7EYuJyFoSyhCQWnpg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">上面这张自动生成的掩模把手也选进去了，所以最后生成的左手效果不好。</div><div class=" pTag">我们手动选取涂抹一下，同时人和衣服全部都用我们自己的图。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhibvt48Mk19PKHt6gIBnYUicd9lWuY9zY9IxDrOrib4bk2kGRibiah22bCyg/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhT84aXRIoibK8yc29IdUcwqveucxL6e0zdpmnL4OKYzSpKH3DEpVuicicg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这次效果大伙儿觉得如何？</div><div class=" pTag">再来展示一波网友的试玩成品图。</div><div class=" pTag">DeepMind联合创始人苏莱曼穿上了微笑面具修格斯联名款T恤：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhzGHTYLllYNmicayLBAsUWm16hFyhicAkJOboCROEWIwGrYALpGbELRibw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">甚至不少网友真想要这件衣服。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhgPnQIMetZ260U8AwIWibkO33HAxopEUrT0HqJfUfPqBJvsic04qRz9Uw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">奥特曼再次被网友当成模特：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh1NFMuKU691ZnA9d9rEJ0UpZo29HVmPEzzZeMibUqZFu5ngP5Ufy5mvA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">当然也有翻车的时候，比如马斯克穿的就是山寨CUCCI。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhw9acEuncBZUUR34UHAVVUiabXKaC3WYLPJ8Gy8GaTbKRDCJicpV1bhFQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">看完效果后，接着来看IDM–VTON在技术上是如何实现的。</div><h2>基于扩散模型</h2><div class=" pTag">技术方面，IDM–VTON基于扩散模型，通过设计精细的注意力模块来提高服装图像的一致性，并生成真实的虚拟试穿图像。</div><div class=" pTag">模型架构大概包含三部分：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">TryonNet</strong>：主UNet，处理人物图像。</div></li><li><div class=" pTag"><strong style="font-weight: 600;">IP-Adapter</strong>：图像提示适配器，编码服装图像的高级语义。</div></li><li><div class=" pTag"><strong style="font-weight: 600;">GarmentNet</strong>：并行UNet，提取服装的低级特征。</div></li></ul><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhOJUXZAU4Vxm25ttia0SzibwPo2WBGFLZ9JlBtCHzdicsLtCgL3vIgWEaw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在为UNet提供输入时，研究人员将人物图片的含噪声潜在特征、分割掩模、带掩蔽的图片和Densepose数据整合在一起。</div><div class=" pTag">他们还会为服装添加详细描述，例如[V]表示“短袖圆领T恤”。这个描述随后用作GarmentNet<span>（例如，“一张[V]的照片”）</span>和TryonNet<span>（例如，“模特正在穿[V]”）</span>的输入提示。</div><div class=" pTag">TryonNet和GarmentNet产生的中间特征进行了合并，随后传递至自我注意力层。研究人员只使用了来自TryonNet的输出的前半部分。这些输出与文本编码器和IP-Adapter的特征一起，通过交叉注意力层进行融合。</div><div class=" pTag">最终，研究人员对TryonNet和IP-Adapter模块进行了精细调整，并锁定了模型的其它部分。</div><div class=" pTag">实验阶段，他们使用VITON-HD数据集训练模型，并在VITON-HD、DressCode和内部收集的In-the-Wild数据集上进行评估。</div><div class=" pTag">IDM–VTON在定性和定量上都优于先前的方法。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhXWXzmU5afb5HevdZNIfkS8z74dWoicYiaTSkwj6v1ZwicvpjHzW5OF7Xw/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhj4DTHJwSsavtuOV8Q0UQmiaoGRMCQ6BKj1c8w0c5lQcL8JIw6m1DCibw/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhTDVNTWcT9dtXUGOk18dZFfNMT5bfTYXic3SaPFNWR77bbPibOUic9jkhQ/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhho7nVcbq9iamn2F2td37sCpekTqKyc7OH706E0icnFytrZylkxd6KnWA/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhxkVP4jcA7KQz6qjQwia8TkXLehPba5n0khWyMFPlmJ1cyVBTbbdkibTQ/640?wx_fmt=png&amp;from=appmsg" /></div></div><br /><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhH5Frtgf6v8CIdDy3mEKByyUXKhnibHHsT2vZApWetFBd8zejDLUyMHQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">IDM-VTON可以生成真实的图像并保留服装的细粒度细节。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhG3ELFzg2B5aUP2mcBBpK9QF3k0vSxDH894uSCg7mJ2hqv3IqxwLuvA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">更多细节，感兴趣的家人们可以查看原论文。</div><div class=" pTag"><span style="font-size: 17px;"><span>项目链接：</span><br /><span>[1]https://idm-vton.github.io/?continueFlag=589fb545dbbb123446456b65a635d849</span></span><br /><span style="font-size: 17px;">[2]https://arxiv.org/abs/2403.05139</span><br /><span style="font-size: 17px;">[3]https://huggingface.co/spaces/yisol/IDM-VTON?continueFlag=589fb545dbbb123446456b65a635d849</span><br /><span style="font-size: 17px;"><span>参考链接：</span><br /><span>[1]https://twitter.com/multimodalart/status/1782508538213933192</span></span><br /><span style="font-size: 17px;">[2]https://twitter.com/fffiloni/status/1783158082849108434</span><br /><span style="font-size: 17px;">[3]https://twitter.com/ClementDelangue/status/1783179067803533577</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FxULhCgGawzwuuG-bALRazw">阅读原文 </a>
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 12:47:35 GMT</pubDate>
</item>
<item>
<title>AI机器人开始卷家务了，深圳创业果然务实</title>
<link>https://posts.careerengine.us/p/662ba25575e9e7777af106b3</link>
<guid>https://posts.careerengine.us/p/662ba25575e9e7777af106b3</guid>
<content:encoded><![CDATA[
<div> 关键词: Astribot S1, 家务劳动, 智能技术, 星尘智能, 机器人助理

总结:<br /><br />文章介绍了来自星尘智能的全新国产AI机器人Astribot S1，展示了其在家务劳动方面的出色表现。S1具有丰富的实用技能，通过软硬件协同实现了高难度动作的准确完成。其研发团队在技术和经验方面具有优势，致力于让机器人无限接近人类水平。由CEO来杰领导的团队，旨在让数十亿人拥有AI机器人助理，实现机器人劳动、学习和思考等多种功能。星尘智能公司在智能技术领域不断探索创新，将S1推向商业化应用，并致力于打造数十亿个机器人的智能世界。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">注意看，这个机器人迅速地将三层红酒杯下面的布抽了出来。</div><div class=" pTag">动作敏捷干脆，红酒杯没有丝毫的晃动。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yHjEHl2Hn8Sv0gibex0pECy785mVbvn2nxS1cx21RgDa49kTRUvmOejA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">它就是来自星尘智能的全新国产AI机器人Astribot S1<span>（简称S1）</span>。</div><div class=" pTag">它不仅可以华丽炫技，完成抽出桌布这样的高难度动作，也拥有许多实用技能。</div><div class=" pTag"><strong style="font-weight: 600;"><span>无需遥操作</span></strong>，就能完成熨衣服、叠衣服等家务劳动，动作敏捷得和一个成年人如出一辙。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yQSYCC8Ddnqub1lTK6OOkibRGPia0M8Fib5PQqwgxjLkictzFoaibiaHV2yRQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">那么，下面就来看看，这个机器人到底都能干些啥。</div><h2>能大力出奇迹，也能慢工出细活</h2><div class=" pTag">首先值得一提的是，常见的机器人视频大部分是多倍速的，而S1的DEMO<span><strong style="font-weight: 600;">基本上都是原速，甚至敢于慢放</strong></span>、不怕挑刺。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yGuMfwRh9G1w3k9msibRRZnLIrCID5oO5jcia0ak61MWkwosqMIxn42Dw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">而且接下来所有的家务劳动，都没有遥操作，完全靠机器人自主完成。</div><div class=" pTag">它出得厅堂，修凳子、浇花、接电源，这些动作都能轻松完成，双手配合得十分默契。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yetn1QXk2J2tEaaKOSyLqynFxiaVd4X7seC0Yl5TeRZM7skjJRNpzrLw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">复杂一些的电器，比如吸尘器，用起来也是得心应手，几下就把桌上的纸屑清理得干干净净。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3y2MhamHHbZx2cGzrLbwFicp0NlfC5koTXBp9OjA9bbC9cib3yxiaqGuSMg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">甚至还学会了投掷，在远处就能把纸飞机这样轻的物体精准“空投”入桶。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yhN5ianbIliaTibP7anZANk4nwRBBWM6Jv5jmcH1DJYbgZcAQnL2mJSv4w/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">而且它也下得厨房，塑料瓶玻璃瓶都能轻松打开，也不会让瓶子里的液体洒落。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3ytqAUW6zicheUWzSgKZMRToqfer9fIhUzMYLR0X1Hia7MhoHkFFlyaELg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">削黄瓜皮这种细致活，也是做到了既干净又不浪费，而且还学会了炒菜颠锅。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yoictatWFljl2GAtfOGbTl0Aia76u3f83c4lMKFILX7xw6oicH1pjWM2mQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">更为智能的是，它还可以识别眼前的物体，然后在对话指导之下设计子目标，完成物品分类的任务。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yFMAy1PnNrPMUGKkSwsicj3iaONefWbMqRmwGTibiaQUz1Z0bsp8HibpuRIw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">以上这些场景都是我们生活中可能会遇到的，所以S1的这些技能<strong style="font-weight: 600;"><span>绝非花拳绣腿，而是实用的家务助手</span></strong>。</div><div class=" pTag">当然除了这些劳动，S1的<strong style="font-weight: 600;"><span>模仿能力</span></strong>也是很强的，比如跟着人类跳舞的视频，它也有模有样地跳了起来。</div><div class=" pTag">当机器人跳起海草舞，在魔性之余，连贯细腻的动作却说得上丝毫没有机械感。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3y4IhhCmgwhIStn5aUv4m3JBruLbLsVia615bkZxxbHiaWgspKCQz6OmwA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">更绝的是，像写书法这种对手部细腻度和稳定性要求极高的活动，也被它给学会了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3ym60yqv0s1vg34LHgHcB1XT9mJ4icGzwfLWfAt0dJxx7fPZbac7uxNuQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><h2>腾讯RobticsX一号员工创业</h2><div class=" pTag">那么，在S1这一系列精彩表现的背后，都运用了什么样的技术？它背后的星尘智能，又是怎样的一家公司呢？</div><div class=" pTag">研发团队介绍，让S1具有丰富技能的一大关键因素，在于<strong style="font-weight: 600;"><span>“软硬件协同”</span></strong>，既要有智慧的“大脑”，也要有敏捷灵活的“身体”。</div><div class=" pTag">软件上，它背后的系统支持视频、动捕及遥操作等多种数据收集手段，可使用强化学习、模仿学习和多模态大模型等完成学习和训练。</div><div class=" pTag">而且软件的升级也会带动机器人的进步，不断提升智能化和多任务泛化能力。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yIU838vQz0xmy1WokwY4dmLPWff2KVnZ7TicCJ0x68qTxm9xhAgIx7oQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">硬件上，团队设计了自研的高性能电机传动系统，并经过多次迭代，最终集成了控制、传感、传动与驱动等多个复杂系统，为S1机器人提供了敏捷、灵活、丝滑的动态操作能力，以及<strong style="font-weight: 600;"><span>接近工业机器人的速度和精度</span></strong>。</div><div class=" pTag">此外，它的头、手、躯干均采用了<strong style="font-weight: 600;"><span>模块化设计</span></strong>，可按不同需求灵活组装或拆卸，进一步提升了任务适应性。</div><div class=" pTag">它的最高速度达到了10m/s<span>（36km/h）</span>，单臂负载达到了10公斤，拥有七个自由度，而且<strong style="font-weight: 600;"><span>重复定位误差只有30微米</span></strong>，一系列指标都超越了普通的成年男性。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yw6UeZHia4Blzicw7XO0X0AycGJI3An2AJvcYiaTZImKDCiaugibsGttyRfg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同时，团队使用了“以力为中心”的创新设计方法，保障了机器人的安全性，能精准控制与人体、物体和环境的交互力度，在运动中不伤人、不伤物、不伤自己。</div><div class=" pTag">目前，S1机器人<strong style="font-weight: 600;"><span>已接入大模型测试，并预计在今年年内完成商业化</span></strong>。</div><div class=" pTag">而S1的研发公司星尘智能，于2022年底在深圳成立，这次发布的S1，是团队耗时一年研发出的成果。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yF9oUicsicOlGwBhKIZrPK97FoQqoc1wRtzvFzniaaAwwFVAmInwaic2myw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">公司<strong style="font-weight: 600;"><span>创始人兼CEO来杰</span></strong>，拥有16年的机器人研发经验。</div><div class=" pTag">他曾任腾讯RobticsX一号员工、百度“小度机器人”团队负责人；腾讯的轮腿式机器人Ollie，以及多款新型机器人，都由他主导研发。</div><div class=" pTag">来杰本科在西安电子科技大学就读，后在五邑大学攻读智能系统硕士学位，毕业后首先来到了香港理工大学担任助理研究员。</div><div class=" pTag">2014年，走出学术界的来杰开始了他在百度的四年研发生涯，并于2018年转入刚成立的腾讯RoboticsX实验室，直到出走创业。</div><div class=" pTag">除了来杰之外，公司团队其他成员的背景也包括腾讯、谷歌、优必选、百度和华为等前沿科技公司，在技术和商业领域都拥有丰富的经验。</div><div class=" pTag">而谈及未来的目标，来杰的回答是，<strong style="font-weight: 600;"><span>让机器人无限接近人类的水平</span></strong>。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我们的目标是让数十亿人拥有AI机器人助理，能像人一样学习、思考和劳动，会使用人的工具和设备、帮人完成枯燥、困难或危险的任务，甚至能适应环境和变化，从而真正照顾家庭老幼。</div><div class=" pTag"><br />这样的世界将需要数百万、甚至数十亿个机器人。</div><div class=" pTag"><br />我们希望机器人的能力能从55%、85%成长到99.99%，无限接近人类水平。</div></blockquote><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FX0zNfUbAwazl9_EwJkU1XQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 12:47:17 GMT</pubDate>
</item>
<item>
<title>字节发布视觉基础模型ViTamin，多项任务实现SOTA，入选CVPR2024</title>
<link>https://posts.careerengine.us/p/662ba246595624771b4059bc</link>
<guid>https://posts.careerengine.us/p/662ba246595624771b4059bc</guid>
<content:encoded><![CDATA[
<div> ViTamin、视觉模型、扩展性、零样本准确率、下游任务
<br />
<br />
总结: 文章介绍了新型基础模型ViTamin，设计专为视觉语言时代，相比传统ViT在ImageNet零样本准确率上有明显提高，表现出色在分类、检索、开放词汇检测和分割等任务上。研究团队对主流视觉模型在视觉语言情境下进行了评估，发现ViTamin在数据扩展性、模型可扩展性、特征分辨率和混合架构等方面有优势。ViTamin不仅在零样本ImageNet准确率和平均38个数据集准确率方面超越ViT，还在多项下游任务中达到新的技术水平。智能创作团队通过这项工作展现了他们在计算机视觉和多媒体技术领域的领先地位，并为行业提供了先进的技术能力和解决方案。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">允中 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">视觉语言模型屡屡出现新突破，但ViT仍是图像编码器的首选网络结构。</div><div class=" pTag"><strong style="font-weight: 600;">字节提出新基础模型——ViTamin</strong>，专为视觉语言时代设计。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yn2pvOgulEqU2TiaFwVfnDeHGKF93ecwfvc9Dgw9nOicNlB2lmesW4dC3A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在使用相同的数据集和训练方案时，ViTamin在ImageNet零样本准确率上比ViT提高了2.0%。</div><div class=" pTag">此外在分类、检索、开放词汇检测和分割、多模态大语言模型等60个不同基准上都表现出了良好的结果。</div><div class=" pTag">当进一步扩展参数规模时，ViTamin-XL仅有436M参数，却达到了82.9%的ImageNet零样本准确率，超过了拥有十倍参数（4.4B）的EVA-E。</div><div class=" pTag">最终这一成果，<strong style="font-weight: 600;">入选计算机视觉顶会CVPR2024</strong>。</div><h2>视觉语言时代新基准</h2><div class=" pTag"><strong style="font-weight: 600;">在视觉语言时代下，如何设计一个更好可扩展的视觉模型？</strong></div><div class=" pTag">在ImageNet时代，新的视觉模型在ImageNet数据集得以验证，也造就了不断有新的视觉模型涌现。但在视觉语言时代，新的视觉模型鲜为人见。</div><div class=" pTag">此外，基于现有常见视觉模型，在面对比ImageNet数据规模还大的情况下表现又是如何？研究团队们测试了几种常见模型，包括纯Transformer的ViT，纯卷积网络的ConvNeXt，以及混合卷积和Transformer的CoAtNet。</div><div class=" pTag">最终在一个公开的数据集上进行了系统性的训练和比较，得出了一些关键发现：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">第一，模型的扩展性</strong>：由于可扩展的自注意力机制，ViT能最好地适应不同规模的任务。</div></li><li><div class=" pTag"><strong style="font-weight: 600;">第二，数据的扩展性</strong>：随着训练数据的增加，所有模型的性能都有所提升。</div></li><li><div class=" pTag"><strong style="font-weight: 600;">第三，特征的分辨率</strong>：在训练过程中，模型需要理解更广泛的信息，而不仅仅是简单的类别标签。因此，提取的特征的分辨率对模型的预测能力有很大影响。</div></li><li><div class=" pTag"><strong style="font-size: 17px; text-align: justify; font-weight: 600;">第四，混合架构</strong><span style="font-size: 17px; text-align: justify;">：</span><span style="font-size: 17px; text-align: justify;">在一般情况下，CoAtNet表现优于其他模型，但将其扩展到处理数十亿数据可能会有一些挑战。</span></div></li></ul><div class=" pTag">基于这些发现，研究人员设计了<strong style="font-weight: 600;">ViTamin模型</strong>。</div><div class=" pTag">它采用了三个阶段的混合架构。前两个阶段使用了轻量级的MBConv Blocks，第三个阶段包含了可扩展的Transformer Blocks。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnVYIOjia9yK8sQiceibnFn2AX9bibOhaCZEjWyelUOFMn25qUETuvfPdPDg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">具体来说，一张图片首先经过卷积stem处理，得到2倍降采样的特征图。</div><div class=" pTag">然后，这个特征图经过第一阶段，由两个MBConv-LN Blocks组成，接着经过第二阶段，由四个MBConv-LN Blocks组成，然后降采样得到16倍降采样的二维特征。</div><div class=" pTag">接下来，这些特征被展平成一维，并输入到第三阶段，该阶段由N_B个TFB-GeGLU Block组成。最后，通过对比图像特征和语言特征，来学习对比损失函数。</div><div class=" pTag">作者们致力于简单有效的<strong style="font-weight: 600;">scaling law</strong>，只考虑模型的宽度C和模型第三阶段的深度N_B，因此在scaling到更大的模型中，通过模型的参数规模可以直接反推需要多大的宽度和深度，进而实现模型的scaling。</div><h2>多项SOTA</h2><div class=" pTag">在<strong style="font-weight: 600;">零样本性能</strong>上面，研究结果显示，ViTamin-L的零样本ImageNet准确率比ViT-L/14高出了2.0%。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnE7EFvnypvBLyw7ujJerVo1BwSfjl88jnJME9PDcxstqQ9BA9pKTzUg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">当将特征分辨率增加到576个patch时，ViTamin-L的准确率进一步提高到了81.8%，比之前的ViT-L/14 CLIPA-v2高出了1.5%。在38个数据集的平均性能上，ViTamin-L比ViT-H/14模型高出了0.4%，而且参数数量只有ViT-H/14的一半。</div><div class=" pTag">此外，当进一步扩大模型规模时，参数量为436M的ViTamin-XL达到了82.9%的ImageNet零样本准确率，超过了4.4B参数量的EVA-E取得的82.0%。</div><div class=" pTag">作者们进一步验证了<strong style="font-weight: 600;">ViTamin模型对下游任务而言是个强大的视觉编码器</strong>。</div><div class=" pTag">作者们引入了一系列下游任务，包括开放词汇检测和分割，以及多模态大模型（LMMs）。</div><div class=" pTag">ViTamin在开放词汇检测任务OV-LVIS上，相比比ViT-L模型能提高了3.1%。ViTamin在8个开放词汇分割任务中，相比ViT-L平均提升了2.6%。</div><div class=" pTag">ViTamin能直接迁移到多模态大模型诸如LLaVA上，并在12个多模态问答等基准上表现出色。值得注意的是，ViTamin在7个开放词汇分割基准上创造了新SOTA。</div><div class=" pTag">在这项工作中，作者们建立了主流视觉模型在视觉语言情境下的评估基准，并对它们进行了重新基准测试。作者们从数据可扩展性、模型可扩展性、特征分辨率和混合架构四个方面考察了主流的视觉模型。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yn5IfcSZrrY5aD5ZGG0LrS5OdIictPSfJTwkuszUvPNNNp1MZbbDABwQw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这四个方面的关键发现为ViTamin的设计提供指导，ViTamin模型不仅在零样本ImageNet准确率和平均38个数据集准确率方面全面超越ViT，而且在包括开放词汇检测和分割以及大型多模态模型在内的22个下游任务上达到了最新的技术水平。</div><h2>来自智能创作团队</h2><div class=" pTag">智能创作团队是字节跳动 AI &amp; 多媒体技术团队，覆盖了计算机视觉、音视频编辑、特效处理等技术领域。</div><div class=" pTag"><div class=" pTag">他们借助公司丰富的业务场景、基础设施资源和技术协作氛围，实现了前沿算法 - 工程系统 - 产品全链路的闭环，旨在以多种形式为公司内部各业务提供业界前沿的内容理解、内容创作、互动体验与消费的能力和行业解决方案。</div><br /><div class=" pTag">目前，智能创作团队已通过字节跳动旗下的云服务平台火山引擎向企业开放技术能力和服务。更多大模型算法相关岗位开放中。</div></div><div class=" pTag"><span style="font-size: 17px;"><span>论文链接：</span><br /><span>https://arxiv.org/pdf/2404.02132.pdf</span></span><br /><span style="font-size: 17px;"><span style="font-size: 17px;">项目主页:</span><br /><span style="font-size: 17px;">https://beckschen.github.io/vitamin</span></span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FtQl3bVSPpDWeqJmwpWzfhQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 12:47:02 GMT</pubDate>
</item>
<item>
<title>你的超级知识助手来了！讯飞星火支持长文本长图文长语音，生产力直线UP</title>
<link>https://posts.careerengine.us/p/662ba246595624771b4059b2</link>
<guid>https://posts.careerengine.us/p/662ba246595624771b4059b2</guid>
<content:encoded><![CDATA[
<div> 知识获取、大模型、科大讯飞、智能体平台、落地应用
<br />总结:
知识获取是讯飞星火大模型V3.5春季上新的关键，支持长文本、长图文、长语音等多种形式。科大讯飞推出的智能体平台为企业解决了大模型应用落地的难题。新功能包括多情感超拟人声音合成和一句话声音复刻，增强用户体验。大模型升级的技术理念着眼于解决现实问题，帮助企业实现数字化转型。智能体平台是大模型在企业落地应用的新方式，极大提高了企业的工作效率和智能化水平。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">白交 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">这一次，大模型真的可以让人类解放双手了。</div><div class=" pTag">今天讯飞星火大模型V3.5春季上新，直戳办公场景的痛点！</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">星火大模型能力升级，支持长文本、长图文、长语音……不仅能够把各种来源的海量文本、图文资料、会议录音等进行快速学习，还能够在各种行业场景中给出专业、准确回答。</div></li><li><div class=" pTag">还有专门为企业推出的<strong style="font-weight: 600;">“</strong><strong style="font-weight: 600;">智能体平台”</strong>，打造智能助手，解决大模型应用企业落地的最后一公里难题。</div></li><li><div class=" pTag">另外讯飞星火语音交互能力进一步升级，首发多情感超拟人声音合成，AI能“情感共鸣”了，还上线“一句话声音复刻”等功能。</div></li></ul><div class=" pTag">好了，目前星火大模型已经升级，这就来第一时间体验一下。</div><h2>“超级知识助手”来了</h2><div class=" pTag">在此前官方预告中，大家就对即将发布的三个“长”功能颇为关注。科大讯飞推出这一系列新功能，背后有着怎样的考虑？</div><div class=" pTag"><div class=" pTag">据科大讯飞董事长刘庆峰透露，他们看到一段时间以来，讯飞星火的开发者和用户都高度关注知识的获取和学习问题。</div><br /></div><div class=" pTag"><span style="font-size: 17px; text-align: left;">在知识获取和学习的过程中，广大用户能拿到的资料往往不仅是现成的长文本，还有随手可见的报刊书籍内容、各种研讨会的PPT内容，老师黑板上的板书、同学的笔记，以及各种会议录音、访谈，各种网上的发布会、培训教育视频等，能不能把这些文本、图片、语音等都上传到讯飞星火</span><span style="font-size: 17px; text-align: left;">中，快速地获取知识？</span></div><div class=" pTag">这就要求大模型不仅要解决长文本、还有长图文、长音频以及各种企业和专业行业应用的准确率问题。</div><div class=" pTag">为此，科大讯飞推出首个支持长文本、长图文、长语音的大模型，来解决用户真实场景中多源信息的获取需求。</div><h3>长文本</h3><div class=" pTag">据介绍，升级之后，当前星火大模型通用长文本能力，包括长文档信息抽取、长文档知识问答、长文档总结、长文档文本生成等，总体已经达到GPT-4 Turbo 4月最新大模型版本的97%水平，而在银行、保险、汽车、电力等多个垂直领域的知识问答任务上，星火大模型长文本总体水平已经超过GPT-4 Turbo。</div><div class=" pTag">而为了应对运行效率问题，星火大模型特别进行了剪枝和蒸馏，推出13B版本，效果损失仅3%以内，但响应时间、生成效果等方面的效率都有提升。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yKukic8ib012HAGA9RO8S8Xiaiak3awbkt0G6XibeY3dtIibfvtpiajsyoz6WA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">话不多说，这就来开始实际评测一番。</div><div class=" pTag">首先来看第一题开胃小菜，把费曼物理学讲义第一卷直接扔给他，也不告诉它书名叫啥，直接问书中讲了什么。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yCYwzNXT2957BuFacUhTcficwKZSyWf8dMQYCM61jLBmQiaOM2SI99Sfg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">嗯~还不错，大致方向是对的。</div><h3>长图文</h3><div class=" pTag">接下来，来看第二题，考验它长图文识别的能力。</div><div class=" pTag">据刘庆峰介绍，图文识别大模型现在已经覆盖了31个最常见的典型场景，像教育类的书刊、学术论文、专利、报纸、海报、产品白皮书、PPT和菜单、APP截图、演讲照片等等都已经进行了覆盖，以及18种版面要素（包括页眉、页脚、标题、栏目、段落、表格、插图等）</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3ytx16C9rlicj3uFsdDHiam6MsUJ97RmEp04OaaMhmyB2zNOkw5oy3y9ng/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">既然如此，那就扔给它一份最新量子位智库出品的《中国AIGC应用全景报告》PPT，并询问相关细节问题。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yW3SUlB0Gv4MOpLliaUZOcuueGTA0hYx3Bwicsbic5COzYx5kwBs2AqSOw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yY5mBZMZfRl30lhSYRTb4TMQ5DicbPuemV4UcrzWA8IlqRJNHhC2icGFg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3y1TnUpOhYess1PR2OibDTACzE5sHE4GKM4xZJJKA9lpLq0dJ45l6SW8w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">结果不管是市场规模、商业模式、投融资情况都一一清楚的回答上来。</div><h3>长语音</h3><div class=" pTag">最后再来考验一下它的长语音能力。可以看到，讯飞星火可以支持多种音视频格式，只要不超过1GB大小就好。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yduZWH8ozBj8PXPpI9DR5wE3nlN0SHrcjHibKKtr7nAXKhdIiaWX2LJ8w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么就扔给他这次科大讯飞官方发布长语音能力的演示视频试试。</div><div class=" pTag">结果：</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yMhgicB2T7oAnp1ibYo1yRv94RRvVgicpo60jj70W7fEwJa3RtAIicGtKqg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">甚至还包括像「刘庆峰做了什么」也都精准回答了。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3y2dDia7zJXlBZ9WgJIgB6v0GdjmibSSBDyiaKkCFHurwhpReFILUDMDYIg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">想象一下，在信息获取或知识学习中，拿到的资料无非就是现成长文本、论文书籍，又或者研讨会PPT、笔记截图，以及各种会议录音、发布会、网上教学视频等等。</div><div class=" pTag">而此次科大讯飞星火大模型的升级：“长文本、长图文、长语音”的支持，可以说把整个场景全覆盖了。</div><div class=" pTag">用上了它，相当于每个人都拥有了个知识助手，这不就是妥妥的学习工作小利器嘛~</div><h3>多情感超拟人合成&amp;一句话声音复刻</h3><div class=" pTag">除此之外，还有多情感超拟人合成功能、一句话复刻的功能的首发上新，可直接去星火APP上体验。</div><div class=" pTag">年初讯飞星火V3.5发布会上，科大讯飞推出的超拟人对话功能，如今该功能得以进一步升级，不仅更逼真，情绪表达也更为丰富，包括高兴、抱歉、安慰、撒娇、困惑等情绪表达的可感知度达到85%以上。</div><div class=" pTag">与此同时还推出了一句话声音复刻，一句话就可以定制你的AI助手声音。这样出差的时候，就还可以给孩子讲故事，又或者给爷爷奶奶读书读报，给世界带来更多温度。</div><h3>星火智能体平台</h3><div class=" pTag">办公场景，长期以来一直面临一个痛点——如何高效地获取和学习知识。此次推出的智能体平台正是专门面对企业场景。</div><div class=" pTag">在讯飞星火智能体平台上，首先，基于星火大模型，会自动实现用户输入的精准理解和任务规划。解析完了相关的任务和对应的工具之后，讯飞星火已构建形成了包括天气、航班、企查查等成体系的外部信息来源的对接；</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yUmbRqiakBpJRcT7LkLUTTcap2nIiaibGXlHOQO7ia6pgXHzDSXdhKmtic3g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同时，星火智能体平台还通过互认证的机制，实现了往往是独立的、隔离的OA系统、CRM系统以及ERP系统的打通，完成相应操作；最后，通过私域知识融入机制，智能体平台很容易实现企业所属行业以及企业私域知识的融入，实现更精准的专业理解和知识问答。</div><div class=" pTag">此外，星火智能体平台还可以通过拖拽方式实现新智能体的创建和多智能体的协作。用以上一套组合拳，敏捷触达大模型应用企业落地的最后一公里。</div><h2>讯飞大模型的技术理念：从解决现实问题出发</h2><div class=" pTag">可以看到的是，此次星火大模型的升级，更偏落地，更偏解决现实刚需，而非只是性能参数的升级。</div><div class=" pTag">一方面，讯飞星火大模型实际体验中，都是企业的刚需场景。</div><div class=" pTag">据七麦数据显示，讯飞星火APP在安卓端的下载量已经超过9600万次，在国内工具类通用大模型APP中排名第一。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yNy0cGjPTzicxI1Vu8vicOpaAOLqwLg5hPNHP3kiaoKIoh6VA8xWNk1Ticw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">从<strong style="font-weight: 600;">C端使用场景</strong>来看，讯飞星火的用户主要集中在办公领域。具体使用高峰期集中在工作日的上午9点半和下午的3点左右，以互联网、科研、教育、传媒行业为主。</div><div class=" pTag">这种用技术解决刚需的逻辑，也体现在科大讯飞的多项业务增长中。</div><div class=" pTag">在大模型加持下，开放平台与消费者业务全年营收达到61.9亿元，成为科大讯飞最大的业务板块。智慧汽车、智慧医疗、智慧金融业务板块则分别贡献了7亿元、5.4亿元和2.9亿元的营收，同比分别增长52.2%、14.9%及26.1%。在C端智能硬件领域，搭载讯飞星火的讯飞智能办公本、讯飞智能录音笔、讯飞智能翻译机等消费者硬件GMV同比大增84%。</div><div class=" pTag">另一方面，这也是讯飞一直以来所对外传达的技术理念：<strong style="font-weight: 600;">先进技术持续迭代的同时，也始终致力于去解决现实场景。</strong></div><div class=" pTag">典型例子就是大模型的每次升级，讯飞星火都有会新的亮点行业应用，比如今年1月发布首个语音大模型，以及此次首次亮相的图文识别大模型。在底座大模型的加持下，不断突破大模型能力的边界。</div><div class=" pTag">但每次升级，同样也都对应了实际场景应用，真正做到现实问题的解决。比如此次刘庆峰就重点介绍了在招投标、合同、教育等场景下的应用。</div><div class=" pTag">比如在<strong style="font-weight: 600;">招投标场景</strong>中，科大讯飞和国家能源物资公司在企业采购场景合作了智能无人评审系统，已经在国资委网站上被作为典型案例推荐。</div><div class=" pTag">此次该系统还将进一步叠加长文本和长图文能力，可以让评标更便捷、更高效、更准确。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3ykRjhONk0sWmwAibIkTJmNPX7ustz0rdBsqGhsRSt7vpmKH10syjkf4g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">还有<strong style="font-weight: 600;">合同助手</strong>。它可以对合同进行风险审核、合同比对、摘要总结以及合同生成，迅速识别潜在风险和漏洞。除了工作中需要，在日常生活中买卖商品、装修或者购买保险等场景也都完全用得上。</div><div class=" pTag">这种解决现实问题的大模型技术理念，也让讯飞星火在业内快速构建起一定的影响力。</div><div class=" pTag">自今年1月30日发布以来，讯飞星火V3.5作为首个全国产算力训练的大模型，受到了各行业伙伴和开发者的广泛欢迎。尤其在一些关键行业和重大战略领域，星火大模型以“云、边、端”的整体解决方案赋能到越来越多的行业，比如汽车、比如家电、比如运营商……在实体经济中发挥价值。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yHDJQ7VEdw7PzroEUHK7dbHnQ5FZLc5BCtMlRyMaNvmN4XMLcyLksRQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">从开发者生态上来看，在过去不到3个月的时间里，讯飞新增了55万实名认证的开发者，其中一半以上来自企业。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAx0ovKAXiaFMKDdhSY0pY3yaibwdNh8NF3mRkl4wjYmbFZCUa1dZM6HS6eyElzgvGFJSZdYWrFywGg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>大模型支撑起新质生产力</h2><div class=" pTag"><div class=" pTag">今年，毫无疑问的是大模型应用元年。大模型支撑起新质生产力，帮助企业数字化转型。</div><br /></div><div class=" pTag">但企业到底应该怎么用？如何去用？大模型发展到现在，大致可以梳理出这样三种模式来。</div><div class=" pTag">一种简言之就是<strong style="font-weight: 600;">当前大模型加持的通用AI原生APP</strong>，功能碎片化每次能调用的工具有限，还依赖于每次大模型公司的模型升级。</div><div class=" pTag">还有就是<strong style="font-weight: 600;">开源大模型或者接入API</strong>，但是通用大模型去落地真实应用场景中间还有很长一段距离，这需要技术与行业Know-how协同，对企业来说是个不小的挑战。</div><div class=" pTag">再者就是<strong style="font-weight: 600;">超级APP</strong>，各种AI原生碎片化能力集成在一起，实现工作流程中沟通、执行等方面的提效。但如果没有计入内部数据，实现内外知识的打通，那么大模型的提效能力是有限的。</div><div class=" pTag">而讯飞星火此次展现了第四种模式——<strong style="font-weight: 600;">智能体平台</strong>。AI Agent作为企业提效手段已经成为确定的趋势。而科大讯飞直接推出产品化的解决方式，并且整个流程低门槛，只需简单拖拽就可实现智能体构建和多智能体的协同，企业可以更容易地直接上手使用，有助于实现智能体的规模化落地，实现大模型普惠价值。</div><div class=" pTag">最后可以看到，越来越多大模型升级朝着更落地的方向走去，其实也代表了一种特定的趋势。</div><div class=" pTag">那就是大模型已经走向我们日常生活，人工智能朝着解决真实世界的问题的方向不断深入。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FurUwx1pH3BW5vFMpPRRU_g">阅读原文 </a>
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 12:47:02 GMT</pubDate>
</item>
<item>
<title>老黄亲自上门送超算！OpenAI奥特曼签收后到斯坦福演讲GPT-5</title>
<link>https://posts.careerengine.us/p/662a1a2193e56b68d73732e4</link>
<guid>https://posts.careerengine.us/p/662a1a2193e56b68d73732e4</guid>
<content:encoded><![CDATA[
<div> OpenAI、老黄、DGX H200、AI、GPT-5
<br /><br />
总结:OpenAI收到了世界上第一台DGX H200超算，老黄亲自上门送货。这次收到的超算具有更大的内存和更高的内存带宽，是首款搭载HBM3e内存的GPU。该超算可能会用于加速运行ChatGPT等任务。与此同时，老黄还在斯坦福大学的Nvidia礼堂发表演讲，后来参加了闭门会议，传言中讨论了GPT-5的一些大事。整体来说，AI领域发展迅速，各项技术不断创新，为人工智能和计算科学的进步带来了新的可能性。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">梦晨 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">皮衣老黄亲自上门送货！OpenAI收到<span><strong style="font-weight: 600;">世界上第一台DGX H200超算</strong></span>。<span style="display: none;">‍‍‍‍‍‍‍‍</span></div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">致推进人工智能、计算和人类发展。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqheyhciaxr3Sib0n5KBLEaRkQmrEB1V7gd3kialfOQxxVEzYM2VvfvG2Jeg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这下呼吁快发布GPT-5的声音更高了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhRxD9h0zs0uIIOcmzcug1NuWyvgrcNfJrPRbj5q735MV7WicGGGG5DNQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在OpenAI负责模型微调的员工Steven Heidel开玩笑说：“老黄签过名上了Buff的GPU，运算速度可是会加快20%。<span style="font-size: 17px; text-align: left;">”</span></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhXlen2LK32LzYDJp31PVu383f7OOY5ae1gxNm4ECBURTicvzKk1bInoA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这场面与八年前，2016年老黄向OpenAI赠送世界上第一台DGX 1超算时何其相似，相似的皮衣，相似的致辞，相似的算力巨兽，只是遍插茱萸少两人：</div><ul class="list-paddingleft-1"><li><div class=" pTag">与OpenAI分道扬镳的联合创始人<span><strong style="font-weight: 600;">马斯克</strong></span></div></li><li><div class=" pTag">不知踪影的首席科学家<span><strong style="font-weight: 600;">Ilya Sutskever</strong></span></div></li></ul><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhUtHZuUcB4CJJwA7gsKBUXzZUdjLrhUoPuI9FKaTg6xwvztusIb24Ew/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">一到这种时候，自然少不了热衷玩梗的网友。</div><div class=" pTag">只花1分钟，在线AI修图工具Dingboard.com开发者就把Ilya照片无违和感的变换姿态，P到合影里。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh2vlmP2nsCEO3YzMVY3ZLa3aDicTpibCLB5WbVOu2MiaXjCEBg6nNPw4rA/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">以及有眼尖的网友指出，Brockman身后墙上的装置可能是居家健身品牌Tonel的力量训练器械。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhyVXjFhdaKMyibBQ8fHEAQdJB2vaFIht6YY31CUMWzBG1MXZsKaHuMCw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>DGX H200超算有多强？</h2><div class=" pTag">奇怪的是，OpenAI总裁Brockman的推文与机器上的签名都是<span><strong style="font-weight: 600;">“DGX H200”</strong></span>，而英伟达官网上相关产品只有<span><strong style="font-weight: 600;">“DGX GH200”</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh5Ksjqo9t6iaxfs6QwYjKFzUEdfpt35sIMtMickq5iaddfLphvgZI9kxVA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">目前尚不清楚两者是否指代同一产品，或者是英伟达为OpenAI推出了特殊定制版本，去掉了DGX GH200中的Grace CPU，只留下了H200 GPU。</div><div class=" pTag">H200 GPU的特点一言以蔽之：<span><strong style="font-weight: 600;">141GB大内存</strong></span>，与H100的80GB相比直接提升76%。</div><div class=" pTag">作为首款搭载HBM3e内存的GPU，内存带宽也从3.35TB/s提升至4.8TB/s，提升43%。</div><div class=" pTag">除内存升级之外，H200的其他各方面规格和峰值算力与H100保持一致，一个优势在于可以直接替换到现有的H100计算机群中去，不用做任何调整。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhJQpEJzfJURSoiaYAUzqXuCibP2tzB9kU3CtVibMsVO5vOZOJ6Sgyp2bgg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">ChatGPT官号也透露，<span><strong style="font-weight: 600;">更多的内存带来更多的KV缓存，也就可以运行更多的ChatGPT</strong></span>。</div><div class=" pTag">暗示新超算可能会用于ChatGPT的推理加速。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhXokBia9DIeMlsnQQefQmWc0CwWwsAReR5JnGE8h6CBFiavzTibsVxbiaXg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>One More Thing</h2><div class=" pTag">与老黄合影几个小时后，奥特曼被曝现身斯坦福大学的Nvidia礼堂发表演讲。</div><div class=" pTag">礼堂可容纳342人已经爆满，还有约200人挤在外面。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhqCSFO8dfibWJsCdN3OXcricvasib3icfrL3buKcG1FKBz821Q31oaSzIlA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">根据斯坦福学生Andrew Gao介绍，随后他有机会参加了奥特曼<strong style="font-weight: 600;"><span>20人左右的闭门会议</span></strong>。</div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">他提到了一些大事，但我不能分享。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhwjox1icM4ItIiafV0iaiaXyWMjXWT71U9YUmX2cC07iafB6v9Maw76mELkw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span><span style="font-size: 17px;">另一位参加闭门会议的人也没有透露具体内容，但总之对GPT-5很兴奋。</span></span><span><span style="font-size: 17px;"><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span><span style="display: none;">‍</span></span></span></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhDFWlaHbhyJHlLdskGOzef3dATde6CxtDOjuvr7PZyA8Wib5AfEo5GyA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://x.com/gdb/status/1783234941842518414</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://x.com/itsandrewgao/status/1783301236126847379</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSDEh9MncYtpTYv3922y86w">阅读原文 </a>
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 08:53:53 GMT</pubDate>
</item>
<item>
<title>揭秘腾讯混元大模型：400+场景落地，协作SaaS产品全面接入</title>
<link>https://posts.careerengine.us/p/662a1a1127ae07689b8d7afb</link>
<guid>https://posts.careerengine.us/p/662a1a1127ae07689b8d7afb</guid>
<content:encoded><![CDATA[
<div> 腾讯混元大模型、应用落地、用户体验、混元一站式平台、模型精调<br />
<br />
总结:<br />
文章介绍了腾讯混元大模型应用落地的最新趋势，强调了重视用户体验和精细化应用的重要性。腾讯混元团队通过混元一站式平台的完整流程，实现了模型研发到应用落地的成功落地。文章还揭示了腾讯混元大模型团队与业务团队之间紧密合作的关键，以及如何通过混元一站式平台快速精调模型并提升数据处理能力。该平台的自动化和智能工具为业务接入大模型提供了便利。继续助力合作伙伴业务智能化升级是下一步的重点。文章最后描述了团队对问题的追求和改进精神。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">梦晨 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">进入2024，大模型的风向变了。</div><div class=" pTag">当初“百模大战”时，只要<span><strong style="font-weight: 600;">简单粗暴拿个Demo搞MaaS</strong></span><span>（模型即服务）</span>，也就是让用户直接和大模型交互就足以上牌桌。</div><div class=" pTag">但现在，<span><strong style="font-weight: 600;">精耕细作搞应用</strong></span>，无论是原生AI应用，还是在已有产品上整合AI功能，成了最新潮流趋势。</div><div class=" pTag">就连一向低调神秘的<strong style="font-weight: 600;">腾讯混元大模型团队</strong>，也对外公布了应用落地进展：</div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">腾讯混元大模型已经支持内部超过400个业务和场景接入，并通过腾讯云，面向企业和个人开发者全面开放。</div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh0hZ3EJ1PMh54tXEBwCJuVufO16mwzwta3UMV6pywZmN2t7NG6X9wdw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这里面有很多为人熟知的“国民级”App，如<span><strong style="font-weight: 600;">企业微信、腾讯文档、腾讯会议</strong></span>，都已经被AI全副武装。</div><div class=" pTag">还有更多腾讯云SaaS产品，如企业知识学习平台<span><strong style="font-weight: 600;">腾讯乐享</strong></span>、电子合同管理工具<span><strong style="font-weight: 600;">腾讯电子签</strong></span>等，也都有了AI加持。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhFBhKKqI1rLbBsRuppueO5YsiasQhvZXMa8OINFFDEy0gVqxh95fbJpA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">腾讯混元大模型去年9月才首次亮相，是否有意在加速赶进度？</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhTBSOFwgUMawVxt9wKbiclodW9KqhmSjskduMYyoljnicVFZXl8iagJvZg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">面对这个问题，<span><strong style="font-weight: 600;">腾讯混元大模型应用负责人张锋</strong></span>的回答就有点“凡尔赛”了：</div><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag">我们只是按照正常的节奏，而且不光是接入大模型这么简单，已经进入打磨用户体验阶段。</div></blockquote><div class=" pTag">在国内大模型厂商中，腾讯为何走出这样一条独特的路线？我们与张锋深入聊了聊。</div><h2>腾讯AI产品，已经在打磨用户体验了</h2><div class=" pTag">腾讯这么多年来一直以产品见长，AI时代也延续了这种风格。</div><div class=" pTag">就拿大模型的门面<strong style="font-weight: 600;">腾讯混元助手</strong>来说，“已经在打磨用户体验了”还真不是一句空话。</div><div class=" pTag">比如让它做一道简单的数学题，就可以发现AI在分析思路时非常流畅，还判断出题目中缺少条件，但<span><strong style="font-weight: 600;">最后给出结果前却稍有停顿</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhZVQGhVxGMnNIickU3PCH9lPAc46dHHDDGEaTu1bAavviawkicPAz3WhHQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">这并不符合大模型预测下一个token的运作原理，反倒像是真的在计算。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh303bMa5iaZIqctPvTHLzIlJlNseQatM0zNyibWrTD43FKk5xmYMqodTg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">张锋揭秘，背后其实是<span><strong style="font-weight: 600;">AI先写了一段代码，在后端执行再返回结果</strong></span>。</div><div class=" pTag">不得不说，这是一种解决大模型计算不准确问题的巧妙思路。但为什么不像GPT-4代码解释器版一样，把代码在前台显示出来？</div><div class=" pTag">腾讯混元助手一个重要场景是在微信小程序里使用，移动端展示代码就会显得特别长。张锋认为，现在的策略更符合用户体验习惯。</div><div class=" pTag">产品策略有了，但实现起来并不是一件简单的事。首先需要大模型明白当前用户需求需要精准计算，接着要生成合适的代码，最后还要成功通过函数调用来执行代码。</div><div class=" pTag"><strong style="font-weight: 600;">像这样从细节出发，打磨用户体验的例子还有很多。</strong></div><div class=" pTag">比如大家很熟悉的<strong style="font-weight: 600;">腾讯会议</strong>，比起简单的AI语音转写和会议纪要总结，也做了不少差异化功能。</div><div class=" pTag">人的口头表达免不了停顿磕绊，腾讯会议AI在转写时把“嗯嗯啊啊”这样的部分智能规整，让会后文字记录看起来更整洁。</div><div class=" pTag">腾讯会议正在思考的另一个问题是，AI 生成的会议总结格式应该根据会议类型做出适当调整。</div><div class=" pTag">有明确主题和议程的会议，与大家畅所欲言的头脑风暴会议，需要的总结的格式就截然不同。因此，除了按时间分章节生成会议纪要外，腾讯会议也将推出按发言人/主题生成会议纪要的功能。</div><div class=" pTag"><strong style="font-weight: 600;">腾讯乐享</strong>，作为企业知识协作平台，在AI问答功能中就做到了识别提问者身份，做到回答千人千面。</div><div class=" pTag">如果是企业HR问AI有关薪酬结构的问题，就可以得到正面回答，其他岗位问同样的问题AI会拒绝提供。做到在便利的同时还非常安全。</div><div class=" pTag">湖南的律师事务所旷真接入了乐享助手去做AI知识库， 员工调研显示，对典型问题的AI回答满意度高达93分，端到端问题准确率达91%。</div><div class=" pTag"><strong style="font-weight: 600;">腾讯电子签</strong>，利用AI智能文件审查系统，识别合同风险条款，便于企业把控合同风险。企业对合同的风险控制需求各不相同。腾讯电子签还利用大模型和few-shot技术训练适合客户行业的垂类小模型，实现低成本运行。同时，通过混合云的模式，支持数据、模型的私有化部署，解决效率问题的同时保证合规。</div><div class=" pTag">总计400+的应用场景中，像这样的例子还比比皆是，这里不再赘述。</div><div class=" pTag">值得探讨的下一个问题是，腾讯如何做到在短时间内把AI产品打磨成熟的。</div><h2>应用落地完整流程已跑通</h2><blockquote style="text-align: start; font-size: 17px;"><div class=" pTag"><span><strong style="font-weight: 600;">在腾讯，大模型研发和业务应用是“双向奔赴”的。</strong></span></div></blockquote><div class=" pTag">根据张锋介绍，腾讯混元大模型研发过程中迭代速度很快，基本一个月就有四到五个版本。</div><div class=" pTag">这种速度就来自于和业务应用团队的高效合作，业务团队提出需求并贡献微调数据，研发团队就能有针对性的加强大模型的能力。上线测试过程中不断发现Bad case，也能迅速为大模型补齐短板。</div><div class=" pTag">在这种研发时就考虑到实际应用需求的模式下，腾讯混元大模型定位成了“实用级通用大模型”。</div><div class=" pTag">在国内大模型中，腾讯混元率先完成MoE<span>（Mix of Experts，专家混合）</span>架构升级，也就是从单个稠密模型升级到多个专家组成的稀疏模型。</div><div class=" pTag">MoE架构在激活参数不变情况下，总参数量加大，可以吞吐更多的token，同时，得益于较小的实际激活量，可显著降低训推成本。</div><div class=" pTag">这种路线的快速转型，也得益于与早期就了解了业务应用一方需求。</div><div class=" pTag">在与业务应用相互打磨的过程中，腾讯混元着重提升了通用模型的三个能力：</div><div class=" pTag"><span><strong style="font-weight: 600;">指令跟随能力</strong></span>，提出各种各样复杂的结构化长指令，腾讯混元都能按要求执行。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhjgVl0eLyLib1nSJXIuZcHxJfzcMHdLWkpve7PEMSHWNAextnWbeUxyw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span><strong style="font-weight: 600;">网页及文档理解能力</strong></span>，满足用户经常需要AI来总结长文本内容、减轻认知负的需求。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhFAibp6qGvLYmAmoEmBC3GgV084n9wq7e6HfZnmcZozfF8bAypNloc9w/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag"><span><strong style="font-weight: 600;">函数调用能力</strong></span>，也是腾讯混元团队判断大模型下一阶段的趋势之一。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhGBpAe5dJql2Z0MCvgZfKj5wnub5hNgv9q4MlJdCVyqyH62M6ok0YXA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">通用大模型只是一个开始。</div><div class=" pTag">张锋介绍，在实际应用中，除了MoE主模型，如果调用量很大，从性价比的角度，<span><strong style="font-weight: 600;">各业务可以考虑使用不同尺寸的小模型，或者采用根据业务数据微调后的垂直小模型</strong></span>。</div><div class=" pTag">微调<span>（Fine-Tuning）</span>是学术界通用叫法，在腾讯内部更愿意用<span><strong style="font-weight: 600;">“精调”</strong></span>。</div><div class=" pTag">从数据管理到自研AngelPTM训练框架、AngelHCF推理框架，再到模型评测、部署都有一股精耕细作的劲儿。</div><div class=" pTag">那么，面对如今 400+场景，以及未来更多业务都要上大模型的情况，研发团队显然无法分出精力逐个精调，如何解决这个问题呢？</div><div class=" pTag">答案是通过<span><strong style="font-weight: 600;">混元一站式平台</strong></span>，许多需求业务团队自己就能轻松搞定。</div><div class=" pTag">混元一站式平台不仅支持通过API接口直接调用混元大模型服务，还把大模型从训练到部署的很多流程都做到可视化，不用写代码只需鼠标点点就能快速完成。</div><div class=" pTag">有了混元一站式平台很多AI工程师都不怎么去折腾代码了，而不精通机器学习的业务工程师也能轻松上手操作。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhibrJwiaMNtJT41gzP0yibpStWgnH1W1ic3piaib8bqVGSShN7Maszgsr5iaGg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">接下来根据一个完整的模型精调到上线的过程，来了解混元一站式平台的能力。</div><div class=" pTag"><span><strong style="font-weight: 600;">首先是模型方面</strong></span>，平台提供了各种尺寸的基座模型矩阵。又分为通用模型、针对典型场景的优化模型、针对更垂直领域任务的子模型三个层次。</div><div class=" pTag">通用模型前面已经介绍过，场景优化模型可以举两个例子：开发Agent类应用，就可以用到强化了函数调用能力的模型来做；在知识密度高的场景，则可以选择优化摘要能力的模型。</div><div class=" pTag">如果不光有垂直的应用场景，还有垂直的数据集，混元一站式平台上就可以完成针对私有数据集的二次训练，让垂直子模型不仅有很好的通用理解能力，也很擅长专业领域的知识也很擅长。</div><div class=" pTag"><span><strong style="font-weight: 600;">接下来便要说到靠混元一站式平台的数据处理能力。</strong></span></div><div class=" pTag">对于来自不同来源、质量参差的数据，从数据清洗流程如质检、去重，到统计调配不同主题数据的比例，再到更困难的数据价值观对齐，去除其中包含的偏见，都能靠自动化手段高效完成。</div><div class=" pTag">即使模型上线之后，再发现由于某类数据缺失造成模型某方面能力不强，也能迅速把补充数据投入到持续训练，支持模型的快速迭代。</div><div class=" pTag"><span><strong style="font-weight: 600;">有了基座模型和数据，就能通过精调来按需求打造专属模型。</strong></span>无论是速度快成本低的Lora精调，还是全参数深度精调都能在混元一站式平台完成。</div><div class=" pTag"><span><strong style="font-weight: 600;">精调后模型的评测、部署上线也都做到了自动化</strong></span>，特别是部署可以做到一键发布，是混元一站式平台的核心技术之一。</div><div class=" pTag">总结来看，相较于传统的机器学习平台，混元一站式平台的最大特点在于：提供预训练好的基座模型、自动化优化数据处理流程，以及精简高效的模型精调和应用集成工作流。该平台通过自动化和智能工具应对海量训练数据、模型定制和部署等挑战，极大地降低了业务接入大模型的门槛，实现了速度快、效果好、接入方式多样的目标。</div><div class=" pTag">一言以蔽之：<span><strong style="font-weight: 600;">已跑通从模型研发到应用落地的完整流程。</strong></span></div><div class=" pTag">内部流程彻底跑通、并经过400+场景验证，外部开发者和企业可以通过腾讯云上API直接调用腾讯混元能力，接下来就要在<span><strong style="font-weight: 600;">助力合作伙伴业务智能化升级上发力</strong></span>了。</div><h2>One More Thing</h2><div class=" pTag">在这次交流的最后，量子位把在测试腾讯混元助手过程中发现的，模型仍无法很好解决的问题提交给了团队。</div><div class=" pTag">结束后已经是北京时间晚上6点多，比原定的结束时间推迟了近2个小时。</div><div class=" pTag">腾讯混元团队大部分成员都准备动身去往机场，要赶回深圳研发总部。</div><div class=" pTag">张锋没有与大家一同离开会议室。</div><div class=" pTag">简单告别后，他又一屁股坐回沙发上，一心沉醉到琢磨怎么改进Bad case的世界里了。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FmD8WjR4n-I3X3XkISRAfPA">阅读原文 </a>
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 08:53:37 GMT</pubDate>
</item>
<item>
<title>支付宝悄悄上线智能助理，我们也偷偷测了下</title>
<link>https://posts.careerengine.us/p/662a1a1127ae07689b8d7af3</link>
<guid>https://posts.careerengine.us/p/662a1a1127ae07689b8d7af3</guid>
<content:encoded><![CDATA[
<div> 支付宝、AI产品、智能助理、灰度测试、功能模块
<br />
总结: 支付宝推出了新的AI产品——智能助理，通过灰度测试。这款AI助手与常见的对话或创作类大模型不同，更偏向服务办事型，能解答医疗问诊、信息推荐、商务旅行等问题。智能助理和支付宝深度绑定，可以调用支付宝及第三方功能模块或小程序，回答用户问题。对话速度较快，能处理多轮对话，提供基本支付相关信息。虽然还有改进空间，但已能满足日常需求。用户体验或许会不同，等待更多用户分享体验。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">支付宝被曝推出了新的AI产品！</div><div class=" pTag">量子位了解到，支付宝对一款AI智能助理进行灰度测试。</div><div class=" pTag">这款AI产品入口，就在支付宝最核心的首页位置，但又隐藏得较深。</div><div class=" pTag">如果你有幸被灰度到，那么点击首页右上角的加号时会看到“智能助理”的按钮。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhrUbOwVZdfdcLO5pdRynsicaGZpYcXOwAcguKaozIiaW0CTbyIfFFdX4A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不过，支付宝智能助理不同于对话交流、辅助创作的常见大模型，而是更偏向服务办事型的AI助手。</div><div class=" pTag">根据其界面显示，可根据医疗问诊、查办公积金、买机票找厕所、推荐上映电影等办事指令。</div><div class=" pTag">此外，它还能根据需求推荐支付宝的相应功能或直连小程序，起到App内的智能导航作用。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhWPeLA0qDedQIap8nbicFeFVKJmebQE58Ry7ZRHwI6uT7T4QBYacR4Mw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">获知这一消息后，量子位马上点开了支付宝里的加号，一看还真的获得了灰测资格，那就马上进行第一手实测。</div><h2>多种生活信息，对话就能查询</h2><div class=" pTag">先简单总结一下，这个智能助手不同于一般的对话或创作类大模型，而是和支付宝深度绑定的服务型AI助手。</div><div class=" pTag">它的主要功能，是匹配或调用支付宝生态内（包括第三方）的功能模块或小程序，来解答用户有关医疗问诊、信息推荐、商务旅行等方面的问题。</div><div class=" pTag">根据模块的不同，模型的回答可能是直接提取到的信息，也可能是告知用户使用方法和相应的入口。</div><div class=" pTag">比如我们的第一个问题关于天气，是“今天晚上会下雨吗”。</div><div class=" pTag">响应的速度还算不错，大概两三秒就给出了结果，而且知道了我们的意图是了解天气情况，并结合当前定位进行了准确搜索。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhVotWaea6Y9L1qkyiceUqFC7sMF2zeXPM2R2nVsT8xcIfDxvULDxMOLQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">但如果细看回复的文本，就会发现并未直接体现出问题的答案，而且看上去有一些套模板的痕迹。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhxiaicQxicOMhy3biaTsiaYPXktpsPNO8doux95V5ASH7Y4KCaN6AqXiaGWMw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">第二个问题关于出行，只需要直接问去目的地要怎样走，智能助理就会根据定位自动规划，不需要手动说明当前位置，除非当前位置不是起点。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhoZbP34icXFVQIx4fLmrdw2GQibvkqChibRIBIfl7vdO3SibWsMmzTsUwbA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同样美中不足的是，如果直接问打车要多少钱，智能助理反而不会提供这些信息了，而是直接给出了打车小程序的入口。</div><div class=" pTag">不过整体来看问题也不大，毕竟真想打车的话，总归也是要进入到相应的程序里面的。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhZbVaH0XH36JHOPVk1icDAR3SfXiaAFwIclkK3FiciaEMR4IiaJL5GhXb6vA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">如果要出远门，也可以让它来帮忙搜索机票和高铁信息，顺便推荐一些酒店。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhtvpUn4Okge8njq7u0ZL7c09eKgN8V9tZEth8YbL9o00iaJgN0YVXUfQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而且多轮对话能力也不错，我们分别省略了地点和任务信息，支付宝智能助理都能准确地根据前后文判断出我们的意图。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhtNawdmp4f134IJ7ooHyicrgR1FEqXDX0wwRb2ib5XXnayJaiaIFucHBGQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">当然了，作为一款支付软件里的助手，最基本的支付相关问题，也必须要有能力解决。</div><div class=" pTag">比如通过对话，直接让助手帮我们调出上个月的账单，还能指定某一类消费让助理给出相应数据。</div><div class=" pTag">当然了，给出的信息也都还不是直接指向问题，而是提供了相应的原始数据，需要自己进一步查阅。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh4U6jp4n0LZqfBjYEZAuaKibXUz4BoibPhjLNTmsia8kNj2S2SRSpFGs1w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">目前看来，AI助理已经可以在一定精准度上处理我们的数据，比如当我们要求查询指定的信用卡账单日时，它可以准确地定位到想要查询的那一张卡。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhSdr1ZzO7FyYPibYiaFVFlp87RwhicAR3aCADq48mmd5caJmaMOaSeRZPA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而存储在第三方的信息，就无法直接获取了，但智能助理也会给出详细的查询方式，并给出相应的入口。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhqtC8EicWBpPvUoq00NDH7F8ibbLibOnYs8VBTCVhicRdeCoUO1nibLVHK6w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">当然了，除了支付宝内的功能和小程序，一般的常识或生活问题，也可以拿来问，或者硬要尬聊也不是不行。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhrEc9VBdWZ2icMiaKXHaA8FrZOxyzrQODQQP9vTEkxY3IzMdkSpEPRlmQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而在输入方式上，或许从前面的截图当中已经看到了，支持打字和语音两种模式。</div><div class=" pTag">另外也可以上传图片，不过目前看这个功能还是个花瓶，上传后得到的回复是还不具有图片理解能力。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhEkCgSSc8K2Mib4sB5OlQlOMV5wG3v0ib3bExsubglOumm6nGmRH1rHGg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">总之，支付宝正在测试的这个智能助理，基本上可以满足我们的日常需求了，但在细节上，仍有不少提升的空间。</div><div class=" pTag">你被灰度到了吗，欢迎分享你的体验和感受。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FoGQDyKGQ7arlnmIWML-QDA">阅读原文 </a>
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 08:53:37 GMT</pubDate>
</item>
<item>
<title>GPT-4现场被端侧小模型“暴打”，商汤日日新5.0：全面对标GPT-4 Turbo</title>
<link>https://posts.careerengine.us/p/662a1a011c0db0684ea2df93</link>
<guid>https://posts.careerengine.us/p/662a1a011c0db0684ea2df93</guid>
<content:encoded><![CDATA[
<div> 关键词：商汤、大模型、日日新、端侧模型、功能全面<br />
<br />
要点1: 商汤发布了日日新大模型和端侧模型SenseChat Lite，展示了强大的功能和性能。<br />
要点2: 商汤日日新5.0全面对标GPT-4 Turbo，在逻辑推理、自然语言生成和数学能力方面表现优异。<br />
要点3: 商汤在多模态领域表现出色，展示了秒画5.0的生成效果和多模态能力。<br />
要点4: 商汤的办公小浣熊和代码小浣熊提高了办公和编程效率，展示了在办公和编程场景中的应用价值。<br />
要点5: 商汤在发展路线上注重大模型+大装置的打法，具备实践经验，受到客户好评，并展望了未来发展前景。<br />
<br />
总结: 商汤发布了强大的日日新大模型和端侧模型SenseChat Lite，展示了在多个领域的全面功能和性能，包括逻辑推理、自然语言生成和数学能力。同时，多模态能力和办公小浣熊、代码小浣熊的应用展示了商汤在多个领域的优势。通过大模型+大装置的发展路线，商汤在AIGC领域展示了强大的技术实力和应用价值，受到客户好评，展望未来发展前景看好。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">金磊 发自 商汤AIDC</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag" style="font-size: 17px;">够刺激，<strong style="font-weight: 600;">GPT-4竟然当众被“揍”了</strong>，甚至连还手的机会都没有：</div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqheaGbJ9whqk8JoYKeMpElevXguWNpicwFJmQTVbHWvUX87EejLtEP7Tw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">是的，就是在一场《街头霸王》游戏现场PK中，发生了这样的名场面。</div><div class=" pTag" style="font-size: 17px;">而且二者还是不在一个“重量级”的那种：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">绿人</strong>：由GPT-4操纵</div></li><li><div class=" pTag"><strong style="font-weight: 600;"><span>红人</span></strong>：由一个端侧小模型操纵</div></li></ul><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhrotVgvY2yygLUDZ6x31m0vEaZ59FF572DGvPb7Xg1NSibwmMoMJ9RfQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">那么这位又小又彪悍的选手到底什么来头？</div><div class=" pTag" style="font-size: 17px;">不卖关子，它正是由<strong style="font-weight: 600;">商汤科技</strong>最新发布的日日新端侧大模型——<strong style="font-weight: 600;">SenseChat Lite</strong><span>（商量轻量版）</span>。</div><div class=" pTag" style="font-size: 17px;">单是在《街头霸王》里的表现，这个小模型就颇有一种“天下武功，唯快不破”的气势：</div><div class=" pTag" style="font-size: 17px;">GPT-4还在想着怎么决策，SenseChat Lite的拳头就已经打上去了。</div><div class=" pTag" style="font-size: 17px;">不仅如此，商汤CEO<strong style="font-weight: 600;">徐立</strong>还在现场加大难度，直接<strong style="font-weight: 600;">在手机上断网开测</strong>！</div><div class=" pTag" style="font-size: 17px;">例如离线模式下生成员工请假一周的申请，效果是这样的：</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqht8nnicCVSJdicQgZicl504mYmgBsIXI0HJFYjkm2T939yGGCrsuZdDTPg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>现场原速</h6><div class=" pTag" style="font-size: 17px;"><span>（当然，徐立开玩笑表示“假太长了，不批噢~”）</span></div><div class=" pTag" style="font-size: 17px;">也可以对长段文字做快速总结：</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhP3Eof8399kQT6b4iagOHFP5eBabpqzAbrO8NzkkwujZqyxZV4nCr8Cg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>现场原速</h6><div class=" pTag" style="font-size: 17px;">而之所能够做到如此，是因为SenseChat Lite在同等尺度性能上已经达到了SOTA水平。</div><div class=" pTag" style="font-size: 17px;">更是用“以小博大”的姿势在多项测试中击败了Llama2-7B，甚至是13B。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhLRBhqXWicIBaW7gyeq2bEjObfFXLOP9B05icKLHGB13jWmZIPcTue8xg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">在速度方面，SenseChat Lite则是采用了端云“联动”的MoE框架，在部分场景中端侧推理占70%，会让推理成本变得更低。</div><div class=" pTag" style="font-size: 17px;">具体而言，对比人眼20字/秒的阅读速度来说，SenseChat Lite在中等性能手机上，可以达到18.3字/秒推理速度。</div><div class=" pTag" style="font-size: 17px;">若是在高端旗舰手机，那么推理速度可以直接飙到78.3字/秒！</div><div class=" pTag" style="font-size: 17px;">但除了文本生成之外，徐立同样在现场还展示了商汤端侧模型的<strong style="font-weight: 600;">多模态</strong>能力。</div><div class=" pTag" style="font-size: 17px;">例如同样是<strong style="font-weight: 600;">扩图</strong>，商汤的端侧大模型在慢半拍启动的情况下，扩了3种不同图片的速度比友商扩1张的速度还快：</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhVPMwOaficKHjwiaYlnZLL6OEkL1Uibw3n452ErlnMicfgEYdKFvTsMufEw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">演示的同学甚至直接<strong style="font-weight: 600;">现场拍照</strong>，把照片缩小了很多以后再来<strong style="font-weight: 600;">自由扩图</strong>：</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhkZriaCldVlyIicuxmWZvIiahHUC9BichBBYsurXIkfGqM5r5fyXdUZr9Sw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">嗯，不得不说，商汤是敢在现场动真格的。</div><div class=" pTag" style="font-size: 17px;">然而，纵观整场活动，端侧大模型也还仅是此次发布会的一隅。</div><div class=" pTag" style="font-size: 17px;">在“大基座”方面，商汤更是把自家的日日新大模型来了个大版本的升级——<strong style="font-weight: 600;">SenseNova 5.0</strong>。并且直接将其定位到了一个新高度：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag"><strong style="font-weight: 600;">全面对标GPT-4 Turbo！</strong></div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhSh9ibsAXriaRF6B9sib1QibnqH4PvsCYYl9LN2nlGICB0KascSvickM8a9A/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">那么日日新大模型5.0版本实力到底如何，我们这就来实测一波~</div><h2>有请，“弱智吧”！</h2><div class=" pTag" style="font-size: 17px;">自打大模型火爆以来，“弱智吧”就一直成了检测大模型逻辑能力的标准之一，江湖戏称为<strong style="font-weight: 600;">“弱智吧Benchmark”</strong>。</div><div class=" pTag" style="font-size: 17px;"><span>（“弱智吧”源自百度贴吧，是一个充满荒谬、离奇、不合常理发言的中文社区。）</span></div><div class=" pTag" style="font-size: 17px;">而且就在前不久，“弱智吧”还登上正经AI论文，成了最好的中文训练数据，引发了一波不小的热议。</div><div class=" pTag" style="font-size: 17px;">那么当文本对话的商量大模型5.0遇到了“弱智吧”，二者又会擦出怎样的花火？</div><h4>逻辑推理：“弱智吧”</h4><div class=" pTag" style="font-size: 17px;"><strong style="font-weight: 600;">请听第一题：</strong></div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我爸妈结婚为什么没有叫我？</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhOGeMcLNuicexbicmJo2kicsFozK7oEgduynkQD50Kh0LyFXIsaT0DprWQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">商量的回答不同于其它AI，它会比较拟人的用“我”来做回答，而且从答案结果来看并没有过多冗余的内容，而是精准地做了回答和解释，“他们结婚时您还未出生”。</div><div class=" pTag" style="font-size: 17px;"><strong style="font-weight: 600;">请听第二题：</strong></div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">网吧能上网，为什么弱智吧不能上弱智？</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhe5SXE1yhxPEhlBJaExicibZRIibGm8y0icIK5Dk860cGQxV4Gkg5IjOnwA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">同样的，商量直接精准点出“这是个玩笑性质的问题”，以及道出了“‘弱智吧’并非一个实际的地方”。</div><div class=" pTag" style="font-size: 17px;">不难看出，对于“弱智吧”这种魔幻、不按套路出牌的逻辑，商量5.0是已经能够hold住了。</div><h4>自然语言：高考《红楼梦》</h4><div class=" pTag" style="font-size: 17px;">除了逻辑推理能力之外，在<strong style="font-weight: 600;">自然语言生成</strong>方面，我们可以直接用<strong style="font-weight: 600;">2022年高考作文</strong>题目，来对比看下GPT-4和商量大模型5.0。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhusAI8rOQv5GEdT7SpV2Ge622p7ol1Aba9gfQ6RRiaLxZteWSy4QC8aw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">从结果上来看，GPT-4的文章还是一眼“AI模版”；而商量5.0这边，则是颇有诗意，不仅句子工整对仗，还能引经据典。</div><div class=" pTag" style="font-size: 17px;">嗯，AI的思路是被打开、发散了。</div><h4>数学能力：化繁为简</h4><div class=" pTag" style="font-size: 17px;">同样是让GPT-4和商量5.0同台竞技，我们这次来测试一下它们的数学能力：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">妈妈给圆圆冲了一杯咖啡，圆圆喝了半杯后，将它加满水，然后她又喝了半杯后，再加满水，最后全部喝完。问圆圆喝的咖啡多，还是水多？咖啡和水各喝了几杯？</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhOevgTJ7ZNicVwaZUxu75hNDM4OmiaV2RoQWxOCuZQBA4aFjkL4MPdS0A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">这道题对于人类来说，其实是一个比较简单的问题，但是GPT-4却对此做出了看似一本正经的缜密推导，结果还是错误的。</div><div class=" pTag" style="font-size: 17px;">究其原因，是大模型背后的思维链在逻辑上的构建并不完整，若是遇到小众的问题就极容易出错；反观商量5.0这边，思路和结果就是正确的了。</div><div class=" pTag" style="font-size: 17px;">再如下面这道<strong style="font-weight: 600;">“老鹰抓小鸡”</strong>的问题，GPT-4或许不理解这种游戏的规则，因为所算出来的答案依旧是错误：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhXVqz7PRlwyGIiaFpCxE0LGsX2BLENxEibUy7Ric87qzfKicvekniaZCZIyA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">不仅从实际体验的效果中可以感知一二，更为直接的评测榜单数据，也反应出了商量5.0的能力——</div><div class=" pTag" style="font-size: 17px;">常规客观评测已经达到或超越GPT-4 Turbo。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhBduQrFC8ha9mF9dlVRFj2CibRyyN5jG942GHODP3SQ7ibCg55qm88ic3w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">那么日日新5.0又是如何做到的呢？一言蔽之，<strong style="font-weight: 600;">左手数据，右手算力</strong>。</div><div class=" pTag" style="font-size: 17px;">首先，为了打破<strong style="font-weight: 600;">数据</strong>层面上的瓶颈，商汤采用了超过10T的tokens，使其具备了高质量数据的完备性，让大模型对客观知识和世界有了初级的认知。</div><div class=" pTag" style="font-size: 17px;">此外，商汤还合成构造了高达数千亿tokens的思维链数据，这也是此次在数据层面上发力的关键点，能够激活大模型强推理的能力。</div><div class=" pTag" style="font-size: 17px;">其次，是在<strong style="font-weight: 600;">算力</strong>层上，商汤是将算法设计和算力设施进行了联合的优化：算力设施的拓扑极限用来定义下一阶段的算法，而算法上的新进展又要重新知道算力设施的建设。</div><div class=" pTag" style="font-size: 17px;">这便是商汤AI大装置对算法和算力联合迭代的核心能力所在了。</div><div class=" pTag" style="font-size: 17px;">整体而言，日日新5.0的更新亮点可以总结为：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">采用MoE架构</div></li><li><div class=" pTag">基于超过10TB tokens训练，拥有大量合成数据</div></li><li><div class=" pTag">推理上下文窗口达到200K</div></li><li><div class=" pTag">知识、推理、数学和代码等能力全面对标GPT-4 Turbo</div></li></ul><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhPtY1zQos0Xu9icOt5icicMLTCfybkqnQ3wx0hMp8UaHyKrgs6rcHlVaUw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">除此之外，在<strong style="font-weight: 600;">多模态</strong>领域，日日新5.0在多项核心指标中也取得了较为领先的成绩：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhmA3A3UekwE2ZckT1MuC8g0hMjsicspPicyM234W65zkBy2BuibCGQystQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">老规矩，我们继续来看多模态的生成效果。</div><h4>更会看图了</h4><div class=" pTag" style="font-size: 17px;">例如“投喂”给商量5.0一张超级长的图片（646*130000），只需让它识别，便可以得到所有内容的概述：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhKwyqHk43C3UtUMhOn9qmLRzzr1bp2zZxsibxH1VXx40taNibdHk0CD9A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">再如随意丢给商量5.0一张有意思的猫咪图片，它就能根据派对帽、蛋糕和“生日快乐”等细节内容推断猫在庆生。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhUNhiamiaaicpbibRKt3cFUZeghj2tAvSFj8Hx5Ya20XYBjJIlJaJCxAVSQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">更实用一些的，例如上传一张复杂截图，商量5.0就能精准提取并总结出关键的信息，而这一点GPT-4在识别过程中却出现了失误：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh7BreugnNyrvQVrGiaBicZJ3uqW0WyN7IudoUSBLI7YUGybnIK9uJsglw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h4>秒画5.0：和三大顶流PK</h4><div class=" pTag" style="font-size: 17px;">在文生图方面，日日新的<strong style="font-weight: 600;">秒画5.0</strong>直接和Midjourney、Stable Diffuison和DALL·E 3进行了同台竞技。</div><div class=" pTag" style="font-size: 17px;">例如在风格上，秒画生成的图片可能会更加接近prompt中提到的“国家地理”：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhpkbNvWvib8JmkUYSYquou8nQfG3gam79yqQ7t8Qg7VwHYdo0Ycwle9A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">人物形象上，可以展示更加复杂的皮肤纹理：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhic0EO1VXXWEmLMmVtkVzEPRNx3TAsgOicdaAhskib0Pia7iawmyia8a3YPnQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">甚至是文字也可以精准无误地嵌入到图像当中：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhlQp8LDkBccfmS9HEX0RNoXp4d6PpmyRQsVrx5zLia2oWyV9TtUd8NZg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h4>还有个拟人大模型</h4><div class=" pTag" style="font-size: 17px;">除此之外，商汤在此次发布中还推出了一个比较特殊的大模型——<strong style="font-weight: 600;">拟人大模型</strong>。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqheiaqmImgBMxBVl73ibibrE9iciaHibhibphECPILgwa7DQCMJ4G9V8N91TJvg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">从体验来看，它已经可以模仿影视角色、现实名人、原神世界等各种破次元的人物，并且与你展开高情商对话。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh7rjnkuldaG3Onn7ichW0SFsIPt2xNX4GOnSkwqBia5gYFibalibtBcpzCg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">从功能上来看，商量拟人大模型支持角色创建与定制、知识库构建、长对话记忆等，甚至是可以三人以上群聊的那种哦~</div><div class=" pTag" style="font-size: 17px;">也正是基于如此多模态能力，商汤大模型家族的另一大成员——小浣熊也迎来了能力上的升级。</div><h2>办公、编程变得更easy</h2><div class=" pTag" style="font-size: 17px;">商汤的小浣熊目前细分为<strong style="font-weight: 600;">办公小浣熊</strong>和<strong style="font-weight: 600;">编程小浣熊</strong>两大类，顾名思义，分别是作用于办公场景和编程场景。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhxOkCr6iaYo9WbXZAzUI8icIr9mV6NV9rUTljkqFIbD43TPZ2hD34VM8g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">有了办公小浣熊，现在处理表格、文档甚至代码文件，都成了<strong style="font-weight: 600;">“一丢+一问”</strong>的事情了。</div><div class=" pTag" style="font-size: 17px;">以采购场景为例，我们可以先上传不同来源的供应商名单信息，然后跟办公小浣熊说：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">单位、单价、备注。因为不同 sheet 中的表头信息并不一致，可将类似的表头内容进行合并。在对话框中展示表格结果，并生成本地下载链接，谢谢。</div></blockquote><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhZZMB5449WichLAFypIEE3g3N2P80ibjMDDx6BwOVvM3jvzibJpbqGwgXQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">只需稍等片刻，我们就可以得到处理完后的结果了。</div><div class=" pTag" style="font-size: 17px;">而且在左侧栏中，办公小浣熊还给出了分析过程的Python代码，主打一个“有迹可循”。</div><div class=" pTag" style="font-size: 17px;">我们还可以同时上传库存信息和采购需求等多个文件：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhwtPwTiajPu78JR3EMBiaibK3Tuic3qTjmHoyuZQEKhIVwXyCEPkCj4VrnA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">然后继续提要求，办公小浣熊依旧是能够快速完成任务。</div><div class=" pTag" style="font-size: 17px;">并且即使是数据形式不规范，它也能自行发现并解决：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhViaPUkjD3gTQ2SoyV8PYmSgbdzAZqdVJLsxEzc2mOtpLF8icnzChZBhQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">当然，数据计算也是不在话下，依旧是提要求的事情。</div><div class=" pTag" style="font-size: 17px;">除此之外，办公小浣熊也可以基于数据文件做可视化的工作，直接展示下有难度的热力图：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhUCSFo47XRZY6PmPib4uic9ezP15uxAicoTF1P7richu2A9mZndhABVEqdQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">总结来看，办公小浣熊可以对多个、不同类型（如 Excel、csv、json 等）做处理，在中文理解、数理计算和数据可视化等维度有非常强的能力。并且它通过代码解释器的形式，增强了大模型生成内容的准确性与可控性。</div><div class=" pTag" style="font-size: 17px;">另外，发布会上办公小浣熊还当场展示了结合复杂数据库进行分析的能力。</div><div class=" pTag" style="font-size: 17px;">上周，中国首位F1车手周冠宇完成了他在F1中国大奖赛的比赛。商汤在发布会现场直接给办公小浣熊“投喂”了一份数据量庞大的数据库文件，让小浣熊当场分析周冠宇和F1赛事的相关情况。</div><div class=" pTag" style="font-size: 17px;">如统计周冠宇的参赛信息、F1总共有多少车手、有哪些车手获得过总冠军并按照获奖次数从高到低排列，这些计算涉及量更大、逻辑更复杂的数据表格和圈数、领奖数等更多维度的细节信息，最终也都给出了完全正确的答案。</div><div class=" pTag" style="font-size: 17px;">在编程场景中，<strong style="font-weight: 600;">代码小浣熊</strong>也是可以让程序员们的效率直接Pro Max了。</div><div class=" pTag" style="font-size: 17px;">例如只需在VS Code中安装扩展的插件：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhibYCqTENj4al6iaddhmLN46MpoicwXoBTykR5Y1tlXmFdHCGM6CQCvELQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">然后编程的各个环节就变成了输入一句自然语言的事情了。</div><div class=" pTag" style="font-size: 17px;">例如把需求文档丢给代码小浣熊，然后就说句：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">帮我写一个公有云上微信扫码支付的详细PRD文档。PRD格式和内容请遵循“产品需求文档PRD模板”的要求，生成的内容清晰、完整、详细。</div></blockquote><div class=" pTag" style="font-size: 17px;">然后代码小浣熊就“唰唰唰”地开始做<strong style="font-weight: 600;">需求分析</strong>的工作了：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhrhHeicLC8jC8uadicQagthvn0DnvcjAakiaQ3RtuaribcTBpNPcSKexCog/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">代码小浣熊也可以为你做<strong style="font-weight: 600;">架构设计</strong>：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh0ROlfDQt8UPqT0PesGpog5uVibUqOaIeK3nraafcLgyibG9uEmibibpiadw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;"><strong style="font-weight: 600;">写代码</strong>也可以通过自然语言提需求，或者通过鼠标一键注释、测试生成代码，代码翻译、重构或修正等等：</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhCHdf0LnpmSDn0ciaVViaZhw3WFe2xtrcL2X51unotcLpqS0HMDOYYWew/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">最后的<strong style="font-weight: 600;">软件测试</strong>环节也可以交给代码小浣熊来执行哦~</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqh1CLyPuuI0wWJLESgia2NAPujAvZFraDprE4SOxXibRyX9HqH0BciaSpTw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">总而言之，有了代码小浣熊，它就能帮你处理平日里一些重复性、繁琐性高的编程任务。</div><div class=" pTag" style="font-size: 17px;">而且商汤此次还不只是发布这么个动作，更是将代码小浣熊“打包”推出了<strong style="font-weight: 600;">轻量版一体机</strong>。</div><div class=" pTag" style="font-size: 17px;">一台一体机就能支持100人团队开发，且成本仅为<strong style="font-weight: 600;">每人每天4.5元</strong>。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhrEw5HjWibexic7Z2OicJluyqHUomOibkhVnClcCYvSa48n3cBSdQUH79hQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">以上便是商汤此次发布的主要内容了。</div><div class=" pTag" style="font-size: 17px;">那么最后，我们还需要总结性地聊一聊一个话题。</div><h2>商汤的大模型路数</h2><div class=" pTag" style="font-size: 17px;">纵观整场发布会，给人最为直观的感受首先就是<strong style="font-weight: 600;">够全面</strong>。</div><div class=" pTag" style="font-size: 17px;">不论是端侧模型，亦或者“大底座”日日新5.0，是属于云、边、端全栈的发布或升级；能力上更是涵盖到了语言、知识、推理、数学、代码，以及多模态等AIGC近乎所有主流的“标签”。</div><div class=" pTag" style="font-size: 17px;">其次就是<strong style="font-weight: 600;">够抗打</strong>。</div><div class=" pTag" style="font-size: 17px;">以日日新5.0的综合实力为例，目前放眼整个国内大模型玩家，能够喊出全面对标GPT-4的可以说是为数不多；并且商汤是敢在现场直接拿多项能力做实测，也是敢第一时间开放体验，对自身实力的信心可见一斑。</div><div class=" pTag" style="font-size: 17px;">最后就是<strong style="font-weight: 600;">够速度</strong>。</div><div class=" pTag" style="font-size: 17px;">商汤的速度不只限于像端侧大模型的运行效果之快，更宏观地来看，是自身在迭代优化进程上的速度。若是我们把时间线拉长，这种speed就会格外得明显：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">日日新1.0→2.0：3个月</div></li><li><div class=" pTag">日日新2.0→4.0：6个月</div></li><li><div class=" pTag">日日新4.0→5.0：3个月</div></li></ul><div class=" pTag" style="font-size: 17px;">如此平均下来，近乎是一个季度便有一次大版本的升级，其整体能力也会随之大幅提高。</div><div class=" pTag" style="font-size: 17px;">那么接下来的一个问题便是，商汤为什么可以做到如此？</div><div class=" pTag" style="font-size: 17px;">首先从大方向来看，便是商汤一直强调的<strong style="font-weight: 600;">“大模型+大装置”</strong>的打法。</div><div class=" pTag" style="font-size: 17px;">大模型是指日日新大模型体系，可以提供自然语言处理、图片生成、自动化数据标注、自定义模型训练等多种大模型及能力。</div><div class=" pTag" style="font-size: 17px;">大装置则是指商汤打造的高效率、低成本、规模化的新一代AI基础设施，以AI大模型开发、生成、应用为核心；总算力规模高达12000 petaFLOPS ，已有超4.5万块GPU。</div><div class=" pTag" style="font-size: 17px;">二者的异曲同工之妙，便是<strong style="font-weight: 600;">早已布局</strong>，它们并非是AIGC大热潮之下的产物，而是可以追溯到数年前、具有前瞻性的两项工作。</div><div class=" pTag" style="font-size: 17px;">其次更深入到大模型层面，商汤基于自身在实际的测试和实践过程中，对行业所共识的基本法则<strong style="font-weight: 600;">尺度定律</strong><span>（Scaling Law）</span>有着新的理解和解读。</div><div class=" pTag" style="font-size: 17px;">尺度定律通常是指随着数据量、参数量和训练时长的增加，大模型所表现出来的性能会更好，是一种大力出奇迹的感觉。</div><div class=" pTag" style="font-size: 17px;">这个定律还包含两条隐藏的假设：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">可预测性：可以跨越5-7个数量级尺度依然保持对性能的准确预测</div></li><li><div class=" pTag">保序性：在小尺度上验证了性能优势，在更大尺度上依然保持</div></li></ul><div class=" pTag" style="font-size: 17px;">因此，尺度定律是可以指导在有限的研发资源中，找到最优的模型架构和数据配方，让大模型能够高效地去学习。</div><div class=" pTag" style="font-size: 17px;">而也正是基于商汤如此的观察和实践，诞生了“小且能打”的端侧模型。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhYnbvpIkM1s4NsLXvgzXKvj4odIea4q3sIUTQ75sWf9NTW7JsxOxqVQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">除此之外，商汤对于大模型的能力还有独到的三层架构（KRE）的理解。</div><div class=" pTag" style="font-size: 17px;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicCowAibjwItlqbMZTvmEqhYXTtXTzYj9EVVhuq4Du6vUwxPQXdx406gJ2TwsiaCyBJniaV1CCBLLRg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag" style="font-size: 17px;">徐立对此做了深入地解读。</div><div class=" pTag" style="font-size: 17px;">首先是在知识，是指世界知识的全面灌注。</div><div class=" pTag" style="font-size: 17px;">目前大模型等新质生产力工具近乎都是基于此来解决问题，也就是根据前人已经解决过的问题的方案，来回答你的问题。</div><div class=" pTag" style="font-size: 17px;">这可以认为是大模型能力的基本功，但更为高阶的知识，应当是基于这样能力下推理得到的新知识，这也就是这个架构的第二层——推理，即理性思维的质变提升。</div><div class=" pTag" style="font-size: 17px;">这一层的能力是可以决定大模型是否够聪明、是否可以举一反三的关键和核心。</div><div class=" pTag" style="font-size: 17px;">再在此之上，便是执行，是指世界内容的交互变革，也就是如何跟真实世界产生互动（就目前而言，具身智能在这一层是潜力股般的存在）。</div><div class=" pTag" style="font-size: 17px;">三者虽相互独立，但层与层之间也是紧密关联，徐立打了一个较为形象的比喻：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">知识到推理是像大脑，推理到执行则像小脑。</div></blockquote><div class=" pTag" style="font-size: 17px;">在商汤看来，这三层的架构是大模型应当具备的能力，而这也正是启发商汤构建高质量数据的关键；不仅如此，也是基于KRE这套逻辑，才有了此次发布中的众多产品。</div><div class=" pTag" style="font-size: 17px;">那么最后一个问题是，基于KRE、基于“大模型+大装置”这样的路线，最新的日日新在产业中“上岗”到了什么程度？</div><div class=" pTag" style="font-size: 17px;">正所谓“实践是检验真理的唯一标准”，来自客户的使用反馈或许才是最真实的答案。</div><div class=" pTag" style="font-size: 17px;">而在此，商汤也交出了一份较为高分的作业——在现场，华为、WPS、小米、阅文、海通证券，从办公到文娱，从金融到终端，纷纷分享了使用商汤日日新大模型体系后，给自身业务带来的降本增效。</div><div class=" pTag" style="font-size: 17px;">总而言之，有技术、有算力、有方法论、有场景，商汤日日新在AIGC时代接下来的发展，是值得期待了。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FoiP4LPjVWo-9FLJXiGrz5A">阅读原文 </a>
]]></content:encoded>
<pubDate>Thu, 25 Apr 2024 08:53:21 GMT</pubDate>
</item>
<item>
<title>“AIGC第一股”首日市值54亿！出门问问正式登陆港交所，李志飞身家10亿</title>
<link>https://posts.careerengine.us/p/662904481cdf4828c289d3c2</link>
<guid>https://posts.careerengine.us/p/662904481cdf4828c289d3c2</guid>
<content:encoded><![CDATA[
<div> 出门问问、港股、IPO、财务数据、关键投资人
总结:<br /><br />文章介绍了出门问问在港股上市的情况，股票代码为“2438”，创始人李志飞持股25.2%。公司的财务数据显示，预计2023年实现营业收入5.07亿元人民币，净亏损接近8亿元人民币。出门问问在AI软件解决方案和AIoT领域取得进展，以通用大模型“序列猴子”为底座。投资者包括谷歌、红杉资本等。公司创始人背景为谷歌科学家，毕业于南京理工大学和约翰霍普金斯大学。自2012年成立以来，公司经历了7轮融资，总计融资超过2.5亿美元。公司重启IPO计划，目标是定义下一代人机交互，成为新AI时代的引领者。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">明敏 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag"><strong style="font-weight: 600;">出门问问，正式成为港股“AIGC第一股”</strong>。</div><div class=" pTag">今日，出门问问在港交所正式挂牌上市，股票代码“2438”，发售定价<strong style="font-weight: 600;">每股3.8港元</strong>。</div><div class=" pTag">截至今日收盘，出门问问市值已达54亿。</div><div class=" pTag">创始人<strong style="font-weight: 600;">李志飞</strong>作为最大股东持股25.2%，身价超10亿。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnAibicY13FaTia9Q3rmpjwAzrP9xJLI4GiaGv2mNN3YfXnLEPG8KtZbEvfA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">据配发结果公告显示，此次出门问问全球发售8456.9万股股份，国际发售4228.4万股份，公开发售4228.4万股。其中，公开发售获117.39倍认购，国际发售获1.58倍认购。</div><div class=" pTag">上市当日出门问问收盘价为3.68港元。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnnFdGdvcNxasUicWTCYn8BFAm3BzoqYHPa1eB5MibrPhQu4kvnoaXlfpA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">早在去年5月30日，出门问问向港交所递交招股书。</div><div class=" pTag">创始人李志飞是前谷歌科学家、NLP专家，也是中国最早一批投身于AI语音语言技术的创业者。</div><div class=" pTag">出门问问创立后，大众汽车谷歌红杉中国等纷纷加持，累计吸金超2亿美元，并先后在语音交互、智能硬件、AIoT等领域展开商业化落地。大模型东风吹来后，出门问问迅速将2020年发布的通用大模型UCLAI升级为“序列猴子”。</div><div class=" pTag">如今又率先抢跑，成为AIGC第一股。</div><div class=" pTag">出门问问，到底由哪些数据构成？</div><h2>关键财务数据</h2><div class=" pTag">根据最新招股书披露信息显示，出门问问由以下关键财务指标构成。</div><div class=" pTag"><strong style="font-weight: 600;">营收方面</strong>：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">2021年：实现营业收入3.97亿元人民币。</div></li><li><div class=" pTag">2022年：实现营业收入5.00亿元人民币。</div></li><li><div class=" pTag">2023年：实现营业收入5.07亿元人民币。</div></li></ul><div class=" pTag"><strong style="font-weight: 600;">毛利情况</strong>：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">2021年：毛利为1.49亿元人民币，毛利率为37.5%。</div></li><li><div class=" pTag">2022年：毛利为3.36亿元人民币，毛利率为67.2%。</div></li><li><div class=" pTag">2023年：毛利为3.26亿元人民币，毛利率为64.3%。</div></li></ul><div class=" pTag"><strong style="font-weight: 600;">净亏损情况</strong>：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">2021年：年内亏损2.76亿元人民币。</div></li><li><div class=" pTag">2022年：年内亏损6.70亿元人民币。</div></li><li><div class=" pTag">2023年：年内亏损8.03亿元人民币。</div></li></ul><div class=" pTag"><strong style="font-weight: 600;">经调整净利润</strong>：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">2021年：经调整后净利润为-7343.9万元人民币。</div></li><li><div class=" pTag">2022年：经调整后净利润为1.09亿元人民币，实现扭亏为盈。</div></li><li><div class=" pTag">2023年：经调整净利润为1753.5万元人民币，暴跌80%。</div></li></ul><div class=" pTag"><strong style="font-weight: 600;">收入构成方面</strong>，AI软件解决方案收入从2021年的0.60亿元增长到2023年的3.43亿元，年复合增长率为140%，收入占比从15%上升到67.7%。AIGC解决方案在2021-2023年的收入分别为682.2万元、3985.7万元和1.18亿元，复合年增长率超300%。</div><div class=" pTag">智能设备及其他配件的收入从2021年的3.38亿元减少到2023年的1.64亿元。</div><div class=" pTag">支出方面，从2021年-2023年，出门问问在研发上的投入分别是<strong style="font-weight: 600;">0.92亿元</strong>人民币、<strong style="font-weight: 600;">1.19亿元</strong>人民币和<strong style="font-weight: 600;">1.55亿元</strong>人民币。</div><div class=" pTag">研发开支的增加归因于研发职能的员工人数增加及大模型开发服务费增加。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnHicARjZQBuzwGAZOM7rvqDzwv4oDqDQPjvG37fkIkwg63QVxmbukJbw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>大模型为底座，软硬件通“吃”</h2><div class=" pTag">不过值得一提的是，尽管研发投入不断提高，但有关开支占总收入的比例从2020年的36.7%下降到2022年的23.7%。</div><div class=" pTag">对此，出门问问解释说这是因为业务增加带来了更多收入。</div><div class=" pTag">自成立以来，出门问问先后推出了AI软硬件集成、AIGC、AI CoPilot方面业务。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Ynq3d6YXGvrhKEkN0z9ExUibTPMVicZd8kBBegPpn1mDwrfknDSRwVKxkA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">招股书中显示，在2022年出门问问AI软件解决方案业务收入增幅达到<strong style="font-weight: 600;">408.89%</strong>，共计带来3亿元收入，占总收入的60%。</div><div class=" pTag">它具体包括AIGC解决方案和AI企业解决方案。</div><div class=" pTag">前者占比在2023年增幅明显，从原本不足10%上涨到23%。</div><div class=" pTag">后者则在2022年成为公司最赚钱的业务，带来一半以上业务，三年13.3%、52.6%、44.5%。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnNs9Ytt396R4E6Xy6fq84k5vZHFukSnyWl01ULIibopoib37lEicgN1ibOg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">他们的底层能力来自于出门问问的通用大模型。2020年，出门问问开发出通用大模型UCLAI，在今年升级为“序列猴子”。</div><div class=" pTag">具体到实际产品，他们先后推出了AI配音助手“魔音工坊”、AI写作助手“魔撰写作”以及AI数字人“奇妙元”。</div><div class=" pTag">据悉从自2020年以来，他们已为全球超过1000万用户提供服务，涵盖内容创作者、企业和消费者。</div><div class=" pTag">出门问问表示，这部分业务的增长，就在于AIGC解决方案方面的付费用户增加。而AI企业解决方案的收入增加，则是因为进行了知识产权安排。</div><div class=" pTag">另一大块收入构成，是<strong style="font-weight: 600;">AIoT解决方案</strong>。</div><div class=" pTag">2020-2022年带来的收入分别为：2.20亿、3.39亿和1.97亿。在2020和2021年，这部分收入占比均达到总收入的80%以上。</div><div class=" pTag">2022年的数字有所下降，此前招股书中解释说“部分被AIoT解决方案收入受延迟推出新旗舰产品影响而有所减少抵消”。</div><div class=" pTag">具体来看，出门问问AIoT智能设备主要包括AI智能手表、AI智能跑步机等。自2020年以来，AIoT智能设备销量已超过100万件。</div><div class=" pTag">其旗下的TicWatch智能手表，如今已经推出了4代共80款产品，最新产品TicWatch Pro 5在递交招股书前5天于海外正式发布。</div><div class=" pTag">出门问问表示通过软硬件结合，逐步将先进的AI技术应用于可穿戴、汽车及智能家居三大人机交互生活场景。相关的AIoT智能设备均可通过其虚拟助理“小问”进行连接。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnfNn8RCnSzIzaiaE7ib1GUjw2z02QS2LKPAibIiaiaGPOYvOfLIibr98vibfxw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">除此之外，招股书中披露的信息显示，出门问问对于大客户的依赖程度在2022年尤为明显，2023年有所缓解。</div><div class=" pTag">在2021年、2022年和2023年，出门问问的前五大客户分别占其收入的37.0%、62.8%和49.9%。</div><div class=" pTag">在同一时期，出门问问的最大客户分别占其收入的24.1%、42.6%和27.4%。</div><div class=" pTag">其中2022年出现的巨大增长，或许主要来自于汽车附属公司A的2亿元大单，比重甚至占到22年总收入的42.6%。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnMpFa4uM9jibLRUN8zUIcQ8lEiaTyDjFKC4VxA4y9iaQ4yONW1Vqav2tlQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>10年7轮融资，谷歌红杉中国押注</h2><div class=" pTag">出门问问成立于2012年，招股书显示自2013年至2019年，公司共融资七轮，累计融资金额超过<strong style="font-weight: 600;">2.5亿美金</strong>，<strong style="font-weight: 600;">约17.8亿人民币</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnG08Ov9lpEaia31pMo2aLltsoRFg3Fgkp7qTzc5YfCiaiaFEdGFcViatkeA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">参投者包括红杉资本、真格基金、SIG海纳亚洲、谷歌Google、歌尔声学及大众汽车集团（中国）等。</div><div class=" pTag">此外，两大地方国资中关村国际有限公司和南京经开聚智科创投资合伙企业，作为基石投资者参与出门问问本次IPO发行。</div><div class=" pTag">招股书披露的公司股权架构如下：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnF2cGNoM0CZicO2lrLcyCkoHiahevEsvKOK2tqWgZAiaBGwVRWbDm8q1dg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">创始人兼CEO<strong style="font-weight: 600;">李志飞</strong>是公司的第一大股东，IPO前个人持股<strong style="font-weight: 600;">26.72%</strong>。</div><div class=" pTag">李志飞、联合创始人李媛媛以及另一自然人旗下三家全资控股公司，共持股32.74% ，其中包括出门问问（Mobvoi Limited）、CMWW Limited以及Amberlei Limited。</div><div class=" pTag">随后，SIG、Google、红杉等持股介于17.03%与0.92%，声学设备龙头歌尔也在前十大投资人之列。</div><div class=" pTag">创始人李志飞，现同时任董事长、执行董事兼首席行政官，负责监管集团整体管理以及主要业务决策。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yn1szoQCR79aXpgekA75NOnvGdchibBuZzcn1u1qyJl4VCFqicjW2nvE1g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">他本科毕业于南京理工大，硕士毕业于南京航空航天大学，并分别获得南洋理工大学、约翰霍普金斯大学博士学位。</div><div class=" pTag">读博期间，他就开发了一款广为应用的开源机器翻译系统Joshua，在NLP领域有了积累。</div><div class=" pTag">2010年5月至2012年8月，在Google Inc.（现称Google LLC）总部担任研究科学家，负责语言翻译模型的算法研发。</div><div class=" pTag">2012年，拿到红杉资本和真格基金的天使投资后，回国创办出门问问。</div><div class=" pTag">成立10年之久，出门问问的上一次披露的融资也是5年前的事了。</div><div class=" pTag">2017年，出门问问获得大众汽车1.8亿美元D轮融资。此后，公司已有6年未宣布获得融资。</div><div class=" pTag">前段时间针对融资一事，李志飞正面回应称：近期不考虑融资，不需要外部融资也能支撑研发投入。</div><div class=" pTag">现在看来，或许是因为IPO，所以对融资并不“感冒”。资料显示，此次出门问问港股IPO，亦并非第一次。</div><div class=" pTag">时间回到2017年，彼时李志飞就曾表示计划两年内寻求IPO，当时称或许会在美国或香港上市。</div><div class=" pTag">而后到2019年，也曾爆出消息，出门问问即将获得融资，且公司正寻求筹集1亿美元资金，计划在上海证券交易所科创板上市。</div><div class=" pTag">不过当时李志飞对上市的回应则是：“感兴趣，有计划”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YngF3ZXzSQ74QXxVibWvN9v8KLtOsq8ibsSjOfMNZCnaZSHj8pdIYSkHWQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">随后4年，出门问问上市鲜少被提及，直至2023年AIGC大火，出门问问在发布大模型「序列猴子」及一站式AIGC产品后趁热打铁，火速重启IPO。并在一年后的今天正式登陆港交所。</div><div class=" pTag">在上市致辞中，李志飞表示：在成立之初，出门问问就以“定义下一代人机交互”为使命驱动，从语音助手到智能硬件，再到今天的大模型和AIGC，跨越十二年行业周期，逐步成为新AI时代的引领者。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">科技跟随者因为看见而相信，科技创新者因为相信而看见。明天开始，出门问问便将开启新一轮12年征程！</div></blockquote><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">招股书：</div><br /></span><span style="font-size: 17px;">https://www1.hkexnews.hk/listedco/listconews/sehk/2024/0416/2024041600025.pdf</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FF2XIouCJwxKC2t4WHt9G4A">阅读原文 </a>
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 13:08:24 GMT</pubDate>
</item>
<item>
<title>全球首个「油电平权」智驾方案：10万级入门标配高速NOA，高通Momenta联合出品</title>
<link>https://posts.careerengine.us/p/6629042f34c2052868e150cd</link>
<guid>https://posts.careerengine.us/p/6629042f34c2052868e150cd</guid>
<content:encoded><![CDATA[
<div> 关键词：高阶智能驾驶、高通、Momenta、普及、合作

总结:<br /><br />
高通和Momenta联手推出高阶智能驾驶产品，标配普及进入时代。该产品基于高通最新的Snapdragon Ride平台，使智能驾驶功能成为主流车型的标配。油车和电动车都可以享受智能化体验，无需区分。通过降低成本和提高性能，智能驾驶技术得到广泛普及。AI摩尔定律和Momenta的飞轮效应在推动智能驾驶快速发展。智能驾驶的标配时代将使更多人获益，推动整个交通系统朝着更加安全、高效的方向发展。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">贾浩楠 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">高阶智驾，正式开启标配攻势。</div><div class=" pTag">类比智能手机进程，旗舰机型进入面向所有人的普及阶段:</div><div class=" pTag">不论是自主泊车、高速环路NOA，还是城区通勤的记忆领航，能识别红绿灯、避让行人、自主绕障、左右转，CNCAP五星满分的主动安全功能，……应配尽配。</div><div class=" pTag sectionReplaced" style="text-align: center;"><strong style="font-size: 17px; text-align: right; font-weight: 600;">△</strong><span style="font-size: 17px; text-align: right;">高通8620量产方案全球首次实车体验</span></div><div class=" pTag"><div class=" pTag">而且这个方案同样面向燃油车、喊话燃油车，油和电对立的中国车圈话题里，这一次，油电同智。</div><br /></div><div class=" pTag">最重要的是，如此高阶智能驾驶产品，体验往上走、价格成本不断下探。数千元级硬件成本，标配的是旗舰级高阶智能驾驶的能力……</div><div class=" pTag">搅动风云者：<strong style="font-weight: 600;">高通</strong>、<strong style="font-weight: 600;">Momenta</strong>。</div><div class=" pTag">两家各自领域内最好的公司，卷出了新方向。</div><h2>高通Momenta联手，最新一代Snapdragon Ride平台智驾系统全球首发</h2><div class=" pTag">双方刚刚官宣，新智驾方案基于高通最新的<strong style="font-weight: 600;">Snapdragon Ridep平台（骁龙SA8620P和骁龙SA8650P）打造</strong>：</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnicNdicnDfiangYe9cgiadRLics93PH5NS7yKbwHGhAwEIpysw4zicMEInaFg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">其中，骁龙SA8620P芯片采用4nm工艺制程，具备36TOPsAI稠密算力，对Transformer架构支持更友好。Transformer则是实现BEV感知能力，也就是高阶城市、高速NOA的技术基础。</div><div class=" pTag">传感器方案上，可以选择搭载7V3R/7V1R两种不同方案。适合在10-20万元的主流乘用车上搭载。</div><div class=" pTag">注意是<strong style="font-weight: 600;">“主流乘用车车”，智能不再区分油电</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yn7zGjmMGaPKgSmiaemsVjreFAWCO3AaVcBqtDn03UqkJ8uc86HJwjhng/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">据介绍，这是因为骁龙8620芯片能支持被动散热，对于基础架构高度成熟、车载用电“冗余度”不高的油车来说，可在不增加额外成本的情况下直接上车。</div><div class=" pTag">具体功能体验上实现“行泊一体”，包括L2级的ADAS全功能，同时还可支持HNP高速高架领航辅助<span>（高速NOA）</span>，MNP记忆领航辅助<span>（通勤NOA）</span>，LPNP记忆泊车领航辅助、PNP泊车领航辅助等高阶智驾功能。</div><div class=" pTag">Momenta CEO曹旭东认为：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">“骁龙8620芯片为实现更高性价比的高阶智驾解决方案提供了全新可能，Momenta的算法优势可以进一步发挥，加速高阶智驾在更多主流价格段车型的标配落地。</div></blockquote><div class=" pTag">8620是“油电同智”的硬件基础。</div><div class=" pTag">另外高通公司副总裁羡磊表示：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">“Momenta的算法能力和高通在芯片上的技术优势属于双剑合璧，能够带来更好的产品体验，更有亲和力的成本，更广泛的智驾普及率。</div></blockquote><div class=" pTag">Momenta的算法能力以及数据闭环“飞轮”，则是高阶智驾标配的软件保障。</div><div class=" pTag">双方都提到了高阶智驾的普及和标配。这其实就是今年智能驾驶竞争的核心之一。</div><div class=" pTag">有两个重要指标，一个是以能覆盖从收费站到收费站全程，且能自主变道、避让、进出匝道的高速NOA为功能体验的起点。</div><div class=" pTag">之前不具备导航功能的ACC，或者只能实现“拨杆变道”的辅助驾驶功能，竞争力已经不够了。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Ynic9EG4B73Lh3wXaQhtB1QW71fbZ7Y53bsiaGr7118Ca8iaHWT9wUteRwQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">第二个指标是高速NOA功能不再花几万元选配，随车标配并且车型跨过15万元分水岭。</div><div class=" pTag">而高通和Momenta的新方案，是行业针对高阶NOA标配具有专门策略和清晰配置的第一个产品。</div><div class=" pTag">速度令人惊叹。</div><div class=" pTag">据透露，双方其实早在芯片研发阶段，就已经深入探讨合作可行性，并且充分发挥Momenta在量产交付上的经验和优势。<strong style="font-weight: 600;">仅用了不到两个月，就跑通跑好了产品功能</strong>。</div><div class=" pTag">应该也是全球首个基于量产车，最早实现的Refcar。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yncj3WjwYxm3icPmxq0iaj1OTHlsMialn1Lb8oG9FPrbCicKLxL0kk4RKE6g/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">实际上，这也是智舱王者高通，正式开启智驾的普及战，而更进一步被透露的是合作不止于高通的骁龙8620芯片，还包括骁龙8650——意味着城区NOA、记忆路线等等最先进的高阶智驾能力，也都开启了量产和上车。</div><div class=" pTag">这是高通的“硬”实力基础，也是Momenta飞轮驱动之下的兵贵神速。</div><h2>产生的影响：强强联手高阶智驾进入“标配时代”</h2><div class=" pTag">首发、上车的价值不止于高通和Momenta，更重要的意义是对于汽车产业和所有潜在消费者。</div><div class=" pTag">至少有明确的三点。</div><div class=" pTag"><div class=" pTag">第一，突破“15万以下无智能”的壁垒。</div><br /><div class=" pTag">第二，智能体验不再区别对待油电。</div><br /><div class=" pTag">第三，对消费者，汽车的智能化普及进入类比智能手机的“千元旗舰机”时代。</div></div><div class=" pTag">第一点， 入门级车型享受和豪华车型完全相同的智能驾驶功能体验，史上头一回。</div><div class=" pTag">智能车发展的早期阶段，高速NOA硬件配置成本是十分高昂的。光是搭载能够支撑高阶智驾芯片的域控制器，成本就要数千元甚至过万，再加上激光雷达，摄像头，毫米波雷达全套的传感器… 轻松过万，光这个硬件成本，就把很多10-20万的主流车型，拦在门外。</div><div class=" pTag">当时15万以下的入门级车型，选配上高阶智驾，售价就会上升到20万级别，失去竞争力。</div><div class=" pTag">不过经过数年智能车对传统汽车的渗透，供应链规模快速扩大，降本效应明显。</div><div class=" pTag">高通的骁龙8620、骁龙8650…一系列车规级智驾芯片从推出到进入量产车型落地的周期中可以说正逢其时，占了后发优势。</div><div class=" pTag">这就使得高通和Momenta可以把新平台BOM成本降到数千元量级——一部旗舰智能手机的价位，对于售价15万以内的车型来说足够合理，再没有理由不上车标配。</div><div class=" pTag">第二点，广大燃油车用户，终于不再是智能化浪潮中的被遗忘者。</div><div class=" pTag">从技术层面看，油车电子电气架构成熟，但也代表着对智能化的支持心有余力不足，比如信号传输的延迟问题、冗余不好做的问题、控制反馈响应慢的问题…</div><div class=" pTag">所以油车智能化核心问题，一个是架构上融合智驾硬件，以及算法上提升响应速度。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnmoDdyFbUibykY0dnSyWpPOdvXd4k6c3VIcyCewiagpPU7LwbibC7ka72A/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">高通在硬件层面，带来高性能低功耗且支持被动散热的优势。Momenta则是用<strong style="font-weight: 600;">数据驱动</strong>替代规则驱动，面对不同动力系统的特征，最大程度以成熟人类司机的方法训练AI控制油门刹车等，避免复杂的人工调整适配。</div><div class=" pTag">这两点综合看，高阶智驾标配，惠及的是两个最大的用户群体。</div><div class=" pTag">一个是占新车销售一半的燃油车用户，另一个同样是占一半份额的10-20万车型用户。</div><div class=" pTag">没有续航焦虑、高阶智驾随车标配，价格持平且体验远优于传统“功能车”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnCwDRTJwOicPlDNG3miboRib7g8XjKTMdLFibAh1icRnOU6GiahUUMjrbhsfg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px; text-align: left;">这种意义和价值，很难令人不联系类比到智能手机的普及浪潮中，千元的价位但拥有旗舰智能手机的部分功能和特性，这样具有推动性的变革——真正让所有人无差别进入了移动互联网的智能生活浪潮。</span></div><div class=" pTag">而对于主流乘用车，意义还不止于体验上的舒适性，还在于曾经豪华车专属的选配能力，现在正在加速标配到每一辆车，赋能到每一位车主。</div><div class=" pTag">更更重要的是，智能驾驶和智能汽车普及，一定也会推动整个路况和交通走向更为安全的新阶段。</div><div class=" pTag">这是所有用户和潜在消费者的福音。</div><h2>高阶智驾进入“标配时代”，还反映了什么？</h2><div class=" pTag">实际上，高阶智驾“标配时代”的历史进程，来得迅猛，但并非毫无征兆。</div><div class=" pTag">合作发布的现场，高通公司副总裁羡磊和Momenta CEO曹旭东在对谈中，分享了背后的作用规律。</div><div class=" pTag">第一是<strong style="font-weight: 600;">AI摩尔定律</strong>。</div><div class=" pTag">第二是Momenta一直实践的<strong style="font-weight: 600;">飞轮效应</strong>。</div><div class=" pTag">所谓AI摩尔定律，Momenta CEO曹旭东通过回忆2年前的行业趋势来让更多人感知:</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">就在两年前，智能驾驶还是竞争高速NOA的量产落地，体验上大部分产品体验都不过关，让人惊出一身冷汗的场景时常发生。</div><div class=" pTag">现在高速NOA已经完全覆盖从收费站到收费站的所有场景，并且从30万车型选配下探到20万车型标配。</div></blockquote><div class=" pTag">2年时间，高速NOA从智驾“试金石”，变成了“基础必修课”。</div><div class=" pTag">而曹旭东判断，AI技术和产品带来的体验，每2年就会有10倍提升——这是目前来自一线实践的洞察，但确实也在反映着行业发展的趋势。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2Yn1r7nsZGAecr2m1pItA2BhBlnWqtgjLvxR1T6bMdEicfMePiaJDibkqovw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">所以Momenta CEO认为，再过2到4年，高阶智能驾驶的标配渗透率，就会超过50%，开始成为大多数。</div><div class=" pTag">高通公司则完整经历过PC，互联网，手机等智能终端品类各个时代的发展，从自身经历的角度出发，高通方面也认同Momenta的洞察，认为每一个时代都有技术飞速发展和商业化快速迭代的周期。</div><div class=" pTag">而人工智能，现在正处于这样的引爆期。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnuOIVeejLBibuH6PUZiahYib3ZJ52PbEJPBibiaIRtTaXnwqo1j4ZjDxiaDZQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">AI摩尔定律背后，更进一步发挥作用的，实际是数据。</div><div class=" pTag">曹旭东强调，自动驾驶行业有明显<strong style="font-weight: 600;">数据驱动</strong>特征。海量数据的处理和训练，能够大幅提升系统的性能，意味着同样能降低对传感器的需求。</div><div class=" pTag">就是说从成本角度看，AI摩尔定律可以表达为：<strong style="font-weight: 600;">“同样性能的智驾产品，每两年成本需要大幅下降”</strong>。</div><div class=" pTag">也正是这种从数据迭代领悟的洞藏，在更早之前，<strong style="font-weight: 600;">飞轮效应</strong>就被Momenta作为了指引、方法论和胜利法宝。</div><div class=" pTag">所谓飞轮效应，简单说就是以数据为核心，构建数据迭代的闭环自动化，然后驱动实现L4级技术流和L2级量产数据流之间的端到端提升。</div><div class=" pTag">一旦L4高阶技术赋能到L2量产产品，并通过量产车辆产生的海量数据回流，自动化地训练算法，AI司机的能力就会一日千里，进步神速。</div><div class=" pTag">随着量产装机量的不断扩大，“飞轮”就能越转越快，智能驾驶的体验也会越来越好，Momenta的技术壁垒也会越来越高。</div><div class=" pTag">所以这也能解释，为啥高阶智能驾驶的“标配时代”，会在此时、此地到来，会由高通和Momenta率先打响第一枪。</div><div class=" pTag">这离不开高通在芯片、计算和底层AI软硬件架构上的积淀，离不开对智能车成本和性能的平衡，包括解决油车搭载需要克服的散热难题，奠定爆款基础。</div><div class=" pTag">更离不开Momenta在高阶智驾上的功力、效率和口碑，特别是飞轮效应带来的技术和产品迭代成果，让行业内外，供应链上下，真正因为看见而相信。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCzFpJCBJsgbhsSsiaZcm2YnRsjgyMZ3FxaZhibGSQnbSyRUnss4NL3TBDLMdKuP6icVtMCMb2fsKCrA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">有意思的是，在高通和Momenta联手之前，外界对于高阶智驾的标配和普及，更多是寄希望于燃油车被完全“新能源化”后，先电动化，然后智能化。</div><div class=" pTag">但两家各自领域内最好的公司，改变了这种进程，AI也好、高阶智驾也好，不应该按照能源动力形式划分阵营，更不应该在价位上造成区分。</div><div class=" pTag">AI赋能每个人，AI赋能每辆车，推动一个更加安全、便捷和高效的未来……这才是高阶智驾“标配时代”最朴素又最具价值的意义。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FtdvvoxoAZHq35nhZDcJijA">阅读原文 </a>
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 13:07:59 GMT</pubDate>
</item>
<item>
<title>AI刘强东007带货，背后大模型也就10亿参数，京东：我家数字人平均水平</title>
<link>https://posts.careerengine.us/p/6629042f34c2052868e150c5</link>
<guid>https://posts.careerengine.us/p/6629042f34c2052868e150c5</guid>
<content:encoded><![CDATA[
<div> 京东云言犀、刘强东、数字人、直播、AI
<br />
<br />
总结: 京东云言犀团队开发了刘强东的AI数字人形象"采销东哥"，进行直播带货。数字人效果逼真，展现了技术水平。京东云言犀数字人已商业化，可广泛应用。AI数字人表现出色，中看不中用，达到了新的直播带货水准。技术上可实现类似于董宇辉的AI数字人，但在伦理和感情上有待考量。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">衡宇 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">京东创始人刘强东啊，他昨天又加班了。</div><div class=" pTag">准确来说，是他的AI数字人形象“采销东哥”，昨晚开启了自己生涯第四场直播。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4pHqRB63Xibib4jG0yTwa2MQZKdiaweeQsCVcpVd458PYOVsdgQjqC6yHg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">这次东哥干的是图书采销工作。</div><div class=" pTag">与上两次直播不同，这一回直播间不仅有了数字人助理，还有多机位切换等展现方式。与此同时，和留言区及屏幕前观众的互动方式也有所增强。</div><div class=" pTag">量子位就此事询问了<strong style="font-weight: 600;">京东云言犀算法总监</strong>，得到答案是：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">每一场想侧重表示的不一样。技术的手段比较丰富，很难一场里面都推出来。</div></blockquote><div class=" pTag">不得不说，京东这回拿自家的京东云言犀数字人挤牙膏，还挺有自己的节奏<span>（doge）</span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4T8f4GhmJVRh8ah9LoKjQ49s3Lx1d37w38TVQkumc4w6anu9KJe9CSg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">一周时间里，四场刘强东数字人连播，可谓出师大捷——</div><div class=" pTag">据公开的“战报”，其首秀不到1小时，直播间观看量超2000万，带货GMV超5000万。</div><div class=" pTag">难怪网上冲浪的时候，有人评价道，AI东哥真的是“数字人带货的天花板”了。</div><div class=" pTag">而且京东自己放话，这就是京东云言犀数字人的平均技术水平，且成本不到真人直播的1/10。</div><h2>“自己的狗粮自己先吃”</h2><div class=" pTag">刘强东AI数字人“采销东哥”上播第一天起，就有许多质疑。</div><div class=" pTag"><strong style="font-weight: 600;">质疑一</strong>，真的是数字人吗？真的不是让刘强东提前坐那儿，录好视频然后再播吗？</div><div class=" pTag">且看采销东哥的表现：</div><div class=" pTag"><span><strong style="font-weight: 600;">形象</strong></span>和真人刘强东几乎一毛一样，寸头、西装、左手腕带表，肉眼难辨真伪。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4jqoCWdcl11v1rbMquIssxkNyvptgCPHVy2eDnDIDD9wy8gGNcyKefw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span><strong style="font-weight: 600;">口音</strong></span>能较好贴合唇部动作，语速快、连音多，一般语句吐字较轻，一些重点会重音表强调，寻求认同时用“啊”来衔接；耳朵尖的朋友可能还能听出他的宿迁口音。</div><div class=" pTag"><span><strong style="font-weight: 600;">动作姿态</strong></span>不算僵硬，能有头部、手部的动态动作，且动起来后整个人也受光均匀。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4EmUJrVZtlGXRhM8gsUuT0XvEvn301FDK1JO7TqHHoF18LtsV0xZlibQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">但随着直播场数的增加，这种疑惑声渐渐下去了。</div><div class=" pTag">可能大家都觉得，是在没什么可能让刘强东忙中拨冗，每天坐在那儿提前录播吧。</div><div class=" pTag"><strong style="font-weight: 600;">质疑二</strong>，如果真的是数字人刘强东，那大伙儿看到的效果，会不会是面对自家一号位做的“特供版”？</div><div class=" pTag">换言之，其他公司如果同样想用京东云言犀数字人来做主播，是不是根本达不到这个效果？</div><div class=" pTag">就这个问题，<strong style="font-weight: 600;">京东云言犀负责人</strong>是站出来给了解释的：“刘总数字人技术，代表了我们现在的通用技术。”</div><div class=" pTag">大白话就是说，用了京东云言犀数字人，所有的大V/CEO主播都能有同样的这个效果，至少在120秒之内“惟妙惟肖”。</div><div class=" pTag">如果不信，可以亲自验证——前段时间京东618招商，给所有品牌商家免费开放了数字人基础版使用30天权益，都能用上。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4YoD0kz8wP1By3osYzWsLqPoY2qxNMAxkg6EB8Ax729jsib0leRjuPBw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">京东云言犀负责人笑着表示，去年京东云就已经基于言犀大模型升级了数字人技术。</div><div class=" pTag">用句软件公司的梗，“Eat your own dog food”，自己的狗粮自己先吃，最开始团队内部先给京东云言犀负责人做了个AI数字人出来，但回头看和现在刘强东的数字人没法比。</div><div class=" pTag">2022年开始，京东云言犀数字人就已经开始商业化，目前有4000多家品牌使用。</div><div class=" pTag">去年双十一后，京东云言犀团队开始制作采销AI数字人，首先是在大时尚事业部测试，包括公众接受程度，停留时长，用户转换率，交互程度等。</div><div class=" pTag">团队心想，既然要追求刺激，那就把“Eat your own dog food”贯彻到底，干脆给公司老大也搞一个吧！</div><div class=" pTag">刘强东AI数字人“采销东哥”就这么诞生了。</div><h2>10亿参数数字人大模型轻量上阵</h2><div class=" pTag">采销东哥身后，是京东云言犀大模型团队，及其<span><strong style="font-weight: 600;">大模型做小</strong></span>后打造的10亿参数数字人大模型。</div><div class=" pTag">总的技术来看，言犀2年多前就选择了端到端的方式，即建模——驱动——渲染的一体化。以至于Sora出来后，团队惊喜发现端到端的技术方向是可取、可喜的。</div><div class=" pTag">不过，虽然和Sora是同一条路子，但最后应用的场景不太一样，言犀大模型数字人的赛道更聚焦，专注人物生成<span>（原因是团队评估人物视频生成商业价值和社会影响力可能都更大）</span>。</div><div class=" pTag">而关于端到端的路线，这里展开说两句。</div><div class=" pTag">现在基本分为两大类，一类是<strong style="font-weight: 600;">完全端到端</strong>，中间不对任何环节进行显示的建模，完全是隐性的，都在一个空间里面做；另一类是<span><strong style="font-weight: 600;">对简单基本素材的人脸建3万多个点Mesh模型</strong></span>，再去控制人物的表情、唇型，然后做纹理的渲染。</div><div class=" pTag">京东云言犀说得很明白，2种方案会根据场景需求做不同使用。</div><div class=" pTag">京东云言犀负责人表示，其间比较得意的是<strong style="font-weight: 600;">人物大姿态的动作</strong>。</div><div class=" pTag">“早期真人数字人，动作幅度比较小。基本上脸部不会怎么动，因为一旦头动了，可能就剩半个嘴唇了。”他透露，在大姿态方面做了较多技术投入，才有了现在AI刘强东的活动自如。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4j0iaQbiblvQWCqaWTuI3x7klXkJuIv8RWibWtVcoxc1PncRdDNxibViazbw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外，身为主播，语音表达无疑也十分重要。</div><div class=" pTag">既要复现真人主播的语音、语调，又要学习真人说话的习惯，如语速、语调、重音、倒吸气。</div><div class=" pTag">就拿刘强东本人来说，他讲话很少有辅助词，也较少清晰读出连接词，如“跟着”的“着”字经常被一笔带过。</div><div class=" pTag">因为出生江苏宿迁，他的话语里还是会“露馅”，冒出宿迁口音来。比如“时间”中的“sh”会有更重的鼻音；后鼻音有时会被吞掉，变成前鼻音。</div><div class=" pTag">就，还挺有特色的。</div><div class=" pTag">原本呢，京东云言犀技术团队的计划是用刘强东2017年的一段演讲音频作学习素材，但测试发现，演讲时刘强东的语气太过正式了，和直播带货有点画风不搭。</div><div class=" pTag">团队无奈把刘强东“抓”到镜头前，录了30分钟的音视频，让他闲聊自己的经历什么的。</div><div class=" pTag">用这段音频为底提取出声学特征，就能通过已经被喂了5万小时语音数据训练的言犀语音大模型合成出人工语音。</div><div class=" pTag">不过据量子位了解，京东云言犀大模型团队的最新战绩，是<strong style="font-weight: 600;">使用6秒素材复现具体某个人的声音</strong>。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4JWygicG63swibZQxRE1wEkt06pNfRdWyIuicJMGRXYgrzpoLvlicZaKQxA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">团队成员还分享了其他一些关于AI数字人背后的事：</div><div class=" pTag"><strong style="font-weight: 600;">训练过程</strong>中，主赛道锚定人物向，因此不管是从数据的采集、清洗和各方面都做了精细化聚焦。</div><div class=" pTag"><strong style="font-weight: 600;">推理实现</strong>方面，除了模型代码压缩、量化等常规操作，还对INT4和INT8进行了精度调改。</div><div class=" pTag">团队下一步计划，是把语音、视频生成两块综合到一起。</div><div class=" pTag">当然，另一部分挑战是尝试用非常小样本或零样本学习的方式就能抓住真人本尊的特点，继而生成惟妙惟肖的数字人。</div><h2>“采销东哥是京东数字人平均水平”</h2><div class=" pTag">京东云言犀负责人表示，其实京东内部对数字人有一个分级。</div><div class=" pTag"><span><strong style="font-weight: 600;">第一级</strong></span>的数字人效果，可以做真人的补充工作，处于向真人看齐阶段。</div><div class=" pTag"><span><strong style="font-weight: 600;">第二级</strong></span>数字人可以媲美真人，真人不在，也可以承担重要场合、重要时间的主播工作。</div><div class=" pTag">并且播出后，会有人分不清主播是真是假——从这个角度来说，图灵测试应该算是通过了。</div><div class=" pTag">不过，虽然在形象、表情、语音、动作复刻尚佳，但是本尊的深度思想，大模型数字人还没有办法1:1同步。</div><div class=" pTag">到了<span><strong style="font-weight: 600;">第三阶段</strong></span>，本尊和数字人之间不是替代关系，更像是真人有了个数字分身，能够真正深度抓住本尊的思想、文化、知识背景、一些理念。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4RXJJWIh7Wnoibicib5PWat6USCV3qwCqHM9O6PiblJbsKxuGEKv4m0LCyQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而且，京东自家直播间有一个<strong style="font-weight: 600;">120s战斗</strong>。</div><div class=" pTag">简单说就是直播时，如果用户在120s之内都不觉得眼前的数字人让自己别扭，就会跨过恐怖谷效应，接受这个数字人，看他的展示、听他的解说。</div><div class=" pTag">而且看到120s，因为对主播产生了信任，往往很大概率会下单。</div><div class=" pTag">“目前来看，数字人直播带货有很大机会会成为一个大的爆点。”京东云言犀负责人解释道，“主要是内容层次达到了新的水准，大家的接受度和信任度已经过了关键点了。”</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4LpOM6BgWYMiaFqia7ibhibDM4qzeavSZIPJL5QU5nt0GxbRmicdQ00ELoNQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">说回“采销东哥”，他现在几乎能很完美地被生成120s以上的形象，并且足以以假乱真。</div><div class=" pTag">也就是说，“采销东哥”现在处于京东数字人分级里的第二阶段，这也是京东云言犀数字人的平均水平。</div><div class=" pTag">团队还提到，其实目前AI大模型数字人大规模商用，技术已经不是难点了。</div><div class=" pTag">难点是什么呢？是主播个人的形象要跟整体调性相匹配，在选品、互动方面还需要下很多功夫。</div><h2>One More Thing</h2><div class=" pTag">聊着聊着，一个有趣的问题被抛出来。</div><div class=" pTag">问，未来在京东直播间，有没有可能诞生一个类似于董宇辉的AI数字人超级主播？</div><div class=" pTag">京东云言犀负责人和算法总监相视一笑，说：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag"><span>（这件事）</span><span><strong style="font-weight: 600;">技术上是有可能的，但在伦理和感情上不一定能成立</strong></span><div class=" pTag">。</div><br /><div class=" pTag">比如很多丈母娘喜欢董宇辉，是因为这个人有很实在的特质，很文雅，有知识。</div><br /><div class=" pTag">我不知道在伦理上到底之后会怎么解决……</div></div></blockquote><div class=" pTag" style="text-align: center;"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">联系</strong><strong style="font-weight: 600;">作者</strong>&nbsp;—</span></div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KnWh0nUISaHLKzTQicv5uBfZIJUibx58EQfIXv6oSM67PK5ZTxjzLVakQ/640?wx_fmt=png" /></div></div></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbOE_1zca38lGi09fGqn2pQ">阅读原文 </a>
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 13:07:59 GMT</pubDate>
</item>
<item>
<title>快速低成本构建应用，浪潮信息把企业大模型落地门槛打下来了</title>
<link>https://posts.careerengine.us/p/6629042f34c2052868e150d6</link>
<guid>https://posts.careerengine.us/p/6629042f34c2052868e150d6</guid>
<content:encoded><![CDATA[
<div> 关键词: 大模型, 浪潮信息, 企业应用, 算法, 数据

总结:<br /><br />浪潮信息推出了集算法、算力、数据和互联为一体的端到端解决方案，帮助企业用户更好地实现大模型应用落地。在大模型2.0时代，企业用户面临着数据不足、算法创新保守等问题。浪潮信息的企业大模型开发平台EPAI提供了丰富数据支持、高效微调工具，并降低了使用门槛。平台支持多种使用方式，同时保障数据安全。浪潮信息的全面布局在算力、存储、互联等方面也为大模型行业带来新格局。EPAI促进了大模型产业协作，让企业用户可以从自身做起，掌握方法和工具，助力产业AI落地发展。 <div>
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">百模大战愈演愈烈，各大厂商卷出了不同形态：</div><div class=" pTag">有的大秀肌肉，在文本长度上一骑绝尘；有的与搜索等功能深度融合，成为了全能型AI助手……琳琅满目的大模型产品令人目不暇接。</div><div class=" pTag">但对于企业用户而言，尽管这些通用大模型各有各的特色，但在解决行业任务时，表现得却并非那么完美。</div><div class=" pTag">究其“不能胜任”的原因，主要是通用大模型在特定行业的知识储备并不充足，甚至存在严重的幻觉。</div><div class=" pTag">为了弥补这样的缺陷，需要大量的行业<strong style="font-weight: 600;">数据</strong>，模型<strong style="font-weight: 600;">算法</strong>也需要进行优化，而这又会牵扯出<strong style="font-weight: 600;">算力</strong>问题……</div><div class=" pTag">也是这种背景之下，为了帮助企业用户更好地实现大模型应用落地，<strong style="font-weight: 600;">浪潮信息</strong>提出了集算法、算力、数据和互联为一体的端到端解决方案。</div><h2>大模型进入2.0时代，但落地依旧困难</h2><div class=" pTag">随着人工智能技术的快速发展，AI正在变得无处不在，影响着各种计算设备和平台。</div><div class=" pTag">从服务器到个人电脑<span>（PC）</span>，甚至是移动设备，AI算力正在渗透进每一个计算设备，面向人工智能的算力范式不断革新。</div><div class=" pTag">除了这种“<span><strong style="font-weight: 600;">一切计算皆AI</strong></span>”的大背景，人工智能的代表性产品——<span><strong style="font-weight: 600;">大模型也进入了2.0时代</strong></span>。</div><div class=" pTag">这意味着将会出现<span><strong style="font-weight: 600;">更大的模型</strong></span>，随之而来的是<span><strong style="font-weight: 600;">更多的数据需求</strong></span>，以及<span><strong style="font-weight: 600;">对算力资源的更大需求</strong></span>。</div><div class=" pTag">而<strong style="font-weight: 600;"><span>算法、算力和数据正是人工智能发展的“三驾马车”</span></strong>，但从当今发展来看，发展得都不充分。</div><div class=" pTag">首先，由于大模型的训练成本极其高昂，导致试错代价极高，进而出现了在大模型时代<strong style="font-weight: 600;"><span>对于算法的创新依旧有所保守</span></strong><span>的局面</span>。</div><div class=" pTag"><strong style="font-weight: 600;"><span>算力的资源也并不均衡</span></strong>，北京智源研究院副院长兼总工程师<strong style="font-weight: 600;">林咏华</strong>认为，大模型2.0时代，不能只关注单颗芯片的能力，而是需要考虑从芯片到服务器集群，再到数据中心的存储和计算关系，以及整个网络的协同。</div><div class=" pTag">数据方面的情况一样不乐观，随着大模型对计算规模的需求增加，<strong style="font-weight: 600;"><span>人类产生的已知数据，对于大模型而言即将甚至已经不足</span></strong>。</div><div class=" pTag">除了大模型自身发展受到算力和数据等方面的桎梏，对于企业用户来说，大模型落地还存在更多的现实问题。</div><div class=" pTag">一是大模型缺少专业的行业数据，不可避免地导致了<strong style="font-weight: 600;">幻觉问题</strong>，难以适用于企业场景。</div><div class=" pTag">另一方面，有些企业应用场景中，对模型<strong style="font-weight: 600;">窗口长度</strong>需求极大，现有的模型可能无法满足需求。</div><div class=" pTag">此外，<span><strong style="font-weight: 600;">开发难度大、技术门槛高</strong></span>，也是企业实现大模型落地的一个重要壁垒。</div><div class=" pTag">想要解决这些痛点难点，需要从上到下的整个生态为之发力，而<strong style="font-weight: 600;"><span>浪潮信息</span></strong>正是企业大模型落地助推者中的一份子。</div><h2>端到端开发企业大模型应用</h2><div class=" pTag">第十届IPF浪潮信息生态伙伴大会上，浪潮信息AI软件研发总监<strong style="font-weight: 600;">吴韶华</strong>隆重发布了企业大模型开发平台<strong style="font-weight: 600;">元脑企智EPAI</strong>。</div><div class=" pTag">EPAI平台提供了端到端的企业大模型落地解决方案，解决了企业大模型应用开发流程复杂、门槛高等困难。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4ReU1FMyN9sc09XmYblwZCFyZB7Gf73mIdTrIWt9o3x2Bb21PjialLqw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">大模型2.0时代，<span><strong style="font-weight: 600;">数据就是资产</strong></span>，掌握数据就等于掌握了话语权。</div><div class=" pTag">而EPAI提供了上亿条基础知识数据，同时还包含了自动化的数据处理工具，可以帮助用户整理行业数据和专业数据，生成高质量的微调数据和行业/企业知识库，进而打造企业专属数据资产。</div><div class=" pTag">有优质的基础+行业+企业数据作为支撑，大模型生成内容的准确性和可靠性就有了保证，<span><strong style="font-weight: 600;">幻觉问题将大幅缩减</strong></span>。</div><div class=" pTag">同时，结合检索增强生成（RAG）技术，EPAI可以解决企业知识库更新频率高但大模型微调耗时长、频率低的矛盾，保证模型能够及时获得处理最新知识的能力。</div><div class=" pTag">另一方面，EPAI还提供了高效的微调工具，支持千亿参数模型面向产业知识的快速再学习，并<strong style="font-weight: 600;">让模型具备百万Token的长文档处理能力</strong>，解决窗口长度不足的问题，快速打造领域大模型。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2chZz3rVgy8OMaZiaZFfE0fFeGppG5ibQicH0anz0JvQ91dhXkf3yenLLw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">好马当配好鞍，EPAI不仅拥有强大的企业大模型开发功能，在易用性方面也帮助开发者<span><strong style="font-weight: 600;">降低了使用门槛</strong></span>。</div><div class=" pTag">使用方式上，EPAI支持API、对话UI和智能体三种使用方式，可以面对不同的业务场景需求，并让不同技术水平的开发者都能拥有与自己能力相匹配的开发方式。</div><div class=" pTag">甚至是<span>非专业开发人员，也能在几天培训之后快速掌握平台的使用方法，摆脱专业知识的限制</span>。EPAI<span><strong style="font-weight: 600;">实现了大模型应用开发的普及化，降低了企业的用工成本</strong></span>。</div><div class=" pTag">吴韶华举例说，假如要开发一个“智能编程助手”，即使是经验非常丰富的工程师可能也需要两到三周的时间，但用了EPAI，可以非常快速地执行。</div><div class=" pTag">而且EPAI既支持包括CPU和各种GPU在内的<span><strong style="font-weight: 600;">多元算力</strong></span>，又支持包括自研的“源”大模型和其他主流开源、闭源模型，适配快，迁移成本低，为企业提供了<span><strong style="font-weight: 600;">丰富的模型和算力选择</strong></span>。</div><div class=" pTag">此外，企业用户最担心的数据安全问题，EPAI也提供了坚实保障，通过权限管理、数据加密、内容审查等多种技术手段，确保<span><strong style="font-weight: 600;">数据和模型安全</strong></span>，做到了隐私信息不泄露。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2Y4QLQnwTcoEcicOJ43GzMoa9jTnpia0RO30ibVPPPfszbKJlNAwOzPmlA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">相较于其他开发平台，浪潮信息的一个独特优势是，从“左手”的算力、模型等底层技术提供者，到“右手”的各行业软件开发商，<span><strong style="font-weight: 600;">都是浪潮信息生态中的伙伴</strong></span>。</div><div class=" pTag">这意味着，EPAI平台可以<span><strong style="font-weight: 600;">上承算力，下接应用</strong></span>，成为整个生态的“交通枢纽”，加速面向应用的快速创新。</div><div class=" pTag">EPAI为企业用户很好地解决了算法和数据问题，但浪潮信息提供的支持不止于此，而是<strong style="font-weight: 600;"><span>集算法、算力、数据、存储、互联为一体的全面布局</span></strong>。</div><div class=" pTag">在算力方面，面向越来越多的大模型推理场景，浪潮信息还联合英特尔发布可运行千亿参数大模型的AI通用服务器；存储方面，发布分布式全闪存储AS13000G7，解决大模型训练数据挑战；互联方面，发布国内首款超级AI以太网交换机 X400，加速大模型训练推理……</div><div class=" pTag">浪潮信息的这一系列布局，或将给大模型行业带来新的格局。</div><h2>EPAI将促进大模型产业协作</h2><div class=" pTag">谈及EPAI平台的意义，<strong style="font-weight: 600;">吴韶华</strong>介绍到，EPAI平台提供的是工具箱和方法论，让用户可以尽可能地发挥自己企业的价值。</div><div class=" pTag">而且，EPAI平台将能够实现<strong style="font-weight: 600;"><span>对于开发者的普惠</span></strong>，企业不必再花费大量资金构建一个高精尖的团队，也可以做起大模型。</div><div class=" pTag">通过EPAI和其所提供的方法论，企业用户可以从自己做起，掌握这样一套方法和工具，然后再去服务好、支持好他们行业的客户。</div><div class=" pTag">只有借助最适合、最高效的工具，让它在工作的时候拥有很高的效率和成功率，才能真正把产业快速地做大。</div><div class=" pTag">对此，浪潮信息高级副总裁<strong style="font-weight: 600;">刘军</strong>表示，EPAI“让我们看到大模型的另外一面，它的产业化落地的这一面”。</div><div class=" pTag">此外，EPAI对于整个产业的协作也大有裨益——</div><div class=" pTag">过去，恨不得每个人都想做大模型企业，都想自己从头彻尾都搞一套工具，但事实上不可能所有人都能把生意做大。</div><div class=" pTag">只有<strong style="font-weight: 600;"><span>依靠优质的产业协作分工</span></strong>，大家都做自己最擅长的事情，形成多元多样化的、共同去促进的生态，才能让产业AI真正落地。</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4UkKqXvp4I9KK2q7_UpHgw">阅读原文 </a>
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 13:07:59 GMT</pubDate>
</item>
<item>
<title>微软推出iPhone能跑的ChatGPT级模型，网友：OpenAI得把GPT-3.5淘汰了</title>
<link>https://posts.careerengine.us/p/662742e6745f1a3c48c18fa4</link>
<guid>https://posts.careerengine.us/p/662742e6745f1a3c48c18fa4</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">梦晨发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">Llama 3发布刚几天，微软就出手截胡了？</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4aiausUiahBaB9dptUUsShAqLpFvNYBiaTib9QNHJWSRHC5PzyLpDGUgCFg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">刚刚发布的<span><strong style="font-weight: 600;">Phi-3系列小模型</strong></span>技术报告，引起AI圈热议。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4SxsMgsoRAs0zHdZhFwsPApDKqYibCsGLopxrCkguEVL8tRPUDwiag0mA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">其中仅<span><strong style="font-weight: 600;">3.8B参数的Phi-3-mini</strong></span>在多项基准测试中<span><strong style="font-weight: 600;">超过了Llama 3 8B</strong></span>。</div><div class=" pTag">为了方便开源社区使用，还特意设计成了与Llama系列兼容的结构。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4P9mg5xQ994cgffyLrU0sHFqFpDOIpkAIH2U6ic0KISShpAqfXIicFSicg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">微软这次打出<span><strong style="font-weight: 600;">“手机就能直接跑的小模型”</strong></span>的旗号，4bit量化后的phi-3-mini在iPhone 14 pro和iPhone 15使用的<span><strong style="font-weight: 600;">苹果A16芯片</strong></span>上跑到每秒12 token。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU413f534NPmacYCwMrOZ2s9sZY0LgjiaXnj2icO2y98mgJE5jiagcI722yw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这意味着，现在手机上能本地运行的最佳开源模型，已经做到ChatGPT水平。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4qX2hTh6aXKJaZmf8XE2F3zZOP0OGT3F7DBzRqZwTYaEBuGAajfm5icA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在技术报告中还玩了一把花活，让phi-3-mini自己解释为什么构建小到手机能跑的模型很令人惊叹。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4yuDPkYkEFyibeOQkVcoHDhJKHDDAcC9KVaBFybJwQOQCZDAiaxyCBGQQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">除了mini杯之外，小杯中杯也一并发布：</div><div class=" pTag"><span><strong style="font-weight: 600;">Phi-3-small</strong></span><span>，</span>7B参数，为支持多语言换用了tiktoken分词器，并额外增加10%多语种数据。</div><div class=" pTag"><span><strong style="font-weight: 600;">Phi-3-medium</strong></span>，14B参数，在更多数据上训练，多数测试中已超越GPT-3.5和Mixtral 8x7b MoE。</div><div class=" pTag"><span style="font-size: 17px; text-align: left;">（</span><span style="font-size: 17px; text-align: left;">大杯他们目前不打算做）</span></div><div class=" pTag">作者阵容一看也不简单，一眼扫过去MSRA和MSR雷蒙德团队都投入了不少人。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU460rqB19WIlZ4rN6aAQb53jM7lBy5xKCfWUWpaicnMugmQ2uaU4DOiaDQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么，Phi-3系列到底有什么独特之处呢？</div><div class=" pTag">根据技术报告中披露，其核心秘诀就在于<span><strong style="font-weight: 600;">数据</strong></span>。</div><div class=" pTag">去年团队就发现，单纯堆砌参数量并不是提升模型性能的唯一路径。</div><div class=" pTag">反而是精心设计训练数据，尤其是利用大语言模型本身去生成合成数据，配合严格过滤的高质量数据，反而能让中小模型的能力大幅跃升。</div><div class=" pTag">也就是训练阶段只接触<span><strong style="font-weight: 600;">教科书级别</strong></span>的高质量数据，<span><strong style="font-weight: 600;">Textbooks are all you need</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4tL0ziaqh6s4h6vw0mmOAdC0MQWuagZ2N4TPuviaMVrEomJMdPtQHtFww/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">Phi-3也延续了这一思路，这次他们更是下了血本:</div><ul class="list-paddingleft-1"><li><div class=" pTag">投喂了多达3.3万亿token的训练数据（medium中杯是4.8万亿）</div></li><li><div class=" pTag">大幅强化了数据的”教育水平”过滤</div></li><li><div class=" pTag">更多样化的合成数据，涵盖逻辑推理、知识问答等多种技能</div></li><li><div class=" pTag">独特的指令微调和RLHF训练，大幅提升对话和安全性</div></li></ul><div class=" pTag">举个例子，比如某一天足球比赛的结果可能对于大模型是良好的训练数据，但微软团队<span><strong style="font-weight: 600;">删除了这些加强知识的数据</strong></span><span><strong style="font-weight: 600;">，留下更多能提高模型推理能力的数据</strong></span>。</div><div class=" pTag">这样一来，对比Llama-2系列，就可以用更小的参数获得更高的MMLU测试分数了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4B7ffNAoINc4flFWtXKquoPkKS7MCnrQJNAQ185dLPeXdPlZNmYR31Q/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不过小模型毕竟是小模型，也不可避免存在一些弱点。</div><div class=" pTag">微软透露，模型本身参数中没能力存储太多事实和知识，这一点也可以从TriviaQA测试分数低看出来。</div><div class=" pTag">缓解办法就是联网接入搜索引擎增强。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4sT3DmiaMgEJOvttLnqoJEhYHrdwGZ1cLZPguYdxgiaqcFzCDXq6WrXgg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">总之，微软研究院团队是铁了心了要在小模型+数据工程这条路上走下去，未来还打算继续增强小模型的多语言能力、安全性等指标。</div><div class=" pTag">对于开源小模型超过ChatGPT这回事，不少网友都认为压力现在给到OpenAI这边，需要赶快推出GPT-3.5的继任者了。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4E5LDIN8ibaEtBTCrdric5Hx3qRBV8MRUNXbAiaf0ZNQUbts5cA3ENkTgQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://arxiv.org/abs/2404.14219</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FF9K0A_f4CFgfFyY3bf4F8g">阅读原文 </a>
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 05:11:02 GMT</pubDate>
</item>
<item>
<title>对话蚂蚁李建国：当前AI写代码相当于L2.5，实现L3后替代50％人类编程</title>
<link>https://posts.careerengine.us/p/662742e5745f1a3c48c18f95</link>
<guid>https://posts.careerengine.us/p/662742e5745f1a3c48c18f95</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">白交 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">超70%代码问题，单纯靠基座大模型是解决不了的；</div><div class=" pTag">未来3-5年，人类50%编程工作可以被替代，有些环节甚至完全自动化。</div></blockquote><div class=" pTag">蚂蚁集团代码大模型CodeFuse负责人李建国说道。</div><div class=" pTag">当下，AI代码生成领域正在野蛮式生长，巨头涌入，AI员工频频上线企业；首个AI程序员Devin被曝造假…… 面对风起云涌的代码生成变革，李建国给出了这样一个明确论断。</div><div class=" pTag"><strong style="font-weight: 600;">李建国</strong>是谁？</div><div class=" pTag">清华大学博士，机器学习、深度学习深耕十余年，论文被引万余次。在他的带领下，蚂蚁内部正全面推行AI编程。每周已有<strong style="font-weight: 600;">超五成程序员</strong>使用CodeFuse，目前<strong style="font-weight: 600;">CodeFuse生成代码整体采纳率为30%</strong>，已经属于整个AI编程工具中能力第一梯队，最强Copilot代码整体采纳率差不多在35%。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2GBSzSIGIPuXTuosiaTcAzVJI398hq6cFRU48tF5NVepZKspsn1YZE5Q/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">而在开源这边，在各社区网站上CodeFuse下载量已经达到<strong style="font-weight: 600;">170万左右</strong>。</div><div class=" pTag">因此不管是学术的权威性，还是产业落地的代表性，李建国博士极具话语权。于是在代码生成模型和产品爆发式发展的当下，量子位同李建国博士展开了进一步交流。</div><div class=" pTag">核心观点如下：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">编写代码在整个企业研发过程中所占的比重可能连1/5，甚至1/10都不到；</div></li><li><div class=" pTag">要实现项目级的需求实现，从原子级需求端到端渐进发展的模式是切实可行的；</div></li><li><div class=" pTag"><strong style="font-weight: 600;">AI程序员成为企业运营中的新常态</strong>已经是势不可挡的趋势；</div></li><li><div class=" pTag">超70%代码问题，单纯靠基座大模型是解决不了的；</div></li><li><div class=" pTag">目前自然语言编程处于L2.5阶段，按照万物摩尔定律的发展趋势，未来3-4年达到L3，甚至接近L4的水平是有可能的。</div></li><li><div class=" pTag">相较于前、后端的软件工程师，<strong style="font-weight: 600;">AI全栈工程师需求更大</strong>。</div></li><li><div class=" pTag">当前代码生成变革所面对的挑战包括：端到端代码生成能力、Agent推理能力、复杂需求拆解、跨模态横向交互、安全可信可靠。</div></li></ul><h2>编写代码只占整个研发生命周期1/5不到</h2><div class=" pTag">首先，程序员这个行业历史并不算长，从20世纪50年代至今，大约有七八十年的历史。随着技术的进步，编程工具不断更新迭代（打孔- VI编辑器-集成开发环境-辅助编程工具），程序员的工作效率得到了显著提升。</div><div class=" pTag">来到大模型时代，相关模型和产品演化迭代十分迅速，可以说十分的“卷”。</div><div class=" pTag">对个人开发者而言，AI编程工具只需完成从需求到代码实现的闭环过程就够了，就像Copilot这样的工具。<strong style="font-weight: 600;">他们更倾向于关注如何高效地实现需求</strong>。</div><div class=" pTag">但从企业维度则更关注整个研发流程的效率提升，除了关注代码生成的安全可靠可信，测试构建、发布运维以及数据洞察等方面也是至关重要的。</div><div class=" pTag">我们期望能够有一个研发智能体，甚至是一个智能总线（bus），它能够与各个Agent进行交互，并将任务分发下去——从架构设计到前端实现，再到后端开发，以及安全测试和功能测试，最后是效能方面的持续集成/持续部署（CICD）和运维自动化。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2wV8qibuNGqDEfKvWwBfV60pwMrMUHwSulGVKpn45YmctxD2wHSfktTQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>测试-自然语言生成终端用例</h6><div class=" pTag">整个系统上线后，还能够自动进行运维布控，并分析产品的用户访问量（UV）、页面浏览量（PV）等数据。</div><h6 style="text-align: center; font-size: 17px;"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2czrrUH1JnhtqgJu4TlQfk7DspUjHvkp33P7DAARHhcic5ibjHZtb43JQ/640?wx_fmt=gif&amp;from=appmsg" /></div></div></strong></h6><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>运维-监控解读</h6><div class=" pTag"><strong style="font-weight: 600;">编写代码在整个过程中所占的比重可能连五分之一或十分之一都不到</strong>。但如果这样的Agent能将所有环节高效连接起来，从而真正提升整个流程的效率。</div><div class=" pTag">再加上当前程序员实际所面临的痛点在于，市面上一些产品大多是原子级能力的实现——通过单体大模型只能解决30%的代码补全，无法解决更多的代码问题，比如跨库的函数调用。</div><div class=" pTag">基于这样的行业思考，去年9月份开始，我们开源了<strong style="font-weight: 600;">CodeFuse</strong>，并明确提出要<strong style="font-weight: 600;">构建全生命周期的代码大模型</strong>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2e8xLYhsaQ23ibbA3lPJ5XWOMicZohQXe0peJqQiahZG2nOkX7Kv0U4g7w/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">目前，我们已经发布基础模型，并持续开发和开源相关的仓库，涵盖了从需求设计、编程开发、测试构建、发布运维、到数据洞察分析等多个方面，在modelscope和huggingface上<strong style="font-weight: 600;">模型下载量已经达到170万左右</strong>。</div><div class=" pTag">下一步，我们计划进行项目级的需求实现，这相当于去实现一个全新的系统。这对基础模型提出更高的要求——</div><div class=" pTag">自然语言理解的能力至少达到GPT-4或GPT-4.5的水平。但从目前的情况来看，我们更倾向于采取一种<strong style="font-weight: 600;">渐进</strong>的模式。</div><div class=" pTag">我们首个MileStone是<strong style="font-weight: 600;">解决仓库内及跨仓库的需求实现问题</strong>，包括API调用、服务调用，以及涉及到的外部中间件版本更新问题。</div><div class=" pTag">如果我们能够妥善处理这些问题，就能解决刚才提到的70%问题中很大一部分（比如20%的问题），这将显著提高代码采纳率，并让用户感到满意。</div><div class=" pTag">最终要实现项目级别的需求任重而道远。我认为，代码基础模型和Agent技术需要同步快速发展，才能达到我们的目标。</div><div class=" pTag">我们的思路相对保守，因为就基础模型的要求而言，我认为短期内国内要达到GPT水平还存在一定差距。</div><h2>大模型对软件开发的范式改变</h2><div class=" pTag"><strong style="font-weight: 600;">AI程序员成为企业运营中的新常态</strong>已经成为势不可挡的趋势。不管是像Devin这种AI程序员，还是我们提到的全生命周期研发智能体，大模型对整个软件研发范式都是非常大的提效。</div><div class=" pTag">过去遇到不懂的问题，人们可能首先会去Google或百度上搜索，而现在，他们可以直接在代码中提问，随即获得一个相对精确的结果，采纳后即可使用。</div><div class=" pTag">我认为这是一个巨大的效率提升，它代表着进步。人们可以将更多的精力释放出来，投入到更具创造性的工作中去。</div><div class=" pTag">前段时间，CodeFuse发布了<strong style="font-weight: 600;">图生代码</strong>的功能，它可以通过在界面上简单画一个框，就能自动生成相应的代码。</div><div class=" pTag">以往可能需要编写数百行代码的工作，现在只需一次点击和画框操作就能实现。</div><div class=" pTag">而要从产品设计的角度来看，我认为<strong style="font-weight: 600;">实现无缝接入和无感体验是至关重要的</strong>。</div><div class=" pTag">这意味着产品应能平滑地融入现有的工作模式中，用户在使用过程中几乎不会意识到它的存在，从而极大地提升用户体验，并推动整个研发流程的创新和进步。</div><div class=" pTag">例如，我们内部每周有超过一万人的智能代码生成活跃用户，很多人都没意识到自己在使用CodeFuse，在日常使用IDE插件、浏览器的过程中，用户已经不知不觉地使用了我们的产品。</div><div class=" pTag">我们的目标是服务于整个研发的全生命周期。如果能够实现这一点，那将是一个革命性的成功。</div><h2>现在AI写代码相当于L2.5</h2><div class=" pTag">目前整个代码生成领域，可能处于一个类似于自动驾驶技术中的L2.5级别，许多公司都处于这一水平。</div><div class=" pTag">比如自动驾驶L2.5级别的功能，如车道线辅助、前方碰撞检测等，这些都是作为整体存在的一部分。在大模型领域，也看到了类似的补充功能，包括解释、注释、简化优化和单元测试等。</div><div class=" pTag">我们接下来的目标是在<strong style="font-weight: 600;">某些特定场景下实现L3级别的完全自动化</strong>，这是有可能实现的。例如，在效能领域中的持续集成<span>（CICD）</span>场景，就有可能通过大模型的驱动来自动完成，包括触发检查、提交，甚至创建拉取请求<span>（PR）</span>等操作。</div><div class=" pTag">然而，要实现全场景、全链路的自动化，前端可能还需要一段时间才能发展起来，复杂的项目级的需求拆解特别是特定领域的拆解，也面临较大挑战。我认为可能还需要3-5年的时间，在万物摩尔定律的推动下，整个社区，包括我们自己的不断努力和发展。</div><div class=" pTag">到那时候，我们可以期待从当前的状态发展到一个新的阶段——</div><div class=" pTag">例如，<strong style="font-weight: 600;">从Copilot到co-worker</strong>，现在可能有20%到30%的编程工作可以被替代，未来这个比例可能会提高到50%，甚至有些环节可以完全被自动化取代，释放人去做更有创意的工作。</div><div class=" pTag"><strong style="font-weight: 600;">甚至成为一个full agent</strong>。虽然可能无法完全替代人类，但在未来3-5年内，达到L3甚至接近L4的水平是有可能的。</div><div class=" pTag">正如自动驾驶技术一样，虽然已经提出很多年，许多人声称已经达到L4级别，但实际上许多场景仍然处于L2.5到L3级别。要实现全场景的自动化，人类仍然需要在其中扮演一个重要的角色。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2260h339wapoCVMpuA83UXPIndHe2Spf0G0wWLsnSXaOPsqMDnnOMfw/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">这样一来，软件工程人员的定位其实也在发生变化。以前大家可能专注于前端或后端的开发工作。而现在，<strong style="font-weight: 600;">AI全栈工程师的需求更大</strong>。</div><div class=" pTag">过去所谓的全栈工程师意味着前端、后端和数据都懂，但现在可能还需要理解算法。随着大模型发展，前端和后端的工作可能会逐渐由大模型辅助，即作为协作者<span>（Co-worker）</span>来分担部分功能，从而释放出开发者的时间。这样开发者就可以将更多时间投入到提升新的技能上，比如对产品的深入理解，对用户体验的关注，对算法创新等。</div><div class=" pTag">基于对整个领域进行了深入的探索，我发现要进一步去实现还有不少挑战，主要有五个方面：</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">端到端代码生成能力</strong></div></li></ul><div class=" pTag">基础模型层面，目前主要是实现代码补全的功能，但在实际应用中只有大约30%问题可以通过这种方式解决，剩余的70%则需要<strong style="font-weight: 600;">端到端代码生成能力，需要跨文件、跨代码库</strong>，甚至跨代码库和文档库的理解和交互。</div><div class=" pTag">所谓的端到端，对于一个代码库而言，一个典型的例子，我们需要能够直接调用库中的API，修复问题（issue），甚至能够复用跨库的中间件能力。</div><div class=" pTag">然而，仅凭基础模型是无法实现这些的，我们还需要探索更多的能力。</div><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag"><strong style="font-weight: 600;">Agent推理能力</strong></div></li></ul><div class=" pTag">尽管最近Devin 被曝出演示视频存在造假，备受关注，但我认为它还是代表了一种趋势、一种技术流派——</div><div class=" pTag"><strong style="font-weight: 600;">如何将定制工具调用与大型模型相结合，实现整个工作流程的自动化</strong>。这个问题，尤其是扩展到全生命周期，实际上相当困难，尤其是面向云后端的研发环境，工具种类繁多。</div><div class=" pTag">比如面向前端应用可能只有天气预报、查询火车票、预定酒店等十几个工具，但在云后端，则可能会有数百个甚至上千个工具，每个工具都包含数十个参数。</div><div class=" pTag">除此之外，还有<strong style="font-weight: 600;">需求拆解、跨模态横向交互、安全可信可靠</strong>的挑战。</div><div class=" pTag">尤其<strong style="font-weight: 600;">代码的安全可信可靠</strong>，像蚂蚁这样的企业级用户，需要应对面向金融级别的高可用性和安全性的要求，也充满了挑战。</div><div class=" pTag">不过也正因为在金融级垂直场景的深耕，包括资源配置和历史经验积累，蚂蚁也构成了属于自己的场景优势。</div><div class=" pTag">首先，我们拥有涵盖整个生命周期各个环节全方位的团队，尤其在双十一等大型促销活动期间的高可用性方面经验丰富，这有助于推进全生命周期的代码大模型，这是我们与外部的主要区别之一。</div><div class=" pTag">其次，我们在特定领域，如金融领域，以及前端领域，都有一定经验积累，尤其是在支付系统等对安全性要求极高的场景中。这些积累使我们在安全性、可靠性和可信度方面具有差异化优势。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb26tvzLeg3wDFzxaKWkdycTg4SzV2lBYy8SfY8pYKicpsibJqibDiaT6FdIA/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><div class=" pTag">虽然挑战不少、道阻且长，但我认为，蚂蚁将携手开源社区一起努力，在万物摩尔定律的牵引下，未来两三年可以一定程度解决好这个问题。</div><h2>One More Thing</h2><div class=" pTag">最后，面对当下大模型发展，李建国博士忍不住感叹：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">我以前做深度学习，那时候非常卷，可能2019年之前，我发现这个领域已经卷不动了，跳出来做NLP，发现这个领域也还是更加的卷。</div><div class=" pTag">但不得不承认，大模型再次点燃了NLP、视觉处理、代码生成等各个领域的热度，焕发新的活力。</div></blockquote><div class=" pTag">对于接下来的发展，李建国点名最看好<strong style="font-weight: 600;">具身智能</strong>的发展，这将是未来5到10年的研究热点。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag">它将成为数字世界与物理世界之间的桥梁，能够感知并执行操作。这可能会带来类似Matrix（黑客帝国）这样的场景的巨大进步，甚至可能像电影《终结者》中展示的那样，成为真正的巨大飞跃。</div></blockquote><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FXAnMM8crpyjiCtg0UwqRzw">阅读原文 </a>
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 05:11:01 GMT</pubDate>
</item>
<item>
<title>大模型一对一战斗75万轮，GPT-4夺冠，Llama 3位列第五</title>
<link>https://posts.careerengine.us/p/662742e5745f1a3c48c18f8d</link>
<guid>https://posts.careerengine.us/p/662742e5745f1a3c48c18f8d</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">关于Llama 3，又有测试结果新鲜出炉——</div><div class=" pTag">大模型评测社区LMSYS发布了一份大模型排行榜单，Llama 3位列第五，英文单项与GPT-4并列第一。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4tNU5Ndu7V3QPRWtDDLHVJX5iaoILS1RmfyWI8VgpqsGiaElFTzN7TsSA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">不同于其他Benchmark，这份榜单的依据是模型一对一battle，由全网测评者自行命题并打分。</div><div class=" pTag">最终，Llama 3取得了榜单中的第五名，排在前面的是GPT-4的三个不同版本，以及Claude 3超大杯Opus。</div><div class=" pTag">而在英文单项榜单中，Llama 3反超了Claude，与GPT-4打成了平手。</div><div class=" pTag">对于这一结果，Meta的首席科学家LeCun十分高兴，转发了推文并留下了一个“Nice”。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4AGjVtEAq0kibjD7kD8dOFe7ibymFEVAua8fjrznXWiaY6HZjXnd0Uibpjw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">PyTorch之父Soumith Chintala也激动地表示，这样的成果令人难以置信，对Meta感到骄傲。</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag"><div class=" pTag">Llama 3的400B版本还没出来，单靠70B参数就获得了第五名……</div><br /><div class=" pTag">我还记得去年三月GPT-4发布的时候，达到与之相同的表现几乎是一件不可能的事。</div><br /><div class=" pTag">……</div><br /><div class=" pTag">现在AI的普及化实在是令人难以置信，我对Meta AI的同仁们做出这样的成功感到非常骄傲。</div></div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4MbRzr8ZZJqq3gBHic0UCUibOK3Zia75x1Iv1yz2kQIKp25uzbdbcTeuBw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么，这份榜单具体展示了什么样的结果呢？</div><h2>近90个模型对战75万轮</h2><div class=" pTag">截至最新榜单发布，LMSYS共收集了近75万次大模型solo对战结果，涉及的模型达到了89款。</div><div class=" pTag">其中，Llama 3参与过的有1.27万次，GPT-4则有多个不同版本，最多的参与了6.8万次。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU45ytH39YQyLgdxqBicAwTCTo1OrnANuskQyVPj1A0mD12D5kmY8yCofQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">下面这张图展示了部分热门模型的比拼次数和胜率，图中的两项指标都没有统计平局的次数。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4OgOibrYicWo7eJJ8IvNicGortJ4mpiaKfwQN26tgqHv82sT6vic5dkKIOJg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">榜单方面，LMSYS分成了总榜和多个子榜单，GPT-4-Turbo位列第一，与之并列的是早一些的1106版本，以及Claude 3超大杯Opus。</div><div class=" pTag">另一个版本（0125）的GPT-4则位列其后，紧接着就是Llama 3了。</div><div class=" pTag">不过比较有意思的是，较新一些的0125，表现还不如老版本1106。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4tNU5Ndu7V3QPRWtDDLHVJX5iaoILS1RmfyWI8VgpqsGiaElFTzN7TsSA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而在英文单项榜单中，Llama 3的成绩直接和两款GPT-4打成了平手，还反超了0125版本。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4TMsLibYpUgJf7Ub6DTz7ASc6fpTSiary4NURATXD3gIDqX2daLdJvqCg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">中文能力排行榜的第一名则由Claude 3 Opus和GPT-4-1106共享，Llama 3则已经排到了20名开外。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4jHr1xib783XyPxLOxaO3OWbMoxcocEbnjrRXicZEKRZtbm6qYZFKvwibg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">除了语言能力之外，榜单中还设置了长文本和代码能力排名，Llama 3也都名列前茅。</div><div class=" pTag">不过，LMSYS的“游戏规则”又具体是什么样的呢？</div><h2>人人都可参与的大模型评测</h2><div class=" pTag">这是一个人人都可以参与的大模型测试，题目和评价标准，都由参与者自行决定。</div><div class=" pTag">而具体的“竞技”过程，又分成了battle和side-by-side两种模式。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU47ia4ib56B1g73QgKto6okfcGD3Z31nVvib6MfzVbsCCyic16WWcfHrv7fw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">battle模式下，在测试界面输入好问题之后，系统会随机调用库中的两个模型，而测试者并不知道系统到底抽中了谁，界面中只显示“模型A”和“模型B”。</div><div class=" pTag">在模型输出答案后，测评人需要选择哪个更好，或者是平手，当然如果模型的表现都不符合预期，也有相应的选项。</div><div class=" pTag">只有在做出选择之后，模型的身份才会被揭开。</div><div class=" pTag">side-by-side则是由用户选择指定的模型来PK，其余测试流程与battle模式相同</div><div class=" pTag">不过，只有battle的匿名模式下的投票结果才会被统计，且在对话过程中模型不小心暴露身份就会导致结果失效。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4lTFNR4tBIHdCbP6yIS0F6qRNTsAfs95NK1ztmfY3rsCW3NN8nvZDZA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">按照各个模型对其他模型的Win Rate，可以绘制出这样的图像：</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4A908XrCT0SUlNK47G7vua1GbBueScpRX8ETRqEGcFUc2RfLKgPicKkw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h6 style="text-align: right; font-size: 17px;"><strong style="font-weight: 600;">△</strong>示意图，较早版本</h6><div class=" pTag">而最终的排行榜，是利用Win Rate数据，通过Elo评价系统换算成分数得到的。</div><div class=" pTag">Elo评价系统是一种计算玩家相对技能水平的方法，由美国物理学教授Arpad Elo设计。</div><div class=" pTag">具体到LMSYS，在初始条件下，所有模型的评分（R）都被设定为1000，然后根据这样的公式计算出期待胜率（E）。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4ElicSz0e1lXLlD89rRahMeUgsdqvNJLlFkheHPMib9EGc2vnYrmIsKMg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">随着测试的不断进行，会根据实际得分（S）对评分进行修正，S有1、0和0.5三种取值，分别对应获胜、失败和平手三种情况。</div><div class=" pTag">修正算法如下式所示，其中K为系数，需要测试者根据实际情况调整。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4H0E7VnDwMS1MgyR2gzpLwke5jtklfjyFibgWibOibBJrJRnedUXJTFcyQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">最终将所有有效数据纳入计算后，就得到了模型的Elo评分。</div><div class=" pTag">不过实际操作过程中，LMSYS团队发现这种算法的稳定性存在不足，于是又采用了统计学方法进行了修正。</div><div class=" pTag">他们利用Bootstrap方法进行重复采样，得到了更稳定的结果，并估计了置信度区间。</div><div class=" pTag">最终修正后的Elo评分，就成了榜单中的排列依据。</div><h2>One More Thing</h2><div class=" pTag">Llama 3已经可以在大模型推理平台Groq<span>（不是马斯克的Grok）</span>上跑了。</div><div class=" pTag">这个平台的最大亮点就是“快”，之前用Mixtral模型跑出过每秒近500 token的速度。</div><div class=" pTag">跑起Llama 3，也是相当迅速，实测70B可以跑到每秒约300 Token，8B版本更是接近了800。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU403WS0uxNRe9sBSnfgKiaiavlgcdYb4RTKUM1pu8mQTVL49MiaianiaPj6zg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]https://lmsys.org/blog/2023-05-03-arena/</div><br /><div class=" pTag">[2]https://chat.lmsys.org/?leaderboard</div><br /><div class=" pTag">[3]https://twitter.com/lmsysorg/status/1782483699449332144</div></span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fulo0CiwMvmnE90JsmjJhlg">阅读原文 </a>
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 05:11:01 GMT</pubDate>
</item>
<item>
<title>华为P70闪拍功能意外爆火，CTO亲自下场解读技术原理</title>
<link>https://posts.careerengine.us/p/6626424e52c1a75f6b106b5a</link>
<guid>https://posts.careerengine.us/p/6626424e52c1a75f6b106b5a</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">克雷西 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">一段博主拍摄的视频，让华为P70的抓拍功能意外火了……</div><div class=" pTag">注意看，这里有一个高速运转的机械，是不是让你看得已经眼花缭乱了？</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2LYD0lTv6AlNSPNicoJial6icubehIRvzS92ImyOCt9gn83AGIfST5vqMw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">但P70手机可以秒秒钟捕捉到高清大图，和视频抽帧的结果对比一下就高下立判了。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2SDoibaPdIhd5GRDB9mc9OicaSnsMoYDe3oFFgibdichXCYkM8sXsEpVepQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在博主拍摄的现场，这张照片就已经让周围的观众为之惊艳，引发一片惊叹之声。</div><div class=" pTag">微博上更是一片赞叹之声，其中还不乏知名科技博主宝玉、清华大学计算机系教授马少平等大佬的夸赞。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb27iaLCRy5wSYtPHFfVndV1wFcqAZFMENZvT9Hp3HXEJxoTeWDIia3rSBQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">其背后的原理也引发了猜测，还有人直接@华为终端的CTO求讲解，结果CTO亲自发文介绍了背后的全新技术。</div><h2>AI算法功不可没</h2><div class=" pTag">Pura 70中搭载了名为“XD Motion”的运动引擎，核心原理是双快门、双曝光，再结合AI算法，对照片进行高清复原。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2aPibbMOCznIt3ebRUYDMdktTMMmbQkZEcxjnO4P1HFrnseno0iczUmvA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">在拍摄高速运动的物体时，有曝光时长不同的两个摄像头同时工作，分别完成不同的任务。</div><div class=" pTag">曝光时间短的摄像头负责捕捉主要物体的细节，长曝光摄像头的任务则是记录下相对固定的背景信息。</div><div class=" pTag">对于这种操作方法的优势，摄影博主木析给出了这样的分析，并获得了CTO官方认证：</div><blockquote style="font-size: 17px; text-align: start;"><div class=" pTag"><div class=" pTag">长曝光可以提高信噪比，但会形成动态模糊；短曝光可以精准定格物体形态，但噪声较高。</div><br /><div class=" pTag">所以通过计算让两者进行优势互补，在提升信噪比的同时，又保障了图片的清晰度。</div></div></blockquote><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2ia8yTUPibUfIDibvUJPZ5qyLiaS3MoKzjoSYsS7HAs2JDLWTLA9LaFvj2w/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">而至于在两个摄像头完成各自的工作后如何合二为一，就到了AI登场的时间了。</div><div class=" pTag">系统会通过AI运动矢量计算，将两次曝光的图片进行局部特征匹配，通过计算将模糊的图像复原，得到高清照片。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2H7ibGnKNPhgCHvsKPERIrnXhb0uQ10icDUXKjdmFCJRdDkcldMdae1yw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">比如开头看到的照片，实际上就经历了这种从模糊到清晰的处理运算过程。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2EPxZlgaNEJS2rSm8sVGvyvaVPbBknQSkefWFZia8oy0mibBsyxxIkEQg/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">据介绍，在算法的加持下，在保证抓拍率的同时，Pura 70可以大幅度还原细节，最高可抓拍时速300km/h的运动物体。</div><div class=" pTag">这样的速度意味着，飞驰的赛车、快速奔跑的宠物，甚至连运行中的高铁，都能抓拍出高清晰度的照片。</div><div class=" pTag sectionReplaced" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2DZNGrohciasykKGEgvJd9qnlcyLcCnHh5r7emUcrHZG5ro2htanVItw/640?wx_fmt=gif&amp;from=appmsg" /></div></div></div><div class=" pTag">有网友看过后调侃说，大嘴又躲在手机里P图了。</div><div class=" pTag">不过正经地讲，虽然是融合了AI算法，但的确能适应许多场景需求。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb283q0yp2bNu2qWqxj4QTGg8TFOiadGKKpicicw4wV3KYuaHISAOEib0IS9g/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>一切终端终将走向AI</h2><div class=" pTag">用算法高速捕捉图像，只是AI在手机端诸多应用中的冰山一角。</div><div class=" pTag">单说华为P70，就集成了智能修图、多模态大模型等众多AI功能，其他厂商推出的AI手机更是不胜枚举。</div><div class=" pTag">不仅是像华为、小米、OV这些手机大厂，像高通这样的芯片供应商也在根据AI的算力特点调整着自己的产品。</div><div class=" pTag">总之，在AI迅速发展的时代，一切的终端设备，包括手机，走向智能化都是必然的趋势。</div><div class=" pTag">但具体的实现方式，可能生态中的每个厂商，都有自己独特的道路。</div><div class=" pTag">不过可以肯定的是，包括华为在内，认识到这一趋势的厂商，已然在一条新的赛道上卷起来了。</div><div class=" pTag"><span style="font-size: 17px;">参考链接：</span><br /><span style="font-size: 17px;">https://weibo.com/1945906841/Oar8yDASU</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FX7VmHWS-7-h74TfJHG3Zfw">阅读原文 </a>
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 10:56:14 GMT</pubDate>
</item>
<item>
<title>印象笔记唐毅：AI如何升级你的“第二大脑”｜中国AIGC产业峰会</title>
<link>https://posts.careerengine.us/p/6626423b6984cd5f2aa50dfa</link>
<guid>https://posts.careerengine.us/p/6626423b6984cd5f2aa50dfa</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">编辑部 整理自 AIGC峰会</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag"><div class=" pTag">百模大战之后，大伙儿或许有个共识：</div><br /></div><div class=" pTag">现在不缺大模型，缺的是怎么更好地把大模型用起来的方法。</div><div class=" pTag">有个现成的例子是，<strong style="font-weight: 600;">印象笔记</strong>一直被很多知识工作者当成自己的“第二大脑”来用，在AIGC时代，用户看到了它更智能的改变。</div><div class=" pTag">其实早在2018年，印象笔记就在AIGC的领域里开启了自己的摸爬滚打，几年下来，积累了不少经验和思考。</div><div class=" pTag">在本次中国AIGC产业峰会上，<strong style="font-weight: 600;">印象笔记董事长兼CEO唐毅</strong>从知识管理的角度，分享了印象笔记在AIGC领域，从技术到应用和产品的所见所闻、所思所感。</div><div class=" pTag sectionReplaced"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDFvCrRxT3Q6KkhlpJcWeEDNOQOKTG83XeyiaOhlblU6kBvzbyRCOPTZlOqCuJWBNoImrjfV4Cup2A/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">为了完整体现唐毅的思考，在不改变原意的基础上，量子位对演讲内容进行了编辑整理，希望能给你带来更多启发。</div><div class=" pTag">中国AIGC产业峰会是由量子位主办的行业峰会，20位产业代表与会讨论。线下参会观众近千人，线上直播观众300万，获得了主流媒体的广泛关注与报道。</div><h2>话题要点</h2><ul class="list-paddingleft-1" style="text-align: start; font-size: 17px;"><li><div class=" pTag">模型算法进展缓慢，算力投入与收益不成比例；</div></li><li><div class=" pTag">公域数据穷尽，合成数据使用导致模型输出效果下降；</div></li><li><div class=" pTag">小型化、垂直化的模型可以更高效地处理问题；</div></li><li><div class=" pTag">强调了AI交付和模型之间的中间层——复合AI系统的重要性；</div></li><li><div class=" pTag"><div class=" pTag">AIGC产品的交互不是绝对的LUI</div><span>（语言用户界面）</span><div class=" pTag">或者CUI</div><span>（对话式用户界面）</span><div class=" pTag">；</div><br /><div class=" pTag">……</div></div></li></ul><div class=" pTag"><span>以下为唐毅演讲全文：</span></div><h2>大量使用合成数据导致模型输出效果下降</h2><div class=" pTag">大家下午好，我是印象笔记唐毅，我今天演讲的题目是《用AI驱动的第二大脑实现增强人生》。</div><div class=" pTag">针对AIGC技术，我认为从技术到模型、算法、实践和应用的一系列垂直和落地的思考是非常重要的。所以，今天我从知识管理的角度，分享一下印象笔记<strong style="font-weight: 600;">从技术到应用和产品</strong>的一些想法。</div><div class=" pTag">首先简单介绍一下印象笔记，它源于硅谷的一款叫<strong style="font-weight: 600;">Evernote</strong>的产品。</div><div class=" pTag">一直以来，印象笔记的愿景就是成为知识人群的第二大脑。这使得我们的思考一直围绕着“知识场景”和“大脑的关键功能”。</div><div class=" pTag">今天我会从AI驱动印象笔记系列产品，在内容理解、智慧提炼、个人知识积累和公域知识获取等知识管理的场景中的实践经验，来做分享。</div><div class=" pTag">印象笔记对AIGC的研发和实践早在2018年完成国内公司独立重组时就开始了。正式独立之后，我们首先更多地用了supervise learning的方式来做NLP，同时也开始启动了自己的小规模模型训练。</div><div class=" pTag">早在2023年3月，我们就已经开始利用自己的垂直专有模型驱动自己的AI产品，并将功能落地在旗下的软件和智能硬件产品。</div><div class=" pTag">由于印象笔记在国内市场较早地启动了AIGC的全面实践，我们也积累了更多的经验和更深入的思考。</div><div class=" pTag">在我们看来，AIGC的发现还处在比较早期的阶段，对人类社会的影响也才刚刚开始，但现阶段，关于大趋势和方向性的思考更是必不可少的。</div><div class=" pTag">首先，相比算力的发展和模型规模的扩大发展，<strong style="font-weight: 600;">模型算法的进展却是相对缓慢</strong>的。</div><div class=" pTag">同时，到现在为止，<strong style="font-weight: 600;">算力的投入和收益是不成比例</strong>的，我相信真正对产业经济产生深远影响的技术，最终总的回报ROI要达到正向才可以。</div><div class=" pTag"><span style="text-align: start; font-size: 17px;">另一个对于基座模型的挑战是，在基座模型训练中</span>，或许不一定每位在座的朋友都同意。</div><div class=" pTag">我们看到一个现象，在模型训练中，随着公域数据的逐渐穷尽，合成数据被大量加入使用，这也会直接导致模型输出效果下降。</div><div class=" pTag">有挑战也有机遇，我们看到，<span style="text-align: start; font-size: 17px;">特定数据的优化在模型能力提升中的作用、模型的小型化趋势、小规模模型能力的持续提升在<span lang="EN-US">AI</span>产品交付效果的提升中都起着越来越关键的作用。</span></div><h2>强调“复合AI系统”概念</h2><div class=" pTag">谈到AI交付，印象笔记是既做工具又做模型的厂商，在垂直整合的过程中，<span style="text-align: start; font-size: 17px;">我们发现，由于我们采用印象专有大模型直接服务用户，用户可以对模型的效果和性能有着迅速和直观的感受，从而对背后的训练和调优过程给予直接有效的反馈。</span></div><div class=" pTag"><span style="text-align: start; font-size: 17px;"><span style="text-align: start; font-size: 17px;">而另一方面，<span lang="EN-US">AI</span>产品的交付又远远不是仅仅将模型能力简单直接地交付到用户面前。</span></span></div><div class=" pTag"><strong style="font-weight: 600;"><span style="text-align: justify; font-size: 17px;">另一个显著的趋势是，小型化、垂直化的模型可以更高效地处理问题</span><span style="text-align: justify; font-size: 17px;">。</span></strong><span style="text-align: justify; font-size: 17px;">在行业日益追求模型效率化的过程中，数据对模型质量和交付质量的影响在提</span><span style="text-align: justify; font-size: 17px;">升，对算力的需求反而在下降。</span></div><div class=" pTag"><span style="text-align: justify; font-size: 17px;">基于这</span><span style="text-align: justify; font-size: 17px;">些趋势和我们的实践经验，我想强调“复合AI系统”的概念，这是在AI产品交付和大模型本身之间的一个非常关键的应用思考点和架构设计点。</span></div><div class=" pTag"><span style="text-align: justify; font-size: 17px;">从不同的论文中我们也可以看到相似观点——系统性思维下的模型训练、调优，以及与整个AI系统其它组成部分的有机组合，是现在AIGC应用的一个重要思考角度。</span></div><div class=" pTag">不同AI系统需要不同角度的思考，印象笔记关于“复合AI系统”的思考主要有以下几点：</div><div class=" pTag"><strong style="font-weight: 600;">第一</strong>，我们的模型采用混合部署策略，以专有模型驱动主要用户服务和交互场景，模型本身具有路由和任务判断能力，<span style="font-size: 17px; text-align: justify;">同时也具备质量判断和云端一体的路由判断能力。</span></div><div class=" pTag"><strong style="font-weight: 600;">第二</strong>，我们对公域和私域数据的区分处理和保护管理有独特的系统和严密的规则。</div><div class=" pTag"><strong style="font-weight: 600;">第三</strong>，智能代理本身的功能是阵列式的，在关键节点分析用户的意图、做任务的拆解，最后还要系统化地接收用户反馈的过程。</div><ul class="list-paddingleft-1"><li><div class=" pTag"><span><strong style="font-weight: 600;">模型：</strong></span><span style="font-size: 17px; text-align: justify;">印象大模型是高效率、轻量化的专有模型，在知识场景中有着独特的和优异的性能表现。印象大模型端、云部署一体化，并具备一个重要的性能——能够根据意图判断和选择哪一个混合部署中的模型会有更好的处理的效果，也能判断和分析任务本身并在云或端模型中进行选择。</span></div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">数据：</strong></span>严格区分管理公、私域数据，确保模型训练和AI产品交付中的用户数据隐私保护。</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">Agent：</strong></span>在混合部署策略下，<span style="text-align: start; font-size: 17px;">模块化的<span lang="EN-US">Agent</span>阵列能够真正有效地判断用户意图并根据拆解的任务步骤分步执行任务。</span></div></li></ul><div class=" pTag"><span style="text-align: start; font-size: 17px;">“复合<span lang="EN-US">AI</span>系统”超越<span lang="EN-US">AIGC</span>应用单一模型驱动的思考方式，</span>而在此系统下设计一款成功的AI应用也需要考虑不同的因素，这也是印象笔记在AI产品的打造中比较独特的体会。</div><div class=" pTag">首先，我们需要非常明确地分析和判断出这款应用的准确使用场景。</div><div class=" pTag">同时，你的AI复合系统如何驱动这个产品给用户进行交付也十分关键。</div><div class=" pTag">对此，也有两个重要思考点。</div><div class=" pTag"><span style="font-size: 17px; text-align: justify;">一个是最合适的</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">AI</span><span style="font-size: 17px; text-align: justify;">应用载体在哪——是在云端？在移动端？在某一个第三方平台？还是</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">GPTs</span><span style="font-size: 17px; text-align: justify;">或插件？不用的载体在不同的场景和工作流中有着不同的作用。</span></div><div class=" pTag">另一个是何为最适合的交互——自然语言交互还是传统GUI交互？</div><h2>提倡用直觉性的方式进行交互设计</h2><div class=" pTag">我们提倡用符合用户<strong style="font-weight: 600;">直觉性的方式</strong>进行交互设计，<span style="font-size: 17px; text-align: justify;">使用户用到</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">AI</span><span style="font-size: 17px; text-align: justify;">功能和</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">AI</span><span style="font-size: 17px; text-align: justify;">产品的时候是一种最自然的选择和体验。</span></div><div class=" pTag">因此产品的交互不是绝对的LUI或者CUI——<span style="text-align: start; font-size: 17px;">例如在纯粹<span lang="EN-US">LUI</span>或<span lang="EN-US">CUI</span>的交互中，它虽然更自由、更开放，但完全开放的对话窗口也会增加用户的焦虑感 ——用户会停在那里不知道该做什么。</span></div><div class=" pTag">所以产品中<strong style="font-weight: 600;">既应该有完全开放的交互窗口，也应该有开放交互和传统的GUI相辅相成的Copilot性质的交互设计，同时也应该有降低用户焦虑感的传统限制性菜单处理交互式设计</strong>。</div><div class=" pTag">因此，在一个“复合AI系统”下打造AI超级应用时，我们认为除了AI系统思维之外，数据、用户、场景、载体、交互等关键的要素是需要非常慎重考虑的关键点。</div><div class=" pTag">回到印象笔记的实践，我们通过自有模型的混合部署，比较早地进行了全面的布局和落地，推出了多种方向的功能：</div><div class=" pTag">内容生成与搜索、语义性搜索、大文件理解、多文件理解、与上万篇笔记的私人对话等等。</div><div class=" pTag"><span style="font-size: 17px; text-align: justify;">通过逐步实践，我们总结出了一些令我们感到兴奋的方法和获得了一些较为满意的结果。</span></div><div class=" pTag"><span style="font-size: 17px; text-align: justify;">“印象</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">AI</span><span style="font-size: 17px; text-align: justify;">”的推出，对新用户的增长、用户留存和商业化转化的驱动效果都非常显著。</span></div><div class=" pTag"><span style="font-size: 17px; text-align: justify;">呼应我在今天演讲开始提到的观点——</span><span style="font-size: 17px; text-align: justify;">作为</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">AI</span><span style="font-size: 17px; text-align: justify;">从业者，对于核心技术、产品策略、市场投入等方面的实践的检验，最终总要能够回到对</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">ROI</span><span style="font-size: 17px; text-align: justify;">的结果的衡量上来。</span></div><div class=" pTag"><strong style="font-weight: 600;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDFvCrRxT3Q6KkhlpJcWeEDNOwWIcYh3jbm4PufPexOmFF5MKPdLejZrHnKFCfuKmic1oc7nb74VAQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></strong></div><div class=" pTag">目前，印象笔记旗下全系列的软件和智能硬件产品都已经在印象大模型的驱动下，完成了AI功能和产品的落地交付。</div><div class=" pTag"><span style="font-size: 17px; text-align: justify;">最后，我想说的是，在</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">AI</span><span style="font-size: 17px; text-align: justify;">能力的加持下，印象笔记希望能够帮助用户智能汇聚信息、高效阅读内容并吸收知识、辅助灵感记录与创作、自动完成知识整理与提炼，让印象笔记和印象</span><span lang="EN-US" style="font-size: 17px; text-align: justify;">AI</span><span style="font-size: 17px; text-align: justify;">为您增强人生，成为您真正的“第二大脑”。</span></div><div class=" pTag">谢谢大家！</div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FwKB6UwdaNnD7X5CMpEwd4A">阅读原文 </a>
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 10:55:55 GMT</pubDate>
</item>
<item>
<title>新测试基准发布，最强开源Llama 3尴尬了</title>
<link>https://posts.careerengine.us/p/6626423a6984cd5f2aa50df0</link>
<guid>https://posts.careerengine.us/p/6626423a6984cd5f2aa50df0</guid>
<content:encoded><![CDATA[
<h5 style="font-size: 17px; text-align: left;"><div class=" pTag">梦晨 发自 凹非寺</div><br /><div class=" pTag">量子位 | 公众号 QbitAI</div></h5><div class=" pTag">如果试题太简单，学霸和学渣都能考90分，拉不开差距……</div><div class=" pTag">随着Claude 3、Llama 3甚至之后GPT-5等更强模型发布，业界急需一款<span><strong style="font-weight: 600;">更难、更有区分度的基准测试</strong></span>。</div><div class=" pTag">大模型竞技场背后组织LMSYS推出下一代基准测试<span><strong style="font-weight: 600;">Arena-Hard</strong></span>，引起广泛关注。</div><div class=" pTag">Llama 3的两个指令微调版本实力到底如何，也有了最新参考。</div><div class=" pTag" style="text-align: center;"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2zpkbvwUF8fbNMAxlDohbyQ3Aq1yIgzYC9eGbxMxLqYSC8dBxFic5pCg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">与之前大家分数都相近的MT Bench相比，Arena-Hard<span><strong style="font-weight: 600;">区分度从22.6%提升到87.4%</strong></span>，孰强孰弱一目了然。</div><div class=" pTag">Arena-Hard利用竞技场实时人类数据构建，<span><strong style="font-weight: 600;">与人类偏好一致率也高达89.1%</strong></span>。</div><div class=" pTag">除了上面两个指标都达到SOTA之外，还有一个额外的好处：</div><div class=" pTag">实时更新的测试数据包含人类新想出的、AI在训练阶段从未见过的提示词，<span><strong style="font-weight: 600;">减轻</strong><strong style="font-weight: 600;">潜在的数据泄露</strong></span>。</div><div class=" pTag">并且新模型发布后，无需再等待一周左右时间让人类用户参与投票，只需花费25美元快速运行测试管线，即可得到结果。</div><div class=" pTag">有网友评价，<span><strong style="font-weight: 600;">使用真实用户提示词而不是高中考试来测试，真的很重要。</strong></span></div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2kOV8K8ArfwxicxhXzUW5NMjzg1AG2EF4ZLxLQNvOkiaiaJYmlzicPnFKug/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><h2>新基准测试如何运作？</h2><div class=" pTag">简单来说，通过大模型竞技场20万个用户查询中，挑选500个高质量提示词作为测试集。</div><div class=" pTag">首先，挑选过程中确保<span><strong style="font-weight: 600;">多样性</strong></span>，也就是测试集应涵盖广泛的现实世界话题。</div><div class=" pTag">为了确保这一点，团队采用BERTopic中主题建模管道，首先使用OpenAI的嵌入模型<span>（text-embedding-3-small）</span>转换每个提示，使用 UMAP 降低维度，并使用基于层次结构的模型聚类算法<span> (HDBSCAN)</span> 来识别聚类，最后使用GPT-4-turbo进行汇总。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2x9su7iciccRFp9gBycyVGVCzIVKKjyHIfLoHzDzaJ5QIG0O5vhfSjfvg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">同时确保入选的提示词具有<span><strong style="font-weight: 600;">高质量</strong></span>，有七个关键指标来衡量：</div><ul class="list-paddingleft-1" style="font-size: 17px; text-align: start;"><li><div class=" pTag"><span><strong style="font-weight: 600;">具体性：</strong></span>提示词是否要求特定的输出？</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">领域知识：</strong></span>提示词是否涵盖一个或多个特定领域？</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">复杂性：</strong></span>提示词是否有多层推理、组成部分或变量？</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">解决问题：</strong></span>提示词是否直接让AI展示主动解决问题的能力？</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">创造力：</strong></span>提示词是否涉及解决问题的一定程度的创造力？</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">技术准确性：</strong></span>提示词是否要求响应具有技术准确性？</div></li><li><div class=" pTag"><span><strong style="font-weight: 600;">实际应用：</strong></span>提示词是否与实际应用相关？</div></li></ul><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb23iat6M1Vh1wDmCumYicDQh3l2suZRKGIqMIHdWlALV8oELTcNWzcEGgw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">使用GPT-3.5-Turbo和GPT-4-Turbo对每个提示进行从 0 到 7 的注释，判断满足多少个条件。然后根据提示的平均得分给每个聚类评分。</div><div class=" pTag">高质量的问题通常与有挑战性的话题或任务相关，比如游戏开发或数学证明。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2G2Tt7kdXfPibnFcl2b16O3BacvtZiaGm6L8gKrGqSBibE5W0CJgAGhaTg/640?wx_fmt=jpeg&amp;from=appmsg" /></div></div></div><h2>新基准测试准吗？</h2><div class=" pTag">Arena-Hard目前还有一个弱点：使用GPT-4做裁判更偏好自己的输出。官方也给出了相应提示。</div><div class=" pTag">可以看出，最新两个版本的GPT-4分数高过Claude 3 Opus一大截，但在人类投票分数中差距并没有那么明显。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb260JvYvHQ6VFSrk0gEyvgDGfwEl4lerc1Xh35pnZ83QlqIgkljwrGjg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">其实关于这一点，最近已经有研究论证，<span><strong style="font-weight: 600;">前沿模型都会偏好自己的输出</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb25eUwJZiatSgUaXG1dwYPHw49qbicA0zNBBH8jt5X7z3ac98oHDhaGYnA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">研究团队还发现，AI天生就可以判断出一段文字是不是自己写的，经过微调后自我识别的能力还能增强，并且<span><strong style="font-weight: 600;">自我识别能力与自我偏好线性相关</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2KJFS2Vn4XiaFKZCkibEEukMWX9TrywDfcEt6bU1GicIzq48ojerxd6hmQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">那么使用Claude 3来打分会使结果产生什么变化？LMSYS也做了相关实验。</div><div class=" pTag">首先，Claude系列的分数确实会提高。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2IOnm1P84DXoCMSS3W7SBYOjqcxDxJusw7Zods7VIKH6yTECgZz8kZg/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">但令人惊讶的是，它更喜欢几种开放模型如Mixtral和零一万物Yi，甚至对GPT-3.5的评分都有明显提高。</div><div class=" pTag">总体而言，使用Claude 3打分的区分度和与人类结果的一致性都不如GPT-4。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2JWaSO5ibPzPsn9jiaID4OZkrwHezeLqslJHFKkpJSCKtRcVepRbuhYZA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">所以也有很多网友建议，<span><strong style="font-weight: 600;">使用多个大模型来综合打分</strong></span>。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb22NXtlADVOPbuNcgUKnFZIBJG0ZfoVsicC0YsfGR1X77M61TdBicMNJKQ/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">除此之外，团队还做了更多消融实验来验证新基准测试的有效性。</div><div class=" pTag">比如在提示词中加入“让答案尽可能详尽”，平均输出长度更高，分数确实会提高。</div><div class=" pTag">但把提示词换成“喜欢闲聊”，平均输出长度也有提高，但分数提升就不明显。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb2B3mQsTnibXxkuqK8mD12PkQ7bUgLVZ0kZ9a8aDrIDbsrJ4LoKBTYSjw/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">此外在实验过程中还有很多有意思的发现。</div><div class=" pTag">比如GPT-4来打分非常严格，如果回答中有错误会狠狠扣分；而Claude 3即使识别出小错误也会宽大处理。</div><div class=" pTag">对于代码问题，Claude 3倾向于提供简单结构、不依赖外部代码库，能帮助人类学习编程的答案；而GPT-4-Turbo更倾向最实用的答案，不管其教育价值如何。</div><div class=" pTag">另外即使设置温度为0，GPT-4-Turbo也可能产生略有不同的判断。</div><div class=" pTag">从层次结构可视化的前64个聚类中也可以看出，大模型竞技场用户的提问质量和多样性确实是高。</div><div class=" pTag"><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBYugOibJeiaqqXD34iaK5Ivb27ia3iazn23ADibsia8Sq2wp0L0FSLSacdpJBvGoLUWtokiaXsIMvrozlicIA/640?wx_fmt=png&amp;from=appmsg" /></div></div></div><div class=" pTag">这里面也许就有你的贡献。</div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">Arena-Hard GitHub：</div><br /></span><span style="font-size: 17px;">https://github.com/lm-sys/arena-hard</span><br /><span style="font-size: 17px;"><div class=" pTag">Arena-Hard HuggingFace：</div><br /></span><span style="font-size: 17px;">https://huggingface.co/spaces/lmsys/arena-hard-browser</span><br /><span style="font-size: 17px;"><div class=" pTag">大模型竞技场：</div><br /></span><span style="font-size: 17px;">https://arena.lmsys.org</span></div><div class=" pTag"><span style="font-size: 17px;"><div class=" pTag">参考链接：</div><br /><div class=" pTag">[1]</div></span><span style="font-size: 17px;">https://x.com/lmsysorg/status/1782179997622649330</span><br /><span style="font-size: 17px;">[2]</span><span style="font-size: 17px;">https://lmsys.org/blog/2024-04-19-arena-hard/</span></div><div class=" pTag sectionReplaced"><span style="font-size: 17px;">—&nbsp;<strong style="font-weight: 600;">完</strong>&nbsp;—</span></div><div class=" pTag" style="clear: both;"><span style="font-size: 17px;"><strong style="font-size: 17px; font-weight: 600;"><span>点这里<span>👇</span>关注我，记得标星哦～</span></strong></span></div><div class=" pTag sectionReplaced" style="font-size: 17px;"><div><div style="text-align: center;"><div style="text-align: right; font-size: 17px;"><div class=" pTag"><strong style="font-weight: 600;">一键三连「分享」、「点赞」和「在看」</strong></div><div class=" pTag"><strong style="font-weight: 600;">科技前沿进展日日相见 ~&nbsp;</strong></div></div></div><div><div><div class=" ce-ao-image-holder pTag"><div class=" ce-ao-image-holder-inner"><img class=" ce-ao-image" src="https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg" /></div></div></div></div></div></div> <div class="read-more-button"><div class="cce-btn cce-btn-light-grey" id="readMore">继续阅读</div></div> <a class="post-original-link" href="https://careerengine.us/redirect/to?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-lZKrLWICRdnabzvoqvGKw">阅读原文 </a>
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 10:55:54 GMT</pubDate>
</item>
</channel>
</rss>